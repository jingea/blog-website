{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/jacman/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/FontAwesome.otf","path":"font/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","path":"font/coveredbyyourgrace-webfont.eot","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","path":"font/coveredbyyourgrace-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","path":"font/coveredbyyourgrace-webfont.woff","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","path":"font/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","path":"font/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.eot","path":"font/fontdiao.eot","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.ttf","path":"font/fontdiao.ttf","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.woff","path":"font/fontdiao.woff","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","path":"img/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","path":"img/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nc.svg","path":"img/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-nd.svg","path":"img/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by-sa.svg","path":"img/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-by.svg","path":"img/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/cc-zero.svg","path":"img/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/logo.png","path":"img/logo.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/logo.svg","path":"img/logo.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/scrollup.png","path":"img/scrollup.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/js/gallery.js","path":"js/gallery.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","path":"js/jquery.qrcode-0.12.0.min.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/js/totop.js","path":"js/totop.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","path":"font/coveredbyyourgrace-webfont.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","path":"font/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontdiao.svg","path":"font/fontdiao.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","path":"font/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/banner.jpg","path":"img/banner.jpg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/author.jpg","path":"img/author.jpg","modified":1,"renderable":1},{"_id":"themes/jacman/source/img/jacman.jpg","path":"img/jacman.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.html","hash":"95e0296d25ff2d3216f38d624c2f069ea0020763","modified":1465653885000},{"_id":"source/CNAME","hash":"b94100d6afddd9feaffb8707a02a31879ef7c06a","modified":1465653885000},{"_id":"themes/jacman/.gitignore","hash":"7d65523f2a5afb69d76824dd1dfa62a34faa3197","modified":1465653886000},{"_id":"themes/jacman/LICENSE","hash":"d8780b41bab4b87bdd21eca444cae11af72617f4","modified":1465653886000},{"_id":"themes/jacman/README.md","hash":"b5d265267ed9f44a5edf848033e5ac0491004bd0","modified":1465653886000},{"_id":"themes/jacman/README_zh.md","hash":"9c818b2c1f8c216c439be6bc574469d1dc338c12","modified":1465653886000},{"_id":"themes/jacman/_config.yml","hash":"40cab51f30f65283d79fee0bf9a5f735527719c6","modified":1465653886000},{"_id":"source/.DS_Store","hash":"4d2812492c8731840f3dd19682b32ecd03029961","modified":1465652969000},{"_id":"source/about/index.md","hash":"d1842586d75bce421a755f8394b32ff1ca934ac5","modified":1465653886000},{"_id":"themes/jacman/languages/default.yml","hash":"966be0b585cd3e3b7f0e485c896c24dfdfee423a","modified":1465653886000},{"_id":"themes/jacman/languages/zh-CN.yml","hash":"6e1460594fa50394ac6f11fe9d39dc59478ddd0c","modified":1465653886000},{"_id":"themes/jacman/languages/zh-TW.yml","hash":"0e7912c6505592a10efe2db1c994ccc3ebf91239","modified":1465653886000},{"_id":"themes/jacman/layout/archive.ejs","hash":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1465653886000},{"_id":"themes/jacman/layout/category.ejs","hash":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1465653886000},{"_id":"themes/jacman/layout/index.ejs","hash":"b832b280ec0a2b741e73a2300f219f0075c99278","modified":1465653886000},{"_id":"themes/jacman/layout/layout.ejs","hash":"ceeb2a7410b96b81310ed9b1279f62e953b0a6ca","modified":1465653886000},{"_id":"themes/jacman/layout/page.ejs","hash":"bd6bbf2ea8e183bd835867ff617dc6366b56748c","modified":1465653886000},{"_id":"themes/jacman/layout/post.ejs","hash":"3114134775bdde5a83cf14feb019606fa2b2b2be","modified":1465653886000},{"_id":"themes/jacman/layout/tag.ejs","hash":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1465653886000},{"_id":"themes/jacman/scripts/fancybox.js","hash":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c","modified":1465653886000},{"_id":"source/_posts/.DS_Store","hash":"f794f9a366d46dd629d4e572da04ff86a91fdfe8","modified":1465653887000},{"_id":"source/_posts/ICE/ZeroC ICE Hello Demo.md","hash":"6eaa1c85cefde30b2bb85f8d5d9d8d9ad4cce048","modified":1465653885000},{"_id":"source/_posts/ICE/ZeroC ICE 编译后的Java文件.md","hash":"f76d698e0134c55ce82bd6d67beaa61c1c740d02","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Archiva.md","hash":"116d2bf121fdbce1a1479ee986c366de1b806b57","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Feign.md","hash":"8f1e77cde25cf638b8ee215941d3c01604697129","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Guava CachesExplained.md","hash":"4f1644a10b7b37a9a7e104ee04ef524cb18d4824","modified":1465653885000},{"_id":"source/_posts/Java 工具库/JMeter.md","hash":"b84dbdacd533776cef8bbcfbf122759ac478a23d","modified":1465653885000},{"_id":"source/_posts/Java 工具库/JProfiler nowait连接.md","hash":"3d89a2a6983f523d6f139c37fcefac994310802e","modified":1465653885000},{"_id":"source/_posts/Java 工具库/MessagePack 初探.md","hash":"90b34baefc21688a367e80f191df53517bf7dc01","modified":1465653885000},{"_id":"source/_posts/Java 工具库/OWNER 初探.md","hash":"f1778c0fe3130c3d4532cb968480e70a2cfe99e5","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Oracle Solaris Studio.md","hash":"eedc0eb197b589b47c963d1a6511e14f51e3db9f","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Retrofit.md","hash":"bee88029a9c03776665f31c97b916312e96007b7","modified":1465653885000},{"_id":"source/_posts/Java 工具库/SqlSession.md","hash":"c007e1ed6d4b70625f7348207519d61aeee35c48","modified":1465653885000},{"_id":"source/_posts/Java 工具库/Typesafe Config 初探.md","hash":"11127a6537805f6fd513b40ee4e4664ab8d71f6d","modified":1465653885000},{"_id":"source/_posts/Java 工具库/args4j.md","hash":"16470376bc09ec0880956aad59a234ac8d408a96","modified":1465653885000},{"_id":"source/_posts/Java 工具库/dropwizard.md","hash":"1b1df14e2e7dd616be91f9493bb70024728f0967","modified":1465653885000},{"_id":"source/_posts/Java 工具库/fastjson.md","hash":"a2e20d6d438b959e2fd62d580efc4f079a37c0ef","modified":1465653885000},{"_id":"source/_posts/Java 工具库/gradle.md","hash":"4cc07636345cde3fbcb2e5e7c95e5e53b3c3d111","modified":1465653885000},{"_id":"source/_posts/Java 工具库/log4j2 Appender.md","hash":"9db7de3491d91c4cb359b4a228e4394d523ce0f2","modified":1465653885000},{"_id":"source/_posts/Java 工具库/log4j2.md","hash":"90cca0d8d550cd8628c66223cf691c1cf868a71f","modified":1465653885000},{"_id":"source/_posts/Java 工具库/lombok.md","hash":"25821297392904fd67116fd6f0185e90dc2317b6","modified":1465653885000},{"_id":"source/_posts/Java 工具库/maven assembly插件.md","hash":"8bae875a417b5158e667883f4b7ce39df42e2e9c","modified":1465653885000},{"_id":"source/_posts/Java 工具库/maven.md","hash":"752ac6b131cd3c06ea4253fcf000626ec1c28e22","modified":1465653885000},{"_id":"source/_posts/Java 工具库/maven插件.md","hash":"d537663f2270b947c642dc17aeb9427fbdd7c99b","modified":1465653885000},{"_id":"source/_posts/Java 工具库/读取csv文件.md","hash":"a7dc168e955ef982c1a0d98053e16fc48709c160","modified":1465653885000},{"_id":"source/_posts/asm/ASM Core(1) 初探.md","hash":"3faee8445bf9648abb72a0418bd808f2ce1c7f41","modified":1465653886000},{"_id":"source/_posts/asm/ASM Core(3) Methods.md","hash":"57d2ae02f0ef1849805cba8fb2279a70c3ba2873","modified":1465653886000},{"_id":"source/_posts/asm/ASM Core(2) 操作.md","hash":"66836b5edda89f9dc6d8785b13937562d89c0b05","modified":1465653886000},{"_id":"source/_posts/asm/ASM Core(5) 工具.md","hash":"e17ba2ce276544c1e48a3fd21249a71b59638a4e","modified":1465653886000},{"_id":"source/_posts/JavaSE/JavaIO NIO.md","hash":"1f8d882e5faad8bf5367fb27bd9c79a9dbd1709a","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO Scalable.txt","hash":"7bd6258cb97d84260d091a376887c8c5753f73f2","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO 内存IO.md","hash":"af741e635bd91be167f9611499df0a4f7416b9f3","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO 写文件.md","hash":"0e45edbe264cee10d685eb5d18338a957bedcd61","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO 序列化.md","hash":"089ffd82bfc6d60c07fbc302a797056133b575fc","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO 文件操作.md","hash":"e440ffaa0e8ca7ba8aab956884d2ff7fdf1ec6d3","modified":1465653885000},{"_id":"source/_posts/JavaSE/JavaIO 读文件.md","hash":"cde837a205e11fdb4665e1281d28a31c72621a71","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 对称加密.md","hash":"23ef1ee21e3b38d1cea08d916396ce94fbc00651","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 数字证书实现.md","hash":"99c723a060102b7a7cb2048a306d913667c59112","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 概述.md","hash":"0c567f72c0482dba42f60a6f9c3be9db65b56d05","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 消息摘要实现.md","hash":"b455fb8e9f884ec7392bb54f329c63a31166882c","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 辅助工具.md","hash":"5605aa868acc2a832d87d52e61ab5b67238032b8","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java加密 非对称加密实现.md","hash":"52968c37ab0186f422ed4d8bbefab257a5151ffb","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络 BIO server.md","hash":"b8fda1629e071ca85ed3ae75043d35981351e962","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络 IP.md","hash":"f3670dae0b3dc2ee9addc0b72c3738aa574b858d","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络 Socket.md","hash":"940c4da63556657046602f62504988bd4ad8fb3c","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络 代理.md","hash":"e4e4b61095a5c95c57f50f4920360dd8665fdbff","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络 网卡.md","hash":"16dc2bd6fdfdc7c107f75ba93f09e8c91963d6e8","modified":1465653886000},{"_id":"source/_posts/JavaSE/Java网络.md","hash":"f62e2a96b9740053f73fc4cba7196ed8a3fccb10","modified":1465653886000},{"_id":"source/_posts/JavaSE/ListVSMap.md","hash":"b6c907a6bee941593f84618ce226e46064567d1c","modified":1465653886000},{"_id":"source/_posts/JavaSE/java equals hashcode.md","hash":"d669adf07a26252b888ef44a07e3376e3b0422c7","modified":1465653886000},{"_id":"source/_posts/JavaSE/java hook.md","hash":"3ecf1939fe2fcf7b95fb50e6f70a0e17b831f8e1","modified":1465653886000},{"_id":"source/_posts/JavaSE/java volatile.md","hash":"f23bdee31a729889ec0f5278928c402f59485028","modified":1465653886000},{"_id":"source/_posts/JavaSE/java 初始化.md","hash":"a85a54fa4686a0332d3aa068fe887a195e8de8ea","modified":1465653886000},{"_id":"source/_posts/JavaSE/java 泛型.md","hash":"39948ab573267fc24487610ec0c886fd7ef8a3cc","modified":1465653886000},{"_id":"source/_posts/JavaSE/java 集合.txt","hash":"5eb13e9ac47bf4924f388de4369b311c0da56685","modified":1465653886000},{"_id":"source/_posts/JavaSE/java8 lambda.md","hash":"351e496da8f4fed6e8ceae97bcbdba8f99a40cbc","modified":1465653886000},{"_id":"source/_posts/JavaSE/java8 time.md","hash":"8b60aa5697ac52a0c856e46e9e1c8c93bc7c9d7a","modified":1465653886000},{"_id":"source/_posts/JavaSE/java8 流.md","hash":"021f42c21d07fff6dba746971d4b4e0798a558d9","modified":1465653886000},{"_id":"source/_posts/JavaSE/java小常识.md","hash":"4cfdeb65b5bd98556a1efbd8ff7414e256a6b52e","modified":1465653886000},{"_id":"source/_posts/JavaSE/java网络 URL.md","hash":"83cde34ec024be1facf2eaa2c41a56a4aa6a5f82","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 ForkJoin.md","hash":"32b1f59a37df3de5b3256bda394061f147f0d00c","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 ThreadLocal.md","hash":"ca5597e7b4fbc98eac9632797cfb0f064ca08094","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 线程同步辅助类.md","hash":"c7c9dfbc6107e6352284abb4909de63abcaa553f","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 线程执行器原理.md","hash":"9c3485a339634884311437db9993a1646b3da371","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 线程执行器应用.md","hash":"c13155c9a7d01a8775cbc86340384af17f285403","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 线程执行器简介.md","hash":"85a25647d9f3cf33f2867592f96cf62eb42f5bc0","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 线程管理.md","hash":"ceb33f503a306474e701f76401056d8f5e0f53d8","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 锁实现.md","hash":"acbf9831d8ac242c62dbf436ee0b5b5200373699","modified":1465653886000},{"_id":"source/_posts/JavaSE/并发 集合.md","hash":"703ca91439dd90a8c28d5eb63d92ff0607e67a12","modified":1465653886000},{"_id":"source/_posts/guice/Injections.md","hash":"2b0c2e13d2e44f7e414a4864282c51755917fc39","modified":1465653886000},{"_id":"source/_posts/guice/Linked Bindings.md","hash":"f71fea451dc330db7f19140dcf68f72ebc7ac25d","modified":1465653886000},{"_id":"source/_posts/guice/Multiple Modules.md","hash":"023eb252dbaa1ab48c57b82dcf8f3e6ee782ad50","modified":1465653886000},{"_id":"source/_posts/guice/Provides Methods.md","hash":"aadeae82d13d427ddc032cb3c21cd26335d760fb","modified":1465653886000},{"_id":"source/_posts/guice/Scopes.md","hash":"81891a540d3dbcf3a6169e4ffc5a79f64d948038","modified":1465653886000},{"_id":"source/_posts/guice/guice初探.md","hash":"88af100caf27cd613900353e4abea8b109404234","modified":1465653886000},{"_id":"source/_posts/guice/mybatis-guice.md","hash":"3ba448a8578eab61fb0a353fa531061f584f6559","modified":1465653886000},{"_id":"source/_posts/JavaSE/.DS_Store","hash":"aec4cdc7ad4f550245a77abebca6cae6ce486aea","modified":1465534786000},{"_id":"source/_posts/jmh/JMHSample_01_HelloWorld.md","hash":"090bd1fbc2c9d837694b6917fb67457cad901754","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_02_BenchmarkModes.md","hash":"d76846b90d871241b56750d8a4a017fc8e2083f9","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_03_States.md","hash":"43197ff90d0ecf651f712cb6dd7d484444357898","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_04_DefaultState.md","hash":"0ba23ce29900216c7a91d4046aff944a3bd7b50c","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_05_StateFixtures.md","hash":"8afb46e7b64ea8eef9060dffb08d6bd1d24cd3e3","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_06_FixtureLevel.md","hash":"5f158fce8d6bdf84a17eb6f2aa9a89701572b1e9","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_07_FixtureLevelInvocation.md","hash":"801c699f78e789c870cb2e06c22736a191d8a283","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_08_DeadCode.md","hash":"12fc58751946503c748418d1fe6ffe34252240f3","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_09_Blackholes.md","hash":"2f1ec1ceb1969f71736c1893c2640922d6f6797e","modified":1465653886000},{"_id":"source/_posts/jmh/JMHSample_10_ConstantFold.md","hash":"951360e31f9593d6db41cc454d3c213daffc4aa3","modified":1465653886000},{"_id":"source/_posts/jmh/JMH初探.md","hash":"11e5ca6f53fa9b84e2413a3714a56f410a860446","modified":1465653886000},{"_id":"source/_posts/jvm/CRaSH 命令行.md","hash":"e0da489de2c1bbd32a705a5df254cb05bad6d90d","modified":1465653886000},{"_id":"source/_posts/jvm/JPS.md","hash":"dcaaed278ad7d5339131804616f81bbf4899eae9","modified":1465653886000},{"_id":"source/_posts/jvm/JVM 内存参数.md","hash":"a9d2865597bb1b419a12b8e084fd277f2724dfbf","modified":1465653886000},{"_id":"source/_posts/jvm/JVM 堆内存.md","hash":"b9a98e6452e8b4befe6c91d5bbb1c4b03d5e54a6","modified":1465653886000},{"_id":"source/_posts/jvm/JVM 栈.md","hash":"51db9a670d18b6205cd7cab26ececa399c9d0590","modified":1465653886000},{"_id":"source/_posts/jvm/JVM方法调用.md","hash":"68b80454af2f13018368192b26033b72872ed0b0","modified":1465653886000},{"_id":"source/_posts/jvm/Java 引用类型.md","hash":"4cef898f39b1bda5c297a268023750986d1864cb","modified":1465653886000},{"_id":"source/_posts/jvm/Jinfo.md","hash":"606eb4cd4644e710cf45b447c3bd580b65bedeb7","modified":1465653886000},{"_id":"source/_posts/jvm/Jmap.md","hash":"4f8536c115db8c8fbfa6aa6627b043f994e1effc","modified":1465653886000},{"_id":"source/_posts/jvm/class文件格式.md","hash":"c6af9260054dd3eb0ab1e4013ed337fdb365291b","modified":1465653886000},{"_id":"source/_posts/jvm/hprof.md","hash":"f0ccbdb24d532082aac29e3cefb8972039755082","modified":1465653886000},{"_id":"source/_posts/jvm/instrument agentmain.md","hash":"5c5257af4f571d015dbaebfd452c87803540f479","modified":1465653886000},{"_id":"source/_posts/jvm/instrument premain.md","hash":"fd9c0bb748000e1717d9349917f9475ff38d8b16","modified":1465653886000},{"_id":"source/_posts/jvm/javap.md","hash":"6bd132a8bbadfbcc0d23273218e58ba0ea14b131","modified":1465653886000},{"_id":"source/_posts/jvm/jcmd.md","hash":"f3af264adc94251a4abea0f54a63083061b3bac7","modified":1465653886000},{"_id":"source/_posts/jvm/jhat.md","hash":"80753959f4e4737ac72affc19b836aa0913b865b","modified":1465653886000},{"_id":"source/_posts/jvm/jstack.md","hash":"01bb36df29d39b6dcaf26379a1cc4ef8deead61b","modified":1465653886000},{"_id":"source/_posts/jvm/jstat.md","hash":"eddf909db8017ca129244e071580615ab5a1cd07","modified":1465653886000},{"_id":"source/_posts/jvm/使用Classloader加载类.md","hash":"5588fcfbbf833e85f8a7502ab04736854faafd3a","modified":1465653886000},{"_id":"source/_posts/jvm/内存分配.md","hash":"d2ae980c99d4671624d1cbadf2766566a4a9cf90","modified":1465653886000},{"_id":"source/_posts/jvm/内存溢出.md","hash":"fcf5d5691262974129cb29b1a86a9b38c056f584","modified":1465653886000},{"_id":"source/_posts/jvm/垃圾收集算法及垃圾回收器.md","hash":"3d5686a45505c6b22a2827d85274af7e4a557e87","modified":1465653886000},{"_id":"source/_posts/jvm/字节码指令.md","hash":"c836c07f6ca1b5cb665a1efa4578d81afed8c469","modified":1465653886000},{"_id":"source/_posts/jvm/栈上分配.md","hash":"b3668da5499152144a6b0de2567da14d9cfdad78","modified":1465653886000},{"_id":"source/_posts/jvm/类加载.md","hash":"42e42dc2801adb685319cbb381140c3d013f31dc","modified":1465653886000},{"_id":"source/_posts/linux/2015-10-12-AWK.md","hash":"e411759f65419d1e9a96345c26f0d153c2bb7cd3","modified":1465653886000},{"_id":"source/_posts/linux/Linux常用命令.md","hash":"8872d51755b8f37772926df6f4abed1b77bb4b91","modified":1465653886000},{"_id":"source/_posts/linux/Linux系统命令.md","hash":"4052fde8903e9835bd71530be11841b4dd5467e7","modified":1465653886000},{"_id":"source/_posts/linux/linux系统文件.md","hash":"a20bde4ff270a8ee06ccb318a736553e4fd24971","modified":1465653886000},{"_id":"source/_posts/linux/shell.md","hash":"d8fd8611cc8ffc0c165b35d63e55b8dcfadd60dc","modified":1465653886000},{"_id":"source/_posts/linux/ttystudio.md","hash":"8d43c88b8c1497967a181084fc4eb4863e8cce8b","modified":1465653886000},{"_id":"source/_posts/linux/zsh iterm2.md","hash":"e25b136bfa1191d95bbffc1c0afb12d17ce8fda1","modified":1465653886000},{"_id":"source/_posts/mgits/Flick Ticket Server.md","hash":"359fd05a91d81eda05b22e5af9f8f75cf7ff7c95","modified":1465653886000},{"_id":"source/_posts/mgits/IDEA 设置.md","hash":"87626b3fb918c87c427b1c454b988b805b7a9538","modified":1465653886000},{"_id":"source/_posts/mgits/SVN 总结.md","hash":"0b2890885b4227d42bc8d73ee2a9b78845a1551c","modified":1465653886000},{"_id":"source/_posts/mgits/docker命令.md","hash":"e0fa477ac9054ef35803457eece8b2fb1a6300f7","modified":1465653886000},{"_id":"source/_posts/mgits/git.md","hash":"c5bb1b6407c056540daf3b78b1894e97b5d05e53","modified":1465653886000},{"_id":"source/_posts/mgits/gitbook.md","hash":"784c1a8a7a5ea517e7a850731e6184d927879718","modified":1465653886000},{"_id":"source/_posts/mgits/java游戏服务器.md","hash":"195ae6b6e499ea3f50ab2a5cb45958bc00f33d6d","modified":1465653886000},{"_id":"source/_posts/mgits/mac.md","hash":"551fa1a183b6b3485ea9eba5709cf5f74a00a42e","modified":1465653886000},{"_id":"source/_posts/mgits/svn服务器搭建.md","hash":"efa73457bb0fbb166d857b38e2203a4ccae4b02b","modified":1465653886000},{"_id":"source/_posts/mgits/unity命令行使用.md","hash":"e166069dd95dab9cf2cb6cc41f303d7a728cb9f1","modified":1465653886000},{"_id":"source/_posts/mgits/vim.md","hash":"34f6b2cfc31efd23ed8228edefa204e8bba75db5","modified":1465653886000},{"_id":"source/_posts/mgits/windows rust.md","hash":"41489963defb022f20006d8e90c20ede44f34b93","modified":1465653886000},{"_id":"source/_posts/mgits/技术CheckList.md","hash":"a771343f2af2648edd0618b8f25ccb753f972c91","modified":1465653886000},{"_id":"source/_posts/mgits/编码和补码.md","hash":"462ed03399effc3e9ce3722ae61fc6dad73b0669","modified":1465653886000},{"_id":"source/_posts/mgits/项目CheckList.md","hash":"8683651e88c2b1d874eea4667cca4f522af23c36","modified":1465653886000},{"_id":"source/_posts/netty/ByteBuf.md","hash":"9df473767d354f58db1619f0b5f753657bde6b8a","modified":1465653886000},{"_id":"source/_posts/netty/Channel.md","hash":"dedb8c66cce539be37989bece9ea5a2a55913597","modified":1465653886000},{"_id":"source/_posts/netty/ChannelHandler.md","hash":"7d4ea10ee6470ccf431c8418afcceb3cb4d55252","modified":1465653886000},{"_id":"source/_posts/netty/ChannelPipeline.md","hash":"0702ec991e250de95fdd9673f2a827749458276b","modified":1465653886000},{"_id":"source/_posts/netty/Netty 压测.md","hash":"1b4ad776aa11437d0a4658176a5a61e18678bb0e","modified":1465653886000},{"_id":"source/_posts/netty/NioEventLoop.md","hash":"b83f363a7c26bc68f93fbccf56abea9b7d2a6c9e","modified":1465653886000},{"_id":"source/_posts/netty/ServerBootstrap.md","hash":"9c80433db771c0d26c88c8ad1fbad4a8f1193017","modified":1465653886000},{"_id":"source/_posts/netty/Unsafe.md","hash":"b1e9ef58c625f2805049d467bb68a3fb7d05d7b3","modified":1465653886000},{"_id":"source/_posts/nginx/nginx web服务器.md","hash":"3e489e77b0d9b6561ac450f0a709315ecb847f7a","modified":1465653886000},{"_id":"source/_posts/nginx/nginx安装与命令.md","hash":"1d784df201e3d80e8c2b83e111abc3f2c6314635","modified":1465653886000},{"_id":"source/_posts/nginx/nginx文件服务器.md","hash":"5c14e14fc9e4f1ef0e264afe80535f9863eed600","modified":1465653886000},{"_id":"source/_posts/nginx/nginx负载均衡.md","hash":"7fb8280c57b421c02e38987aaaae2a79deca2b1a","modified":1465653886000},{"_id":"source/_posts/nginx/nginx配置.md","hash":"d60f8362b0a9057975fc96cef8467d98be491383","modified":1465653886000},{"_id":"source/_posts/nosql/Memcache.md","hash":"69dec96b907a9ea8ffc2e2b4eb9a2c7611da7279","modified":1465653886000},{"_id":"source/_posts/nosql/MongoDB Replica.md","hash":"3c9a3bd82e564915ec430dac9662e487e16db321","modified":1465653886000},{"_id":"source/_posts/nosql/MongoDB.md","hash":"a24992a972ee961fc07346a45a1875c85cc95d8f","modified":1465653886000},{"_id":"source/_posts/nosql/MongoDB客户端.md","hash":"3ee84b78bd3659b009a164118eec45bb11c8ce30","modified":1465653886000},{"_id":"source/_posts/nosql/Redis_SortedSet.md","hash":"48c2813c5b2dfd843838146ff2deafec9e27a266","modified":1465653886000},{"_id":"source/_posts/nosql/Redis事务.md","hash":"470c27dbbe4c90858e4309ec4c0a036663d4868e","modified":1465653886000},{"_id":"source/_posts/nosql/Redis部署.md","hash":"80eaec35350e5d33dc4431f6b69ea35141565058","modified":1465653886000},{"_id":"source/_posts/nosql/jedis.md","hash":"d551112744198bcab8ee9bbc3573f00cf3c09322","modified":1465653886000},{"_id":"source/_posts/python/python2 JSON.md","hash":"5ada0d7519a3e689e61ba761bf71aabe1ee3b9da","modified":1465653886000},{"_id":"source/_posts/python/python2函数.md","hash":"ddb20257d930332cf3b0ccd90a8cece351922076","modified":1465653886000},{"_id":"source/_posts/python/python2多线程.md","hash":"751a43f2c0e7db0ef3d9be991c433e0fdb215ee8","modified":1465653886000},{"_id":"source/_posts/python/python2字符串.md","hash":"81545fee36819789cfd8a19d8a990c170be6343e","modified":1465653886000},{"_id":"source/_posts/python/python2异常.md","hash":"3237d4c048d122d651de80e36cf5ca470b1f84bb","modified":1465653886000},{"_id":"source/_posts/python/python2控制流.md","hash":"4933387d72cf1b4831de31d4fe3804c7dc4ae00b","modified":1465653886000},{"_id":"source/_posts/python/python2文件操作.md","hash":"848189a6ddff3a6c766fa8484e7be0de0991f47c","modified":1465653886000},{"_id":"source/_posts/python/python2模块.md","hash":"69f14fce71d5cf7b9d5267a1589ee9767d024a8a","modified":1465653886000},{"_id":"source/_posts/python/python2网络编程.md","hash":"82743ab56d1463504dd559fe5fc02a14be3c557c","modified":1465653886000},{"_id":"source/_posts/python/python2集合.md","hash":"b1c25f7d3565351ded25cb71c2328ee44633d0c8","modified":1465653886000},{"_id":"source/_posts/python/python2面向对象.md","hash":"6eecaa7a7262da9a5b6c4716129cacfa303ad20f","modified":1465653886000},{"_id":"source/_posts/spring/Spring 任务调度.md","hash":"8af98a62b91daa8cab4b2861a6974cfd021f0a1c","modified":1465653886000},{"_id":"source/_posts/spring/Spring 异步方法访问.md","hash":"69af4f17c5cf649836a4e3b41e5189aac63d41a6","modified":1465653886000},{"_id":"source/_posts/spring/spring boot web.md","hash":"6e83e709d7b7646b626d84fc3e74494efae2b478","modified":1465653886000},{"_id":"source/_posts/spring/spring boot.md","hash":"154f87f66443d74185a84949dc7aa513291bbe5d","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper Curator 事件监听.md","hash":"bf2c1eadc276620cec444a419b8c44d0f8e567c0","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper Curator 基本操作.md","hash":"5ae48e802109292434cc1684ba88f733b14ba0ef","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper Java客户端.md","hash":"5f59f1fdbef07f2e21d3f46e61961c7bcfc9a626","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper 原理.md","hash":"bcefe85ba68b352ea42deb5e9867379776e04985","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper 命令行客户端.md","hash":"e46eefa02fa2995e901a8abac094111e52e870c3","modified":1465653886000},{"_id":"source/_posts/zookeeper/ZooKeeper 服务器.md","hash":"452208bebe657cbb12d010abf4f329e9f496e4bf","modified":1465653886000},{"_id":"source/_posts/并发编程/1_1_双线程锁.md","hash":"071fb3c5dac3798b2493939f13580572edd9f68f","modified":1465653886000},{"_id":"source/_posts/并发编程/自旋锁.md","hash":"73c5c7f4f125e4fbf9a62a74abe7a3a2c8e36514","modified":1465653886000},{"_id":"source/_posts/操作系统/NUMA.md","hash":"7d03c618e0edb5eb908c3e142967821796e71c4a","modified":1465653886000},{"_id":"source/_posts/操作系统/io.md","hash":"09d5db4a41869084009e997fffacc282f02a7b20","modified":1465653886000},{"_id":"source/_posts/数据库/Mycat配置文件.md","hash":"7bb590be0100c82c2776e50b6127832eaea331e7","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql JSON Data Type.md","hash":"1776309872dc705b6295f949ac8e3cfa579032b3","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql Secondary Indexes and Generated Virtual Columns.md","hash":"55898025d4476e637e720a901569c9a0259d0424","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql 增删改查.md","hash":"3a2752a6b91d8235ae9210c8a68178f1572224da","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql 客户端.md","hash":"d87b607cb31c2c0f759b12af644df8e804c57745","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql 数据类型.md","hash":"28f472e6c86c179042477f357a024a263c573b20","modified":1465653886000},{"_id":"source/_posts/数据库/Mysql 索引.md","hash":"9b77cece7a49c74cef515b811c788572545a5da1","modified":1465653886000},{"_id":"source/_posts/数据库/mycat全局序列号.md","hash":"2e1e099a286fc41284634778184acc32f8989428","modified":1465653886000},{"_id":"source/_posts/数据库/mycat分片.md","hash":"237a3dddddb307d84a08b61677039bf282c1e5c9","modified":1465653886000},{"_id":"source/_posts/数据库/数据压缩.md","hash":"1d5e5c06f74ac370c8ce39094caed64be01223a3","modified":1465653886000},{"_id":"source/_posts/数据库/数据库事务.md","hash":"59abd7cf82868a8b171786e100b06fd3f1879654","modified":1465653886000},{"_id":"source/_posts/日志工具/Elasticsearch 基本操作.md","hash":"9b72ea7ddc69992ab4d1153724365d482be3d938","modified":1465653886000},{"_id":"source/_posts/日志工具/Elasticsearch 搜索.md","hash":"c449c74f51bf6bce5e2c166a358269b398d64039","modified":1465653886000},{"_id":"source/_posts/日志工具/logstash 编解码日志.md","hash":"10fb612fefd32b7151fbf5b06e79a01de803a109","modified":1465653886000},{"_id":"source/_posts/日志工具/logstash 语法.md","hash":"208d881ba96faf7b8dfb5119e80e358034487845","modified":1465653886000},{"_id":"source/_posts/日志工具/logstash 读取日志.md","hash":"57091ef41cac6e5174a9b02dbf3a19a64741e592","modified":1465653886000},{"_id":"source/_posts/日志工具/logstash 输出日志.md","hash":"055de0984859e82727d03637889004cc38e13bb7","modified":1465653886000},{"_id":"source/_posts/日志工具/logstash 过滤日志.md","hash":"6b844a2e5ceb78578860d94af7d5f1db788a6d6f","modified":1465653886000},{"_id":"source/_posts/Java 工具库/.DS_Store","hash":"ac3958f3f339b3177c3ff344f9b89927acb134bc","modified":1465534803000},{"_id":"source/_posts/算法/二叉树.md","hash":"f90d5d669d481d02f7154473adfa9122422be578","modified":1465653886000},{"_id":"source/_posts/算法/冒泡排序.md","hash":"e1e5602601daec88f4357147bbf76ecff9d0f291","modified":1465653886000},{"_id":"source/_posts/算法/希尔排序.md","hash":"54fc0cd74ad77ec0ae94518f6bf71159ebf9ac1d","modified":1465653886000},{"_id":"source/_posts/算法/插入排序.md","hash":"bb99850dd8f27ca1191b7bb44ca8100e4c9b70a6","modified":1465653886000},{"_id":"source/_posts/算法/环形队列.md","hash":"affc508cdc7f002e1899ab66745b92dfc26b9bd2","modified":1465653886000},{"_id":"source/_posts/算法/计算二维数组索引.md","hash":"e412d978eaf0a6b98529ee7c8b44db569e84a2cf","modified":1465653886000},{"_id":"source/_posts/算法/选择排序.md","hash":"833546563ff1218d65c6c866e7e2a4937fc3a99c","modified":1465653886000},{"_id":"source/_posts/jmh/.DS_Store","hash":"51f2ab1e10e90e97c4c48d9638ce19a983724c28","modified":1465534595000},{"_id":"source/_posts/编程语言/Groovy ANT.md","hash":"32ad5b545eb1c4d6b4f8e682fb79e97b9c7d4905","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy IO.md","hash":"c5a11347609aef1868b76a4135dbb7a3b5311a2f","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy JSON.md","hash":"cd145caf64ce760e5f7f723e62a985ccfdcb5800","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy 字符串.md","hash":"94735b5b89a961ceba38a89af7d5c028437e3b1a","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy 数字.md","hash":"318a7845e217f73468a1f25c1d10bb15995a23d2","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy 集合.md","hash":"86b6d59acf5662a640e03e285946bd9ad2196502","modified":1465653886000},{"_id":"source/_posts/编程语言/Groovy.md","hash":"68be3d13c1163b28ef20fe3c1e50c1fdca2234cb","modified":1465653886000},{"_id":"source/_posts/编程语言/JavaScript.md","hash":"4a0ab84e36bd9de655929e7401ae0708ba53b764","modified":1465653886000},{"_id":"source/_posts/编程语言/JavaScript函数.md","hash":"76190fe9c2a86e4d313c44574e968b9d08d947b7","modified":1465653886000},{"_id":"source/_posts/编程语言/JavaScript面向对象.md","hash":"82cbe9707ea0664026aca7ec3eb8962e613e815b","modified":1465653886000},{"_id":"source/_posts/编程语言/PHP 语法初探.md","hash":"619824efb3c28b3b755b50ea801d3781f9f3c3a6","modified":1465653886000},{"_id":"source/_posts/编程语言/haskell.md","hash":"86de7b88209cab0922452f8cbc4c8a6dba05cacc","modified":1465653886000},{"_id":"source/_posts/编程语言/haskell函数.md","hash":"796d005bfd3d6a690db324ec66ac6b17046a56e6","modified":1465653886000},{"_id":"source/_posts/编程语言/haskell表达式.md","hash":"920f0eac55bf83ac6635ede9696aafb2a62ec746","modified":1465653886000},{"_id":"source/_posts/网络/IP地址.md","hash":"cd6b6261baa147cf741f24ea666131f20e2cfa29","modified":1465653886000},{"_id":"source/_posts/网络/OSI参考模型.md","hash":"07650d6ba992febdacdc5276749f62f507a2556d","modified":1465653886000},{"_id":"source/_posts/网络/http.md","hash":"c732947c0981ee795112f49003eeeb9312eb0719","modified":1465653886000},{"_id":"source/_posts/网络/会话层.md","hash":"51b621b7e60292ddfedb9267a5ee8ebb9ec3dd38","modified":1465653886000},{"_id":"source/_posts/网络/传输层.md","hash":"898dfa8d424b4f05e7e1d4b31cf489c659b5721e","modified":1465653886000},{"_id":"source/_posts/网络/数据链路层.md","hash":"2bf46bbd86964c9461aa0e813d7cbf30089a0eda","modified":1465653886000},{"_id":"source/_posts/网络/网络层.md","hash":"ab7be5c63f9c0e432f6537fe9866d4526ef0e987","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/after_footer.ejs","hash":"7e406be944cb4ab7e02e05f37a1890f47d6bce39","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/analytics.ejs","hash":"5cb06f9d23b92815ff77766b894421e1037505f8","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/archive.ejs","hash":"90502fc2f5b0a5681a6c6588a9ed6ad297e32890","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/article.ejs","hash":"00c00b4a961ac1f7bc8ee688ce134fe0c454edc6","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/article_row.ejs","hash":"2c1f1edfeaebaafe4265d58e0b8110e71673da40","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/categories.ejs","hash":"2b77ff6cbc8571cab27c3bdc4ad51a79510bbca2","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/footer.ejs","hash":"5e02117ed541872115386a0c0257d94a2b3b2bb1","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/head.ejs","hash":"210bb4c1ec77d998dfd93baeb4e3a0b46a925cd1","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/header.ejs","hash":"795435cc84c46a18e4ac597435a81f66eb86b0c4","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/mathjax.ejs","hash":"5636df1f2b6a8d02986d866e3824ec60430046e6","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/pagination.ejs","hash":"6cf37f844f150af4bbe212610da61e5140317de9","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/search.ejs","hash":"732fcd909f6dac557629206dc7e93a7083cda084","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/sidebar.ejs","hash":"846d96ff73409b9a8b34f3cab691821096c03e1d","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/tags.ejs","hash":"c5c858742b29e6364da2e1d098e7d6cd8cef038f","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/tinysou_search.ejs","hash":"67a55a4d94cca2db11a2636f1f2c92c208688b14","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/totop.ejs","hash":"224d078ba1f2c33c52d5e867af71c5fe9f1bdf45","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/archive.ejs","hash":"b82d7fb0d1119738a9f9bb747d415e8c99e454ae","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/category.ejs","hash":"2c1b9ac7666d7d5b9aaf8f33588e10451c4b7841","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/douban.ejs","hash":"6dcb532d02325d2a9f5fb92831401552a5540aa8","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/github-card.ejs","hash":"c8a6fdb883be27f5e7daef6fa8899c17f51548a0","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/links.ejs","hash":"bd73be669ddc47e1daab38736d1cecc3f37662e2","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/lofter.ejs","hash":"51d4458ee96c1b1f7a4dde81e3b6a258b5c1efc1","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/rss.ejs","hash":"ebfb11bdd603cd6e4dcf3949cc52e38009615c25","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/tag.ejs","hash":"43b1c29fea51f849ec0bf85a6d91fe0507f01503","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/tagcloud.ejs","hash":"317d420f5448c7452290e37f0ed8516cb73f4068","modified":1465653886000},{"_id":"themes/jacman/layout/_widget/weibo.ejs","hash":"ff7db098608ba48752964cc67a51a04965ea927e","modified":1465653886000},{"_id":"themes/jacman/source/css/style.styl","hash":"4610c477560086880acc1ba71c3a72e7c89ecdb7","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","hash":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","hash":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","hash":"2da892a02778236b64076e5e8802ef0566e1d9e8","modified":1465653886000},{"_id":"themes/jacman/source/font/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1465653886000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","hash":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1465653886000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","hash":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1465653886000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","hash":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1465653886000},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1465653886000},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1465653886000},{"_id":"themes/jacman/source/font/fontdiao.eot","hash":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1465653886000},{"_id":"themes/jacman/source/font/fontdiao.ttf","hash":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1465653886000},{"_id":"themes/jacman/source/font/fontdiao.woff","hash":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1465653886000},{"_id":"themes/jacman/source/img/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1465653886000},{"_id":"themes/jacman/source/img/favicon.ico","hash":"4a605a4cc4691ad8b07ea9bc7f1a8212f1ee57cb","modified":1465653886000},{"_id":"themes/jacman/source/img/logo.png","hash":"cfe9ece003e30801e82fc31336412b48fd7fdaa2","modified":1465653886000},{"_id":"themes/jacman/source/img/logo.svg","hash":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1465653886000},{"_id":"themes/jacman/source/img/scrollup.png","hash":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1465653886000},{"_id":"themes/jacman/source/js/gallery.js","hash":"735a714e54f0ac229f292a90df3a1f882904f6c7","modified":1465653886000},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","hash":"28ef4346743a60c896a9ae492a544c0854904350","modified":1465653886000},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","hash":"5f690e8588c8493eb9406aa68fbf1765aaff9476","modified":1465653886000},{"_id":"themes/jacman/source/js/totop.js","hash":"48648ec9c86e9ab491831e5a029e6f8864934149","modified":1465653886000},{"_id":"source/_posts/jvm/JVM日志输出.md","hash":"2ad462e0a92303d531b6960f78240e1d312a4795","modified":1465653886000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","hash":"739808e56a56e10a03bc93d03eb55abd19590942","modified":1465653886000},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1465653886000},{"_id":"themes/jacman/source/font/fontdiao.svg","hash":"50e0247e9d39756843b7e4f720503b37bfb6154b","modified":1465653886000},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","hash":"cd981db035ec1b6f502fca78fd394c5bd438aba1","modified":1465653886000},{"_id":"source/_posts/编程语言/.DS_Store","hash":"589015cbb4eb3946207affff3ee278fdda3ce41a","modified":1465534646000},{"_id":"source/_posts/算法/.DS_Store","hash":"daebaa9ccaf97d4fec9d8eb4983dc00f2f8c00c2","modified":1465652974000},{"_id":"themes/jacman/layout/_partial/post/article.ejs","hash":"c01220f0af629f9e23bf125bdc1beef8afc206ef","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/catetags.ejs","hash":"20349dcde9942885d5eae1c302ef26b1b8484f3f","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/comment.ejs","hash":"9db7847461cf8b10a9cd5434deb690c6b26af6f1","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/footer.ejs","hash":"5b9f5ee6a2cc8bd557550bbdc1a03d237681114e","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/gallery.ejs","hash":"fc23ef9b5a412e05436f68ff47146b860d2d4225","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/header.ejs","hash":"351e771b1b38244560fc52cf60d91263d3d63eef","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/jiathis.ejs","hash":"12b7360326691ebf06bea5d7ee4d54c41f64e2ec","modified":1465653886000},{"_id":"themes/jacman/layout/_partial/post/pagination.ejs","hash":"091512e19cfcf5bde2a699b211f99874f26587ad","modified":1465653886000},{"_id":"source/_posts/asm/.DS_Store","hash":"9745e8a6b25f616313ce3c0b4f27b0ada1b03ceb","modified":1465436786000},{"_id":"themes/jacman/source/css/_base/font.styl","hash":"5699c270be7b28c5b2c36f453317ccd42789fd3d","modified":1465653886000},{"_id":"themes/jacman/source/css/_base/public.styl","hash":"657ad4c267490bd3b9ac98b5f864ecddb7025586","modified":1465653886000},{"_id":"themes/jacman/source/css/_base/variable.styl","hash":"0b7d517e12102a99be82bc1a9104bb6bfd4ca10b","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/article.styl","hash":"0bcb684376fcbf4be42d1df5dd02c395760f7ffb","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/aside.styl","hash":"4746783dc7993ac45d8a0e7a9d347bfe137111fe","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/duoshuo.styl","hash":"3ec423b734639614fbd11ec2c3445d3a03f5231d","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/footer.styl","hash":"0300d7d289eceb3933c1eebf38f8d10f425c1128","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/gallery.styl","hash":"75843d727319b1d07ad4b8c2e969036ce0d4f362","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/header.styl","hash":"f1ae52a4f41d4cfdd66cb186b0329af904fead4f","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/helper.styl","hash":"3ca7266a44240093143d0c55c74bb6daf579e298","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/index.styl","hash":"d5a3046587f42703224ac3b761e80baab35d4ccc","modified":1465653886000},{"_id":"themes/jacman/source/css/_partial/totop.styl","hash":"b48360e757d501027b7dbe093859d03795476930","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"4c9c395d705d22af7da06870d18f434e2a2eeaf9","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","hash":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1465653886000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"83cdfea43632b613771691a11f56f99d85fb6dbd","modified":1465653886000},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","hash":"a275426daefd3716c53561fad121d258a7f05b47","modified":1465653886000},{"_id":"themes/jacman/source/img/banner.jpg","hash":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1465653886000},{"_id":"themes/jacman/source/css/_base/highlight/theme.styl","hash":"d280f9ab32d7bf177adb5f7c858444cbfbac651a","modified":1465653886000},{"_id":"themes/jacman/source/css/_base/highlight/highlight.styl","hash":"2aee0cdb80fce512cde66ad229b9e5ee42c0d7b4","modified":1465653886000},{"_id":"themes/jacman/source/img/author.jpg","hash":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1465653886000},{"_id":"themes/jacman/source/img/jacman.jpg","hash":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1465653886000}],"Category":[{"name":"ICE","_id":"cipb8ihlw0004vjs6afygr4xw"},{"name":"Java工具","_id":"cipb8ihmh000cvjs6uvc26441"},{"name":"asm","_id":"cipb8iho4001hvjs6a2lgbgaa"},{"name":"JavaSE","_id":"cipb8ihos001yvjs6pk0zy835"},{"name":"guice","_id":"cipb8ihrg0041vjs6vcmm2g50"},{"name":"JMH","_id":"cipb8ihrx004ivjs6c1wy2u1d"},{"name":"JVM","_id":"cipb8ihsq0057vjs6tzov25e9"},{"name":"linux","_id":"cipb8ihv0006ovjs6hyjatplw"},{"name":"mgits","_id":"cipb8ihvr0075vjs683q0y5fy"},{"name":"Netty","_id":"cipb8ihxd0082vjs6mfcsbh7f"},{"name":"Nginx","_id":"cipb8ihyk008lvjs6ououlp2o"},{"name":"NoSql","_id":"cipb8ihzf0092vjs67jdteyed"},{"name":"python2","_id":"cipb8ii0g009mvjs69ql74hoy"},{"name":"Spring","_id":"cipb8ii1d00a8vjs62unkiizf"},{"name":"ZooKeeper","_id":"cipb8ii2600apvjs6hpi5gul1"},{"name":"并发编程","_id":"cipb8ii3k00bcvjs6zztf9r6q"},{"name":"操作系统","_id":"cipb8ii3r00bgvjs65922occt"},{"name":"数据库","_id":"cipb8ii4200bsvjs6aqv0lgkz"},{"name":"日志工具","_id":"cipb8ii5800d1vjs6i33si4f0"},{"name":"算法","_id":"cipb8ii5v00dpvjs60v9ouyyx"},{"name":"编程语言","_id":"cipb8ii6100e3vjs6bwcalphe"},{"name":"网络","_id":"cipb8ii6c00evvjs6bv2yijai"}],"Data":[],"Page":[{"_content":"<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.gnim.wang\" homePageName=\"gnim.wang\"></script>","source":"404.html","raw":"<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.gnim.wang\" homePageName=\"gnim.wang\"></script>","date":"2016-06-11T14:04:45.000Z","updated":"2016-06-11T14:04:45.000Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"cipb8ihi20000vjs6e84ffkd5"},{"title":"关于","_content":"","source":"about/index.md","raw":"title: 关于\n---\n","date":"2016-06-11T14:04:46.000Z","updated":"2016-06-11T14:04:46.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cipb8ihjd0001vjs6v29b1v3c"}],"Post":[{"date":"2016-03-29T16:00:00.000Z","title":"ZeroC ICE Hello Demo","_content":"接触ICE有段时间了, 今天就找个时间将ZEROC ICE官网的hello Demo讲解一下.\n\n当我们打开hello demo的时候,我们会看到如下几个文件\n×　Client.java : 启动客户端进程\n×　config.client : 客户端配置文件\n×　config.server : 服务器配置文件\n×　Hello.ice : \n×　HelloI.java : 服务器逻辑接入文件\n×　Server.java : 启动服务器进程\n\n我们首先看一下Hello.ice这个文件\n```java\n#pragma once\n\n// module相当于package\nmodule Demo\n{\n\n// 定义了一个Hello的服务\ninterface Hello\n{\n    idempotent void sayHello(int delay);\n    void shutdown();\n};\n\n};\n```\n然后我们看一下HelloI.java这个文件, 这里面是服务器用来处理客户端请求的\n```java\nimport Demo.*;\n\npublic class HelloI extends _HelloDisp {\n    public void sayHello(int delay, Ice.Current current) {\n        if(delay > 0) {\n            try {\n                Thread.currentThread().sleep(delay);\n            }\n            catch(InterruptedException ex1){\n            }\n        }\n        System.out.println(\"Hello World!\");\n    }\n\n    public void shutdown(Ice.Current current) {\n        System.out.println(\"Shutting down...\");\n        current.adapter.getCommunicator().shutdown();\n    }\n}\n```\n至于_HelloDisp我们会在下面讲解.\n\n然后我们现在启动服务器, 在看启动服务器进程的我们首先看一下, 服务器端的配置(由于配置较多,我只将最基本的配置挑选出来了)\n```java\nHello.Endpoints=tcp -h localhost -p 10000:udp -h localhost -p 10000\n```\n然后看服务器进程启动过程\n```java\nimport Demo.*;\n\npublic class Server extends Ice.Application\n{\n    public int run(String[] args) {\n\t\t// 创建Hello适配器(也就是config.server文件中的Hello.Endpoints), 创建网络监听\n        Ice.ObjectAdapter adapter = communicator().createObjectAdapter(\"Hello\");\n\t\t// 然后在Hello适配器中监听hello调用, 当监听到hello调用时由HelloI进行处理\n        adapter.add(new HelloI(), communicator().stringToIdentity(\"hello\"));\n        adapter.activate();\n        communicator().waitForShutdown();\n        return 0;\n    }\n\n    public static void main(String[] args) {\n        Server app = new Server();\n        int status = app.main(\"Server\", args, \"config.server\");\n        System.exit(status);\n    }\n}\n```\n\n现在我们启动客户端进程, 同样在启动之前看一下客户端的配置\n```java\nHello.Proxy=hello:tcp -h localhost -p 10000:udp -h localhost -p 10000\n```\n在下面的客户端示例中我们会拿到`Hello.Proxy`代理, 然后ice内部会发送hello调用从而实现RPC业务逻辑调用\n\n然后我们看一下启动过程\n```java\nimport Demo.*;\n\npublic class Client extends Ice.Application {\n    class ShutdownHook extends Thread {\n        public void run() {\n            try {\n                communicator().destroy();\n            }\n            catch(Ice.LocalException ex) {\n                ex.printStackTrace();\n            }\n        }\n    }\n\n    private static void menu() {\n        System.out.println(\n            \"usage:\\n\" +\n            \"t: send greeting as twoway\\n\" +\n            \"o: send greeting as oneway\\n\" +\n            \"O: send greeting as batch oneway\\n\" +\n            \"d: send greeting as datagram\\n\" +\n            \"D: send greeting as batch datagram\\n\" +\n            \"f: flush all batch requests\\n\" +\n            \"T: set a timeout\\n\" +\n            \"P: set a server delay\\n\" +\n            \"S: switch secure mode on/off\\n\" +\n            \"s: shutdown server\\n\" +\n            \"x: exit\\n\" +\n            \"?: help\\n\");\n    }\n\n    public int run(String[] args) {\n        setInterruptHook(new ShutdownHook());\n\n\t\t// 根据配置中的Hello.Proxy创建代理, 稍后根据代理进行网络连接\n        HelloPrx twoway = HelloPrxHelper.checkedCast(\n            communicator().propertyToProxy(\"Hello.Proxy\").ice_twoway().ice_timeout(-1).ice_secure(false));\n        if(twoway == null) {\n            System.err.println(\"invalid proxy\");\n            return 1;\n        }\n        HelloPrx oneway = (HelloPrx)twoway.ice_oneway();\n        HelloPrx batchOneway = (HelloPrx)twoway.ice_batchOneway();\n        HelloPrx datagram = (HelloPrx)twoway.ice_datagram();\n        HelloPrx batchDatagram = (HelloPrx)twoway.ice_batchDatagram();\n\n        boolean secure = false;\n        int timeout = -1;\n        int delay = 0;\n\n        menu();\n\n        java.io.BufferedReader in = new java.io.BufferedReader(new java.io.InputStreamReader(System.in));\n\n        String line = null;\n        do {\n            try {\n                System.out.print(\"==> \");\n                System.out.flush();\n                line = in.readLine();\n                if(line == null) {\n                    break;\n                }\n                if(line.equals(\"t\")) {\n                    twoway.sayHello(delay);\n                }\n                else if(line.equals(\"o\")) {\n                    oneway.sayHello(delay);\n                }\n                else if(line.equals(\"O\")) {\n                    batchOneway.sayHello(delay);\n                }\n                else if(line.equals(\"d\")) {\n                    if(secure) {\n                        System.out.println(\"secure datagrams are not supported\");\n                    }\n                    else {\n                        datagram.sayHello(delay);\n                    }\n                }\n                else if(line.equals(\"D\")) {\n                    if(secure) {\n                        System.out.println(\"secure datagrams are not supported\");\n                    }\n                    else {\n                        batchDatagram.sayHello(delay);\n                    }\n                }\n                else if(line.equals(\"f\")) {\n                    communicator().flushBatchRequests();\n                }\n                else if(line.equals(\"T\")) {\n                    if(timeout == -1) {\n                        timeout = 2000;\n                    }\n                    else {\n                        timeout = -1;\n                    }\n\n                    twoway = (HelloPrx)twoway.ice_timeout(timeout);\n                    oneway = (HelloPrx)oneway.ice_timeout(timeout);\n                    batchOneway = (HelloPrx)batchOneway.ice_timeout(timeout);\n\n                    if(timeout == -1) {\n                        System.out.println(\"timeout is now switched off\");\n                    }\n                    else {\n                        System.out.println(\"timeout is now set to 2000ms\");\n                    }\n                }\n                else if(line.equals(\"P\")) {\n                    if(delay == 0) {\n                        delay = 2500;\n                    }\n                    else {\n                        delay = 0;\n                    }\n\n                    if(delay == 0) {\n                        System.out.println(\"server delay is now deactivated\");\n                    }\n                    else {\n                        System.out.println(\"server delay is now set to 2500ms\");\n                    }\n                }\n                else if(line.equals(\"S\")) {\n                    secure = !secure;\n\n                    twoway = (HelloPrx)twoway.ice_secure(secure);\n                    oneway = (HelloPrx)oneway.ice_secure(secure);\n                    batchOneway = (HelloPrx)batchOneway.ice_secure(secure);\n                    datagram = (HelloPrx)datagram.ice_secure(secure);\n                    batchDatagram = (HelloPrx)batchDatagram.ice_secure(secure);\n\n                    if(secure) {\n                        System.out.println(\"secure mode is now on\");\n                    }\n                    else {\n                        System.out.println(\"secure mode is now off\");\n                    }\n                }\n                else if(line.equals(\"s\")) {\n                    twoway.shutdown();\n                }\n                else if(line.equals(\"x\")) {\n                    // Nothing to do\n                }\n                else if(line.equals(\"?\")) {\n                    menu();\n                }\n                else {\n                    System.out.println(\"unknown command `\" + line + \"'\");\n                    menu();\n                }\n            }\n            catch(java.io.IOException ex) {\n                ex.printStackTrace();\n            }\n            catch(Ice.LocalException ex) {\n                ex.printStackTrace();\n            }\n        }\n        while(!line.equals(\"x\"));\n\n        return 0;\n    }\n\n    public static void main(String[] args)\n    {\n        Client app = new Client();\n        int status = app.main(\"Client\", args, \"config.client\");\n        System.exit(status);\n    }\n}\n```\n这里我们要详细讲一下客户端示例中的几种调用\n* oneway \n* batchOneway\n* datagram\n* batchDatagram","source":"_posts/ICE/ZeroC ICE Hello Demo.md","raw":"category: ICE\ndate: 2016-03-30\ntitle: ZeroC ICE Hello Demo\n---\n接触ICE有段时间了, 今天就找个时间将ZEROC ICE官网的hello Demo讲解一下.\n\n当我们打开hello demo的时候,我们会看到如下几个文件\n×　Client.java : 启动客户端进程\n×　config.client : 客户端配置文件\n×　config.server : 服务器配置文件\n×　Hello.ice : \n×　HelloI.java : 服务器逻辑接入文件\n×　Server.java : 启动服务器进程\n\n我们首先看一下Hello.ice这个文件\n```java\n#pragma once\n\n// module相当于package\nmodule Demo\n{\n\n// 定义了一个Hello的服务\ninterface Hello\n{\n    idempotent void sayHello(int delay);\n    void shutdown();\n};\n\n};\n```\n然后我们看一下HelloI.java这个文件, 这里面是服务器用来处理客户端请求的\n```java\nimport Demo.*;\n\npublic class HelloI extends _HelloDisp {\n    public void sayHello(int delay, Ice.Current current) {\n        if(delay > 0) {\n            try {\n                Thread.currentThread().sleep(delay);\n            }\n            catch(InterruptedException ex1){\n            }\n        }\n        System.out.println(\"Hello World!\");\n    }\n\n    public void shutdown(Ice.Current current) {\n        System.out.println(\"Shutting down...\");\n        current.adapter.getCommunicator().shutdown();\n    }\n}\n```\n至于_HelloDisp我们会在下面讲解.\n\n然后我们现在启动服务器, 在看启动服务器进程的我们首先看一下, 服务器端的配置(由于配置较多,我只将最基本的配置挑选出来了)\n```java\nHello.Endpoints=tcp -h localhost -p 10000:udp -h localhost -p 10000\n```\n然后看服务器进程启动过程\n```java\nimport Demo.*;\n\npublic class Server extends Ice.Application\n{\n    public int run(String[] args) {\n\t\t// 创建Hello适配器(也就是config.server文件中的Hello.Endpoints), 创建网络监听\n        Ice.ObjectAdapter adapter = communicator().createObjectAdapter(\"Hello\");\n\t\t// 然后在Hello适配器中监听hello调用, 当监听到hello调用时由HelloI进行处理\n        adapter.add(new HelloI(), communicator().stringToIdentity(\"hello\"));\n        adapter.activate();\n        communicator().waitForShutdown();\n        return 0;\n    }\n\n    public static void main(String[] args) {\n        Server app = new Server();\n        int status = app.main(\"Server\", args, \"config.server\");\n        System.exit(status);\n    }\n}\n```\n\n现在我们启动客户端进程, 同样在启动之前看一下客户端的配置\n```java\nHello.Proxy=hello:tcp -h localhost -p 10000:udp -h localhost -p 10000\n```\n在下面的客户端示例中我们会拿到`Hello.Proxy`代理, 然后ice内部会发送hello调用从而实现RPC业务逻辑调用\n\n然后我们看一下启动过程\n```java\nimport Demo.*;\n\npublic class Client extends Ice.Application {\n    class ShutdownHook extends Thread {\n        public void run() {\n            try {\n                communicator().destroy();\n            }\n            catch(Ice.LocalException ex) {\n                ex.printStackTrace();\n            }\n        }\n    }\n\n    private static void menu() {\n        System.out.println(\n            \"usage:\\n\" +\n            \"t: send greeting as twoway\\n\" +\n            \"o: send greeting as oneway\\n\" +\n            \"O: send greeting as batch oneway\\n\" +\n            \"d: send greeting as datagram\\n\" +\n            \"D: send greeting as batch datagram\\n\" +\n            \"f: flush all batch requests\\n\" +\n            \"T: set a timeout\\n\" +\n            \"P: set a server delay\\n\" +\n            \"S: switch secure mode on/off\\n\" +\n            \"s: shutdown server\\n\" +\n            \"x: exit\\n\" +\n            \"?: help\\n\");\n    }\n\n    public int run(String[] args) {\n        setInterruptHook(new ShutdownHook());\n\n\t\t// 根据配置中的Hello.Proxy创建代理, 稍后根据代理进行网络连接\n        HelloPrx twoway = HelloPrxHelper.checkedCast(\n            communicator().propertyToProxy(\"Hello.Proxy\").ice_twoway().ice_timeout(-1).ice_secure(false));\n        if(twoway == null) {\n            System.err.println(\"invalid proxy\");\n            return 1;\n        }\n        HelloPrx oneway = (HelloPrx)twoway.ice_oneway();\n        HelloPrx batchOneway = (HelloPrx)twoway.ice_batchOneway();\n        HelloPrx datagram = (HelloPrx)twoway.ice_datagram();\n        HelloPrx batchDatagram = (HelloPrx)twoway.ice_batchDatagram();\n\n        boolean secure = false;\n        int timeout = -1;\n        int delay = 0;\n\n        menu();\n\n        java.io.BufferedReader in = new java.io.BufferedReader(new java.io.InputStreamReader(System.in));\n\n        String line = null;\n        do {\n            try {\n                System.out.print(\"==> \");\n                System.out.flush();\n                line = in.readLine();\n                if(line == null) {\n                    break;\n                }\n                if(line.equals(\"t\")) {\n                    twoway.sayHello(delay);\n                }\n                else if(line.equals(\"o\")) {\n                    oneway.sayHello(delay);\n                }\n                else if(line.equals(\"O\")) {\n                    batchOneway.sayHello(delay);\n                }\n                else if(line.equals(\"d\")) {\n                    if(secure) {\n                        System.out.println(\"secure datagrams are not supported\");\n                    }\n                    else {\n                        datagram.sayHello(delay);\n                    }\n                }\n                else if(line.equals(\"D\")) {\n                    if(secure) {\n                        System.out.println(\"secure datagrams are not supported\");\n                    }\n                    else {\n                        batchDatagram.sayHello(delay);\n                    }\n                }\n                else if(line.equals(\"f\")) {\n                    communicator().flushBatchRequests();\n                }\n                else if(line.equals(\"T\")) {\n                    if(timeout == -1) {\n                        timeout = 2000;\n                    }\n                    else {\n                        timeout = -1;\n                    }\n\n                    twoway = (HelloPrx)twoway.ice_timeout(timeout);\n                    oneway = (HelloPrx)oneway.ice_timeout(timeout);\n                    batchOneway = (HelloPrx)batchOneway.ice_timeout(timeout);\n\n                    if(timeout == -1) {\n                        System.out.println(\"timeout is now switched off\");\n                    }\n                    else {\n                        System.out.println(\"timeout is now set to 2000ms\");\n                    }\n                }\n                else if(line.equals(\"P\")) {\n                    if(delay == 0) {\n                        delay = 2500;\n                    }\n                    else {\n                        delay = 0;\n                    }\n\n                    if(delay == 0) {\n                        System.out.println(\"server delay is now deactivated\");\n                    }\n                    else {\n                        System.out.println(\"server delay is now set to 2500ms\");\n                    }\n                }\n                else if(line.equals(\"S\")) {\n                    secure = !secure;\n\n                    twoway = (HelloPrx)twoway.ice_secure(secure);\n                    oneway = (HelloPrx)oneway.ice_secure(secure);\n                    batchOneway = (HelloPrx)batchOneway.ice_secure(secure);\n                    datagram = (HelloPrx)datagram.ice_secure(secure);\n                    batchDatagram = (HelloPrx)batchDatagram.ice_secure(secure);\n\n                    if(secure) {\n                        System.out.println(\"secure mode is now on\");\n                    }\n                    else {\n                        System.out.println(\"secure mode is now off\");\n                    }\n                }\n                else if(line.equals(\"s\")) {\n                    twoway.shutdown();\n                }\n                else if(line.equals(\"x\")) {\n                    // Nothing to do\n                }\n                else if(line.equals(\"?\")) {\n                    menu();\n                }\n                else {\n                    System.out.println(\"unknown command `\" + line + \"'\");\n                    menu();\n                }\n            }\n            catch(java.io.IOException ex) {\n                ex.printStackTrace();\n            }\n            catch(Ice.LocalException ex) {\n                ex.printStackTrace();\n            }\n        }\n        while(!line.equals(\"x\"));\n\n        return 0;\n    }\n\n    public static void main(String[] args)\n    {\n        Client app = new Client();\n        int status = app.main(\"Client\", args, \"config.client\");\n        System.exit(status);\n    }\n}\n```\n这里我们要详细讲一下客户端示例中的几种调用\n* oneway \n* batchOneway\n* datagram\n* batchDatagram","slug":"ICE/ZeroC ICE Hello Demo","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihlm0002vjs60ee8pwbn"},{"date":"2016-03-29T16:00:00.000Z","title":"ZeroC ICE 编译后的java文件","_content":"我们可以将hello.ice文件\n```java\n#pragma once\n\n// module相当于package\nmodule Demo\n{\n\n// 定义了一个Hello的服务\ninterface Hello\n{\n    idempotent void sayHello(int delay);\n    void shutdown();\n};\n\n};\n```\n通过下面的命令将其编译成我们需要的java文件\n```java\nslice2java -I. Hello.ice\n```\n编译后的文件如下\n\n下面的是服务端要用到的文件\n* Hello.java\n* _HelloOperations.java\n* _HelloOperationsNC.java\n* _HelloDel.java\n* _HelloDelD.java\n* _HelloDelM.java\n* _HelloDisp.java\n\n下面是客户端需要使用到的文件\n* HelloHolder.java\n* HelloPrx.java\n* HelloPrxHelper.java\n* HelloPrxHolder.java\n\n* Callback_Hello_sayHello.java\n* Callback_Hello_shutdown.java\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/ICE/ZeroC ICE 编译后的Java文件.md","raw":"category: ICE\ndate: 2016-03-30\ntitle: ZeroC ICE 编译后的java文件\n---\n我们可以将hello.ice文件\n```java\n#pragma once\n\n// module相当于package\nmodule Demo\n{\n\n// 定义了一个Hello的服务\ninterface Hello\n{\n    idempotent void sayHello(int delay);\n    void shutdown();\n};\n\n};\n```\n通过下面的命令将其编译成我们需要的java文件\n```java\nslice2java -I. Hello.ice\n```\n编译后的文件如下\n\n下面的是服务端要用到的文件\n* Hello.java\n* _HelloOperations.java\n* _HelloOperationsNC.java\n* _HelloDel.java\n* _HelloDelD.java\n* _HelloDelM.java\n* _HelloDisp.java\n\n下面是客户端需要使用到的文件\n* HelloHolder.java\n* HelloPrx.java\n* HelloPrxHelper.java\n* HelloPrxHolder.java\n\n* Callback_Hello_sayHello.java\n* Callback_Hello_shutdown.java\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"ICE/ZeroC ICE 编译后的Java文件","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihlt0003vjs65j364bx3"},{"date":"2015-09-07T16:00:00.000Z","title":"Archiva 初探","_content":"\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n\n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n\n </settings>\n ```\n","source":"_posts/Java 工具库/Archiva.md","raw":"category: Java工具\ndate: 2015-09-08\ntitle: Archiva 初探\n---\n\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n\n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n\n </settings>\n ```\n","slug":"Java 工具库/Archiva","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihly0005vjs69ae0uc58"},{"date":"2015-12-22T16:00:00.000Z","title":"Feign 初探","_content":"RESTful 服务的HTTP客户端连接器\n```\nimport feign.gson.GsonDecoder;\nimport feign.gson.GsonEncoder;\nimport feign.httpclient.ApacheHttpClient;\nimport feign.slf4j.Slf4jLogger;\n\nimport java.util.List;\n\npublic class Main {\n\n\tpublic static void main(String... args) {\n\t\tGitHub github = Feign.builder()\n\t\t\t\t.decoder(new GsonDecoder())\t\t// 设置解码器, 我们使用Gson将应答解析成Contributor\n\t\t\t\t.encoder(new GsonEncoder())\n\t\t\t\t.logger(new Slf4jLogger())\t\t// 设置日志\n\t\t\t\t.client(new ApacheHttpClient())\t\t// 我们使用Apache的HttpClient组件\n\t\t\t\t.target(GitHub.class, \"https://api.github.com\");\n\n\t\tList<Contributor> contributors = github.contributors(\"netflix\", \"feign\");\n\t\tSystem.out.println(\"netflix :\" + contributors.size());\n\n\t\tList<Contributor> contributors1 = github.contributors(\"ming15\", \"VertxServer\");\n\t\tSystem.out.println(\"ming15 :\" + contributors1.size());\n\t}\n}\ninterface GitHub {\n\t@RequestLine(\"GET /repos/{owner}/{repo}/contributors\")\n\t@Headers(\"Content-Type: application/json\")\n\tList<Contributor> contributors(@Param(\"owner\") String owner, @Param(\"repo\") String repo);\n}\n\nclass Contributor {\n\tString login;\n\tint contributions;\n}\n```","source":"_posts/Java 工具库/Feign.md","raw":"category: Java工具\ndate: 2015-12-23\ntitle: Feign 初探\n---\nRESTful 服务的HTTP客户端连接器\n```\nimport feign.gson.GsonDecoder;\nimport feign.gson.GsonEncoder;\nimport feign.httpclient.ApacheHttpClient;\nimport feign.slf4j.Slf4jLogger;\n\nimport java.util.List;\n\npublic class Main {\n\n\tpublic static void main(String... args) {\n\t\tGitHub github = Feign.builder()\n\t\t\t\t.decoder(new GsonDecoder())\t\t// 设置解码器, 我们使用Gson将应答解析成Contributor\n\t\t\t\t.encoder(new GsonEncoder())\n\t\t\t\t.logger(new Slf4jLogger())\t\t// 设置日志\n\t\t\t\t.client(new ApacheHttpClient())\t\t// 我们使用Apache的HttpClient组件\n\t\t\t\t.target(GitHub.class, \"https://api.github.com\");\n\n\t\tList<Contributor> contributors = github.contributors(\"netflix\", \"feign\");\n\t\tSystem.out.println(\"netflix :\" + contributors.size());\n\n\t\tList<Contributor> contributors1 = github.contributors(\"ming15\", \"VertxServer\");\n\t\tSystem.out.println(\"ming15 :\" + contributors1.size());\n\t}\n}\ninterface GitHub {\n\t@RequestLine(\"GET /repos/{owner}/{repo}/contributors\")\n\t@Headers(\"Content-Type: application/json\")\n\tList<Contributor> contributors(@Param(\"owner\") String owner, @Param(\"repo\") String repo);\n}\n\nclass Contributor {\n\tString login;\n\tint contributions;\n}\n```","slug":"Java 工具库/Feign","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihm00006vjs6od720vuy"},{"date":"2013-09-12T16:00:00.000Z","title":"Guava Cache","_content":"\n## Example\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .expireAfterWrite(10, TimeUnit.MINUTES)  \n       .removalListener(MY_LISTENER)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n## 适用范围\n缓存的使用范围是十分广泛的。每当计算或者通过一些方式生成一个值的时候，会造成资源严重浪费的时候我们可以考虑用缓存技术来存储该值。\n\n缓存和`CurrentMap`十分相似(键值对形式),但是他们之间还是仍有诸多不同.他们之间最大的不同之处是`ConcurrentMap`里的元素在被明确地删除之前会一直被存储在`Map`里，但是对于cache来说，为了维护cache的内存占用，cache被设计成会自动删除其中的数据。在一些应用场合中，使用`LoadingCache也`是非常有用的，即使它不被允许自动删除其entries(由于它的自动内存加载机制，他不允许这么做)。\n\n一般来说，Guava的缓存技术一般适用于以下场合\n1. 想要消耗掉一些内存来换取速度的提升\n2. key(map中也有key)会在一段时间内被频繁的访问。\n3. 在cache存储的数据容量不会大于其RAM中存储的。\n\n你可以按照上文中的例子(CacheBuilder的builder pattern)来创建一个Cache，但是定制属于自己应用程序的Cache才是最激动人心的事。\n\n>注：如果你的应用程序中不会用到上文提到的Cache的特性，那么你可以考虑ConcurrentHashMap，它在内存方面也许更有优势。但是ConcurrentHashMap是非常困难，甚至不可能的来模拟出Cache那样的强大功能。\n至于如何选择，就要看你的应用程序需求了,仔细看看下面提到的特性----例如元素的存活期，元素的大小等等，这些特点都是在ConcurrentMap里所不存在的。\n\n## 总体\n你应该先问自己第一个问题：你是否有特定的明确的通过某些keys的作参数生成Value的方法？如果你的回答是肯定的话，那么`CacheLoader`是适合你的。如果你不需要通过某些key来生成value或者你想要重载默认的方法或者想要使用`get-if-absent-compute`方式,你可以参考[From A Callable]()。一般我们可以通过`Cache.put`直接将元素插入cache中，但是我们应该首先考虑它的自动缓存加载，因为它会考虑到所有缓存内容的一致性。\n\n> From A CacheLoader : LoadingCache通过一个附着的CacheLoader来创建。创建一个CacheLoader也是非常简单的，只要实现一个V load(K key) throws exception的方法就可以了.下面的例子展示出如何创建一个LoadingCache\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n\n...  \ntry {  \n  return graphs.get(key);  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\n上面的例子也展示除了我们可以通过`get(K)`的方式对`LoadingCache`进行查询获取值。我们如果可以从cache中查找到该key，那么将会直接返回该key对应的value，否则会通过cache的`CacheLoader`自动加载一个新的键值对，然后返回该值。因为`CacheLoader`可能会抛出异常，所以get(K)可能会抛出`Execution`。如果在`CacheLoader`中定义了一个非异常检查的`load`方法，那么在查询取值时可以使用`getUnchecked(Key)`;但是如果你声明了throws，则一定不要调用`getUnchecked(Key)`. 下面是一个例子：\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .expireAfterAccess(10, TimeUnit.MINUTES)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n\n...  \nreturn graphs.getUnchecked(key);  \n```\n\n当我们想要获取N多值的时候，在查询时可以使用方法`getAll(Iterable<? extends K>)`.在getAll中，对每一个不存在于cache里的key都会执行一个单独的对`CacheLoader.load`的方法调用来加载该值。看，guava提供了如此优秀的方法当进行一次getAll比多次get更有优势时，我们就应该重载`CacheLoader.loadAll`来实现这个功能。\n\n可以通过实现`CacheLoader.loadAll`这个方法来加载那些不被包含的显示请求的值。\n\n如果想要设定cache有一定的大小可以通过`CacheBuilder.maximumSize(long)`来设定。如此设定会使得cache在达到限定值时删除那些没有被使用过或者不经常使用的entries.\n\n> From a Callable: 所有的Guava caches，不管是否是loading模式的，都支持get(K, Callable<V>)方法。这个方法会从cache中返回与该key相关联的value，或者从Callable中计算该值并把它放进cache中。这个方法使用了一个非常简单的模式\"if cached, return; otherwise create, cache and return\"\n\n```java\nCache<Key, Value> cache = CacheBuilder.newBuilder()  \n    .maximumSize(1000)  \n    .build(); // look Ma, no CacheLoader  \n...  \ntry {  \n  // If the key wasn't in the \"easy to compute\" group, we need to  \n  // do things the hard way.  \n  cache.get(key, new Callable<Value>() {  \n    @Override  \n    public Value call() throws AnyException {  \n      return doThingsTheHardWay(key);  \n    }  \n  });  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\nInserted Directly : Values也可以通过cache.put(key,value)直接将值插入cache中。该方法将重写先前与key匹配的entry。\n\n## Eviction\n一个不能避免的问题：由于内存原因，我们不能将所有的东西都加载进cache中。那么你必须下决定：一个cache entry应该何时被抛弃。Guava提供了三种entry释放策略：size-basd evicton，time-based eviction 和reference-based eviction\n\n### Size-based Eviction\n如果你的cache不允许扩容,即不允许超过设定的最大值，那么使用CacheBuilder.maxmuSize(long)即可。在这种条件下，cache会自己释放掉那些最近没有或者不经常使用的entries内存。注意：cache并不是在超过限定时才会删除掉那些entries，而是在即将达到这个限定值时，那么你就要小心考虑这种情况了，因为很明显即使没有达到这个限定值，cache仍然会进行删除操作。\n\n还有一种情况：cache里不同的entries可能会有不同的weight。例如：如果你的cache values有着截然不同的内存占用----你可以使用CacheBuilder.weigher(Weigher)设定weigh和使用CacheBuilder.maximumWeight(long)设定一个最大值。\n下面代码展示了对weight的使用\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumWeight(100000)  \n       .weigher(new Weigher<Key, Graph>() {  \n          public int weigh(Key k, Graph g) {  \n            return g.vertices().size();  \n          }  \n        })  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n### Timed Eviction\nCacheBuilder 提供了俩种方式来实现这一模式\nexpireAfterAccess(long, TimeUnit)\n从最后一次访问(读或者写)开始计时，过了这段指定的时间就会释放掉该entries。注意：那些被删掉的entries的顺序时和size-based eviction是十分相似的。\nexpireAfterWrite(long,TimeUnit)\n它是从entries被创建或者最后一次被修改值的点来计时的，如果从这个点开始超过了那段指定的时间，entries就会被删除掉。这点设计的很精明，因为数据会随着时间变得越来越陈旧。\n如果想要测试Timed Eviction，使用Ticker interface和CacheBuilder.ticker(Ticker)方法对你的cache设定一个时间即可，那么你就不需要去等待系统时间了。\n\n### Reference-based Eviction\nGuava为你准备了entries的垃圾回收器，对于keys或者values可以使用`weak reference` ，对于values可以使用 `soft reference`.\n\n`CacheBuilder.weakKeys()`通过weak reference存储keys。在这种情况下，如果keys没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个key的，而不是equals();\n\n`CacheBuilder.weakValues()`  通过weak referene 存储values.在这种情况下，如果valves没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个values的，而不是equals();\nCacheBuilder.softValues()\n\n### Explicit Removals\n也许在某年某月某天你不想再等cache释放entries，而是自己能手动的去释放掉这些entries，下面三个方法会帮助你\n* 单个释放：Cache.invalidate(key)\n* 多个释放：Cache.invalidateAll(keys)\n* 全部释放：Cache.invalidateAll()\n\n### Removal Listeners\ncache允许你指定一个removal listener监听entry的移除操作(例如`CacheBuilder.removalListener(RemovalListener)`).通过R`emovaNotification`获得的`RemovalListener`制定了RemovalCause,key和value`。\n\n>注意RemovalListener抛出的任何异常都会被Logger记录然后被丢弃\n\n```java\nCacheLoader<Key, DatabaseConnection> loader = new CacheLoader<Key, DatabaseConnection> () {  \n  public DatabaseConnection load(Key key) throws Exception {  \n    return openConnection(key);  \n  }  \n};  \nRemovalListener<Key, DatabaseConnection> removalListener = new RemovalListener<Key, DatabaseConnection>() {  \n  public void onRemoval(RemovalNotification<Key, DatabaseConnection> removal) {  \n    DatabaseConnection conn = removal.getValue();  \n    conn.close(); // tear down properly  \n  }  \n};  \n\nreturn CacheBuilder.newBuilder()  \n  .expireAfterWrite(2, TimeUnit.MINUTES)  \n  .removalListener(removalListener)  \n  .build(loader);  \n```\n警告：removal listeners是被默认同步执行的，而且cache的维护是在其普通操作中维护的，那么“昂贵的”removal listener会降低cache操作(某些方法)的效率。如果你在使用一个\"昂贵的\"removal listener，你可以使用RemovalListener.asynchronous(RemovalListener,Executor),将其布置成异步操作.\n","source":"_posts/Java 工具库/Guava CachesExplained.md","raw":"category: Java工具\ndate: 2013-09-13\ntitle: Guava Cache\n---\n\n## Example\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .expireAfterWrite(10, TimeUnit.MINUTES)  \n       .removalListener(MY_LISTENER)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n## 适用范围\n缓存的使用范围是十分广泛的。每当计算或者通过一些方式生成一个值的时候，会造成资源严重浪费的时候我们可以考虑用缓存技术来存储该值。\n\n缓存和`CurrentMap`十分相似(键值对形式),但是他们之间还是仍有诸多不同.他们之间最大的不同之处是`ConcurrentMap`里的元素在被明确地删除之前会一直被存储在`Map`里，但是对于cache来说，为了维护cache的内存占用，cache被设计成会自动删除其中的数据。在一些应用场合中，使用`LoadingCache也`是非常有用的，即使它不被允许自动删除其entries(由于它的自动内存加载机制，他不允许这么做)。\n\n一般来说，Guava的缓存技术一般适用于以下场合\n1. 想要消耗掉一些内存来换取速度的提升\n2. key(map中也有key)会在一段时间内被频繁的访问。\n3. 在cache存储的数据容量不会大于其RAM中存储的。\n\n你可以按照上文中的例子(CacheBuilder的builder pattern)来创建一个Cache，但是定制属于自己应用程序的Cache才是最激动人心的事。\n\n>注：如果你的应用程序中不会用到上文提到的Cache的特性，那么你可以考虑ConcurrentHashMap，它在内存方面也许更有优势。但是ConcurrentHashMap是非常困难，甚至不可能的来模拟出Cache那样的强大功能。\n至于如何选择，就要看你的应用程序需求了,仔细看看下面提到的特性----例如元素的存活期，元素的大小等等，这些特点都是在ConcurrentMap里所不存在的。\n\n## 总体\n你应该先问自己第一个问题：你是否有特定的明确的通过某些keys的作参数生成Value的方法？如果你的回答是肯定的话，那么`CacheLoader`是适合你的。如果你不需要通过某些key来生成value或者你想要重载默认的方法或者想要使用`get-if-absent-compute`方式,你可以参考[From A Callable]()。一般我们可以通过`Cache.put`直接将元素插入cache中，但是我们应该首先考虑它的自动缓存加载，因为它会考虑到所有缓存内容的一致性。\n\n> From A CacheLoader : LoadingCache通过一个附着的CacheLoader来创建。创建一个CacheLoader也是非常简单的，只要实现一个V load(K key) throws exception的方法就可以了.下面的例子展示出如何创建一个LoadingCache\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n\n...  \ntry {  \n  return graphs.get(key);  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\n上面的例子也展示除了我们可以通过`get(K)`的方式对`LoadingCache`进行查询获取值。我们如果可以从cache中查找到该key，那么将会直接返回该key对应的value，否则会通过cache的`CacheLoader`自动加载一个新的键值对，然后返回该值。因为`CacheLoader`可能会抛出异常，所以get(K)可能会抛出`Execution`。如果在`CacheLoader`中定义了一个非异常检查的`load`方法，那么在查询取值时可以使用`getUnchecked(Key)`;但是如果你声明了throws，则一定不要调用`getUnchecked(Key)`. 下面是一个例子：\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .expireAfterAccess(10, TimeUnit.MINUTES)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n\n...  \nreturn graphs.getUnchecked(key);  \n```\n\n当我们想要获取N多值的时候，在查询时可以使用方法`getAll(Iterable<? extends K>)`.在getAll中，对每一个不存在于cache里的key都会执行一个单独的对`CacheLoader.load`的方法调用来加载该值。看，guava提供了如此优秀的方法当进行一次getAll比多次get更有优势时，我们就应该重载`CacheLoader.loadAll`来实现这个功能。\n\n可以通过实现`CacheLoader.loadAll`这个方法来加载那些不被包含的显示请求的值。\n\n如果想要设定cache有一定的大小可以通过`CacheBuilder.maximumSize(long)`来设定。如此设定会使得cache在达到限定值时删除那些没有被使用过或者不经常使用的entries.\n\n> From a Callable: 所有的Guava caches，不管是否是loading模式的，都支持get(K, Callable<V>)方法。这个方法会从cache中返回与该key相关联的value，或者从Callable中计算该值并把它放进cache中。这个方法使用了一个非常简单的模式\"if cached, return; otherwise create, cache and return\"\n\n```java\nCache<Key, Value> cache = CacheBuilder.newBuilder()  \n    .maximumSize(1000)  \n    .build(); // look Ma, no CacheLoader  \n...  \ntry {  \n  // If the key wasn't in the \"easy to compute\" group, we need to  \n  // do things the hard way.  \n  cache.get(key, new Callable<Value>() {  \n    @Override  \n    public Value call() throws AnyException {  \n      return doThingsTheHardWay(key);  \n    }  \n  });  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\nInserted Directly : Values也可以通过cache.put(key,value)直接将值插入cache中。该方法将重写先前与key匹配的entry。\n\n## Eviction\n一个不能避免的问题：由于内存原因，我们不能将所有的东西都加载进cache中。那么你必须下决定：一个cache entry应该何时被抛弃。Guava提供了三种entry释放策略：size-basd evicton，time-based eviction 和reference-based eviction\n\n### Size-based Eviction\n如果你的cache不允许扩容,即不允许超过设定的最大值，那么使用CacheBuilder.maxmuSize(long)即可。在这种条件下，cache会自己释放掉那些最近没有或者不经常使用的entries内存。注意：cache并不是在超过限定时才会删除掉那些entries，而是在即将达到这个限定值时，那么你就要小心考虑这种情况了，因为很明显即使没有达到这个限定值，cache仍然会进行删除操作。\n\n还有一种情况：cache里不同的entries可能会有不同的weight。例如：如果你的cache values有着截然不同的内存占用----你可以使用CacheBuilder.weigher(Weigher)设定weigh和使用CacheBuilder.maximumWeight(long)设定一个最大值。\n下面代码展示了对weight的使用\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumWeight(100000)  \n       .weigher(new Weigher<Key, Graph>() {  \n          public int weigh(Key k, Graph g) {  \n            return g.vertices().size();  \n          }  \n        })  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n### Timed Eviction\nCacheBuilder 提供了俩种方式来实现这一模式\nexpireAfterAccess(long, TimeUnit)\n从最后一次访问(读或者写)开始计时，过了这段指定的时间就会释放掉该entries。注意：那些被删掉的entries的顺序时和size-based eviction是十分相似的。\nexpireAfterWrite(long,TimeUnit)\n它是从entries被创建或者最后一次被修改值的点来计时的，如果从这个点开始超过了那段指定的时间，entries就会被删除掉。这点设计的很精明，因为数据会随着时间变得越来越陈旧。\n如果想要测试Timed Eviction，使用Ticker interface和CacheBuilder.ticker(Ticker)方法对你的cache设定一个时间即可，那么你就不需要去等待系统时间了。\n\n### Reference-based Eviction\nGuava为你准备了entries的垃圾回收器，对于keys或者values可以使用`weak reference` ，对于values可以使用 `soft reference`.\n\n`CacheBuilder.weakKeys()`通过weak reference存储keys。在这种情况下，如果keys没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个key的，而不是equals();\n\n`CacheBuilder.weakValues()`  通过weak referene 存储values.在这种情况下，如果valves没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个values的，而不是equals();\nCacheBuilder.softValues()\n\n### Explicit Removals\n也许在某年某月某天你不想再等cache释放entries，而是自己能手动的去释放掉这些entries，下面三个方法会帮助你\n* 单个释放：Cache.invalidate(key)\n* 多个释放：Cache.invalidateAll(keys)\n* 全部释放：Cache.invalidateAll()\n\n### Removal Listeners\ncache允许你指定一个removal listener监听entry的移除操作(例如`CacheBuilder.removalListener(RemovalListener)`).通过R`emovaNotification`获得的`RemovalListener`制定了RemovalCause,key和value`。\n\n>注意RemovalListener抛出的任何异常都会被Logger记录然后被丢弃\n\n```java\nCacheLoader<Key, DatabaseConnection> loader = new CacheLoader<Key, DatabaseConnection> () {  \n  public DatabaseConnection load(Key key) throws Exception {  \n    return openConnection(key);  \n  }  \n};  \nRemovalListener<Key, DatabaseConnection> removalListener = new RemovalListener<Key, DatabaseConnection>() {  \n  public void onRemoval(RemovalNotification<Key, DatabaseConnection> removal) {  \n    DatabaseConnection conn = removal.getValue();  \n    conn.close(); // tear down properly  \n  }  \n};  \n\nreturn CacheBuilder.newBuilder()  \n  .expireAfterWrite(2, TimeUnit.MINUTES)  \n  .removalListener(removalListener)  \n  .build(loader);  \n```\n警告：removal listeners是被默认同步执行的，而且cache的维护是在其普通操作中维护的，那么“昂贵的”removal listener会降低cache操作(某些方法)的效率。如果你在使用一个\"昂贵的\"removal listener，你可以使用RemovalListener.asynchronous(RemovalListener,Executor),将其布置成异步操作.\n","slug":"Java 工具库/Guava CachesExplained","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihm20007vjs6dgnh55cn"},{"date":"2016-05-08T16:00:00.000Z","title":"JMeter","_content":"使用JMeter压测服务器登录压力,首先给出几张图看一下我们的配置\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter5.png)\n> 最后一张图是概要结果, 测试GameCenter结果.csv 是聚合报告结果\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter6.png)\n这个是我们要配置的统计结果, 我们只统计了延迟, 耗时以及消息的字节数.\n\n下面我们看一下, JMeter官方对Aggregate report(聚合报告)的说明:\n\n聚合报告为每个不同名的Sampler(注意是不同名的哦)都创建了一个结果记录. 在结果记录中不仅仅统计了请求响应信息, 还提供了对请求的数，最小延迟值，最大延迟值，平均延迟，请求产生的错误比，吞吐量以及每秒吞吐产生的字节数的统计。JMeter在统计时已经考虑了生成消息所消耗的时间. 如果其他的采样器以及定时器在同一个线程中, 那么这将会增加总的时间统计, 从而降低吞吐量. 因此俩个名称不相同的采样器产生的吞吐量加在一起才是总的吞吐量. \n\n在聚合报告中, 计算Median和90% Line值需要消耗额外的内存. JMeter现在将耗时相同的采样都合并到了一起,如此一来可以尽量减少内存占用．然而在某些情况下，　可能还会产生大量消耗内存的情况，因此推荐的方式是使用listener，然后从CSV或者XML文件中重新加载结果进行计算.\n\n* Label - 统计标签\n* # Samples - 相同名称的标签下采样的次数\n* Average - 统计数据结果的平均耗时时间\n* Median - 统计数据中中间的耗时时间, 50%的采样不会超过这个时间. 剩下的则大于等于这个值.\n* 90% Line - 统计结果中90%的不会超过这个时间.剩下的则大于等于这个值.\n* 95% Line - 统计结果中95%的不会超过这个时间.剩下的则大于等于这个值.\n* 99% Line - 统计结果中99%的不会超过这个时间.剩下的则大于等于这个值.\n* Min - 统计结果中最短的耗时时间. \n* Max - 统计结果中最长的耗时时间. \n* Error % - 统计结果中发生错误的百分比. \n* Throughput - 吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5.\n* Kb/sec - The throughput measured in Kilobytes per second\n\n\n接下来我们看一下Summy Report\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter7.png)\nsummary 报告为每个不同名的请求(注意是不同名的哦)都创建了一个结果记录. 这个和聚合报告非常像, 但不同的是它所使用的内存要比聚合报告少.\n\n* Label - 统计标签\n* # Samples - 相同名称的标签下采样的次数\n* Average - 该组统计的平均耗时\n* Min - 该组采样中最短的耗时时间\n* Max - 该组采样中最长的耗时时间\n* Std. Dev. - 采样耗时的标准偏差(Standard Deviation )\n* Error % - 请求发生错误的百分比\n* Throughput -  吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5.\n* Kb/sec - The throughput measured in Kilobytes per second\n* Avg. Bytes - average size of the sample response in bytes. (in JMeter 2.2 it wrongly showed the value in kB)","source":"_posts/Java 工具库/JMeter.md","raw":"category: Java工具\ndate: 2016-05-09\ntitle: JMeter\n---\n使用JMeter压测服务器登录压力,首先给出几张图看一下我们的配置\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter5.png)\n> 最后一张图是概要结果, 测试GameCenter结果.csv 是聚合报告结果\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter6.png)\n这个是我们要配置的统计结果, 我们只统计了延迟, 耗时以及消息的字节数.\n\n下面我们看一下, JMeter官方对Aggregate report(聚合报告)的说明:\n\n聚合报告为每个不同名的Sampler(注意是不同名的哦)都创建了一个结果记录. 在结果记录中不仅仅统计了请求响应信息, 还提供了对请求的数，最小延迟值，最大延迟值，平均延迟，请求产生的错误比，吞吐量以及每秒吞吐产生的字节数的统计。JMeter在统计时已经考虑了生成消息所消耗的时间. 如果其他的采样器以及定时器在同一个线程中, 那么这将会增加总的时间统计, 从而降低吞吐量. 因此俩个名称不相同的采样器产生的吞吐量加在一起才是总的吞吐量. \n\n在聚合报告中, 计算Median和90% Line值需要消耗额外的内存. JMeter现在将耗时相同的采样都合并到了一起,如此一来可以尽量减少内存占用．然而在某些情况下，　可能还会产生大量消耗内存的情况，因此推荐的方式是使用listener，然后从CSV或者XML文件中重新加载结果进行计算.\n\n* Label - 统计标签\n* # Samples - 相同名称的标签下采样的次数\n* Average - 统计数据结果的平均耗时时间\n* Median - 统计数据中中间的耗时时间, 50%的采样不会超过这个时间. 剩下的则大于等于这个值.\n* 90% Line - 统计结果中90%的不会超过这个时间.剩下的则大于等于这个值.\n* 95% Line - 统计结果中95%的不会超过这个时间.剩下的则大于等于这个值.\n* 99% Line - 统计结果中99%的不会超过这个时间.剩下的则大于等于这个值.\n* Min - 统计结果中最短的耗时时间. \n* Max - 统计结果中最长的耗时时间. \n* Error % - 统计结果中发生错误的百分比. \n* Throughput - 吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5.\n* Kb/sec - The throughput measured in Kilobytes per second\n\n\n接下来我们看一下Summy Report\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jmeter/JMeter7.png)\nsummary 报告为每个不同名的请求(注意是不同名的哦)都创建了一个结果记录. 这个和聚合报告非常像, 但不同的是它所使用的内存要比聚合报告少.\n\n* Label - 统计标签\n* # Samples - 相同名称的标签下采样的次数\n* Average - 该组统计的平均耗时\n* Min - 该组采样中最短的耗时时间\n* Max - 该组采样中最长的耗时时间\n* Std. Dev. - 采样耗时的标准偏差(Standard Deviation )\n* Error % - 请求发生错误的百分比\n* Throughput -  吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5.\n* Kb/sec - The throughput measured in Kilobytes per second\n* Avg. Bytes - average size of the sample response in bytes. (in JMeter 2.2 it wrongly showed the value in kB)","slug":"Java 工具库/JMeter","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihm60009vjs60jkmudkp"},{"date":"2016-04-19T16:00:00.000Z","title":"JProfiler nowait连接","_content":"> 下载安装Linux版本(我选择的是LINUX Setup Executable (43 MB) 版本). 下载完成之后, 直接执行下载文件jprofiler_linux_9_1_1.sh就可以了, 然后按照提示一步一步安装.\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler5.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler6.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler7.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler8.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler9.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler10.png)\n\n> 但是需要注意的是, 这种连接方式十分消耗服务器性能, 当我开启了方法消耗统计了之后, 跑了500个机器人之后, 就已经卡的不得了了.","source":"_posts/Java 工具库/JProfiler nowait连接.md","raw":"category: Java工具\ndate: 2016-04-20\ntitle: JProfiler nowait连接\n---\n> 下载安装Linux版本(我选择的是LINUX Setup Executable (43 MB) 版本). 下载完成之后, 直接执行下载文件jprofiler_linux_9_1_1.sh就可以了, 然后按照提示一步一步安装.\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler5.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler6.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler7.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler8.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler9.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/jprofiler/nowait/jprofiler10.png)\n\n> 但是需要注意的是, 这种连接方式十分消耗服务器性能, 当我开启了方法消耗统计了之后, 跑了500个机器人之后, 就已经卡的不得了了.","slug":"Java 工具库/JProfiler nowait连接","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihme000bvjs68ihtdns8"},{"date":"2016-02-02T16:00:00.000Z","title":"MessagePack 初探","_content":"MessagePack 是一个高效的二进制数据序列化工具. 使用它可以让你像使用JSON那样在多种语言中进行数据交换, 但是它比JSON更加小巧,迅捷.\n\n在Java中使用的话, 我们首先添加maven依赖\n```xml\n <dependency>\n    <groupId>org.msgpack</groupId>\n    <artifactId>msgpack</artifactId>\n    <version>0.6.12</version>\n</dependency>\n```\n首先看一个简单的示例\n```java\nimport org.msgpack.MessagePack;\nimport org.msgpack.annotation.Message;\n\npublic class Main1 {\n    @Message // Annotation\n    public static class MyMessage {\n        // public fields are serialized.\n        public String name;\n        public double version;\n    }\n\n    public static void main(String[] args) throws Exception {\n        MyMessage src = new MyMessage();\n        src.name = \"msgpack\";\n        src.version = 0.6;\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        byte[] bytes = msgpack.write(src);\n        // Deserialize\n        MyMessage dst = msgpack.read(bytes, MyMessage.class);\n    }\n}\n```\n在上面的例子中我们看到将一个`MyMessage`序列化成byte数组, 同时又将其反序列化出来了. 但是如果我们要同时序列化多个对象呢？那么我们就可以使用`Packer`和`Unpacker`.\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.annotation.Message;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.unpacker.Unpacker;\n\npublic class Main2 {\n    @Message\n    public static class MyMessage {\n        public String name;\n        public double version;\n    }\n\n    public static void main(String[] args) throws Exception {\n        MyMessage src1 = new MyMessage();\n        src1.name = \"msgpack\";\n        src1.version = 0.6;\n        MyMessage src2 = new MyMessage();\n        src2.name = \"muga\";\n        src2.version = 10.0;\n        MyMessage src3 = new MyMessage();\n        src3.name = \"frsyukik\";\n        src3.version = 1.0;\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        Packer packer = msgpack.createPacker(out);\n        packer.write(src1);\n        packer.write(src2);\n        packer.write(src3);\n        byte[] bytes = out.toByteArray();\n\n        // Deserialize\n        ByteArrayInputStream in = new ByteArrayInputStream(bytes);\n        Unpacker unpacker = msgpack.createUnpacker(in);\n        MyMessage dst1 = unpacker.read(MyMessage.class);\n        MyMessage dst2 = unpacker.read(MyMessage.class);\n        MyMessage dst3 = unpacker.read(MyMessage.class);\n    }\n}\n```\n其实`Packer`和`Unpacker`内置了非常多了序列化类型\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.unpacker.Unpacker;\n\npublic class Main3 {\n    public static void main(String[] args) throws Exception {\n        MessagePack msgpack = new MessagePack();\n\n        // Serialization\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        Packer packer = msgpack.createPacker(out);\n\n        // 对原生类型进行序列化\n        packer.write(true); // boolean value\n        packer.write(10); // int value\n        packer.write(10.5); // double value\n\n        // 对原生包装类型进行序列化\n        packer.write(Boolean.TRUE);\n        packer.write(new Integer(10));\n        packer.write(new Double(10.5));\n\n        // 对数组进行序列化\n        packer.write(new int[] { 1, 2, 3, 4 });\n        packer.write(new Double[] { 10.5, 20.5 });\n        packer.write(new String[] { \"msg\", \"pack\", \"for\", \"java\" });\n        packer.write(new byte[] { 0x30, 0x31, 0x32 }); // byte array\n\n        // 对其他引用类型进行序列化\n        packer.write(\"MessagePack\"); // String object\n        packer.write(ByteBuffer.wrap(new byte[] { 0x30, 0x31, 0x32 })); // ByteBuffer object\n        packer.write(BigInteger.ONE); // BigInteger object\n\n        // 反序列化\n        byte[] bytes = out.toByteArray();\n        ByteArrayInputStream in = new ByteArrayInputStream(bytes);\n        Unpacker unpacker = msgpack.createUnpacker(in);\n\n        // 反序列化出原生类型\n        boolean b = unpacker.readBoolean(); // boolean value\n        int i = unpacker.readInt(); // int value\n        double d = unpacker.readDouble(); // double value\n\n        // 反序列化出原生包装类型\n        Boolean wb = unpacker.read(Boolean.class);\n        Integer wi = unpacker.read(Integer.class);\n        Double wd = unpacker.read(Double.class);\n\n        // 反序列化出数组\n        int[] ia = unpacker.read(int[].class);\n        Double[] da = unpacker.read(Double[].class);\n        String[] sa = unpacker.read(String[].class);\n        byte[] ba = unpacker.read(byte[].class);\n\n        // 反序列化出 String, ByteBuffer, BigInteger, List 和 Map\n        String ws = unpacker.read(String.class);\n        ByteBuffer buf = unpacker.read(ByteBuffer.class);\n        BigInteger bi = unpacker.read(BigInteger.class);\n    }\n}\n```\n对于`List, Map`这俩种类型的序列化, 我们需要额外说明一下. 在序列化`List, Map`的时候, 我们需要使用`Template`对其进行转换.\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.util.*;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.template.Template;\nimport org.msgpack.unpacker.Unpacker;\nimport static org.msgpack.template.Templates.tList;\nimport static org.msgpack.template.Templates.tMap;\nimport static org.msgpack.template.Templates.TString;\n\npublic class Main4 {\n    public static void main(String[] args) throws Exception {\n        MessagePack msgpack = new MessagePack();\n\n\t\t// 创建序列化/反序列化 List 和 Map 对象的模板\n\t\tTemplate<List<String>> listTmpl = tList(TString);\n\t\tTemplate<Map<String, String>> mapTmpl = tMap(TString, TString);\n\n\t\t// 开始序列化\n\t\tByteArrayOutputStream out = new ByteArrayOutputStream();\n\t\tPacker packer = msgpack.createPacker(out);\n\n\t\t// 序列化 List 对象\n\t\tList<String> list = new ArrayList<String>();\n\t\tlist.add(\"msgpack\");\n\t\tlist.add(\"for\");\n\t\tlist.add(\"java\");\n\t\tpacker.write(list); // List object\n\n\t\t// 序列化 Map 对象\n\t\tMap<String, String> map = new HashMap<String, String>();\n\t\tmap.put(\"sadayuki\", \"furuhashi\");\n\t\tmap.put(\"muga\", \"nishizawa\");\n\t\tpacker.write(map); // Map object\n\n\t\t// 开始反序列化\n\t\tbyte[] bytes = out.toByteArray();\n\t\tByteArrayInputStream in = new ByteArrayInputStream(bytes);\n\t\tUnpacker unpacker = msgpack.createUnpacker(in);\n\n\t\t// 反序列化出 List 对象\n\t\tList<String> dstList = unpacker.read(listTmpl);\n\n\t\t//  反序列化出 Map 对象\n\t\tMap<String, String> dstMap = unpacker.read(mapTmpl);\n    }\n}\n```\n\n有时候我们可能没有办法将POJO类添加上`Message`注解(可能没有访问那个类的权限), 但是我们又想对其进行序列化, 那怎么办呢？\n```\nMessagePack msgpack = new MessagePack();\nmsgpack.register(MyMessage2.class);\n```\n我们只要向需要序列化的类注册到`MessagePack`上就可以了.\n\n有时候,我们可能不需要对某个属性进行序列化, 例如线上某个老版本里并没有A属性, 但是在新的版本里填上了A属性, 但是又要兼容老版本怎么办呢？我们可以使用`@Optional`注解\n```java\n@Message\npublic static class MyMessage {\n    public String name;\n    public double version;\n\n    // new field\n    @Optional\n    public int flag = 0;\n}\n```\n\nMessagePack还提供了动态类型特性.\n```java\nimport java.util.*;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.type.Value;\nimport org.msgpack.unpacker.Converter;\n\nimport static org.msgpack.template.Templates.*;\n\npublic class Main5 {\n    public static void main(String[] args) throws Exception {\n        // Create serialize objects.\n        List<String> src = new ArrayList<String>();\n        src.add(\"msgpack\");\n        src.add(\"kumofs\");\n        src.add(\"viver\");\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        byte[] raw = msgpack.write(src);\n\n        // Deserialize directly using a template\n        List<String> dst1 = msgpack.read(raw, tList(TString));\n\n        // Or, Deserialze to Value then convert type.\n        Value dynamic = msgpack.read(raw);\n        List<String> dst2 = new Converter(dynamic).read(tList(TString));\n    }\n}\n```\n当从MessagePack里读取数据的时候, 我们可以先不指定其转换的类型,　使用`Value`来代替, 等后期我们再使用`Converter` 对其转换.\n\n接下来我们对其与JSON进行对比\n```java\npublic class msgpack {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tMessagePack msgpack = new MessagePack();\n\n\t\tList<SeObj> list = list();\n\t\tlong start1 = System.currentTimeMillis();\n\t\tbyte[] bytes1 = msgpack.write(list);\n\t\tlong end1 = System.currentTimeMillis();\n\t\tSystem.out.println((end1 - start1) + \" : \" + bytes1.length);\n\n\t\tlong start2 = System.currentTimeMillis();\n\t\tString json = JSON.toJSONString(list);\n\t\tlong end2 = System.currentTimeMillis();\n\t\tSystem.out.println((end2 - start2) + \" : \" + json.getBytes().length);\n\t}\n\n\tpublic static List<SeObj> list() {\n\t\tList<SeObj> list = new ArrayList<>();\n\t\tRandom random = new Random();\n\t\tfor (int i = 0; i < 10000; i++) {\n\t\t\tSeObj seObj = new SeObj();\n\t\t\tseObj.id = random.nextInt(100000);\n\t\t\tseObj.tall = random.nextFloat();\n\t\t\tseObj.name = \"name\" + random.nextInt(100000);\n\t\t\tlist.add(seObj);\n\t\t}\n\t\treturn list;\n\t}\n}\n\n@Message\nclass SeObj {\n\tpublic int id;\n\tpublic String name;\n\tpublic float tall;\n}\n```\n结果为\n```java\n100的结果\n194 : 1960\n50 : 4947\n1000的结果\n210 : 19589\n70 : 49424\n10000的结果\n212 : 195765\n160 : 493987\n100000的结果\n283 : 1956964\n330 : 4940270\n1000000的结果\n649 : 19573508\n1878 : 49404120\n```\n我们发现MessagePack的耗时相对来说是比较稳定的, 但是在生成的数据量上比JSON要强一倍多\n","source":"_posts/Java 工具库/MessagePack 初探.md","raw":"category: Java工具\ndate: 2016-02-03\ntitle: MessagePack 初探\n---\nMessagePack 是一个高效的二进制数据序列化工具. 使用它可以让你像使用JSON那样在多种语言中进行数据交换, 但是它比JSON更加小巧,迅捷.\n\n在Java中使用的话, 我们首先添加maven依赖\n```xml\n <dependency>\n    <groupId>org.msgpack</groupId>\n    <artifactId>msgpack</artifactId>\n    <version>0.6.12</version>\n</dependency>\n```\n首先看一个简单的示例\n```java\nimport org.msgpack.MessagePack;\nimport org.msgpack.annotation.Message;\n\npublic class Main1 {\n    @Message // Annotation\n    public static class MyMessage {\n        // public fields are serialized.\n        public String name;\n        public double version;\n    }\n\n    public static void main(String[] args) throws Exception {\n        MyMessage src = new MyMessage();\n        src.name = \"msgpack\";\n        src.version = 0.6;\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        byte[] bytes = msgpack.write(src);\n        // Deserialize\n        MyMessage dst = msgpack.read(bytes, MyMessage.class);\n    }\n}\n```\n在上面的例子中我们看到将一个`MyMessage`序列化成byte数组, 同时又将其反序列化出来了. 但是如果我们要同时序列化多个对象呢？那么我们就可以使用`Packer`和`Unpacker`.\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.annotation.Message;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.unpacker.Unpacker;\n\npublic class Main2 {\n    @Message\n    public static class MyMessage {\n        public String name;\n        public double version;\n    }\n\n    public static void main(String[] args) throws Exception {\n        MyMessage src1 = new MyMessage();\n        src1.name = \"msgpack\";\n        src1.version = 0.6;\n        MyMessage src2 = new MyMessage();\n        src2.name = \"muga\";\n        src2.version = 10.0;\n        MyMessage src3 = new MyMessage();\n        src3.name = \"frsyukik\";\n        src3.version = 1.0;\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        Packer packer = msgpack.createPacker(out);\n        packer.write(src1);\n        packer.write(src2);\n        packer.write(src3);\n        byte[] bytes = out.toByteArray();\n\n        // Deserialize\n        ByteArrayInputStream in = new ByteArrayInputStream(bytes);\n        Unpacker unpacker = msgpack.createUnpacker(in);\n        MyMessage dst1 = unpacker.read(MyMessage.class);\n        MyMessage dst2 = unpacker.read(MyMessage.class);\n        MyMessage dst3 = unpacker.read(MyMessage.class);\n    }\n}\n```\n其实`Packer`和`Unpacker`内置了非常多了序列化类型\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.unpacker.Unpacker;\n\npublic class Main3 {\n    public static void main(String[] args) throws Exception {\n        MessagePack msgpack = new MessagePack();\n\n        // Serialization\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        Packer packer = msgpack.createPacker(out);\n\n        // 对原生类型进行序列化\n        packer.write(true); // boolean value\n        packer.write(10); // int value\n        packer.write(10.5); // double value\n\n        // 对原生包装类型进行序列化\n        packer.write(Boolean.TRUE);\n        packer.write(new Integer(10));\n        packer.write(new Double(10.5));\n\n        // 对数组进行序列化\n        packer.write(new int[] { 1, 2, 3, 4 });\n        packer.write(new Double[] { 10.5, 20.5 });\n        packer.write(new String[] { \"msg\", \"pack\", \"for\", \"java\" });\n        packer.write(new byte[] { 0x30, 0x31, 0x32 }); // byte array\n\n        // 对其他引用类型进行序列化\n        packer.write(\"MessagePack\"); // String object\n        packer.write(ByteBuffer.wrap(new byte[] { 0x30, 0x31, 0x32 })); // ByteBuffer object\n        packer.write(BigInteger.ONE); // BigInteger object\n\n        // 反序列化\n        byte[] bytes = out.toByteArray();\n        ByteArrayInputStream in = new ByteArrayInputStream(bytes);\n        Unpacker unpacker = msgpack.createUnpacker(in);\n\n        // 反序列化出原生类型\n        boolean b = unpacker.readBoolean(); // boolean value\n        int i = unpacker.readInt(); // int value\n        double d = unpacker.readDouble(); // double value\n\n        // 反序列化出原生包装类型\n        Boolean wb = unpacker.read(Boolean.class);\n        Integer wi = unpacker.read(Integer.class);\n        Double wd = unpacker.read(Double.class);\n\n        // 反序列化出数组\n        int[] ia = unpacker.read(int[].class);\n        Double[] da = unpacker.read(Double[].class);\n        String[] sa = unpacker.read(String[].class);\n        byte[] ba = unpacker.read(byte[].class);\n\n        // 反序列化出 String, ByteBuffer, BigInteger, List 和 Map\n        String ws = unpacker.read(String.class);\n        ByteBuffer buf = unpacker.read(ByteBuffer.class);\n        BigInteger bi = unpacker.read(BigInteger.class);\n    }\n}\n```\n对于`List, Map`这俩种类型的序列化, 我们需要额外说明一下. 在序列化`List, Map`的时候, 我们需要使用`Template`对其进行转换.\n```java\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.util.*;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.packer.Packer;\nimport org.msgpack.template.Template;\nimport org.msgpack.unpacker.Unpacker;\nimport static org.msgpack.template.Templates.tList;\nimport static org.msgpack.template.Templates.tMap;\nimport static org.msgpack.template.Templates.TString;\n\npublic class Main4 {\n    public static void main(String[] args) throws Exception {\n        MessagePack msgpack = new MessagePack();\n\n\t\t// 创建序列化/反序列化 List 和 Map 对象的模板\n\t\tTemplate<List<String>> listTmpl = tList(TString);\n\t\tTemplate<Map<String, String>> mapTmpl = tMap(TString, TString);\n\n\t\t// 开始序列化\n\t\tByteArrayOutputStream out = new ByteArrayOutputStream();\n\t\tPacker packer = msgpack.createPacker(out);\n\n\t\t// 序列化 List 对象\n\t\tList<String> list = new ArrayList<String>();\n\t\tlist.add(\"msgpack\");\n\t\tlist.add(\"for\");\n\t\tlist.add(\"java\");\n\t\tpacker.write(list); // List object\n\n\t\t// 序列化 Map 对象\n\t\tMap<String, String> map = new HashMap<String, String>();\n\t\tmap.put(\"sadayuki\", \"furuhashi\");\n\t\tmap.put(\"muga\", \"nishizawa\");\n\t\tpacker.write(map); // Map object\n\n\t\t// 开始反序列化\n\t\tbyte[] bytes = out.toByteArray();\n\t\tByteArrayInputStream in = new ByteArrayInputStream(bytes);\n\t\tUnpacker unpacker = msgpack.createUnpacker(in);\n\n\t\t// 反序列化出 List 对象\n\t\tList<String> dstList = unpacker.read(listTmpl);\n\n\t\t//  反序列化出 Map 对象\n\t\tMap<String, String> dstMap = unpacker.read(mapTmpl);\n    }\n}\n```\n\n有时候我们可能没有办法将POJO类添加上`Message`注解(可能没有访问那个类的权限), 但是我们又想对其进行序列化, 那怎么办呢？\n```\nMessagePack msgpack = new MessagePack();\nmsgpack.register(MyMessage2.class);\n```\n我们只要向需要序列化的类注册到`MessagePack`上就可以了.\n\n有时候,我们可能不需要对某个属性进行序列化, 例如线上某个老版本里并没有A属性, 但是在新的版本里填上了A属性, 但是又要兼容老版本怎么办呢？我们可以使用`@Optional`注解\n```java\n@Message\npublic static class MyMessage {\n    public String name;\n    public double version;\n\n    // new field\n    @Optional\n    public int flag = 0;\n}\n```\n\nMessagePack还提供了动态类型特性.\n```java\nimport java.util.*;\n\nimport org.msgpack.MessagePack;\nimport org.msgpack.type.Value;\nimport org.msgpack.unpacker.Converter;\n\nimport static org.msgpack.template.Templates.*;\n\npublic class Main5 {\n    public static void main(String[] args) throws Exception {\n        // Create serialize objects.\n        List<String> src = new ArrayList<String>();\n        src.add(\"msgpack\");\n        src.add(\"kumofs\");\n        src.add(\"viver\");\n\n        MessagePack msgpack = new MessagePack();\n        // Serialize\n        byte[] raw = msgpack.write(src);\n\n        // Deserialize directly using a template\n        List<String> dst1 = msgpack.read(raw, tList(TString));\n\n        // Or, Deserialze to Value then convert type.\n        Value dynamic = msgpack.read(raw);\n        List<String> dst2 = new Converter(dynamic).read(tList(TString));\n    }\n}\n```\n当从MessagePack里读取数据的时候, 我们可以先不指定其转换的类型,　使用`Value`来代替, 等后期我们再使用`Converter` 对其转换.\n\n接下来我们对其与JSON进行对比\n```java\npublic class msgpack {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tMessagePack msgpack = new MessagePack();\n\n\t\tList<SeObj> list = list();\n\t\tlong start1 = System.currentTimeMillis();\n\t\tbyte[] bytes1 = msgpack.write(list);\n\t\tlong end1 = System.currentTimeMillis();\n\t\tSystem.out.println((end1 - start1) + \" : \" + bytes1.length);\n\n\t\tlong start2 = System.currentTimeMillis();\n\t\tString json = JSON.toJSONString(list);\n\t\tlong end2 = System.currentTimeMillis();\n\t\tSystem.out.println((end2 - start2) + \" : \" + json.getBytes().length);\n\t}\n\n\tpublic static List<SeObj> list() {\n\t\tList<SeObj> list = new ArrayList<>();\n\t\tRandom random = new Random();\n\t\tfor (int i = 0; i < 10000; i++) {\n\t\t\tSeObj seObj = new SeObj();\n\t\t\tseObj.id = random.nextInt(100000);\n\t\t\tseObj.tall = random.nextFloat();\n\t\t\tseObj.name = \"name\" + random.nextInt(100000);\n\t\t\tlist.add(seObj);\n\t\t}\n\t\treturn list;\n\t}\n}\n\n@Message\nclass SeObj {\n\tpublic int id;\n\tpublic String name;\n\tpublic float tall;\n}\n```\n结果为\n```java\n100的结果\n194 : 1960\n50 : 4947\n1000的结果\n210 : 19589\n70 : 49424\n10000的结果\n212 : 195765\n160 : 493987\n100000的结果\n283 : 1956964\n330 : 4940270\n1000000的结果\n649 : 19573508\n1878 : 49404120\n```\n我们发现MessagePack的耗时相对来说是比较稳定的, 但是在生成的数据量上比JSON要强一倍多\n","slug":"Java 工具库/MessagePack 初探","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmk000dvjs6jqy31klq"},{"date":"2016-01-18T16:00:00.000Z","title":"OWNER 初探","_content":"OWNER是一个Java库，目标是最大限度的减少应用程序中处理Java properties的代码。\n\n主要功能\n* 加载策略：OWNER通过匹配接口类名和properties文件名自动解析并映射；也可以通过注解定制properties文件名。\n* 导入properties：另外一种加载properties文件到映射接口的方法。\n* 参数化properties：另外一个实用功能，给接口方法提供参数，通过参数配置。\n* 类型转换：支持从String类型到基本类型和枚举类型的转换。\n* 变量扩展：引用properties中的其他属性。\n* 热加载：支持热加载。\n* 可访问和可变：可以继承Config的子接口Accessible或者Mutable实现属性的可访问和可变。\n* 调试：支持调试功能。\n* 禁用功能：可禁用引起问题的功能。\n* 配置ConfigFactory：ConfigFactory也是可配置的。\n* XML支持：支持XML配置。\n* 事件支持：OWNER实现了功能丰富的事件系统，使你知道热加载的发生和属性变化。\n* 单例模式：配置信息在一个应用中是单例的。\n\nOWNER同样是开源的, 我们可以使用maven来引用它\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.aeonbits.owner</groupId>\n        <artifactId>owner</artifactId>\n        <version>1.0.8</version>\n    </dependency>\n</dependencies>\n```\n或者使用java8版本\n```xml\n<dependencies>\n        <dependency>\n            <groupId>org.aeonbits.owner</groupId>\n            <artifactId>owner-java8</artifactId>\n            <version>1.0.6</version>\n        </dependency>\n</dependencies>\n```\n\n## 基本用法\n我们现在在MAVEN项目中测试一下\n首先我们在`test\\src\\main\\java\\ownerTest`目录下创建一个配置类\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.Config;\n\npublic interface ServerConfig extends Config {\n\tint port();\n\tString hostname();\n\t@DefaultValue(\"42\")\n\tint maxThreads();\n}\n```\n然后在`test\\src\\main\\resources\\ownerTest`目录下创建配置文件`ServerConfig.properties`\n```java\nport=80\nhostname=foobar.com\nmaxThreads=100\n```\n然后我们书写一个测试类\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.ConfigFactory;\n\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\tServerConfig cfg = ConfigFactory.create(ServerConfig.class);\n\t\tSystem.out.println(\"Server \" + cfg.hostname() + \":\" + cfg.port() + \" will run \" + cfg.maxThreads());\n\t}\n}\n```\n这时OWNER会自动地将`ServerConfig.properties`配置文件匹配到`ServerConfig`上, 输出结果为\n```java\nServer foobar.com:80 will run 100\n```\n我们看到在`ServerConfig`里我们使用了一个`@DefaultValue`注解, 当在配置文件里找不到这个值的时候, 这个注解值会为我们设置上注解里的默认值.\n> 如果在配置文件里找不到这个设置也没有添加`@DefaultValue`会产生一个空指针异常\n\n有时候我们在配置文件里会使用`server.http.port=80`的配置, 那么这种情况下我们就在使用`@Key`注解\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.Config;\n\npublic interface ServerConfig extends Config {\n\t@Key(\"server.http.port\")\n\tint port();\n\n\t@Key(\"server.host.name\")\n\tString hostname();\n\n\t@Key(\"server.max.threads\")\n\t@DefaultValue(\"42\")\n\tint maxThreads();\n}\n```\n我们的配置文件如下\n```java\nserver.http.port=80\nserver.host.name=foobar.com\nserver.max.threads=100\n```\n\n## 加载策略\n正如上文所说, OWNER是按照classpath去自动匹配配置类和配置文件的, 但是其实我们可以自定义配置文件的加载策略, 如下例\n```java\n@Sources({ \"file:~/.myapp.config\",\n           \"file:/etc/myapp.config\",\n           \"classpath:foo/bar/baz.properties\" })\npublic interface ServerConfig extends Config {\n    @Key(\"server.http.port\")\n    int port();\n\n    @Key(\"server.host.name\")\n    String hostname();\n\n    @Key(\"server.max.threads\");\n    @DefaultValue(\"42\")\n    int maxThreads();\n}\n```\n我们使用了`@Sources`指定配置文件的路径, 按照上面的代码, 它依次按照下面的流程进行文件匹配,一旦匹配成功就进行加载忽略后面的文件\n1. `file:~/.myapp.config`  从home目录开始查找\n2. `file:/etc/myapp.config`  从绝对目录进行查找\n3. `classpath:foo/bar/baz.properties`  classpath从classpath中查找\n\n其实上面的加载策略称为`LoadType.FIRST`(完整注解`@LoadPolicy(LoadType.FIRST)`). 我们还有其他选择`LoadType.MERGE`, 示例如下:\n```java\n@LoadPolicy(LoadType.MERGE)\n@Sources({ \"file:~/.myapp.config\",\n           \"file:/etc/myapp.config\",\n           \"classpath:foo/bar/baz.properties\" })\npublic interface ServerConfig extends Config {\n    ...\n}\n```\n上面的加载策略是, 不管当前路径下是否找到了都会进行路径下查找, 但与`LoadType.FIRST`不同的是, 当找到之后它会替换之前知道的配置文件.\n> TODO 是局部替换还是整个文件一起替换呢？\n\n## 参数化\n我们还可以向配置里传递参数\n```java\npublic interface Sample extends Config {\n    @DefaultValue(\"Hello Mr. %s!\")\n    String helloMr(String name);\n}\n\nSample cfg = ConfigFactory.create(Sample.class);\nprint(cfg.helloMr(\"Luigi\")); // will println 'Hello Mr. Luigi!'\n```\n> OWNER还为我们提供了`@DisableFeature`注解, 让我们关闭参数化功能. 这个注解可以用在类或者方法的级别上\n\n## 自定义类型\n当我们使用OWNER的时候, 不仅仅可以使用原生类型, 还可以使用数组, 集合甚至是自定义类型\n\n下来我们自定义一个类型\n```java\n\n```\n\n下面我们定义一个数组和集合\n```java\npublic class MyConfig extends Config {\n\n  @DefaultValue(\"apple, pear, orange\")\n  public String[] fruit();\n\n  @Separator(\";\")\n  @DefaultValue(\"0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55\")\n  public int[] fibonacci();\n\n  @DefaultValue(\"1, 2, 3, 4\")\n  List<Integer> ints();\n\n  @DefaultValue(\n    \"http://aeonbits.org, http://github.com, http://google.com\")\n  MyOwnCollection<URL> myBookmarks();\n\n  // Concrete class are allowed (in this case java.util.Stack)\n  // when type is not specified <String> is assumed as default\n  @DefaultValue(\n    \"The Lord of the Rings,The Little Prince,The Da Vinci Code\")\n  Stack books();\n\n}\n```\nOWNER默认使用`,`分割元素. 但是我们可以通过`@Separator(\";\")`指定使用`;`进行切割, 需要注意的是OWNER只支持数组, 集合, Java原生类型, 并不支持`Map`.\n> 支持的集合有`Collection, List, Set, SortedSet`\n\n虽然我们可以使用`@Separator(\";\")`进行切割, 但是如果我们有更复杂的切割逻辑的话, 这可能就不再符合需求了, 我们可以使用`@TokenizerClass`来实现更复杂的切割逻辑\n```java\npublic class MyConfig extends Config {\n\n    @Separator(\";\")\n    @DefaultValue(\"0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55\")\n    public int[] fibonacci();\n\n    @TokenizerClass(CustomDashTokenizer.class)\n    @DefaultValue(\"foo-bar-baz\")\n    public String[] withSeparatorClass();\n\n}\n\npublic class CustomDashTokenizer implements Tokenizer {\n\n    // this logic can be as much complex as you need\n    @Override\n    public String[] tokens(String values) {\n        return values.split(\"-\", -1);\n    }\n}\n```\n> 虽然 `@Separator(\";\")` 和  `@TokenizerClass(CustomDashTokenizer.class)`都可以在方法和类的级别上进行注解, 但是他们不允许同时出现在同一个级别上, 而且当分别出现在了方法和类的级别上后, 方法上的注解会替换类上的注解.\n\nOWNER还提供了`@ConverterClass`注解来实现更加复杂的转换逻辑\n```java\ninterface MyConfig extends Config {\n    @DefaultValue(\"foobar.com:8080\")\n    @ConverterClass(ServerConverter.class)\n    Server server();\n\n    @DefaultValue(\n      \"google.com, yahoo.com:8080, owner.aeonbits.org:4000\")\n    @ConverterClass(ServerConverter.class)\n    Server[] servers();\n}\n\nclass Server {\n    private final String name;\n    private final Integer port;\n\n    public Server(String name, Integer port) {\n        this.name = name;\n        this.port = port;\n    }\n}\n\npublic class ServerConverter implements Converter<Server> {\n    public Server convert(Method targetMethod, String text) {\n        String[] split = text.split(\":\", -1);\n        String name = split[0];\n        Integer port = 80;\n        if (split.length >= 2)\n            port = Integer.valueOf(split[1]);\n        return new Server(name, port);\n    }\n}\n\nMyConfig cfg = ConfigFactory.create(MyConfig.class);\nServer s = cfg.server(); // will return a single server\nServer[] ss = cfg.servers(); // it works also with collections\n```\n\nOWNER 支持的全部自动转换类型\n\n* 原生类型: boolean, byte, short, integer, long, float, double.\n* 枚举\n* java.lang.String\n* java.net.URL, java.net.URI.\n* java.io.File\n* java.lang.Class\n* 公有构造器只有一个`java.lang.String`的类\n* 公有构造器只有一个`java.lang.Object`的类\n* 被`public static`修饰, 签名为`valueOf(java.lang.String)`返回自身的方法\n* 带有上述元素的数组\n* 带有上述类的集合(`Set, List, SortedSet or concrete implementations like LinkedHashSet`). Map and sub-interfaces are not supported.\n\n## 变量表达式\nOWNER还提供了一个非常霸道的功能 —— 变量表达式, 参考如下配置文件\n```\nstory=The ${animal} jumped over the ${target}\nanimal=quick ${color} fox\ntarget=${target.attribute} dog\ntarget.attribute=lazy\ncolor=brown\n```\n然后定义一个配置类\n```java\npublic interface ConfigWithExpansion extends Config {\n    String story();\n}\n```\n猜猜会输出什么, 对了\n```java\nThe quick brown fox jumped over the lazy dog\n```\n我们可以在配置文件里引用其他的配置\n\n同样的我们还可以在配置类完成这样的功能\n```java\npublic interface ConfigWithExpansion\n        extends Config {\n\n    @DefaultValue(\n        \"The ${animal} jumped over the ${target}\")\n    String story();\n\n    @DefaultValue(\"quick ${color} fox\")\n    String animal();\n\n    @DefaultValue(\"${target.attribute} dog\")\n    String target();\n\n    @Key(\"target.attribute\")\n    @DefaultValue(\"lazy\")\n    String targetAttribute();\n\n    @DefaultValue(\"brown\")\n    String color();\n}\n\nConfigWithExpansion conf = ConfigFactory\n    .create(ConfigWithExpansion.class);\n\nString story = conf.story();\n```\n\n如果我们不需要开启变量表达式的话, 我们可以使用`@DisableFeature(VARIABLE_EXPANSION)`\n```java\npublic interface Sample extends Config {\n    @DefaultValue(\"Earth\")\n    String world();\n\n    @DisableFeature(VARIABLE_EXPANSION)\n    @DefaultValue(\"Hello ${world}.\")\n\n    // will return the string \"Hello ${world}.\"\n    String sayHello();\n}\n```\n","source":"_posts/Java 工具库/OWNER 初探.md","raw":"category: Java工具\ndate: 2016-01-19\ntitle: OWNER 初探\n---\nOWNER是一个Java库，目标是最大限度的减少应用程序中处理Java properties的代码。\n\n主要功能\n* 加载策略：OWNER通过匹配接口类名和properties文件名自动解析并映射；也可以通过注解定制properties文件名。\n* 导入properties：另外一种加载properties文件到映射接口的方法。\n* 参数化properties：另外一个实用功能，给接口方法提供参数，通过参数配置。\n* 类型转换：支持从String类型到基本类型和枚举类型的转换。\n* 变量扩展：引用properties中的其他属性。\n* 热加载：支持热加载。\n* 可访问和可变：可以继承Config的子接口Accessible或者Mutable实现属性的可访问和可变。\n* 调试：支持调试功能。\n* 禁用功能：可禁用引起问题的功能。\n* 配置ConfigFactory：ConfigFactory也是可配置的。\n* XML支持：支持XML配置。\n* 事件支持：OWNER实现了功能丰富的事件系统，使你知道热加载的发生和属性变化。\n* 单例模式：配置信息在一个应用中是单例的。\n\nOWNER同样是开源的, 我们可以使用maven来引用它\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.aeonbits.owner</groupId>\n        <artifactId>owner</artifactId>\n        <version>1.0.8</version>\n    </dependency>\n</dependencies>\n```\n或者使用java8版本\n```xml\n<dependencies>\n        <dependency>\n            <groupId>org.aeonbits.owner</groupId>\n            <artifactId>owner-java8</artifactId>\n            <version>1.0.6</version>\n        </dependency>\n</dependencies>\n```\n\n## 基本用法\n我们现在在MAVEN项目中测试一下\n首先我们在`test\\src\\main\\java\\ownerTest`目录下创建一个配置类\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.Config;\n\npublic interface ServerConfig extends Config {\n\tint port();\n\tString hostname();\n\t@DefaultValue(\"42\")\n\tint maxThreads();\n}\n```\n然后在`test\\src\\main\\resources\\ownerTest`目录下创建配置文件`ServerConfig.properties`\n```java\nport=80\nhostname=foobar.com\nmaxThreads=100\n```\n然后我们书写一个测试类\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.ConfigFactory;\n\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\tServerConfig cfg = ConfigFactory.create(ServerConfig.class);\n\t\tSystem.out.println(\"Server \" + cfg.hostname() + \":\" + cfg.port() + \" will run \" + cfg.maxThreads());\n\t}\n}\n```\n这时OWNER会自动地将`ServerConfig.properties`配置文件匹配到`ServerConfig`上, 输出结果为\n```java\nServer foobar.com:80 will run 100\n```\n我们看到在`ServerConfig`里我们使用了一个`@DefaultValue`注解, 当在配置文件里找不到这个值的时候, 这个注解值会为我们设置上注解里的默认值.\n> 如果在配置文件里找不到这个设置也没有添加`@DefaultValue`会产生一个空指针异常\n\n有时候我们在配置文件里会使用`server.http.port=80`的配置, 那么这种情况下我们就在使用`@Key`注解\n```java\npackage ownerTest;\n\nimport org.aeonbits.owner.Config;\n\npublic interface ServerConfig extends Config {\n\t@Key(\"server.http.port\")\n\tint port();\n\n\t@Key(\"server.host.name\")\n\tString hostname();\n\n\t@Key(\"server.max.threads\")\n\t@DefaultValue(\"42\")\n\tint maxThreads();\n}\n```\n我们的配置文件如下\n```java\nserver.http.port=80\nserver.host.name=foobar.com\nserver.max.threads=100\n```\n\n## 加载策略\n正如上文所说, OWNER是按照classpath去自动匹配配置类和配置文件的, 但是其实我们可以自定义配置文件的加载策略, 如下例\n```java\n@Sources({ \"file:~/.myapp.config\",\n           \"file:/etc/myapp.config\",\n           \"classpath:foo/bar/baz.properties\" })\npublic interface ServerConfig extends Config {\n    @Key(\"server.http.port\")\n    int port();\n\n    @Key(\"server.host.name\")\n    String hostname();\n\n    @Key(\"server.max.threads\");\n    @DefaultValue(\"42\")\n    int maxThreads();\n}\n```\n我们使用了`@Sources`指定配置文件的路径, 按照上面的代码, 它依次按照下面的流程进行文件匹配,一旦匹配成功就进行加载忽略后面的文件\n1. `file:~/.myapp.config`  从home目录开始查找\n2. `file:/etc/myapp.config`  从绝对目录进行查找\n3. `classpath:foo/bar/baz.properties`  classpath从classpath中查找\n\n其实上面的加载策略称为`LoadType.FIRST`(完整注解`@LoadPolicy(LoadType.FIRST)`). 我们还有其他选择`LoadType.MERGE`, 示例如下:\n```java\n@LoadPolicy(LoadType.MERGE)\n@Sources({ \"file:~/.myapp.config\",\n           \"file:/etc/myapp.config\",\n           \"classpath:foo/bar/baz.properties\" })\npublic interface ServerConfig extends Config {\n    ...\n}\n```\n上面的加载策略是, 不管当前路径下是否找到了都会进行路径下查找, 但与`LoadType.FIRST`不同的是, 当找到之后它会替换之前知道的配置文件.\n> TODO 是局部替换还是整个文件一起替换呢？\n\n## 参数化\n我们还可以向配置里传递参数\n```java\npublic interface Sample extends Config {\n    @DefaultValue(\"Hello Mr. %s!\")\n    String helloMr(String name);\n}\n\nSample cfg = ConfigFactory.create(Sample.class);\nprint(cfg.helloMr(\"Luigi\")); // will println 'Hello Mr. Luigi!'\n```\n> OWNER还为我们提供了`@DisableFeature`注解, 让我们关闭参数化功能. 这个注解可以用在类或者方法的级别上\n\n## 自定义类型\n当我们使用OWNER的时候, 不仅仅可以使用原生类型, 还可以使用数组, 集合甚至是自定义类型\n\n下来我们自定义一个类型\n```java\n\n```\n\n下面我们定义一个数组和集合\n```java\npublic class MyConfig extends Config {\n\n  @DefaultValue(\"apple, pear, orange\")\n  public String[] fruit();\n\n  @Separator(\";\")\n  @DefaultValue(\"0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55\")\n  public int[] fibonacci();\n\n  @DefaultValue(\"1, 2, 3, 4\")\n  List<Integer> ints();\n\n  @DefaultValue(\n    \"http://aeonbits.org, http://github.com, http://google.com\")\n  MyOwnCollection<URL> myBookmarks();\n\n  // Concrete class are allowed (in this case java.util.Stack)\n  // when type is not specified <String> is assumed as default\n  @DefaultValue(\n    \"The Lord of the Rings,The Little Prince,The Da Vinci Code\")\n  Stack books();\n\n}\n```\nOWNER默认使用`,`分割元素. 但是我们可以通过`@Separator(\";\")`指定使用`;`进行切割, 需要注意的是OWNER只支持数组, 集合, Java原生类型, 并不支持`Map`.\n> 支持的集合有`Collection, List, Set, SortedSet`\n\n虽然我们可以使用`@Separator(\";\")`进行切割, 但是如果我们有更复杂的切割逻辑的话, 这可能就不再符合需求了, 我们可以使用`@TokenizerClass`来实现更复杂的切割逻辑\n```java\npublic class MyConfig extends Config {\n\n    @Separator(\";\")\n    @DefaultValue(\"0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55\")\n    public int[] fibonacci();\n\n    @TokenizerClass(CustomDashTokenizer.class)\n    @DefaultValue(\"foo-bar-baz\")\n    public String[] withSeparatorClass();\n\n}\n\npublic class CustomDashTokenizer implements Tokenizer {\n\n    // this logic can be as much complex as you need\n    @Override\n    public String[] tokens(String values) {\n        return values.split(\"-\", -1);\n    }\n}\n```\n> 虽然 `@Separator(\";\")` 和  `@TokenizerClass(CustomDashTokenizer.class)`都可以在方法和类的级别上进行注解, 但是他们不允许同时出现在同一个级别上, 而且当分别出现在了方法和类的级别上后, 方法上的注解会替换类上的注解.\n\nOWNER还提供了`@ConverterClass`注解来实现更加复杂的转换逻辑\n```java\ninterface MyConfig extends Config {\n    @DefaultValue(\"foobar.com:8080\")\n    @ConverterClass(ServerConverter.class)\n    Server server();\n\n    @DefaultValue(\n      \"google.com, yahoo.com:8080, owner.aeonbits.org:4000\")\n    @ConverterClass(ServerConverter.class)\n    Server[] servers();\n}\n\nclass Server {\n    private final String name;\n    private final Integer port;\n\n    public Server(String name, Integer port) {\n        this.name = name;\n        this.port = port;\n    }\n}\n\npublic class ServerConverter implements Converter<Server> {\n    public Server convert(Method targetMethod, String text) {\n        String[] split = text.split(\":\", -1);\n        String name = split[0];\n        Integer port = 80;\n        if (split.length >= 2)\n            port = Integer.valueOf(split[1]);\n        return new Server(name, port);\n    }\n}\n\nMyConfig cfg = ConfigFactory.create(MyConfig.class);\nServer s = cfg.server(); // will return a single server\nServer[] ss = cfg.servers(); // it works also with collections\n```\n\nOWNER 支持的全部自动转换类型\n\n* 原生类型: boolean, byte, short, integer, long, float, double.\n* 枚举\n* java.lang.String\n* java.net.URL, java.net.URI.\n* java.io.File\n* java.lang.Class\n* 公有构造器只有一个`java.lang.String`的类\n* 公有构造器只有一个`java.lang.Object`的类\n* 被`public static`修饰, 签名为`valueOf(java.lang.String)`返回自身的方法\n* 带有上述元素的数组\n* 带有上述类的集合(`Set, List, SortedSet or concrete implementations like LinkedHashSet`). Map and sub-interfaces are not supported.\n\n## 变量表达式\nOWNER还提供了一个非常霸道的功能 —— 变量表达式, 参考如下配置文件\n```\nstory=The ${animal} jumped over the ${target}\nanimal=quick ${color} fox\ntarget=${target.attribute} dog\ntarget.attribute=lazy\ncolor=brown\n```\n然后定义一个配置类\n```java\npublic interface ConfigWithExpansion extends Config {\n    String story();\n}\n```\n猜猜会输出什么, 对了\n```java\nThe quick brown fox jumped over the lazy dog\n```\n我们可以在配置文件里引用其他的配置\n\n同样的我们还可以在配置类完成这样的功能\n```java\npublic interface ConfigWithExpansion\n        extends Config {\n\n    @DefaultValue(\n        \"The ${animal} jumped over the ${target}\")\n    String story();\n\n    @DefaultValue(\"quick ${color} fox\")\n    String animal();\n\n    @DefaultValue(\"${target.attribute} dog\")\n    String target();\n\n    @Key(\"target.attribute\")\n    @DefaultValue(\"lazy\")\n    String targetAttribute();\n\n    @DefaultValue(\"brown\")\n    String color();\n}\n\nConfigWithExpansion conf = ConfigFactory\n    .create(ConfigWithExpansion.class);\n\nString story = conf.story();\n```\n\n如果我们不需要开启变量表达式的话, 我们可以使用`@DisableFeature(VARIABLE_EXPANSION)`\n```java\npublic interface Sample extends Config {\n    @DefaultValue(\"Earth\")\n    String world();\n\n    @DisableFeature(VARIABLE_EXPANSION)\n    @DefaultValue(\"Hello ${world}.\")\n\n    // will return the string \"Hello ${world}.\"\n    String sayHello();\n}\n```\n","slug":"Java 工具库/OWNER 初探","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmn000fvjs6obgprqgq"},{"date":"2016-05-10T16:00:00.000Z","title":"Oracle® Solaris Studio","_content":"在Centos上安装Oracle® Solaris Studio.  [中文教程](http://docs.oracle.com/cd/E27071_01/html/E26451/gemyt.html#scrolltoc)\n\n首先执行下列命令\n```bash\nyum install glibc\nyum install elfutils-libelf-devel\nyum install zlib\nyum install libstdc++\nyum install libgcc\n```\n执行完之后, 会将下列依赖包安装完成\n```bash\nglibc\nglibc.i686\nglibc-devel\nglibc-devel.i686\nelfutils-libelf-devel \nelfutils-libelf-devel.i686\nzlib\nzlib.i686\nlibstdc++\nlibstdc++.i686\nlibgcc\nlibgcc.i686\n```\n\n1. 在[下载界面](http://www.oracle.com/technetwork/server-storage/solarisstudio/downloads/index.html)下载Oracle Linux/ Red Hat Linux - RPM installer on x86 \n2. 运行命令解压`bzcat download_directory/SolarisStudio12.4-linux-x86-rpm.tar.bz2 | /bin/tar -xf -`\n3. 进行安装`./solarisstudio.sh --non-interactive `(包含GUI, 也就是我们可以在Linux的桌面上打开Solaris Studio IDE)\n4. 验证是否安装成功`/opt/oracle/solarisstudio12.4/bin/analyzer -v`\n\n安装完成后会显示\n```bash\nConfiguring the installer...\nSearching for JVM on the system...\nExtracting installation data (can take a while, please wait)...\nRunning the installer wizard...\n/tmp/ossi-c2x_test-20160509142618.silent.log:\n[2016-05-09 14:26:18.764]: WARNING - Your OS distribution is not supported. The list of supported systems can be found in the Oracle Solaris Studio documentation. While it might be possible to install Oracle Solaris Studio on your system, it might not function properly.\n```\n运行`analyzer -v`显示\n```bash\nanalyzer: Oracle Solaris Studio 12.4 Performance Analyzer 12.4 Linux_x64 2014/10/21\nJava at /usr/java/jdk1.8.0_25/bin/java selected by PATH\njava version \"1.8.0_25\"\nJava(TM) SE Runtime Environment (build 1.8.0_25-b17)\nJava HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)\nWARNING: Linux CentOS_6.7 system \"c2x_test\" is not supported by the Performance tools.\nRunning /usr/java/jdk1.8.0_25/bin/java -version\n/opt/oracle/solarisstudio12.4/bin/analyzer: ERROR: environment variable DISPLAY is not set\n```\n\n额外事项\n1. 卸载程序 `/opt/oracle/solarisstudio12.4/uninstall.sh --non-interactive`\n2. 如果安装时不想要GUI, 只需要在后面加上`--libraries-only`就好了\n3. 设置环境变量 `vi /ect/profile` 修改`\nPATH=$PATH:/opt/oracle/solarisstudio12.4/bin/`","source":"_posts/Java 工具库/Oracle Solaris Studio.md","raw":"category: Java工具\ndate: 2016-05-11\ntitle: Oracle® Solaris Studio \n---\n在Centos上安装Oracle® Solaris Studio.  [中文教程](http://docs.oracle.com/cd/E27071_01/html/E26451/gemyt.html#scrolltoc)\n\n首先执行下列命令\n```bash\nyum install glibc\nyum install elfutils-libelf-devel\nyum install zlib\nyum install libstdc++\nyum install libgcc\n```\n执行完之后, 会将下列依赖包安装完成\n```bash\nglibc\nglibc.i686\nglibc-devel\nglibc-devel.i686\nelfutils-libelf-devel \nelfutils-libelf-devel.i686\nzlib\nzlib.i686\nlibstdc++\nlibstdc++.i686\nlibgcc\nlibgcc.i686\n```\n\n1. 在[下载界面](http://www.oracle.com/technetwork/server-storage/solarisstudio/downloads/index.html)下载Oracle Linux/ Red Hat Linux - RPM installer on x86 \n2. 运行命令解压`bzcat download_directory/SolarisStudio12.4-linux-x86-rpm.tar.bz2 | /bin/tar -xf -`\n3. 进行安装`./solarisstudio.sh --non-interactive `(包含GUI, 也就是我们可以在Linux的桌面上打开Solaris Studio IDE)\n4. 验证是否安装成功`/opt/oracle/solarisstudio12.4/bin/analyzer -v`\n\n安装完成后会显示\n```bash\nConfiguring the installer...\nSearching for JVM on the system...\nExtracting installation data (can take a while, please wait)...\nRunning the installer wizard...\n/tmp/ossi-c2x_test-20160509142618.silent.log:\n[2016-05-09 14:26:18.764]: WARNING - Your OS distribution is not supported. The list of supported systems can be found in the Oracle Solaris Studio documentation. While it might be possible to install Oracle Solaris Studio on your system, it might not function properly.\n```\n运行`analyzer -v`显示\n```bash\nanalyzer: Oracle Solaris Studio 12.4 Performance Analyzer 12.4 Linux_x64 2014/10/21\nJava at /usr/java/jdk1.8.0_25/bin/java selected by PATH\njava version \"1.8.0_25\"\nJava(TM) SE Runtime Environment (build 1.8.0_25-b17)\nJava HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)\nWARNING: Linux CentOS_6.7 system \"c2x_test\" is not supported by the Performance tools.\nRunning /usr/java/jdk1.8.0_25/bin/java -version\n/opt/oracle/solarisstudio12.4/bin/analyzer: ERROR: environment variable DISPLAY is not set\n```\n\n额外事项\n1. 卸载程序 `/opt/oracle/solarisstudio12.4/uninstall.sh --non-interactive`\n2. 如果安装时不想要GUI, 只需要在后面加上`--libraries-only`就好了\n3. 设置环境变量 `vi /ect/profile` 修改`\nPATH=$PATH:/opt/oracle/solarisstudio12.4/bin/`","slug":"Java 工具库/Oracle Solaris Studio","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmp000hvjs6i2mjdjhr"},{"date":"2016-01-19T16:00:00.000Z","title":"Retrofit 初探","_content":"首先添加Maven依赖\n```xml\n<dependency>\n\t<groupId>com.squareup.retrofit2</groupId>\n\t<artifactId>retrofit</artifactId>\n\t<version>2.0.2</version>\n</dependency>\n```\n> 注意我们使用的是retrofit2\n\n## Get请求\nRetrofit 将HTTP API转换为了接口形式, 如下\n```java\npublic interface GitHubService {\n  @GET(\"users/{user}/repos\")\n  Call<List<Repo>> listRepos(@Path(\"user\") String user);\n}\n```\n然后`Retrofit`会自动完成其实现类\n```java\nRetrofit retrofit = new Retrofit.Builder()\n    .baseUrl(\"https://api.github.com\")\n    .build();\n\nGitHubService service = retrofit.create(GitHubService.class);\n```\n在上面的示例中我们完成了一个`Get`请求, 然后使用`@Path`进行参数替换\n\n## Post请求\n上面我们展示的是一个`Get`请求, 下面我们再看一个`Post`请求的示例\n```java\n@POST(\"users/new\")\nCall<User> createUser(@Body User user);\n```\n`@Body`注解会将`User`对象转换为请求体\n\n## form-encoded\n我们我们想要将格式转换为`form-encoded`形式, 参考如下示例\n```java\n@FormUrlEncoded\n@POST(\"user/edit\")\nCall<User> updateUser(@Field(\"first_name\") String first, @Field(\"last_name\") String last);\n```\n`@Field`注解会组成一个个字典结构的数据进行发送.\n\n## HEADER\n有时候我们也许想要设置其他的消息头, 我们可以如此做\n```java\n@Headers(\"Cache-Control: max-age=640000\")\n@GET(\"widget/list\")\nCall<List<Widget>> widgetList();\n```\n\n## 异步\n我们在`Call`对象中分别可以调用异步和同步方法进行通信\n```java\nRetrofit retrofit = new Retrofit.Builder()\n\t\t.baseUrl(\"https://api.github.com\")\n\t\t.build();\n\nGitHubService service = retrofit.create(GitHubService.class);\n\nCall<List<String>> repos = service.listRepos(\"octocat\");\n\t// 同步调用\n\tResponse<List<String>> result = repos.execute();\n\n\t// 异步调用\n\trepos.enqueue(new Callback() {\n\n\t\t@Override\n\t\tpublic void onResponse(Response response) {\n\n\t\t}\n\n\t\t@Override\n\t\tpublic void onFailure(Throwable t) {\n\n\t\t}\n\t});\n```\n\n## 测试\n在我的windows的机器上进行测试, 只是测试一下Retrofit的性能消耗\n```java\n\t@Test\n\tpublic void testIte1Minite() throws IOException {\n\t\tint count = 0;\n\t\tlong start = System.currentTimeMillis();\n\t\twhile (true) {\n\t\t\tlong end = System.currentTimeMillis();\n\t\t\tif ((end - start) > 1000 * 60) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tRetrofit retrofit = new Retrofit.Builder()\n\t\t\t\t\t.baseUrl(\"http://192.168.15.20:9091\")\n\t\t\t\t\t.addConverterFactory(GsonConverterFactory.create())\n\t\t\t\t\t.build();\n\t\t\tServerListService loginServerPushService = retrofit.create(ServerListService.class);\n\t\t\tloginServerPushService.serverlist().execute().body();\n\t\t\tcount++;\n\t\t}\n\t\tSystem.out.println(count);\n\t}\n\n\tpublic interface ServerListService {\n\t\t@GET(\"server/serverlist\")\n\t\tCall<MyServer> serverlist();\n\t}\n\n\tpublic class MyServer {\n\t\tpublic List<Map<String, String>> serverlist;\n\t\tpublic List<Map<String, String>> serverlogin;\n\t}\n```\n结果如图\n![]()\n```java\n\t@Test\n\tpublic void testIte1Minite() throws IOException {\n\t\tint count = 0;\n\t\tlong start = System.currentTimeMillis();\n\t\tRetrofit retrofit = new Retrofit.Builder()\n\t\t\t\t.baseUrl(\"http://192.168.15.20:9091\")\n\t\t\t\t.addConverterFactory(GsonConverterFactory.create())\n\t\t\t\t.build();\n\t\twhile (true) {\n\t\t\tlong end = System.currentTimeMillis();\n\t\t\tif ((end - start) > 1000 * 60) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tServerListService loginServerPushService = retrofit.create(ServerListService.class);\n\t\t\tloginServerPushService.serverlist().execute().body();\n\t\t\tcount++;\n\t\t}\n\t\tSystem.out.println(count);\n\t}\n```\n结果如图\n![]()\n这俩次的结果都能达到每分钟13000个请求, 吞吐量和性能消耗是差不多.\n\n## Converter\nRetrofit2为我们提供了多种转换器\n* Gson: com.squareup.retrofit2:converter-gson\n* Jackson: com.squareup.retrofit2:converter-jackson\n* Moshi: com.squareup.retrofit2:converter-moshi\n* Protobuf: com.squareup.retrofit2:converter-protobuf\n* Wire: com.squareup.retrofit2:converter-wire\n* Simple XML: com.squareup.retrofit2:converter-simplexml\n* Scalars (primitives, boxed, and String): com.squareup.retrofit2:converter-scalars\n在使用Retrofit2的时候, 必须指定Converter, 否则程序在运行中会报错. Scalars 只是支持String和基本类型的装包和拆包","source":"_posts/Java 工具库/Retrofit.md","raw":"category: Java工具\ndate: 2016-01-20\ntitle: Retrofit 初探\n---\n首先添加Maven依赖\n```xml\n<dependency>\n\t<groupId>com.squareup.retrofit2</groupId>\n\t<artifactId>retrofit</artifactId>\n\t<version>2.0.2</version>\n</dependency>\n```\n> 注意我们使用的是retrofit2\n\n## Get请求\nRetrofit 将HTTP API转换为了接口形式, 如下\n```java\npublic interface GitHubService {\n  @GET(\"users/{user}/repos\")\n  Call<List<Repo>> listRepos(@Path(\"user\") String user);\n}\n```\n然后`Retrofit`会自动完成其实现类\n```java\nRetrofit retrofit = new Retrofit.Builder()\n    .baseUrl(\"https://api.github.com\")\n    .build();\n\nGitHubService service = retrofit.create(GitHubService.class);\n```\n在上面的示例中我们完成了一个`Get`请求, 然后使用`@Path`进行参数替换\n\n## Post请求\n上面我们展示的是一个`Get`请求, 下面我们再看一个`Post`请求的示例\n```java\n@POST(\"users/new\")\nCall<User> createUser(@Body User user);\n```\n`@Body`注解会将`User`对象转换为请求体\n\n## form-encoded\n我们我们想要将格式转换为`form-encoded`形式, 参考如下示例\n```java\n@FormUrlEncoded\n@POST(\"user/edit\")\nCall<User> updateUser(@Field(\"first_name\") String first, @Field(\"last_name\") String last);\n```\n`@Field`注解会组成一个个字典结构的数据进行发送.\n\n## HEADER\n有时候我们也许想要设置其他的消息头, 我们可以如此做\n```java\n@Headers(\"Cache-Control: max-age=640000\")\n@GET(\"widget/list\")\nCall<List<Widget>> widgetList();\n```\n\n## 异步\n我们在`Call`对象中分别可以调用异步和同步方法进行通信\n```java\nRetrofit retrofit = new Retrofit.Builder()\n\t\t.baseUrl(\"https://api.github.com\")\n\t\t.build();\n\nGitHubService service = retrofit.create(GitHubService.class);\n\nCall<List<String>> repos = service.listRepos(\"octocat\");\n\t// 同步调用\n\tResponse<List<String>> result = repos.execute();\n\n\t// 异步调用\n\trepos.enqueue(new Callback() {\n\n\t\t@Override\n\t\tpublic void onResponse(Response response) {\n\n\t\t}\n\n\t\t@Override\n\t\tpublic void onFailure(Throwable t) {\n\n\t\t}\n\t});\n```\n\n## 测试\n在我的windows的机器上进行测试, 只是测试一下Retrofit的性能消耗\n```java\n\t@Test\n\tpublic void testIte1Minite() throws IOException {\n\t\tint count = 0;\n\t\tlong start = System.currentTimeMillis();\n\t\twhile (true) {\n\t\t\tlong end = System.currentTimeMillis();\n\t\t\tif ((end - start) > 1000 * 60) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tRetrofit retrofit = new Retrofit.Builder()\n\t\t\t\t\t.baseUrl(\"http://192.168.15.20:9091\")\n\t\t\t\t\t.addConverterFactory(GsonConverterFactory.create())\n\t\t\t\t\t.build();\n\t\t\tServerListService loginServerPushService = retrofit.create(ServerListService.class);\n\t\t\tloginServerPushService.serverlist().execute().body();\n\t\t\tcount++;\n\t\t}\n\t\tSystem.out.println(count);\n\t}\n\n\tpublic interface ServerListService {\n\t\t@GET(\"server/serverlist\")\n\t\tCall<MyServer> serverlist();\n\t}\n\n\tpublic class MyServer {\n\t\tpublic List<Map<String, String>> serverlist;\n\t\tpublic List<Map<String, String>> serverlogin;\n\t}\n```\n结果如图\n![]()\n```java\n\t@Test\n\tpublic void testIte1Minite() throws IOException {\n\t\tint count = 0;\n\t\tlong start = System.currentTimeMillis();\n\t\tRetrofit retrofit = new Retrofit.Builder()\n\t\t\t\t.baseUrl(\"http://192.168.15.20:9091\")\n\t\t\t\t.addConverterFactory(GsonConverterFactory.create())\n\t\t\t\t.build();\n\t\twhile (true) {\n\t\t\tlong end = System.currentTimeMillis();\n\t\t\tif ((end - start) > 1000 * 60) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tServerListService loginServerPushService = retrofit.create(ServerListService.class);\n\t\t\tloginServerPushService.serverlist().execute().body();\n\t\t\tcount++;\n\t\t}\n\t\tSystem.out.println(count);\n\t}\n```\n结果如图\n![]()\n这俩次的结果都能达到每分钟13000个请求, 吞吐量和性能消耗是差不多.\n\n## Converter\nRetrofit2为我们提供了多种转换器\n* Gson: com.squareup.retrofit2:converter-gson\n* Jackson: com.squareup.retrofit2:converter-jackson\n* Moshi: com.squareup.retrofit2:converter-moshi\n* Protobuf: com.squareup.retrofit2:converter-protobuf\n* Wire: com.squareup.retrofit2:converter-wire\n* Simple XML: com.squareup.retrofit2:converter-simplexml\n* Scalars (primitives, boxed, and String): com.squareup.retrofit2:converter-scalars\n在使用Retrofit2的时候, 必须指定Converter, 否则程序在运行中会报错. Scalars 只是支持String和基本类型的装包和拆包","slug":"Java 工具库/Retrofit","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmr000jvjs6c845alvd"},{"date":"2016-04-11T16:00:00.000Z","title":"Mybatis SqlSession","_content":"一直在使用Mybatis, 但是一直对Mybatis中的SqlSession的实际操作过程没有深入了解过, 今天在项目中引用了Mybatis-Guice模块, 很好奇Mybatis-Guice是如何做的SqlSeesion自动资源释放,因此今天就找时间好好研究一下`SqlSession`.\n\n首先看一下[Mybatis3官方文档](http://www.mybatis.org/mybatis-3/zh/getting-started.html)中对`SqlSessionFactoryBuilder`, `SqlSessionFactory`和`SqlSession`的描述：\n* `SqlSessionFactoryBuilder` : 一旦`SqlSessionFactoryBuilder`创建出`SqlSessionFactory`, 那么在接下来的应用程序中我们就不应该再使用它(除非我们要使用多个数据源)\n* `SqlSessionFactory` : 用来创建`SqlSession`, 该实例的生命周期应该是整个应用程序, 我们要避免创建多个相同的数据源.\n* `SqlSession` : SqlSession 的实例不是线程安全的. 我们应当在每次收到请求时打开一个 SqlSession,返回一个响应,然后关闭它.这个关闭操作是很重要的,你应该把这个关闭操作放到 finally 块中以确保每次都能执行关闭.SqlSession 完全包含了面向数据库执行 SQL 命令所需的所有方法\n\n`SqlSessionFactoryBuilder`是通过xml配置文件或者`Configuration`建构出`SqlSessionFactory`, 然后`SqlSessionFactory`通过`openSession()`来获得一个`SqlSession`.\n\n`SqlSession`接口实现自`Closeable`接口. 按照官网所说, 我们应该这样使用`SqlSession`\n```java\nSqlSession session = sqlSessionFactory.openSession();\ntry {\n  // do work\n} finally {\n  session.close();\n}\n```\n但其实我们可以使用Java7提供的AutoClose语法\n```java\ntry (SqlSession sqlSession = sqlSessionFactory.openSession()) {\n\t// do work\n}\n```\n这样代码就精简了很多.\n\n`SqlSession`接口中定义了大量的我们操作SQL提供的接口\n* <T> T selectOne(String statement);\n* <E> List<E> selectList(String statement);\n* void select(String statement, ResultHandler handler);\n等等. 我们看一下它的实现类`DefaultSqlSession`的实现:\n```java\nprivate Configuration configuration;\nprivate Executor executor;\nprivate boolean dirty;\n```\n* `Configuration` 是我们通过`SqlSessionFactoryBuilder`构建出`SqlSessionFactory`时使用的配置\n* `Executor` 是真正的sql执行的部分\n* `dirty`\n\n我们在`DefaultSqlSessionFactory`看一下`SqlSession`的真实创建过程\n```java\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n  Transaction tx = null;\n  try {\n    final Environment environment = configuration.getEnvironment();\n    final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);\n    tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n    final Executor executor = configuration.newExecutor(tx, execType, autoCommit);\n    return new DefaultSqlSession(configuration, executor);\n  } catch (Exception e) {\n    closeTransaction(tx); // may have fetched a connection so lets call close()\n    throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n  } finally {\n    ErrorContext.instance().reset();\n  }\n}\n```\n在`final Executor executor = configuration.newExecutor(tx, execType, autoCommit);`会根据execType创建出不同类型的`Executor`\n* BatchExecutor\n* ReuseExecutor\n* SimpleExecutor\n* CachingExecutor\n\n下来我们看一下`selectList()`实现\n```java\n  public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {\n    try {\n      MappedStatement ms = configuration.getMappedStatement(statement);\n      List<E> result = executor.<E>query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n      return result;\n    } catch (Exception e) {\n      throw ExceptionFactory.wrapException(\"Error querying database.  Cause: \" + e, e);\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n```\n> MappedStatement类在Mybatis框架中用于表示XML文件中一个sql语句节点,即一个<select />、<update />或者<insert />标签.Mybatis框架在初始化阶段会对XML配置文件进行读取,将其中的sql语句节点对象化为一个个MappedStatement对象.\n从配置中拿到一个`MappedStatement`然后交给executor去真正的执行, 真正的有query逻辑的只有`BaseExecutor`和`CachingExecutor`, 为了简单起见,我们看一下`BaseExecutor`. 由于中间的过程还涉及到了Mybatis的本地存储, 我们也跳过这部分.\n> `BaseExecutor#query()` -> `BaseExecutor#queryFromDatabase()`-> `SimpleExecutor#doQuery()`\n```java\npublic <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {\n    Statement stmt = null;\n    try {\n      Configuration configuration = ms.getConfiguration();\n\t  // StatementHandler用于管理java.sql.Statement, 执行真正的与数据库操作\n      StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n\t  // 通过StatementHandler实例化出一个Statement\n      stmt = prepareStatement(handler, ms.getStatementLog());\n\t  // Statement开始执行查询逻辑\n      return handler.<E>query(stmt, resultHandler);\n    } finally {\n      closeStatement(stmt);\n    }\n  }\n```\n我们看一下`SimpleStatementHandler`里的查询逻辑\n```java\n public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {\n    String sql = boundSql.getSql();\n    statement.execute(sql);\n    return resultSetHandler.<E>handleResultSets(statement);\n  }\n```\n> `SqlSource`接口只有一个`getBoundSql(Object parameterObject)`方法,返回一个`BoundSql`对象.一个`BoundSql`对象,代表了一次sql语句的实际执行,而`SqlSource`对象的责任,就是根据传入的参数对象,动态计算出这个`BoundSql`,也就是说Mapper文件中的<if />节点的计算,是由SqlSource对象完成的.`SqlSource`最常用的实现类是`DynamicSqlSource`\n\n那么`close()`执行的是什么操作呢？\n```java\n  public void close() {\n    try {\n      executor.close(isCommitOrRollbackRequired(false));\n      dirty = false;\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n```\n我们还是看`BaseExecutor`的`close()`\n```java\npublic void close(boolean forceRollback) {\n    try {\n      try {\n        rollback(forceRollback);\n      } finally {\n\t\t// 真正关闭资源\n        if (transaction != null) transaction.close();\n      }\n    } catch (SQLException e) {\n      log.debug(\"Unexpected exception on closing transaction.  Cause: \" + e);\n    } finally {\n      transaction = null;\n      deferredLoads = null;\n      localCache = null;\n      localOutputParameterCache = null;\n      closed = true;\n    }\n  }\n```\n我们看一下`JdbcTransaction`的`close()`\n```java\n  public void close() throws SQLException {\n    if (connection != null) {\n      resetAutoCommit();\n      if (log.isDebugEnabled()) {\n        log.debug(\"Closing JDBC Connection [\" + connection + \"]\");\n      }\n      connection.close();\n    }\n  }\n```\n* `Transaction` : 包装了一个数据库连接. 处理整个网络连接过程中的所有操作, 例如creation, preparation, commit/rollback and close. \n* `JdbcTransaction` : \n\n\n如果我们不关闭SqlSession会有什么情况发生呢?\n```java\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.Date;\nimport java.util.List;\n\nimport org.apache.ibatis.annotations.Select;\nimport org.apache.ibatis.io.Resources;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.apache.ibatis.session.SqlSessionFactoryBuilder;\n\npublic class TestMybatis {\n\n    public static void main(String[] args) throws IOException {\n        String resource = \"mybatis-config.xml\";\n        InputStream inputStream = Resources.getResourceAsStream(resource);\n        SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n        List<SqlSession> list = new ArrayList<>();\n        for (int i = 1; i < 10; i++) {\n            SqlSession session = sqlSessionFactory.openSession();\n            QueryMapper mapper = session.getMapper(QueryMapper.class);\n            list.add(session);\n            System.out.println(i + \"  :  \" + mapper.select() + \" - \" + new Date().toLocaleString());\n        }\n        list.forEach(session -> {\n            try {\n                System.out.println(session.getConnection().isClosed());\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n}\n\ninterface QueryMapper {\n    @Select(\"select name from user\")\n    public List<String> select();\n}\n\n```\n下面是我们的配置文件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n                <property name=\"url\" value=\"jdbc:mysql://localhost:3306/test?autoReconnect=true\"/>\n                <property name=\"username\" value=\"root\"/>\n                <property name=\"password\" value=\"root\"/>\n                <property name=\"poolMaximumActiveConnections\" value=\"3\"/>\n                <property name=\"poolMaximumIdleConnections\" value=\"1\"/>\n                <property name=\"poolTimeToWait\" value=\"5\"/>\n            </dataSource>\n        </environment>\n    </environments>\n    <mappers>\n        <mapper class=\"QueryMapper\"/>\n    </mappers>\n</configuration>\n```\n我们配置了最大可用连接数为3, 最大的闲置连接为1. 结果为\n```java\n1  :  [123] - 2016-4-12 18:37:28\n2  :  [123] - 2016-4-12 18:37:28\n3  :  [123] - 2016-4-12 18:37:28\n4  :  [123] - 2016-4-12 18:37:48\n5  :  [123] - 2016-4-12 18:37:48\n6  :  [123] - 2016-4-12 18:37:48\n7  :  [123] - 2016-4-12 18:38:08\n8  :  [123] - 2016-4-12 18:38:08\n9  :  [123] - 2016-4-12 18:38:08\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\nfalse\nfalse\nfalse\n```\n","source":"_posts/Java 工具库/SqlSession.md","raw":"category: Java工具\ndate: 2016-04-12\ntitle: Mybatis SqlSession\n---\n一直在使用Mybatis, 但是一直对Mybatis中的SqlSession的实际操作过程没有深入了解过, 今天在项目中引用了Mybatis-Guice模块, 很好奇Mybatis-Guice是如何做的SqlSeesion自动资源释放,因此今天就找时间好好研究一下`SqlSession`.\n\n首先看一下[Mybatis3官方文档](http://www.mybatis.org/mybatis-3/zh/getting-started.html)中对`SqlSessionFactoryBuilder`, `SqlSessionFactory`和`SqlSession`的描述：\n* `SqlSessionFactoryBuilder` : 一旦`SqlSessionFactoryBuilder`创建出`SqlSessionFactory`, 那么在接下来的应用程序中我们就不应该再使用它(除非我们要使用多个数据源)\n* `SqlSessionFactory` : 用来创建`SqlSession`, 该实例的生命周期应该是整个应用程序, 我们要避免创建多个相同的数据源.\n* `SqlSession` : SqlSession 的实例不是线程安全的. 我们应当在每次收到请求时打开一个 SqlSession,返回一个响应,然后关闭它.这个关闭操作是很重要的,你应该把这个关闭操作放到 finally 块中以确保每次都能执行关闭.SqlSession 完全包含了面向数据库执行 SQL 命令所需的所有方法\n\n`SqlSessionFactoryBuilder`是通过xml配置文件或者`Configuration`建构出`SqlSessionFactory`, 然后`SqlSessionFactory`通过`openSession()`来获得一个`SqlSession`.\n\n`SqlSession`接口实现自`Closeable`接口. 按照官网所说, 我们应该这样使用`SqlSession`\n```java\nSqlSession session = sqlSessionFactory.openSession();\ntry {\n  // do work\n} finally {\n  session.close();\n}\n```\n但其实我们可以使用Java7提供的AutoClose语法\n```java\ntry (SqlSession sqlSession = sqlSessionFactory.openSession()) {\n\t// do work\n}\n```\n这样代码就精简了很多.\n\n`SqlSession`接口中定义了大量的我们操作SQL提供的接口\n* <T> T selectOne(String statement);\n* <E> List<E> selectList(String statement);\n* void select(String statement, ResultHandler handler);\n等等. 我们看一下它的实现类`DefaultSqlSession`的实现:\n```java\nprivate Configuration configuration;\nprivate Executor executor;\nprivate boolean dirty;\n```\n* `Configuration` 是我们通过`SqlSessionFactoryBuilder`构建出`SqlSessionFactory`时使用的配置\n* `Executor` 是真正的sql执行的部分\n* `dirty`\n\n我们在`DefaultSqlSessionFactory`看一下`SqlSession`的真实创建过程\n```java\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n  Transaction tx = null;\n  try {\n    final Environment environment = configuration.getEnvironment();\n    final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);\n    tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n    final Executor executor = configuration.newExecutor(tx, execType, autoCommit);\n    return new DefaultSqlSession(configuration, executor);\n  } catch (Exception e) {\n    closeTransaction(tx); // may have fetched a connection so lets call close()\n    throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n  } finally {\n    ErrorContext.instance().reset();\n  }\n}\n```\n在`final Executor executor = configuration.newExecutor(tx, execType, autoCommit);`会根据execType创建出不同类型的`Executor`\n* BatchExecutor\n* ReuseExecutor\n* SimpleExecutor\n* CachingExecutor\n\n下来我们看一下`selectList()`实现\n```java\n  public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {\n    try {\n      MappedStatement ms = configuration.getMappedStatement(statement);\n      List<E> result = executor.<E>query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n      return result;\n    } catch (Exception e) {\n      throw ExceptionFactory.wrapException(\"Error querying database.  Cause: \" + e, e);\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n```\n> MappedStatement类在Mybatis框架中用于表示XML文件中一个sql语句节点,即一个<select />、<update />或者<insert />标签.Mybatis框架在初始化阶段会对XML配置文件进行读取,将其中的sql语句节点对象化为一个个MappedStatement对象.\n从配置中拿到一个`MappedStatement`然后交给executor去真正的执行, 真正的有query逻辑的只有`BaseExecutor`和`CachingExecutor`, 为了简单起见,我们看一下`BaseExecutor`. 由于中间的过程还涉及到了Mybatis的本地存储, 我们也跳过这部分.\n> `BaseExecutor#query()` -> `BaseExecutor#queryFromDatabase()`-> `SimpleExecutor#doQuery()`\n```java\npublic <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {\n    Statement stmt = null;\n    try {\n      Configuration configuration = ms.getConfiguration();\n\t  // StatementHandler用于管理java.sql.Statement, 执行真正的与数据库操作\n      StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n\t  // 通过StatementHandler实例化出一个Statement\n      stmt = prepareStatement(handler, ms.getStatementLog());\n\t  // Statement开始执行查询逻辑\n      return handler.<E>query(stmt, resultHandler);\n    } finally {\n      closeStatement(stmt);\n    }\n  }\n```\n我们看一下`SimpleStatementHandler`里的查询逻辑\n```java\n public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {\n    String sql = boundSql.getSql();\n    statement.execute(sql);\n    return resultSetHandler.<E>handleResultSets(statement);\n  }\n```\n> `SqlSource`接口只有一个`getBoundSql(Object parameterObject)`方法,返回一个`BoundSql`对象.一个`BoundSql`对象,代表了一次sql语句的实际执行,而`SqlSource`对象的责任,就是根据传入的参数对象,动态计算出这个`BoundSql`,也就是说Mapper文件中的<if />节点的计算,是由SqlSource对象完成的.`SqlSource`最常用的实现类是`DynamicSqlSource`\n\n那么`close()`执行的是什么操作呢？\n```java\n  public void close() {\n    try {\n      executor.close(isCommitOrRollbackRequired(false));\n      dirty = false;\n    } finally {\n      ErrorContext.instance().reset();\n    }\n  }\n```\n我们还是看`BaseExecutor`的`close()`\n```java\npublic void close(boolean forceRollback) {\n    try {\n      try {\n        rollback(forceRollback);\n      } finally {\n\t\t// 真正关闭资源\n        if (transaction != null) transaction.close();\n      }\n    } catch (SQLException e) {\n      log.debug(\"Unexpected exception on closing transaction.  Cause: \" + e);\n    } finally {\n      transaction = null;\n      deferredLoads = null;\n      localCache = null;\n      localOutputParameterCache = null;\n      closed = true;\n    }\n  }\n```\n我们看一下`JdbcTransaction`的`close()`\n```java\n  public void close() throws SQLException {\n    if (connection != null) {\n      resetAutoCommit();\n      if (log.isDebugEnabled()) {\n        log.debug(\"Closing JDBC Connection [\" + connection + \"]\");\n      }\n      connection.close();\n    }\n  }\n```\n* `Transaction` : 包装了一个数据库连接. 处理整个网络连接过程中的所有操作, 例如creation, preparation, commit/rollback and close. \n* `JdbcTransaction` : \n\n\n如果我们不关闭SqlSession会有什么情况发生呢?\n```java\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.Date;\nimport java.util.List;\n\nimport org.apache.ibatis.annotations.Select;\nimport org.apache.ibatis.io.Resources;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.apache.ibatis.session.SqlSessionFactoryBuilder;\n\npublic class TestMybatis {\n\n    public static void main(String[] args) throws IOException {\n        String resource = \"mybatis-config.xml\";\n        InputStream inputStream = Resources.getResourceAsStream(resource);\n        SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n        List<SqlSession> list = new ArrayList<>();\n        for (int i = 1; i < 10; i++) {\n            SqlSession session = sqlSessionFactory.openSession();\n            QueryMapper mapper = session.getMapper(QueryMapper.class);\n            list.add(session);\n            System.out.println(i + \"  :  \" + mapper.select() + \" - \" + new Date().toLocaleString());\n        }\n        list.forEach(session -> {\n            try {\n                System.out.println(session.getConnection().isClosed());\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n}\n\ninterface QueryMapper {\n    @Select(\"select name from user\")\n    public List<String> select();\n}\n\n```\n下面是我们的配置文件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n                <property name=\"url\" value=\"jdbc:mysql://localhost:3306/test?autoReconnect=true\"/>\n                <property name=\"username\" value=\"root\"/>\n                <property name=\"password\" value=\"root\"/>\n                <property name=\"poolMaximumActiveConnections\" value=\"3\"/>\n                <property name=\"poolMaximumIdleConnections\" value=\"1\"/>\n                <property name=\"poolTimeToWait\" value=\"5\"/>\n            </dataSource>\n        </environment>\n    </environments>\n    <mappers>\n        <mapper class=\"QueryMapper\"/>\n    </mappers>\n</configuration>\n```\n我们配置了最大可用连接数为3, 最大的闲置连接为1. 结果为\n```java\n1  :  [123] - 2016-4-12 18:37:28\n2  :  [123] - 2016-4-12 18:37:28\n3  :  [123] - 2016-4-12 18:37:28\n4  :  [123] - 2016-4-12 18:37:48\n5  :  [123] - 2016-4-12 18:37:48\n6  :  [123] - 2016-4-12 18:37:48\n7  :  [123] - 2016-4-12 18:38:08\n8  :  [123] - 2016-4-12 18:38:08\n9  :  [123] - 2016-4-12 18:38:08\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\njava.sql.SQLException: Error accessing PooledConnection. Connection is invalid.\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)\n\tat org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)\n\tat com.sun.proxy.$Proxy3.isClosed(Unknown Source)\n\tat TestMybatis.lambda$main$0(TestMybatis.java:29)\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\n\tat TestMybatis.main(TestMybatis.java:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\nfalse\nfalse\nfalse\n```\n","slug":"Java 工具库/SqlSession","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmu000mvjs655ayqtbd"},{"date":"2015-12-29T16:00:00.000Z","title":"args4j 初探","_content":"args4j可以方便地解析CUI（命令行接口）程序的输入参数或选项, 将其解析到一个参数类中.\n\n我们使用MAVEN测试一下这个工具, 首先我们创建一个MAVEN项目\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15.args4j</groupId>\n    <artifactId>demo</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <dependencies>\n        <dependency>\n            <groupId>args4j</groupId>\n            <artifactId>args4j</artifactId>\n            <version>2.32</version>\n        </dependency>\n    </dependencies>\n</project>\n```\n然后创建一个参数类\n```java\npublic class Args {\n\tpublic String name;\n\n\tpublic void run() {\n\t\tSystem.out.println(\"Args Init\");\n\t\tSystem.out.println(\"- name: \" + name);\n\t}\n}\n```\n然后写一个主类\n```java\nimport org.kohsuke.args4j.CmdLineException;\nimport org.kohsuke.args4j.CmdLineParser;\n\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tArgs args1 = new Args();\n\t\tCmdLineParser parser = new CmdLineParser(args1);\n\t\ttry {\n\t\t\tparser.parseArgument(args);\n\t\t} catch (CmdLineException e) {\n\t\t\t// handling of wrong arguments\n\t\t\tSystem.err.println(e.getMessage());\n\t\t\tparser.printUsage(System.err);\n\t\t}\n\t\tSystem.out.println(args1.name);\n\t}\n}\n```\n接着执行`mvn package`打出一个包, 然后执行命令\n```java\njava -jar ./target/demo-1.0-SNAPSHOT.jar Args -name \"Hello World\"\n```\n最后我们会看到输出\n","source":"_posts/Java 工具库/args4j.md","raw":"category: Java工具\ndate: 2015-12-30\ntitle: args4j 初探\n---\nargs4j可以方便地解析CUI（命令行接口）程序的输入参数或选项, 将其解析到一个参数类中.\n\n我们使用MAVEN测试一下这个工具, 首先我们创建一个MAVEN项目\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15.args4j</groupId>\n    <artifactId>demo</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <dependencies>\n        <dependency>\n            <groupId>args4j</groupId>\n            <artifactId>args4j</artifactId>\n            <version>2.32</version>\n        </dependency>\n    </dependencies>\n</project>\n```\n然后创建一个参数类\n```java\npublic class Args {\n\tpublic String name;\n\n\tpublic void run() {\n\t\tSystem.out.println(\"Args Init\");\n\t\tSystem.out.println(\"- name: \" + name);\n\t}\n}\n```\n然后写一个主类\n```java\nimport org.kohsuke.args4j.CmdLineException;\nimport org.kohsuke.args4j.CmdLineParser;\n\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tArgs args1 = new Args();\n\t\tCmdLineParser parser = new CmdLineParser(args1);\n\t\ttry {\n\t\t\tparser.parseArgument(args);\n\t\t} catch (CmdLineException e) {\n\t\t\t// handling of wrong arguments\n\t\t\tSystem.err.println(e.getMessage());\n\t\t\tparser.printUsage(System.err);\n\t\t}\n\t\tSystem.out.println(args1.name);\n\t}\n}\n```\n接着执行`mvn package`打出一个包, 然后执行命令\n```java\njava -jar ./target/demo-1.0-SNAPSHOT.jar Args -name \"Hello World\"\n```\n最后我们会看到输出\n","slug":"Java 工具库/args4j","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihmw000ovjs6qdte44bk"},{"date":"2016-01-29T16:00:00.000Z","title":"Typesafe Config 初探","_content":"Typesafe Config 是为JVM平台语言提供的配置类库.\n\n目前config只支持配置文件，如果想从数据库获取配置文件，需要自己diy。 config库很擅长合并配置。\n\n我们可以直接使用maven方式依赖该库\n```xml\n<dependency>\n    <groupId>com.typesafe</groupId>\n    <artifactId>config</artifactId>\n    <version>1.3.0</version>\n</dependency>\n```\n\nAPI示例\n```java\nimport com.typesafe.config.ConfigFactory\n\nConfig conf = ConfigFactory.load();\nint bar1 = conf.getInt(\"foo.bar\");\nConfig foo = conf.getConfig(\"foo\");\nint bar2 = foo.getInt(\"bar\");\n```\n\n在上面的例子中我们使用了最简单的方式`ConfigFactory.load()`加载出了一个配置类`Config`, config会自动去classPath中查找`reference.conf`. `ConfigFactory.load()`会按照下面的优先级依次从classpath中查找文件进行加载\n1. `system properties`\n2. `application.conf` (all resources on classpath with this name)\n3. `application.json` (all resources on classpath with this name)\n4. `application.properties` (all resources on classpath with this name)\n5. `reference.conf` (all resources on classpath with this name)\n如果我们不想要使用上面的文件名或者我们将配置分配到多个文件中,那么我们可以使用`ConfigFactory.load(\"test.conf\");`\n\n当然如果你想自己创建`Config`也可以调用`ConfigFactory`的`parseXXX`方法\n```java\nConfigFactory.parseFile(new File(\"\"));\nConfigFactory.parseMap(new HashMap<>());\nConfigFactory.parseProperties(new Properties());\n```\n\n> 需要注意的从`Config`实例中得到的`Config`, `ConfigParseOptions`, `ConfigResolveOptions`, `ConfigObject` 得到的对象都是不可变的.\n","source":"_posts/Java 工具库/Typesafe Config 初探.md","raw":"category: Java工具\ndate: 2016-01-30\ntitle: Typesafe Config 初探\n---\nTypesafe Config 是为JVM平台语言提供的配置类库.\n\n目前config只支持配置文件，如果想从数据库获取配置文件，需要自己diy。 config库很擅长合并配置。\n\n我们可以直接使用maven方式依赖该库\n```xml\n<dependency>\n    <groupId>com.typesafe</groupId>\n    <artifactId>config</artifactId>\n    <version>1.3.0</version>\n</dependency>\n```\n\nAPI示例\n```java\nimport com.typesafe.config.ConfigFactory\n\nConfig conf = ConfigFactory.load();\nint bar1 = conf.getInt(\"foo.bar\");\nConfig foo = conf.getConfig(\"foo\");\nint bar2 = foo.getInt(\"bar\");\n```\n\n在上面的例子中我们使用了最简单的方式`ConfigFactory.load()`加载出了一个配置类`Config`, config会自动去classPath中查找`reference.conf`. `ConfigFactory.load()`会按照下面的优先级依次从classpath中查找文件进行加载\n1. `system properties`\n2. `application.conf` (all resources on classpath with this name)\n3. `application.json` (all resources on classpath with this name)\n4. `application.properties` (all resources on classpath with this name)\n5. `reference.conf` (all resources on classpath with this name)\n如果我们不想要使用上面的文件名或者我们将配置分配到多个文件中,那么我们可以使用`ConfigFactory.load(\"test.conf\");`\n\n当然如果你想自己创建`Config`也可以调用`ConfigFactory`的`parseXXX`方法\n```java\nConfigFactory.parseFile(new File(\"\"));\nConfigFactory.parseMap(new HashMap<>());\nConfigFactory.parseProperties(new Properties());\n```\n\n> 需要注意的从`Config`实例中得到的`Config`, `ConfigParseOptions`, `ConfigResolveOptions`, `ConfigObject` 得到的对象都是不可变的.\n","slug":"Java 工具库/Typesafe Config 初探","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihn0000rvjs61y01tyjs"},{"date":"2015-04-07T16:00:00.000Z","title":"Dropwizard 初探","_content":"\n## Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n## Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n## Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n## Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```java\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n## The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n## Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n## Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n## Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n## Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n## Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n## Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n## Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n## Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告\n","source":"_posts/Java 工具库/dropwizard.md","raw":"category: Java工具\ndate: 2015-04-08\ntitle: Dropwizard 初探\n---\n\n## Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n## Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n## Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n## Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```java\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n## The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n## Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n## Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n## Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n## Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n## Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n## Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n## Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n## Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告\n","slug":"Java 工具库/dropwizard","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihn5000tvjs6mr0girud"},{"date":"2015-12-22T16:00:00.000Z","title":"fastjson","_content":"## 读取数组\n```java\nList<Reward> rewards = JSONArray.parseArray(jsonStr, Reward.class);\n```\n\n## json和protobuf相互转换\n```xml\n <dependency>\n    <groupId>com.googlecode.protobuf-java-format</groupId>\n    <artifactId>protobuf-java-format</artifactId>\n    <version>1.2</version>\n</dependency>\n```\n然后使用\n```java\nString string = JsonFormat.printToString(mail);\n```","source":"_posts/Java 工具库/fastjson.md","raw":"category: Java工具\ndate: 2015-12-23\ntitle: fastjson\n---\n## 读取数组\n```java\nList<Reward> rewards = JSONArray.parseArray(jsonStr, Reward.class);\n```\n\n## json和protobuf相互转换\n```xml\n <dependency>\n    <groupId>com.googlecode.protobuf-java-format</groupId>\n    <artifactId>protobuf-java-format</artifactId>\n    <version>1.2</version>\n</dependency>\n```\n然后使用\n```java\nString string = JsonFormat.printToString(mail);\n```","slug":"Java 工具库/fastjson","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihn8000wvjs6yb1kmo5f"},{"date":"2015-11-17T16:00:00.000Z","title":"Gradle 初探","_content":"## 概述\n任何一个 Gradle 构建都是由一个或多个 projects 组成。每个 project 都由多个 tasks 组成。每个 task 都代表了构建执行过程中的一个原子性操作。\n\n我使用idea创建一个gradle项目\n```java\ngroup 'wang.ming15.gradle'\nversion '1.0-SNAPSHOT'\n\napply plugin: 'java'\n\nsourceCompatibility = 1.8\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testCompile group: 'junit', name: 'junit', version: '4.11'\n}\n\n```\n\n\n## 任务\n\n### 自定义任务\n我们可以在task内部自由的使用groovy脚本\n```java\ntask t1 {\n    doLast {\n        println 'task1'\n    }\n}\n```\n或者这种方式\n```\ntask t2 << {\n        println 't2'\n}\n```\n\n> `defaultTasks`我们可以使用这个命令定义一些默认的task : `defaultTasks 't1', 't2'`\n\n### 任务依赖\n我们使用`dependsOn`语法可以让一个任务依赖于另外一个任务\n```java\ntask t2 << {\n        println 't2'\n}\n\ntask t3(dependsOn: t2) {\n    println 't3'\n}\n```\n这种情况下, t2任务会优先于t3任务执行\n\n> 需要注意的是, 如果t1依赖于t2, 那么当t2执行的时候会先执行t1\n\n### 延迟依赖\n```java\ntask t3(dependsOn: 't4') {\n    println 'task3'\n}\n\ntask t4 << {\n    println 'task4'\n}\n```\n我们还可以在定义一个任务之后,再定义其所依赖的任务, 执行顺序仍然是t3 优先于t4\n\n\n### 任务操纵\n\n```java\ntask t4 << {\n    println 'task4'\n}\n\ntask t5 << {\n    println 'task5'\n}\n\nt5.dependsOn t4\n```\ntask还有其他一些api,参考[](https://docs.gradle.org/current/javadoc/org/gradle/api/Task.html)\n\n## 插件\n如前例所示我们已经使用过Gradle提供的插件\n```java\napply plugin: 'java'  \n```\n当我们的项目使用某个插件的时候, 这个项目里就包含了那个插件的任务依赖等等\n\n### java插件任务\n我们使用了java插件, 然后我们打开idea右侧的Gradle标签(我们会看到一些java插件自带的一些task.)：\n![](https://raw.githubusercontent.com/ming15/blog-website/images/gradle/gradle_ui.jpg)\n\n命令含义参考[](http://wiki.jikexueyuan.com/project/gradle/java-package.html)\n\n## 文件\n在Gradle编译脚本文件中我们还可以自如的使用文件\n```java\nFile configFile = file('src/config.xml')\n```\n使用`file()`方法我们就可以打开一个文件.\n\n### 文件集合\n我们还可以使用`files()`方法创建文件集合\n```java\nFileCollection fils = files(\"t.txt\", new File(\"d.txt\"), [\"a.txt\", 'b.txt'])\n```\n我们还可以使用`+`, `-`符号增加或者删减文件\n```java\nFileCollection filc = files(\"t.txt\", new File(\"d.txt\"), [\"a.txt\", 'b.txt'])\nFileCollection newFiles1 = filc + files(\"c.txt\")\nFileCollection newFiles2 = filc - files(\"c.txt\")\n```\n我们还可以使用`as `将其转换为`Set`或者`List`\n```java\nSet set1 = filc.files\nSet set2 = filc as Set\nList list = filc as List\n```\n","source":"_posts/Java 工具库/gradle.md","raw":"category: Java工具\ndate: 2015-11-18\ntitle: Gradle 初探\n---\n## 概述\n任何一个 Gradle 构建都是由一个或多个 projects 组成。每个 project 都由多个 tasks 组成。每个 task 都代表了构建执行过程中的一个原子性操作。\n\n我使用idea创建一个gradle项目\n```java\ngroup 'wang.ming15.gradle'\nversion '1.0-SNAPSHOT'\n\napply plugin: 'java'\n\nsourceCompatibility = 1.8\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testCompile group: 'junit', name: 'junit', version: '4.11'\n}\n\n```\n\n\n## 任务\n\n### 自定义任务\n我们可以在task内部自由的使用groovy脚本\n```java\ntask t1 {\n    doLast {\n        println 'task1'\n    }\n}\n```\n或者这种方式\n```\ntask t2 << {\n        println 't2'\n}\n```\n\n> `defaultTasks`我们可以使用这个命令定义一些默认的task : `defaultTasks 't1', 't2'`\n\n### 任务依赖\n我们使用`dependsOn`语法可以让一个任务依赖于另外一个任务\n```java\ntask t2 << {\n        println 't2'\n}\n\ntask t3(dependsOn: t2) {\n    println 't3'\n}\n```\n这种情况下, t2任务会优先于t3任务执行\n\n> 需要注意的是, 如果t1依赖于t2, 那么当t2执行的时候会先执行t1\n\n### 延迟依赖\n```java\ntask t3(dependsOn: 't4') {\n    println 'task3'\n}\n\ntask t4 << {\n    println 'task4'\n}\n```\n我们还可以在定义一个任务之后,再定义其所依赖的任务, 执行顺序仍然是t3 优先于t4\n\n\n### 任务操纵\n\n```java\ntask t4 << {\n    println 'task4'\n}\n\ntask t5 << {\n    println 'task5'\n}\n\nt5.dependsOn t4\n```\ntask还有其他一些api,参考[](https://docs.gradle.org/current/javadoc/org/gradle/api/Task.html)\n\n## 插件\n如前例所示我们已经使用过Gradle提供的插件\n```java\napply plugin: 'java'  \n```\n当我们的项目使用某个插件的时候, 这个项目里就包含了那个插件的任务依赖等等\n\n### java插件任务\n我们使用了java插件, 然后我们打开idea右侧的Gradle标签(我们会看到一些java插件自带的一些task.)：\n![](https://raw.githubusercontent.com/ming15/blog-website/images/gradle/gradle_ui.jpg)\n\n命令含义参考[](http://wiki.jikexueyuan.com/project/gradle/java-package.html)\n\n## 文件\n在Gradle编译脚本文件中我们还可以自如的使用文件\n```java\nFile configFile = file('src/config.xml')\n```\n使用`file()`方法我们就可以打开一个文件.\n\n### 文件集合\n我们还可以使用`files()`方法创建文件集合\n```java\nFileCollection fils = files(\"t.txt\", new File(\"d.txt\"), [\"a.txt\", 'b.txt'])\n```\n我们还可以使用`+`, `-`符号增加或者删减文件\n```java\nFileCollection filc = files(\"t.txt\", new File(\"d.txt\"), [\"a.txt\", 'b.txt'])\nFileCollection newFiles1 = filc + files(\"c.txt\")\nFileCollection newFiles2 = filc - files(\"c.txt\")\n```\n我们还可以使用`as `将其转换为`Set`或者`List`\n```java\nSet set1 = filc.files\nSet set2 = filc as Set\nList list = filc as List\n```\n","slug":"Java 工具库/gradle","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihna000yvjs6b9k2d0ri"},{"date":"2016-06-11T14:04:45.000Z","title":"Log4J2 Appender","_content":"Log4j2为我们提供了非常多的Appender, 我们就是通过Appender最终将日志输出的.\n\n* Async\n* Console\n* Failover\n* File\n* Flume\n* JDBC\n* JMS Queue\n* JMS Topic\n* JPA\n* Kafka\n* Memory Mapped File\n* NoSQL\n* Output Stream\n* Random Access File\n* Rewrite\n* Rolling File\n* Rolling Random Access File\n* Routing\n* SMTP\n* Socket\n* Syslog\n* ZeroMQ/JeroMQ\n\n下面我们重点看一下, 日常开发中常用的一些\n\n## Async\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <File name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </File>\n    <Async name=\"Async\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Async>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Async\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\nAsyncAppender会在一个单独的线程中将日志写到其他的Appender中. \n\n## ConsoleAppender\n将日志输出到控制台\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <Console name=\"STDOUT\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%m%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"STDOUT\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## FailoverAppender\nFailoverAppender主要是用于当日志没办法输出到指定Appender的时候对这些日志的一个备选方案.\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <RollingFile name=\"RollingFile\" fileName=\"logs/app.log\" filePattern=\"logs/app-%d{MM-dd-yyyy}.log.gz\"\n                 ignoreExceptions=\"false\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n      <TimeBasedTriggeringPolicy />\n    </RollingFile>\n    <Console name=\"STDOUT\" target=\"SYSTEM_OUT\" ignoreExceptions=\"false\">\n      <PatternLayout pattern=\"%m%n\"/>\n    </Console>\n    <Failover name=\"Failover\" primary=\"RollingFile\">\n      <Failovers>\n        <AppenderRef ref=\"Console\"/>\n      </Failovers>\n    </Failover>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Failover\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## FileAppender\n将日志输出到fileName 文件里\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <File name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </File>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## RandomAccessFileAppender\n根据Log4j2的官网介绍RandomAccessFileAppender相比FileAppender有20-200% 的性能提升\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <RandomAccessFile name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </RandomAccessFile>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## RollingFileAppender\n```xml\n\n```\n\n## RollingRandomAccessFileAppender\n同样RollingRandomAccessFileAppender比RollingFileAppender有20%~200%的性能提升\n\n## SyslogAppender\n将日志输出到RSyslog中\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <Syslog name=\"bsd\" host=\"localhost\" port=\"514\" protocol=\"TCP\"/>\n    <Syslog name=\"RFC5424\" format=\"RFC5424\" host=\"localhost\" port=\"8514\"\n            protocol=\"TCP\" appName=\"MyApp\" includeMDC=\"true\"\n            facility=\"LOCAL0\" enterpriseNumber=\"18060\" newLine=\"true\"\n            messageId=\"Audit\" id=\"App\"/>\n  </Appenders>\n  <Loggers>\n    <Logger name=\"com.mycorp\" level=\"error\">\n      <AppenderRef ref=\"RFC5424\"/>\n    </Logger>\n    <Root level=\"error\">\n      <AppenderRef ref=\"bsd\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n","source":"_posts/Java 工具库/log4j2 Appender.md","raw":"category: Java工具\ndate: \ntitle: Log4J2 Appender\n---\nLog4j2为我们提供了非常多的Appender, 我们就是通过Appender最终将日志输出的.\n\n* Async\n* Console\n* Failover\n* File\n* Flume\n* JDBC\n* JMS Queue\n* JMS Topic\n* JPA\n* Kafka\n* Memory Mapped File\n* NoSQL\n* Output Stream\n* Random Access File\n* Rewrite\n* Rolling File\n* Rolling Random Access File\n* Routing\n* SMTP\n* Socket\n* Syslog\n* ZeroMQ/JeroMQ\n\n下面我们重点看一下, 日常开发中常用的一些\n\n## Async\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <File name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </File>\n    <Async name=\"Async\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Async>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Async\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\nAsyncAppender会在一个单独的线程中将日志写到其他的Appender中. \n\n## ConsoleAppender\n将日志输出到控制台\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <Console name=\"STDOUT\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%m%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"STDOUT\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## FailoverAppender\nFailoverAppender主要是用于当日志没办法输出到指定Appender的时候对这些日志的一个备选方案.\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <RollingFile name=\"RollingFile\" fileName=\"logs/app.log\" filePattern=\"logs/app-%d{MM-dd-yyyy}.log.gz\"\n                 ignoreExceptions=\"false\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n      <TimeBasedTriggeringPolicy />\n    </RollingFile>\n    <Console name=\"STDOUT\" target=\"SYSTEM_OUT\" ignoreExceptions=\"false\">\n      <PatternLayout pattern=\"%m%n\"/>\n    </Console>\n    <Failover name=\"Failover\" primary=\"RollingFile\">\n      <Failovers>\n        <AppenderRef ref=\"Console\"/>\n      </Failovers>\n    </Failover>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Failover\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## FileAppender\n将日志输出到fileName 文件里\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <File name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </File>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## RandomAccessFileAppender\n根据Log4j2的官网介绍RandomAccessFileAppender相比FileAppender有20-200% 的性能提升\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <RandomAccessFile name=\"MyFile\" fileName=\"logs/app.log\">\n      <PatternLayout>\n        <Pattern>%d %p %c{1.} [%t] %m%n</Pattern>\n      </PatternLayout>\n    </RandomAccessFile>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"MyFile\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n\n## RollingFileAppender\n```xml\n\n```\n\n## RollingRandomAccessFileAppender\n同样RollingRandomAccessFileAppender比RollingFileAppender有20%~200%的性能提升\n\n## SyslogAppender\n将日志输出到RSyslog中\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"warn\" name=\"MyApp\" packages=\"\">\n  <Appenders>\n    <Syslog name=\"bsd\" host=\"localhost\" port=\"514\" protocol=\"TCP\"/>\n    <Syslog name=\"RFC5424\" format=\"RFC5424\" host=\"localhost\" port=\"8514\"\n            protocol=\"TCP\" appName=\"MyApp\" includeMDC=\"true\"\n            facility=\"LOCAL0\" enterpriseNumber=\"18060\" newLine=\"true\"\n            messageId=\"Audit\" id=\"App\"/>\n  </Appenders>\n  <Loggers>\n    <Logger name=\"com.mycorp\" level=\"error\">\n      <AppenderRef ref=\"RFC5424\"/>\n    </Logger>\n    <Root level=\"error\">\n      <AppenderRef ref=\"bsd\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n","slug":"Java 工具库/log4j2 Appender","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnd0010vjs63io04c8e"},{"date":"2016-06-11T14:04:45.000Z","title":"Log4J2 初探","_content":"\nLog4J2会使用`ConfigurationFactory`从classpath上依次尝试加载下面的配置文件, 一旦找到就停止查找过程\n1. log4j.configurationFil\n2. log4j2-test.properties\n3. log4j2-test.yaml or log4j2-test.yml\n4. log4j2-test.json or log4j2-test.jsn\n5. log4j2-test.xml\n6. log4j2.properties\n7. log4j2.yaml or log4j2.yml\n8. log4j2.json or log4j2.jsn\n9. log4j2.xml\n从上面的配置文件,我们可以看到Log4J2支持, JSON, YAML, properties, XML 等四种格式的配置文件.\n\n如果找不到配置文件的话, 就会使用默认的配置\n* 想root logger 关联一个ConsoleAppender (root logger的默认等级是Level.ERROR)\n* ConsoleAppender指定一个PatternLayout, 其格式内容为`%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n`\n\n官网给出了一个简单的示例\n```java\nimport com.foo.Bar;\nimport org.apache.logging.log4j.Logger;\nimport org.apache.logging.log4j.LogManager;\n \npublic class MyApp {\n \n    // Define a static logger variable so that it references the\n    // Logger instance named \"MyApp\".\n    private static final Logger logger = LogManager.getLogger(MyApp.class);\n \n    public static void main(final String... args) {\n \n        // Set up a simple configuration that logs on the console.\n \n        logger.trace(\"Entering application.\");\n        Bar bar = new Bar();\n        if (!bar.doIt()) {\n            logger.error(\"Didn't do it.\");\n        }\n        logger.trace(\"Exiting application.\");\n    }\n}\n\npackage com.foo;\nimport org.apache.logging.log4j.Logger;\nimport org.apache.logging.log4j.LogManager;\n \npublic class Bar {\n  static final Logger logger = LogManager.getLogger(Bar.class.getName());\n \n  public boolean doIt() {\n    logger.entry();\n    logger.error(\"Did it again!\");\n    return logger.exit(false);\n  }\n}\n```\n配置文件为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\" monitorInterval=\"30\">\n  <Appenders>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n输出结果为\n```bash\n17:13:01.540 [main] TRACE MyApp - Entering application.\n17:13:01.540 [main] TRACE com.foo.Bar - entry\n17:13:01.540 [main] ERROR com.foo.Bar - Did it again!\n17:13:01.540 [main] TRACE com.foo.Bar - exit with (false)\n17:13:01.540 [main] ERROR MyApp - Didn't do it.\n17:13:01.540 [main] TRACE MyApp - Exiting application.\n```\n\n我们在配置里使用了一个`monitorInterval`属性, 这个属性是用来监控日志文件的, 每隔多少秒刷新一次.\n\n下面我们展示一个只有`com.foo.Bar`才会trace全部日志, 而其他的日志则只会输出ERROR级别的.\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Logger name=\"com.foo.Bar\" level=\"trace\" additivity=\"false\">\n      <AppenderRef ref=\"Console\"/>\n    </Logger>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n结果为\n```bash\n17:13:01.540 [main] TRACE com.foo.Bar - entry\n17:13:01.540 [main] ERROR com.foo.Bar - Did it again!\n17:13:01.540 [main] TRACE com.foo.Bar - exit (false)\n17:13:01.540 [main] ERROR MyApp - Didn't do it.\n```\n需要注意的是,我们在com.foo.Bar这个Logger后面添加了一个`additivity=\"false\"`的属性.\n\n关于日志级别我们来测试一下, 我们写一个Java程序\n```java\npublic class TestLevel {\n\tstatic final Logger logger = LogManager.getLogger(TestLookups.class.getName());\n\n\tpublic static void main(String[] args) {\n\n\t\tlogger.trace(\"test\");\n\t\tlogger.debug(\"test\");\n\t\tlogger.info(\"test\");\n\t\tlogger.warn(\"test\");\n\t\tlogger.error(\"test\");\n\t}\n}\n```\nlog4j2的配置文件为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\" monitorInterval=\"30\">\n    <Appenders>\n        <Console name=\"Console\" target=\"SYSTEM_OUT\">\n            <PatternLayout>\n                <pattern>%d %p %c{1.} [%t] $${ctx:loginId} %m%n</pattern>\n            </PatternLayout>\n        </Console>\n    </Appenders>\n    <Loggers>\n        <Root level=\"trace\">\n            <AppenderRef ref=\"Console\"/>\n        </Root>\n    </Loggers>\n</Configuration>\n```\n结果为\n```bash\n2016-05-12 18:29:55,570 TRACE t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,571 DEBUG t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为debug后结果为\n```bash\n2016-05-12 18:30:13,574 DEBUG t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为info后结果为\n```bash\n2016-05-12 18:30:43,042 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:43,043 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:43,044 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为warn后结果为\n```bash\n2016-05-12 18:31:18,095 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:31:18,096 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为error后结果为\n```bash\n2016-05-12 18:31:43,894 ERROR t.TestLookups [main] ${ctx:loginId} test\n```","source":"_posts/Java 工具库/log4j2.md","raw":"category: Java工具\ndate: \ntitle: Log4J2 初探\n---\n\nLog4J2会使用`ConfigurationFactory`从classpath上依次尝试加载下面的配置文件, 一旦找到就停止查找过程\n1. log4j.configurationFil\n2. log4j2-test.properties\n3. log4j2-test.yaml or log4j2-test.yml\n4. log4j2-test.json or log4j2-test.jsn\n5. log4j2-test.xml\n6. log4j2.properties\n7. log4j2.yaml or log4j2.yml\n8. log4j2.json or log4j2.jsn\n9. log4j2.xml\n从上面的配置文件,我们可以看到Log4J2支持, JSON, YAML, properties, XML 等四种格式的配置文件.\n\n如果找不到配置文件的话, 就会使用默认的配置\n* 想root logger 关联一个ConsoleAppender (root logger的默认等级是Level.ERROR)\n* ConsoleAppender指定一个PatternLayout, 其格式内容为`%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n`\n\n官网给出了一个简单的示例\n```java\nimport com.foo.Bar;\nimport org.apache.logging.log4j.Logger;\nimport org.apache.logging.log4j.LogManager;\n \npublic class MyApp {\n \n    // Define a static logger variable so that it references the\n    // Logger instance named \"MyApp\".\n    private static final Logger logger = LogManager.getLogger(MyApp.class);\n \n    public static void main(final String... args) {\n \n        // Set up a simple configuration that logs on the console.\n \n        logger.trace(\"Entering application.\");\n        Bar bar = new Bar();\n        if (!bar.doIt()) {\n            logger.error(\"Didn't do it.\");\n        }\n        logger.trace(\"Exiting application.\");\n    }\n}\n\npackage com.foo;\nimport org.apache.logging.log4j.Logger;\nimport org.apache.logging.log4j.LogManager;\n \npublic class Bar {\n  static final Logger logger = LogManager.getLogger(Bar.class.getName());\n \n  public boolean doIt() {\n    logger.entry();\n    logger.error(\"Did it again!\");\n    return logger.exit(false);\n  }\n}\n```\n配置文件为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\" monitorInterval=\"30\">\n  <Appenders>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n输出结果为\n```bash\n17:13:01.540 [main] TRACE MyApp - Entering application.\n17:13:01.540 [main] TRACE com.foo.Bar - entry\n17:13:01.540 [main] ERROR com.foo.Bar - Did it again!\n17:13:01.540 [main] TRACE com.foo.Bar - exit with (false)\n17:13:01.540 [main] ERROR MyApp - Didn't do it.\n17:13:01.540 [main] TRACE MyApp - Exiting application.\n```\n\n我们在配置里使用了一个`monitorInterval`属性, 这个属性是用来监控日志文件的, 每隔多少秒刷新一次.\n\n下面我们展示一个只有`com.foo.Bar`才会trace全部日志, 而其他的日志则只会输出ERROR级别的.\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\n    </Console>\n  </Appenders>\n  <Loggers>\n    <Logger name=\"com.foo.Bar\" level=\"trace\" additivity=\"false\">\n      <AppenderRef ref=\"Console\"/>\n    </Logger>\n    <Root level=\"error\">\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n```\n结果为\n```bash\n17:13:01.540 [main] TRACE com.foo.Bar - entry\n17:13:01.540 [main] ERROR com.foo.Bar - Did it again!\n17:13:01.540 [main] TRACE com.foo.Bar - exit (false)\n17:13:01.540 [main] ERROR MyApp - Didn't do it.\n```\n需要注意的是,我们在com.foo.Bar这个Logger后面添加了一个`additivity=\"false\"`的属性.\n\n关于日志级别我们来测试一下, 我们写一个Java程序\n```java\npublic class TestLevel {\n\tstatic final Logger logger = LogManager.getLogger(TestLookups.class.getName());\n\n\tpublic static void main(String[] args) {\n\n\t\tlogger.trace(\"test\");\n\t\tlogger.debug(\"test\");\n\t\tlogger.info(\"test\");\n\t\tlogger.warn(\"test\");\n\t\tlogger.error(\"test\");\n\t}\n}\n```\nlog4j2的配置文件为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Configuration status=\"WARN\" monitorInterval=\"30\">\n    <Appenders>\n        <Console name=\"Console\" target=\"SYSTEM_OUT\">\n            <PatternLayout>\n                <pattern>%d %p %c{1.} [%t] $${ctx:loginId} %m%n</pattern>\n            </PatternLayout>\n        </Console>\n    </Appenders>\n    <Loggers>\n        <Root level=\"trace\">\n            <AppenderRef ref=\"Console\"/>\n        </Root>\n    </Loggers>\n</Configuration>\n```\n结果为\n```bash\n2016-05-12 18:29:55,570 TRACE t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,571 DEBUG t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:29:55,572 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为debug后结果为\n```bash\n2016-05-12 18:30:13,574 DEBUG t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:13,575 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为info后结果为\n```bash\n2016-05-12 18:30:43,042 INFO t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:43,043 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:30:43,044 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为warn后结果为\n```bash\n2016-05-12 18:31:18,095 WARN t.TestLookups [main] ${ctx:loginId} test\n2016-05-12 18:31:18,096 ERROR t.TestLookups [main] ${ctx:loginId} test\n```\n级别改为error后结果为\n```bash\n2016-05-12 18:31:43,894 ERROR t.TestLookups [main] ${ctx:loginId} test\n```","slug":"Java 工具库/log4j2","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihng0012vjs6gjv9b66u"},{"date":"2015-12-08T16:00:00.000Z","title":"Lombok初探","_content":"参考文档[lombok](https://projectlombok.org/features/index.html)\n在使用lombok的时候, 我们需要在IDE上安装上lombok插件以及引用相关的jar包依赖\n```xml\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.16.6</version>\n</dependency>\n```\n\nlombok其实帮我们做的事情是, 在编译java源码的时候,会根据相关注解编译出相关的代码. 例如如果我们使用`@Setter`注解的话,那么在编译的会在class文件中添加相应的setter代码\n\n## val\n下来我们看一个小例子\n```java\nval example = new ArrayList<String>();\nexample.add(\"Hello, World!\");\nval foo = example.get(0);\nSystem.out.println(foo.equals(\"Hello, World!\"));\n```\n上面这个例子我们使用val代替了`ArrayList`类型. 插件会只能地帮我们识别出这个真正的类型是什么.\n\n> 注意, `new ArrayList<String>()`菱形符里应该指定类型,否则我们既可以在example上添加String又可以添加int,会带来类型上的不安全\n\n## NonNull\n```java\npublic class TestNonNull {\n\tpublic static void main(String[] args) {\n\t\tprint(null);\n\t}\n\n\tpublic static void print(@NonNull String content) {\n\t\tSystem.out.println(content);\n\t}\n}\n```\n这个注解很简单就是检查参数非null,如果传进的参数为null的就抛出\n```java\nException in thread \"main\" java.lang.NullPointerException: content\n\tat Lombok.TestNonNull.print(TestNonNull.java:13)\n\tat Lombok.TestNonNull.main(TestNonNull.java:10)\n```\n\n## Cleanup\n这个注解会在资源在其作用域离开之后,自动将资源关闭掉\n```java\n@Cleanup BufferedReader fileReader1 = new BufferedReader(new FileReader(\"D://hazelcast-documentation-3.5.3.pdf\"));\n```\n\n## Getter Setter\n```java\npublic class TestGetterSetter {\n\tpublic static void main(String[] args) {\n\t\tA a = new A();\n\t\ta.getA2();\n\t\ta.getA3();\n\t\ta.setA1(\"a1\");\n\t\ta.setA3(\"a3\");\n\t}\n}\n\nclass A {\n\t@Setter private String a1;\n\t@Getter private String a2;\n\t@Setter @Getter private String a3;\n\n}\n```\n`@Getter`和`@Setter`注解有一点需要说明的是,我们可以指定他们的访问级别\n```java\n@Setter(value = AccessLevel.MODULE) private String a1;\n```\n可设置的级别有:\n* PUBLIC,\n* MODULE,\n* PROTECTED,\n* PACKAGE,\n* PRIVATE,\n* NONE;\n\n## ToString\n`@ToString`注解既可以用在类上可以用在方法上, 这个注解会修改类的`toString()`方法\n\n```java\npublic class TestToString {\n\tpublic static void main(String[] args) {\n\t\tC c = new C();\n\t\tc.c1 = \"c_1\";\n\t\tc.c2 = \"c_2\";\n\t\tc.b1 = \"b_1\";\n\t\tc.b2 = \"b_2\";\n\t\tSystem.out.println(c);\n\n\t}\n}\n\n// toString()中不包含b1和b2这俩个属性\n@ToString(exclude={\"b1\", \"b2\"})\nclass B {\n\tpublic String b1;\n\tpublic String b2;\n\tpublic String b3;\n}\n\n// 调用父类的toString和在输出时包含字段名称\n@ToString(callSuper=true, includeFieldNames = true)\nclass C extends B {\n\tpublic String c1;\n\tpublic String c2;\n}\n```\n上面代码输出为\n```java\nC(super=B(b2=null), c1=null, c2=null)\nB(b2=null)\nC(super=B(b2=b_2), c1=c_1, c2=c_2)\n```\n\n## EqualsAndHashCode\n这个注解人如其名, 会为我们生成俩个规范的`equals()`和`hashCode()`方法, 至于什么是规范的,参考Effective java这本书\n```java\n@EqualsAndHashCode\nclass D {\n\n}\n```\n\n## Data\n`@Data`注解是`@ToString, @EqualsAndHashCode, @Getter / @Setter and @RequiredArgsConstructor `这些注解的一个集合. 它会默认地为我们使用那些注解.\n```java\n@Data class Simple {\n\tprivate int id;\n\n\tpublic void init() {\n\t\tsetId(123);\n\t}\n}\n```\n\n## Value\n`@Value`是`@Data`注解的一个变种, 它是在`@Data`注解的基础将,将类成为不可变的.\n```java\n@Value class E {\n\n}\n```\n\n## Builder\n`@Builder`将类修改成Builder模式(同样参考Effective Java).\n\n```java\npublic class TestBuilder {\n\tpublic static void main(String[] args) {\n\t\tF f = F.builder().f1(\"fff\").fAB(123).build();\n\t\tSystem.out.println(f.getF1());\n\t\tSystem.out.println(f.getFABs().size());\n\n\t\tG g = G.GBuilder().buildG();\n\n\t}\n}\n\n@Builder class F {\n\n\t@Getter private String f1;\n\n\t@Singular @Getter private Set<Integer> fABs;\n\t@Singular @Getter private Set<Integer> fAsBs;\n}\n\n@Builder(builderClassName = \"GBuilder\", buildMethodName = \"buildG\", builderMethodName = \"GBuilder\")\nclass G {\n\tpublic static void printG() {\n\t\tSystem.out.println(\"GGG\");\n\t}\n}\n```\n使用`@Singular`注解的集合属性名必须使用`s`结尾, lombok会将属性名结尾的`s`去掉,剩余的名字会作为方法名, 向这个集合中添加元素\n","source":"_posts/Java 工具库/lombok.md","raw":"category: Java工具\ndate: 2015-12-09\ntitle: Lombok初探\n---\n参考文档[lombok](https://projectlombok.org/features/index.html)\n在使用lombok的时候, 我们需要在IDE上安装上lombok插件以及引用相关的jar包依赖\n```xml\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.16.6</version>\n</dependency>\n```\n\nlombok其实帮我们做的事情是, 在编译java源码的时候,会根据相关注解编译出相关的代码. 例如如果我们使用`@Setter`注解的话,那么在编译的会在class文件中添加相应的setter代码\n\n## val\n下来我们看一个小例子\n```java\nval example = new ArrayList<String>();\nexample.add(\"Hello, World!\");\nval foo = example.get(0);\nSystem.out.println(foo.equals(\"Hello, World!\"));\n```\n上面这个例子我们使用val代替了`ArrayList`类型. 插件会只能地帮我们识别出这个真正的类型是什么.\n\n> 注意, `new ArrayList<String>()`菱形符里应该指定类型,否则我们既可以在example上添加String又可以添加int,会带来类型上的不安全\n\n## NonNull\n```java\npublic class TestNonNull {\n\tpublic static void main(String[] args) {\n\t\tprint(null);\n\t}\n\n\tpublic static void print(@NonNull String content) {\n\t\tSystem.out.println(content);\n\t}\n}\n```\n这个注解很简单就是检查参数非null,如果传进的参数为null的就抛出\n```java\nException in thread \"main\" java.lang.NullPointerException: content\n\tat Lombok.TestNonNull.print(TestNonNull.java:13)\n\tat Lombok.TestNonNull.main(TestNonNull.java:10)\n```\n\n## Cleanup\n这个注解会在资源在其作用域离开之后,自动将资源关闭掉\n```java\n@Cleanup BufferedReader fileReader1 = new BufferedReader(new FileReader(\"D://hazelcast-documentation-3.5.3.pdf\"));\n```\n\n## Getter Setter\n```java\npublic class TestGetterSetter {\n\tpublic static void main(String[] args) {\n\t\tA a = new A();\n\t\ta.getA2();\n\t\ta.getA3();\n\t\ta.setA1(\"a1\");\n\t\ta.setA3(\"a3\");\n\t}\n}\n\nclass A {\n\t@Setter private String a1;\n\t@Getter private String a2;\n\t@Setter @Getter private String a3;\n\n}\n```\n`@Getter`和`@Setter`注解有一点需要说明的是,我们可以指定他们的访问级别\n```java\n@Setter(value = AccessLevel.MODULE) private String a1;\n```\n可设置的级别有:\n* PUBLIC,\n* MODULE,\n* PROTECTED,\n* PACKAGE,\n* PRIVATE,\n* NONE;\n\n## ToString\n`@ToString`注解既可以用在类上可以用在方法上, 这个注解会修改类的`toString()`方法\n\n```java\npublic class TestToString {\n\tpublic static void main(String[] args) {\n\t\tC c = new C();\n\t\tc.c1 = \"c_1\";\n\t\tc.c2 = \"c_2\";\n\t\tc.b1 = \"b_1\";\n\t\tc.b2 = \"b_2\";\n\t\tSystem.out.println(c);\n\n\t}\n}\n\n// toString()中不包含b1和b2这俩个属性\n@ToString(exclude={\"b1\", \"b2\"})\nclass B {\n\tpublic String b1;\n\tpublic String b2;\n\tpublic String b3;\n}\n\n// 调用父类的toString和在输出时包含字段名称\n@ToString(callSuper=true, includeFieldNames = true)\nclass C extends B {\n\tpublic String c1;\n\tpublic String c2;\n}\n```\n上面代码输出为\n```java\nC(super=B(b2=null), c1=null, c2=null)\nB(b2=null)\nC(super=B(b2=b_2), c1=c_1, c2=c_2)\n```\n\n## EqualsAndHashCode\n这个注解人如其名, 会为我们生成俩个规范的`equals()`和`hashCode()`方法, 至于什么是规范的,参考Effective java这本书\n```java\n@EqualsAndHashCode\nclass D {\n\n}\n```\n\n## Data\n`@Data`注解是`@ToString, @EqualsAndHashCode, @Getter / @Setter and @RequiredArgsConstructor `这些注解的一个集合. 它会默认地为我们使用那些注解.\n```java\n@Data class Simple {\n\tprivate int id;\n\n\tpublic void init() {\n\t\tsetId(123);\n\t}\n}\n```\n\n## Value\n`@Value`是`@Data`注解的一个变种, 它是在`@Data`注解的基础将,将类成为不可变的.\n```java\n@Value class E {\n\n}\n```\n\n## Builder\n`@Builder`将类修改成Builder模式(同样参考Effective Java).\n\n```java\npublic class TestBuilder {\n\tpublic static void main(String[] args) {\n\t\tF f = F.builder().f1(\"fff\").fAB(123).build();\n\t\tSystem.out.println(f.getF1());\n\t\tSystem.out.println(f.getFABs().size());\n\n\t\tG g = G.GBuilder().buildG();\n\n\t}\n}\n\n@Builder class F {\n\n\t@Getter private String f1;\n\n\t@Singular @Getter private Set<Integer> fABs;\n\t@Singular @Getter private Set<Integer> fAsBs;\n}\n\n@Builder(builderClassName = \"GBuilder\", buildMethodName = \"buildG\", builderMethodName = \"GBuilder\")\nclass G {\n\tpublic static void printG() {\n\t\tSystem.out.println(\"GGG\");\n\t}\n}\n```\n使用`@Singular`注解的集合属性名必须使用`s`结尾, lombok会将属性名结尾的`s`去掉,剩余的名字会作为方法名, 向这个集合中添加元素\n","slug":"Java 工具库/lombok","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnk0014vjs60v2j355p"},{"date":"2016-04-12T16:00:00.000Z","title":"Maven Assembly 插件","_content":"学习自[assembly插件官方教程](http://maven.apache.org/plugins/maven-assembly-plugin/)\n## 目标\n目前assembly插件只有`assembly:single`可用, 其他的都已经被废弃了.\n```xml\nmvn assembly:single\n```\n\n## jar包\n下面我们将assembly插件绑定到package阶段, 打出一个可运行jar包,同时该jar包里包含了所有的依赖类.\n```xml\n<build>\n    <pluginManagement>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-assembly-plugin</artifactId>\n                <version>2.6</version>\n            </plugin>\n        </plugins>\n    </pluginManagement>\n    <plugins>\n        <!-- 引用maven-assembly-plugin插件 -->\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <version>2.6</version>\n            <configuration>\n                <!-- 引用jar-with-dependencies, 在打包时将依赖包也打包进jar包里 -->\n                <descriptorRefs>\n                    <descriptorRef>jar-with-dependencies</descriptorRef>\n                </descriptorRefs>\n                <!-- 创建一个可执行jar包, 我们在此处指定main class-->\n                <archive>\n                    <manifest>\n                        <mainClass>org.sample.App</mainClass>\n                    </manifest>\n                </archive>\n            </configuration>\n            <executions>\n                <!-- 我们将assembly:single目标绑定到package阶段, 那么当我们运行mvn package时, 就会执行该目标 -->\n                <execution>\n                    <id>make-assembly</id> <!-- this is used for inheritance merges -->\n                    <phase>package</phase> <!-- bind to the packaging phase -->\n                    <goals>\n                        <goal>single</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n\n## 过滤文件\n我们可以自己实现一个descriptor来实现文件过滤功能\n```xml\n<assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd\">\n  <id>distribution</id>\n  <formats>\n\t<!-- 设置打包的最终文件格式 -->\n    <format>jar</format>\n  </formats>\n  <fileSets>\n    <fileSet>\n      <directory>${basedir}</directory>\n      <includes>\n        <include>*.txt</include>\n      </includes>\n      <excludes>\n        <exclude>README.txt</exclude>\n        <exclude>NOTICE.txt</exclude>\n      </excludes>\n    </fileSet>\n  </fileSets>\n  <files>\n    <file>\n      <source>README.txt</source>\n      <outputDirectory>/</outputDirectory>\n      <filtered>true</filtered>\n    </file>\n    <file>\n      <source>NOTICE.txt</source>\n      <outputDirectory>/</outputDirectory>\n      <filtered>true</filtered>\n    </file>\n  </files>\n</assembly>\n```\n* fileSets用于过滤文件夹中的文件\n* files用于过滤单个文件\n然后我们在pom文件中使用\n```xml\n<plugin>\n  <artifactId>maven-assembly-plugin</artifactId>\n  <version>2.6</version>\n  <configuration>\n    <filters>\n      <filter>src/assembly/filter.properties</filter>\n    </filters>\n    <descriptors>\n      <descriptor>src/assembly/distribution.xml</descriptor>\n    </descriptors>\n  </configuration>\n</plugin>\n```\nfilter.properties文件内容如下\n```xml\n# lines beginning with the # sign are comments\n\nvariable1=value1\nvariable2=value2\n```\n\n## 过滤依赖\n在pom文件中我们可能会有很多依赖, 但是打出的包, 我们可能并不需要这些依赖, 那么我们 可以在descriptor文件中将其过滤掉\n```\n<dependencySets>\n  <dependencySet>\n    <excludes>\n      <exclude>commons-lang:commons-lang</exclude>\n      <exclude>log4j:log4j</exclude>\n    </excludes>\n  </dependencySet>\n</dependencySets>\n```\n\n## 打包子模块\n有的时候我们的工程会有一些子工程, 那么在打包的时候, 我们也希望将子工程也打包进来. 例如我们有一个这样的工程pom文件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.test</groupId>\n  <artifactId>parent</artifactId>\n  <version>1.0</version>\n\n  <packaging>pom</packaging>\n\n  <name>Parent</name>\n\n  <modules>\n    <module>child1</module>\n    <module>child2</module>\n    <module>child3</module>\n  </modules>\n\n  <build>\n    <plugins>\n      <plugin>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <version>2.6</version>\n        <configuration>\n          <descriptors>\n            <descriptor>src/assembly/src.xml</descriptor>\n          </descriptors>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\nsrc.xml如下\n```xml\n<assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd\">\n  <id>src</id>\n  <formats>\n    <format>dir</format>\n  </formats>\n  <includeBaseDirectory>false</includeBaseDirectory>\n  <moduleSets>\n    <moduleSet>\n      <includes>\n        <include>org.test:child1</include>\n      </includes>\n      <sources>\n        <outputDirectory>sources/${artifactId}</outputDirectory>\n      </sources>\n    </moduleSet>\n  </moduleSets>\n</assembly>\n```\n执行命令`mvn clean assembly:directory`打包的结果为\n```xml\ntarget/parent-1.0-src/\n`-- sources\n    `-- child1\n        |-- pom.xml\n        `-- src\n            |-- main\n            |   `-- java\n            |       `-- org\n            |           `-- test\n            |               `-- App.java\n            `-- test\n                `-- java\n                    `-- org\n                        `-- test\n                            `-- AppTest.java\n```\n","source":"_posts/Java 工具库/maven assembly插件.md","raw":"category: Java工具\ndate: 2016-04-13\ntitle: Maven Assembly 插件\n---\n学习自[assembly插件官方教程](http://maven.apache.org/plugins/maven-assembly-plugin/)\n## 目标\n目前assembly插件只有`assembly:single`可用, 其他的都已经被废弃了.\n```xml\nmvn assembly:single\n```\n\n## jar包\n下面我们将assembly插件绑定到package阶段, 打出一个可运行jar包,同时该jar包里包含了所有的依赖类.\n```xml\n<build>\n    <pluginManagement>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-assembly-plugin</artifactId>\n                <version>2.6</version>\n            </plugin>\n        </plugins>\n    </pluginManagement>\n    <plugins>\n        <!-- 引用maven-assembly-plugin插件 -->\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <version>2.6</version>\n            <configuration>\n                <!-- 引用jar-with-dependencies, 在打包时将依赖包也打包进jar包里 -->\n                <descriptorRefs>\n                    <descriptorRef>jar-with-dependencies</descriptorRef>\n                </descriptorRefs>\n                <!-- 创建一个可执行jar包, 我们在此处指定main class-->\n                <archive>\n                    <manifest>\n                        <mainClass>org.sample.App</mainClass>\n                    </manifest>\n                </archive>\n            </configuration>\n            <executions>\n                <!-- 我们将assembly:single目标绑定到package阶段, 那么当我们运行mvn package时, 就会执行该目标 -->\n                <execution>\n                    <id>make-assembly</id> <!-- this is used for inheritance merges -->\n                    <phase>package</phase> <!-- bind to the packaging phase -->\n                    <goals>\n                        <goal>single</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n\n## 过滤文件\n我们可以自己实现一个descriptor来实现文件过滤功能\n```xml\n<assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd\">\n  <id>distribution</id>\n  <formats>\n\t<!-- 设置打包的最终文件格式 -->\n    <format>jar</format>\n  </formats>\n  <fileSets>\n    <fileSet>\n      <directory>${basedir}</directory>\n      <includes>\n        <include>*.txt</include>\n      </includes>\n      <excludes>\n        <exclude>README.txt</exclude>\n        <exclude>NOTICE.txt</exclude>\n      </excludes>\n    </fileSet>\n  </fileSets>\n  <files>\n    <file>\n      <source>README.txt</source>\n      <outputDirectory>/</outputDirectory>\n      <filtered>true</filtered>\n    </file>\n    <file>\n      <source>NOTICE.txt</source>\n      <outputDirectory>/</outputDirectory>\n      <filtered>true</filtered>\n    </file>\n  </files>\n</assembly>\n```\n* fileSets用于过滤文件夹中的文件\n* files用于过滤单个文件\n然后我们在pom文件中使用\n```xml\n<plugin>\n  <artifactId>maven-assembly-plugin</artifactId>\n  <version>2.6</version>\n  <configuration>\n    <filters>\n      <filter>src/assembly/filter.properties</filter>\n    </filters>\n    <descriptors>\n      <descriptor>src/assembly/distribution.xml</descriptor>\n    </descriptors>\n  </configuration>\n</plugin>\n```\nfilter.properties文件内容如下\n```xml\n# lines beginning with the # sign are comments\n\nvariable1=value1\nvariable2=value2\n```\n\n## 过滤依赖\n在pom文件中我们可能会有很多依赖, 但是打出的包, 我们可能并不需要这些依赖, 那么我们 可以在descriptor文件中将其过滤掉\n```\n<dependencySets>\n  <dependencySet>\n    <excludes>\n      <exclude>commons-lang:commons-lang</exclude>\n      <exclude>log4j:log4j</exclude>\n    </excludes>\n  </dependencySet>\n</dependencySets>\n```\n\n## 打包子模块\n有的时候我们的工程会有一些子工程, 那么在打包的时候, 我们也希望将子工程也打包进来. 例如我们有一个这样的工程pom文件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.test</groupId>\n  <artifactId>parent</artifactId>\n  <version>1.0</version>\n\n  <packaging>pom</packaging>\n\n  <name>Parent</name>\n\n  <modules>\n    <module>child1</module>\n    <module>child2</module>\n    <module>child3</module>\n  </modules>\n\n  <build>\n    <plugins>\n      <plugin>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <version>2.6</version>\n        <configuration>\n          <descriptors>\n            <descriptor>src/assembly/src.xml</descriptor>\n          </descriptors>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\nsrc.xml如下\n```xml\n<assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd\">\n  <id>src</id>\n  <formats>\n    <format>dir</format>\n  </formats>\n  <includeBaseDirectory>false</includeBaseDirectory>\n  <moduleSets>\n    <moduleSet>\n      <includes>\n        <include>org.test:child1</include>\n      </includes>\n      <sources>\n        <outputDirectory>sources/${artifactId}</outputDirectory>\n      </sources>\n    </moduleSet>\n  </moduleSets>\n</assembly>\n```\n执行命令`mvn clean assembly:directory`打包的结果为\n```xml\ntarget/parent-1.0-src/\n`-- sources\n    `-- child1\n        |-- pom.xml\n        `-- src\n            |-- main\n            |   `-- java\n            |       `-- org\n            |           `-- test\n            |               `-- App.java\n            `-- test\n                `-- java\n                    `-- org\n                        `-- test\n                            `-- AppTest.java\n```\n","slug":"Java 工具库/maven assembly插件","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnn0016vjs6rm00tnu5"},{"date":"2015-06-07T16:00:00.000Z","title":"Maven","_content":"## 版本管理\n自动化版本发布基于正确的版本号. 一般我们的版本号构成为`主要版本号.次要版本号.增量版本号-里程碑版本号`. 下面是pom文件中插件设置：\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.5.2</version>\n    <configuration>\n\t\t<!-- 如果项目结构不是采用标准的SVN布局(平行的trunk/tags/branches),则需要配置下面俩项 -->\n\t\t<tagBase>https://svn.mycompany.com/repos/myapplication/tags</tagBase>\n\t\t<branchBase>https://svn.mycompany.com/repos/myapplication/branchs</branchBase>\n    </configuration>\n</plugin>\n```\n下来我们在命令行执行命令：\n```java\nmvn release:clean\n```\n先执行清除操作,然后执行下列命令准备版本发布：\n```java\nmvn release:prepare\n```\n该命令包含下列操作：\n* 检查项目是否有未提交代码\n* 检查项目是否有快照版本依赖\n* 根据用户的输入将快照版本升级为发布版\n* 将POM中的SCM信息更新为TAG地址\n* 基于修改后的POM执行MAVEN构建\n* 提交POM变更\n* 基于用户的输入将代码打TAG\n* 将代码从发布版升级为新的快照版\n* 提交POM变更\n\n当前俩项检查ok之后,插件会提示用户输出想要发布的版本号,TAG名称和新的快照版本号\n\n我们还可以执行回滚:\n```java\nmvn release:rollback\n```\n回滚`release:prepare`所执行的操作. 但是需要注意的是在`release:prepare`步骤中打出的TAG并不会被删除,需要手动删除.\n\n接下来就可以执行版本发布了：\n```java\nmvn release:perform\n```\n它会检出`release:prepare`生成的TAG源码,并在此基础上执行`mvn deploy`,打包并部署到仓库.\n\n\n```java\nmvn release:stage\n```\n\n还有一个更棒的功能：打分支\n```java\nmvn release:branch\n```\n通过maven打分支,执行下列操作\n* 检查项目是否有未提交代码\n* 为分支更改POM的版本,例如从`1.1.00SNAPSHOT`改变为`1.1.1-SNAPSHOT`\n* 将POM中的SCM信息更新为分支地址\n* 提交以上更改\n* 将主干代码更新为分支代码\n* 修改本地代码使之回退到之前的版本(用户可以指定新的版本)\n* 提交本地更改\n\n\n```java\nmvn release:update-versions\n```\n\n## 生命周期\nMaven的生命周期就是对所有的构建过程进行抽象和统一.Maven的生命周期是抽象的,因此生命周期本身是并不做任何实际工作的,实际的任务交给插件来完成.\n\nMaven拥有如下三套相互独立的生命周期,每个生命周期都包含一些阶段(phase),阶段是按照顺序执行的,而且当PhaseA在PhaseB之前,那么当执行PhaseB时会先执行PhaseA. 但是这三套生命周期是完全独立的.\n\n### clean生命周期\n清理项目,下列是该生命周期的阶段\n* `pre-clean`\n* `clean`\n* `post-clean`\n该生命周期包含的Maven命令：\n```java\nmvn clean\n```\n\n### default生命周期\n构建项目,下列是该生命周期的阶段\n* `validate`\n* `initialize`\n* `generate-sources`\n* `process-sources`\n* `generate-resources`\n* `process-resources`\n* `compile`\n* `process-class`\n* `generate-test-sources`\n* `process-test-sourcs`\n* `generate-test-resources`\n* `process-test-resources`\n* `test-compile`\n* `process-test-classes`\n* `test`\n* `generate-package`\n* `package`\n* `pre-interation-test`\n* `interation-test`\n* `post-interatopm-test`\n* `verify`\n* `install`\n* `deploy`\n该生命周期包含的Maven命令：\n```java\nmvn validate\nmvn compile\nmvn test\nmvn package\nmvn verify\nmvn install\nmvn deploy\n```\n\n安装jar包到本地库\n```java\nmvn install:install-file -DgroupId=demo -DartifactId=test -Dversion=1.0 -Dpackaging=jar -Dfile=E:\\XingeApp.jar\n```\n安装到自己搭建的中央仓库\n```java\nmvn deploy:deploy-file -DgroupId=demo -DartifactId=demo -Dversion=1.0 -Dpackaging=jar -Dfile=E:\\XingeApp.jar -Durl=[url] -DrepositoryId=[id]\n```\n\nmaven依赖本地tools.jar\n```xml\n<dependency>\n    <groupId>com.sun</groupId>\n    <artifactId>tools</artifactId>\n    <version>1.8</version>\n    <scope>system</scope>\n    <systemPath>D:/Program Files/Java/jdk1.8.0_77/lib/tools.jar</systemPath>\n</dependency>\n```\n\n### site生命周期\n建立项目站点,下列是该生命周期的阶段\n* `pre-site`\n* `site`\n* `post-site`\n* `site-deploy`\n该生命周期包含的Maven命令：\n```java\nmvn site\n```\n\n\n## maven属性\n### 内置属性\n* `${basedir}`: 表示项目根目录,即包含`pom.xml`文件的目录\n* `${version}`:项目版本\n\n### POM属性\n该类属性引用POM文件中对应的元素值,例如：\n* `${project.artifactId}`: 引用`<project><artifactId>`值\n* `${project.build.sourceDirectory}`: 项目的主源码目录\n* `${project.build.directory}`: 项目构建的输出目录\n\n### 自定义属性\n在`<Properties><property>`里定义的属性\n\n### setting属性\n与POM属性同理,但是以`settings`开头. 这个属性引用的是`setting.xml`文件中XML元素的值.\n\n### Java系统属性\n所有JAVA系统中的属性都可以使用Maven属性引用,使用`mvn help:system`查看所有Java系统属性\n\n### 环境变量属性\n所有环境变量属性属性都可以使用`env`开头的属性引用,例如`${env.JAVA_HOME}`\n","source":"_posts/Java 工具库/maven.md","raw":"category: Java工具\ndate: 2015-06-08\ntitle: Maven\n---\n## 版本管理\n自动化版本发布基于正确的版本号. 一般我们的版本号构成为`主要版本号.次要版本号.增量版本号-里程碑版本号`. 下面是pom文件中插件设置：\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.5.2</version>\n    <configuration>\n\t\t<!-- 如果项目结构不是采用标准的SVN布局(平行的trunk/tags/branches),则需要配置下面俩项 -->\n\t\t<tagBase>https://svn.mycompany.com/repos/myapplication/tags</tagBase>\n\t\t<branchBase>https://svn.mycompany.com/repos/myapplication/branchs</branchBase>\n    </configuration>\n</plugin>\n```\n下来我们在命令行执行命令：\n```java\nmvn release:clean\n```\n先执行清除操作,然后执行下列命令准备版本发布：\n```java\nmvn release:prepare\n```\n该命令包含下列操作：\n* 检查项目是否有未提交代码\n* 检查项目是否有快照版本依赖\n* 根据用户的输入将快照版本升级为发布版\n* 将POM中的SCM信息更新为TAG地址\n* 基于修改后的POM执行MAVEN构建\n* 提交POM变更\n* 基于用户的输入将代码打TAG\n* 将代码从发布版升级为新的快照版\n* 提交POM变更\n\n当前俩项检查ok之后,插件会提示用户输出想要发布的版本号,TAG名称和新的快照版本号\n\n我们还可以执行回滚:\n```java\nmvn release:rollback\n```\n回滚`release:prepare`所执行的操作. 但是需要注意的是在`release:prepare`步骤中打出的TAG并不会被删除,需要手动删除.\n\n接下来就可以执行版本发布了：\n```java\nmvn release:perform\n```\n它会检出`release:prepare`生成的TAG源码,并在此基础上执行`mvn deploy`,打包并部署到仓库.\n\n\n```java\nmvn release:stage\n```\n\n还有一个更棒的功能：打分支\n```java\nmvn release:branch\n```\n通过maven打分支,执行下列操作\n* 检查项目是否有未提交代码\n* 为分支更改POM的版本,例如从`1.1.00SNAPSHOT`改变为`1.1.1-SNAPSHOT`\n* 将POM中的SCM信息更新为分支地址\n* 提交以上更改\n* 将主干代码更新为分支代码\n* 修改本地代码使之回退到之前的版本(用户可以指定新的版本)\n* 提交本地更改\n\n\n```java\nmvn release:update-versions\n```\n\n## 生命周期\nMaven的生命周期就是对所有的构建过程进行抽象和统一.Maven的生命周期是抽象的,因此生命周期本身是并不做任何实际工作的,实际的任务交给插件来完成.\n\nMaven拥有如下三套相互独立的生命周期,每个生命周期都包含一些阶段(phase),阶段是按照顺序执行的,而且当PhaseA在PhaseB之前,那么当执行PhaseB时会先执行PhaseA. 但是这三套生命周期是完全独立的.\n\n### clean生命周期\n清理项目,下列是该生命周期的阶段\n* `pre-clean`\n* `clean`\n* `post-clean`\n该生命周期包含的Maven命令：\n```java\nmvn clean\n```\n\n### default生命周期\n构建项目,下列是该生命周期的阶段\n* `validate`\n* `initialize`\n* `generate-sources`\n* `process-sources`\n* `generate-resources`\n* `process-resources`\n* `compile`\n* `process-class`\n* `generate-test-sources`\n* `process-test-sourcs`\n* `generate-test-resources`\n* `process-test-resources`\n* `test-compile`\n* `process-test-classes`\n* `test`\n* `generate-package`\n* `package`\n* `pre-interation-test`\n* `interation-test`\n* `post-interatopm-test`\n* `verify`\n* `install`\n* `deploy`\n该生命周期包含的Maven命令：\n```java\nmvn validate\nmvn compile\nmvn test\nmvn package\nmvn verify\nmvn install\nmvn deploy\n```\n\n安装jar包到本地库\n```java\nmvn install:install-file -DgroupId=demo -DartifactId=test -Dversion=1.0 -Dpackaging=jar -Dfile=E:\\XingeApp.jar\n```\n安装到自己搭建的中央仓库\n```java\nmvn deploy:deploy-file -DgroupId=demo -DartifactId=demo -Dversion=1.0 -Dpackaging=jar -Dfile=E:\\XingeApp.jar -Durl=[url] -DrepositoryId=[id]\n```\n\nmaven依赖本地tools.jar\n```xml\n<dependency>\n    <groupId>com.sun</groupId>\n    <artifactId>tools</artifactId>\n    <version>1.8</version>\n    <scope>system</scope>\n    <systemPath>D:/Program Files/Java/jdk1.8.0_77/lib/tools.jar</systemPath>\n</dependency>\n```\n\n### site生命周期\n建立项目站点,下列是该生命周期的阶段\n* `pre-site`\n* `site`\n* `post-site`\n* `site-deploy`\n该生命周期包含的Maven命令：\n```java\nmvn site\n```\n\n\n## maven属性\n### 内置属性\n* `${basedir}`: 表示项目根目录,即包含`pom.xml`文件的目录\n* `${version}`:项目版本\n\n### POM属性\n该类属性引用POM文件中对应的元素值,例如：\n* `${project.artifactId}`: 引用`<project><artifactId>`值\n* `${project.build.sourceDirectory}`: 项目的主源码目录\n* `${project.build.directory}`: 项目构建的输出目录\n\n### 自定义属性\n在`<Properties><property>`里定义的属性\n\n### setting属性\n与POM属性同理,但是以`settings`开头. 这个属性引用的是`setting.xml`文件中XML元素的值.\n\n### Java系统属性\n所有JAVA系统中的属性都可以使用Maven属性引用,使用`mvn help:system`查看所有Java系统属性\n\n### 环境变量属性\n所有环境变量属性属性都可以使用`env`开头的属性引用,例如`${env.JAVA_HOME}`\n","slug":"Java 工具库/maven","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnp0018vjs6xw7sgent"},{"date":"2015-06-07T16:00:00.000Z","title":"Maven 插件","_content":"插件里会包含多个目标,每个目标都对应着特定的功能,也就是说插件里的功能是通过目标来实现了. 例如`maven-compiler-plugin`的`compile`目标的写法为`compiler:compile`.\n\n## 插件绑定\n我们可以将插件的目标与生命周期的阶段相绑定.\n\ndefault生命周期与内置插件绑定关系及具体任务:\n\n生命周期阶段                  | 插件目标                              |执行任务\n-----------------------------|--------------------------------------|--------------\nprocess-resources            |maven-resources-plugin:resources      |复制主资源文件至主输出目录\ncompile                      |maven-compile-plugin:compile\t        |编译主代码至主输出目录\nprocess-test-resources       |maven-resources-plugin:testRresources |复制测试资源文件至测试输出目录\ntest-compile                 |maven-compiler-plugin:testCompile     |编译测试代码至测试输出目录\ntest\t                     |maven-surefire-plugin:test            |执行测试用例\npackage\t                     |maven-jar-plugin:jar                  |创建项目jar包\ninstall\t                     |maven-install-plugin:install          |将项目输出构件安装到本地仓库\ndeploy                       |maven-deploy-plugin:deploy            |将项目输出构件部署到远程仓库\n\n\n我们来自定义绑定：\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.codehaus.mojo</groupId>\n            <artifactId>exec-maven-plugin</artifactId>\n            <version>1.1.1</version>\n            <executions>\n                <execution>\n                    <phase>install</phase>\n                    <goals>\n                        <goal>java</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n我们在`install`阶段绑定了`exec-maven-plugin`插件的`java`目标.\n\n## maven-jar-plugin\n当我们定义了`<packaging>jar</packaging>`后, 在packaging阶段就会自动调用`maven-jar-plugin`插件。如果是`<packaging>war</packaging>`则会调用`maven-war-plugin`插件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-jar-plugin</artifactId>\n                <configuration>\n                    <archive>\n                        <manifestFile>\n                            src/main/resources/META-INF/MANIFEST.MF\n                        </manifestFile>\n                    </archive>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n```\n在上面的例子中我们指定了MANIFEST文件, 其实还有另外一种写法\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <configuration>\n        <archive>\n            <manifest>\n                <addClasspath>true</addClasspath>\n                <classpathPrefix>lib/</classpathPrefix>\n                <mainClass>\n                    App\n                </mainClass>\n            </manifest>\n        </archive>\n    </configuration>\n</plugin>\n```\n除了`archive`还有一些其他的配置选项\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <configuration>\n        <!-- 指定排除的文件 -->\n        <excludes>\n            <exclude>**/service/*</exclude>\n        </excludes>\n        <!-- 指定包含的文件 -->\n        <includes>\n            <include>**/</include>\n        </includes>\n        <!-- 最终的jar包名, 会替换jarName -->\n        <finalName>finalName</finalName>\n        <!-- 如果没有指定finalName, 则会使用这个名字-->\n        <jarName>jarName</jarName>\n        <!-- 重新指定输出路径, 替换target-->\n        <outputDirectory>./newoutput</outputDirectory>\n    </configuration>\n</plugin>\n```\n\n## maven-dependency-plugin\nmaven-dependency-plugin是处理与依赖相关的插件. 我们一般使用它的copy依赖功能, 下面的例子就是将依赖copy到target/lib目录下\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-dependency-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <id>copy-dependencies</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>copy-dependencies</goal>\n                        </goals>\n                        <configuration>\n                            <outputDirectory>${project.build.directory}/lib</outputDirectory>\n                            <overWriteReleases>false</overWriteReleases>\n                            <overWriteSnapshots>false</overWriteSnapshots>\n                            <overWriteIfNewer>true</overWriteIfNewer>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n```\n\n## maven-shade-plugin\n引用或者排除引用指定的依赖\n```xml\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.apache.maven.plugins</groupId>\n      <artifactId>maven-shade-plugin</artifactId>\n      <version>2.4.3</version>\n      <executions>\n        <execution>\n          <phase>package</phase>\n          <goals>\n            <goal>shade</goal>\n          </goals>\n          <configuration>\n            <filters>\n              <filter>\n                <artifact>junit:junit</artifact>\n                <includes>\n                  <include>junit/framework/**</include>\n                  <include>org/junit/**</include>\n                </includes>\n                <excludes>\n                  <exclude>org/junit/experimental/**</exclude>\n                  <exclude>org/junit/runners/**</exclude>\n                </excludes>\n              </filter>\n              <filter>\n                <artifact>*:*</artifact>\n                <excludes>\n                  <exclude>META-INF/*.SF</exclude>\n                  <exclude>META-INF/*.DSA</exclude>\n                  <exclude>META-INF/*.RSA</exclude>\n                </excludes>\n              </filter>\n            </filters>\n          </configuration>\n        </execution>\n      </executions>\n    </plugin>\n  </plugins>\n</build>\n```\n\n## maven-resources-plugin\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-resources-plugin</artifactId>\n                <version>2.7</version>\n                <configuration>\n                    <!-- 因为拷贝文件涉及到了文件的读写, 在此指定读写文件时的编码格式-->\n                    <!--<encoding>UTF-8</encoding>-->\n                </configuration>\n                <executions>\n                    <execution>\n                        <id>copy-resources</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>copy-resources</goal>\n                        </goals>\n                        <configuration>\n                            <outputDirectory>${basedir}/target/package</outputDirectory>\n                            <resources>\n                                <resource>\n                                    <directory>d://copy</directory>\n                                    <filtering>false</filtering>\n                                    <includes>\n                                        <include>**/*.jar</include>\n                                    </includes>\n                                </resource>\n                            </resources>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n上面的例子中只拷贝了jar后缀的文件.\n\n> 因为每个execution只能指定一个输出目录, 因此我们要差异化拷贝的话, 可以多写几个execution来实现\n","source":"_posts/Java 工具库/maven插件.md","raw":"category: Java工具\ndate: 2015-06-08\ntitle: Maven 插件\n---\n插件里会包含多个目标,每个目标都对应着特定的功能,也就是说插件里的功能是通过目标来实现了. 例如`maven-compiler-plugin`的`compile`目标的写法为`compiler:compile`.\n\n## 插件绑定\n我们可以将插件的目标与生命周期的阶段相绑定.\n\ndefault生命周期与内置插件绑定关系及具体任务:\n\n生命周期阶段                  | 插件目标                              |执行任务\n-----------------------------|--------------------------------------|--------------\nprocess-resources            |maven-resources-plugin:resources      |复制主资源文件至主输出目录\ncompile                      |maven-compile-plugin:compile\t        |编译主代码至主输出目录\nprocess-test-resources       |maven-resources-plugin:testRresources |复制测试资源文件至测试输出目录\ntest-compile                 |maven-compiler-plugin:testCompile     |编译测试代码至测试输出目录\ntest\t                     |maven-surefire-plugin:test            |执行测试用例\npackage\t                     |maven-jar-plugin:jar                  |创建项目jar包\ninstall\t                     |maven-install-plugin:install          |将项目输出构件安装到本地仓库\ndeploy                       |maven-deploy-plugin:deploy            |将项目输出构件部署到远程仓库\n\n\n我们来自定义绑定：\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.codehaus.mojo</groupId>\n            <artifactId>exec-maven-plugin</artifactId>\n            <version>1.1.1</version>\n            <executions>\n                <execution>\n                    <phase>install</phase>\n                    <goals>\n                        <goal>java</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n我们在`install`阶段绑定了`exec-maven-plugin`插件的`java`目标.\n\n## maven-jar-plugin\n当我们定义了`<packaging>jar</packaging>`后, 在packaging阶段就会自动调用`maven-jar-plugin`插件。如果是`<packaging>war</packaging>`则会调用`maven-war-plugin`插件\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-jar-plugin</artifactId>\n                <configuration>\n                    <archive>\n                        <manifestFile>\n                            src/main/resources/META-INF/MANIFEST.MF\n                        </manifestFile>\n                    </archive>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n```\n在上面的例子中我们指定了MANIFEST文件, 其实还有另外一种写法\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <configuration>\n        <archive>\n            <manifest>\n                <addClasspath>true</addClasspath>\n                <classpathPrefix>lib/</classpathPrefix>\n                <mainClass>\n                    App\n                </mainClass>\n            </manifest>\n        </archive>\n    </configuration>\n</plugin>\n```\n除了`archive`还有一些其他的配置选项\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <configuration>\n        <!-- 指定排除的文件 -->\n        <excludes>\n            <exclude>**/service/*</exclude>\n        </excludes>\n        <!-- 指定包含的文件 -->\n        <includes>\n            <include>**/</include>\n        </includes>\n        <!-- 最终的jar包名, 会替换jarName -->\n        <finalName>finalName</finalName>\n        <!-- 如果没有指定finalName, 则会使用这个名字-->\n        <jarName>jarName</jarName>\n        <!-- 重新指定输出路径, 替换target-->\n        <outputDirectory>./newoutput</outputDirectory>\n    </configuration>\n</plugin>\n```\n\n## maven-dependency-plugin\nmaven-dependency-plugin是处理与依赖相关的插件. 我们一般使用它的copy依赖功能, 下面的例子就是将依赖copy到target/lib目录下\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-dependency-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <id>copy-dependencies</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>copy-dependencies</goal>\n                        </goals>\n                        <configuration>\n                            <outputDirectory>${project.build.directory}/lib</outputDirectory>\n                            <overWriteReleases>false</overWriteReleases>\n                            <overWriteSnapshots>false</overWriteSnapshots>\n                            <overWriteIfNewer>true</overWriteIfNewer>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n```\n\n## maven-shade-plugin\n引用或者排除引用指定的依赖\n```xml\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.apache.maven.plugins</groupId>\n      <artifactId>maven-shade-plugin</artifactId>\n      <version>2.4.3</version>\n      <executions>\n        <execution>\n          <phase>package</phase>\n          <goals>\n            <goal>shade</goal>\n          </goals>\n          <configuration>\n            <filters>\n              <filter>\n                <artifact>junit:junit</artifact>\n                <includes>\n                  <include>junit/framework/**</include>\n                  <include>org/junit/**</include>\n                </includes>\n                <excludes>\n                  <exclude>org/junit/experimental/**</exclude>\n                  <exclude>org/junit/runners/**</exclude>\n                </excludes>\n              </filter>\n              <filter>\n                <artifact>*:*</artifact>\n                <excludes>\n                  <exclude>META-INF/*.SF</exclude>\n                  <exclude>META-INF/*.DSA</exclude>\n                  <exclude>META-INF/*.RSA</exclude>\n                </excludes>\n              </filter>\n            </filters>\n          </configuration>\n        </execution>\n      </executions>\n    </plugin>\n  </plugins>\n</build>\n```\n\n## maven-resources-plugin\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>wang.ming15</groupId>\n    <artifactId>testMavenPlugin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n    </dependencies>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-resources-plugin</artifactId>\n                <version>2.7</version>\n                <configuration>\n                    <!-- 因为拷贝文件涉及到了文件的读写, 在此指定读写文件时的编码格式-->\n                    <!--<encoding>UTF-8</encoding>-->\n                </configuration>\n                <executions>\n                    <execution>\n                        <id>copy-resources</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>copy-resources</goal>\n                        </goals>\n                        <configuration>\n                            <outputDirectory>${basedir}/target/package</outputDirectory>\n                            <resources>\n                                <resource>\n                                    <directory>d://copy</directory>\n                                    <filtering>false</filtering>\n                                    <includes>\n                                        <include>**/*.jar</include>\n                                    </includes>\n                                </resource>\n                            </resources>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n上面的例子中只拷贝了jar后缀的文件.\n\n> 因为每个execution只能指定一个输出目录, 因此我们要差异化拷贝的话, 可以多写几个execution来实现\n","slug":"Java 工具库/maven插件","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihns001avjs6aq64r1jm"},{"date":"2015-06-07T16:00:00.000Z","title":"java读取csv文件","_content":"利用Apache Commons CSV读取csv文件, 首先我们添加如下依赖\n```xml\n<dependency>\n\t<groupId>org.apache.commons</groupId>\n\t<artifactId>commons-csv</artifactId>\n\t<version>1.2</version>\n</dependency>\n```\n读取csv文件\n```java\nReader in = new FileReader(\"path/to/file.csv\");\nIterable<CSVRecord> records = CSVFormat.EXCEL.parse(in);\nfor (CSVRecord record : records) {\n    String lastName = record.get(\"Last Name\");\n    String firstName = record.get(\"First Name\");\n}\n```\n\n\n","source":"_posts/Java 工具库/读取csv文件.md","raw":"category: Java工具\ndate: 2015-06-08\ntitle: java读取csv文件\n---\n利用Apache Commons CSV读取csv文件, 首先我们添加如下依赖\n```xml\n<dependency>\n\t<groupId>org.apache.commons</groupId>\n\t<artifactId>commons-csv</artifactId>\n\t<version>1.2</version>\n</dependency>\n```\n读取csv文件\n```java\nReader in = new FileReader(\"path/to/file.csv\");\nIterable<CSVRecord> records = CSVFormat.EXCEL.parse(in);\nfor (CSVRecord record : records) {\n    String lastName = record.get(\"Last Name\");\n    String firstName = record.get(\"First Name\");\n}\n```\n\n\n","slug":"Java 工具库/读取csv文件","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnx001cvjs60dkni9rx"},{"date":"2016-01-10T16:00:00.000Z","title":"ASM Core(1) 初探","_content":"[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n ASM是一种小巧轻便的 Java 字节码操控框架，它能方便地生成和改造 Java 代码\n\nASM通过`ClassVisitor`来生成和转换class字节码. `ClassVisitor`中的每个方法都对应着class数据结构, 你可以通过每个方法名轻松的判断出这个方法对应的是哪个数据结构. \n\n`ClassVisitor`内的方法调用顺序如下:\n1. visit  : 调用`visit`方法(有且仅有调用一次)\n2. visitSource?  : 调用`visitSource`函数(最多调用一次)\n3. visitOuterClass?  : 调用`visitOuterClass`函数(最多调用一次)\n4. ( visitAnnotation | visitAttribute )* : 调用`visitAnnotation`和`visitAttribute`函数, 这俩个函数的调用可调用任意次且不分前后顺序\n5. ( visitInnerClass | visitField | visitMethod )* : 调用`visitInnerClass`,`visitField`和`visitMethod`函数, 同样对这三个函数的调用不限制次数以及不分前后顺序\n6. visitEnd : 调用`visitEnd`函数(有且仅有调用一次),调用这个函数用于结束整个过程.\n\nASM通过基于`ClassVisitor`的三个API来生成和转换class字节码\n* `ClassReader`: 用于解析一个给定的class二进制字节数组, 然后按照上文介绍的顺序依次调用`accept()`的`ClassVisitor`参数的方法.\n* `ClassWriter` : 一个`ClassVisitor`的子类, 用于直接生成二进制的字节码. \n* `ClassVisitor` : 代理了全部的字节码相关的方法调用. 它接收另一个`ClassVisitor`对象形成责任链模式调用.\n\n我们通过`ClassReader`来解析一个二进制的class结构数据, 然后`ClassReader`按照一定的顺序调用`ClassVisitor` 来改变class结构数据, 最后通过`ClassVisitor`生成新的class二进制数据.","source":"_posts/asm/ASM Core(1) 初探.md","raw":"category: asm\ndate: 2016-01-11\ntitle: ASM Core(1) 初探\n---\n[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n ASM是一种小巧轻便的 Java 字节码操控框架，它能方便地生成和改造 Java 代码\n\nASM通过`ClassVisitor`来生成和转换class字节码. `ClassVisitor`中的每个方法都对应着class数据结构, 你可以通过每个方法名轻松的判断出这个方法对应的是哪个数据结构. \n\n`ClassVisitor`内的方法调用顺序如下:\n1. visit  : 调用`visit`方法(有且仅有调用一次)\n2. visitSource?  : 调用`visitSource`函数(最多调用一次)\n3. visitOuterClass?  : 调用`visitOuterClass`函数(最多调用一次)\n4. ( visitAnnotation | visitAttribute )* : 调用`visitAnnotation`和`visitAttribute`函数, 这俩个函数的调用可调用任意次且不分前后顺序\n5. ( visitInnerClass | visitField | visitMethod )* : 调用`visitInnerClass`,`visitField`和`visitMethod`函数, 同样对这三个函数的调用不限制次数以及不分前后顺序\n6. visitEnd : 调用`visitEnd`函数(有且仅有调用一次),调用这个函数用于结束整个过程.\n\nASM通过基于`ClassVisitor`的三个API来生成和转换class字节码\n* `ClassReader`: 用于解析一个给定的class二进制字节数组, 然后按照上文介绍的顺序依次调用`accept()`的`ClassVisitor`参数的方法.\n* `ClassWriter` : 一个`ClassVisitor`的子类, 用于直接生成二进制的字节码. \n* `ClassVisitor` : 代理了全部的字节码相关的方法调用. 它接收另一个`ClassVisitor`对象形成责任链模式调用.\n\n我们通过`ClassReader`来解析一个二进制的class结构数据, 然后`ClassReader`按照一定的顺序调用`ClassVisitor` 来改变class结构数据, 最后通过`ClassVisitor`生成新的class二进制数据.","slug":"asm/ASM Core(1) 初探","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihnz001evjs6ls9uyvn5"},{"date":"2016-01-12T16:00:00.000Z","title":"ASM Core(3) Methods","_content":"[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n\n本文主要是讲述如何通过ASM CORE API来生成和转换编译好的方法.\n\n## 执行模型\n在讲解字节码结构之前我们要首先讲解一下JVM的执行模型.\n\njava代码都是在线程中执行. 每一个线程都有它自己执行栈, 每个执行栈都是由N个栈帧组成. 每个栈帧都代表着一个方法调用, 每当我们调用一个方法的时候, 就会向当前执行栈(活动线程)中push一个栈帧. 当方法结束(return或者抛出异常)时就会将当前栈帧出栈. 然后继续调用下一个方法.\n\n每一个栈帧都有俩部分组成\n*  local variables 本地变量\n*  operand stack  操作数栈\n\n我们通过索引来访问local variables. operand stack存储的是操作数, 正如其名, 它也是一个栈结构, 因此我们通过Last In First Out对其进行访问.\n\nlocal variables和 operand stack的大小取决于方法的大小. 这些大小是在编译期进行计算, 而且也是进行单独存储的.\n","source":"_posts/asm/ASM Core(3) Methods.md","raw":"category: asm\ndate: 2016-01-13\ntitle: ASM Core(3) Methods\n---\n[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n\n本文主要是讲述如何通过ASM CORE API来生成和转换编译好的方法.\n\n## 执行模型\n在讲解字节码结构之前我们要首先讲解一下JVM的执行模型.\n\njava代码都是在线程中执行. 每一个线程都有它自己执行栈, 每个执行栈都是由N个栈帧组成. 每个栈帧都代表着一个方法调用, 每当我们调用一个方法的时候, 就会向当前执行栈(活动线程)中push一个栈帧. 当方法结束(return或者抛出异常)时就会将当前栈帧出栈. 然后继续调用下一个方法.\n\n每一个栈帧都有俩部分组成\n*  local variables 本地变量\n*  operand stack  操作数栈\n\n我们通过索引来访问local variables. operand stack存储的是操作数, 正如其名, 它也是一个栈结构, 因此我们通过Last In First Out对其进行访问.\n\nlocal variables和 operand stack的大小取决于方法的大小. 这些大小是在编译期进行计算, 而且也是进行单独存储的.\n","slug":"asm/ASM Core(3) Methods","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iho2001gvjs6qcjxaort"},{"date":"2016-01-11T16:00:00.000Z","title":"ASM Core(2) Class的增删改查","_content":"[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n\n## 获取class信息\n下来的示例中我们通过重写`ClassVisitor`相关函数然后依次打印出类型信息, 字段信息和函数信息.\n```java\nclass ClassPrinter extends ClassVisitor {\n\tpublic ClassPrinter() {\n\t\tsuper(Opcodes.ASM4);\n\t}\n\tpublic void visit(int version, int access, String name, String signature, String superName, String[] interfaces) {\n\t\tSystem.out.println(name + \" extends \" + superName + \" {\");\n\t}\n\tpublic void visitSource(String source, String debug) {\n\t}\n\tpublic void visitOuterClass(String owner, String name, String desc) {\n\t}\n\tpublic AnnotationVisitor visitAnnotation(String desc, boolean visible) {\n\t\treturn null;\n\t}\n\tpublic void visitAttribute(Attribute attr) {\n\t}\n\tpublic void visitInnerClass(String name, String outerName, String innerName, int access) {\n\t}\n\tpublic FieldVisitor visitField(int access, String name, String desc, String signature, Object value) {\n\t\tSystem.out.println(\" \" + desc + \" \" + name);\n\t\treturn null;\n\t}\n\tpublic MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) {\n\t\tSystem.out.println(\" \" + name + desc);\n\t\treturn null;\n\t}\n\tpublic void visitEnd() {\n\t\tSystem.out.println(\"}\");\n\t}\n}\n```\n然后我们写一段运行代码\n```java\npublic class Test {\n\tpublic static void main(String[] args) throws IOException {\n\t\t// 读取解析二进制字节流\n\t\tClassReader cr = new ClassReader(\"Test\");\n\t\tClassPrinter cp = new ClassPrinter();\n\t\t// 开始处理字节流信息\n\t\tcr.accept(cp, 0);\n\t}\n}\n```\n结果为\n```java\nTest extends java/lang/Object {\n <init>()V\n main([Ljava/lang/String;)V\n lambda$main$22(Ljava/lang/Integer;)V\n lambda$main$21(Ljava/lang/Integer;Ljava/lang/Integer;)I\n}\n```\n在测试代码中我们首先创建了一个`ClassReader`实例用于读取`Test`字节码. 然后由`accept()`方法依次调用`ClassPrinter`的方法\n\n\n## 动态生成Class\n我们仅仅使用`ClassWriter`就可以生成一个类, 例如我们要生成一个如下的接口\n```java\npackage pkg;\npublic interface Comparable extends Mesurable {\n\tint LESS = -1;\n\tint EQUAL = 0;\n\tint GREATER = 1;\n\tint compareTo(Object o);\n}\n```\n我们仅仅需要调用`ClassVisitor`的六个方法\n```java\npublic class Test {\n\tpublic static void main(String[] args) throws IOException {\n\t\tClassWriter cw = new ClassWriter(0);\n\t\tcw.visit(V1_8,\t\t\t\t\t\t\t\t\t\t\t// 指定class文件版本号, 我们将其设置为java8\n\t\t\t\tACC_PUBLIC + ACC_ABSTRACT + ACC_INTERFACE,\t// 设置接口的修饰符, 需要指出的是由于interface是不可实例化的,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// 因此我们将其设置为ACC_ABSTRACT的\n\t\t\t\t\"pkg/Comparable\",\t\t\t\t\t\t\t\t// 我们设置classname, 需要在这里指定全限定名\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t\t// 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null\n\t\t\t\t\"java/lang/Object\",\t\t\t\t\t\t\t// 设置父类, 同时需要设定全限定名\n\t\t\t\tnew String[] { \"pkg/Mesurable\" });\t\t\t// 设置接口, 同样需要设置全限定名\n\n\t\tcw.visitField(\n\t\t\t\tACC_PUBLIC + ACC_FINAL + ACC_STATIC,\t// 设置字段的修饰符\n\t\t\t\t\"LESS\",\t\t\t\t\t\t\t\t\t\t// 设置字段名\n\t\t\t\t\"I\",\t\t\t\t\t\t\t\t\t\t// 设置字段类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnew Integer(-1))\t\t\t\t\t\t\t// 设置字面量值. (如果这个字段是常量值的话,例如 final static,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// 那么我们就必须设置这个值)\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitMethod(ACC_PUBLIC + ACC_ABSTRACT,\t\t// 设置字段的修饰符\n\t\t\t\t\"compareTo\",\t\t\t\t\t\t\t\t// 设置方法名\n\t\t\t\t\"(Ljava/lang/Object;)I\",\t\t\t\t\t// 设置返回值类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnull)\t\t\t\t\t\t\t\t\t\t// 设置异常信息\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitEnd();\n\t\tbyte[] b = cw.toByteArray();\n\t}\n}\n```\n\n## 使用生成的类\n记下来我们自定义一个`ClassLoader`来加载生成的字节码\n```java\nclass MyClassLoader extends ClassLoader {\n\tpublic Class defineClass(String name, byte[] b) {\n\t\treturn defineClass(name, b, 0, b.length);\n\t}\n}\n```\n然后使用它\n```java\nbyte[] bytes = genComparableInterface();\nMyClassLoader myClassLoader = new MyClassLoader();\nClass c = myClassLoader.defineClass(\"pkg.Comparable\", bytes);\n```\n我们直接使用`defineClass`函数来加载这个类.\n\n另外我们还可以重写`findClass`这个函数来动态的生成我们所需要的类\n```java\nclass StubClassLoader extends ClassLoader {\n\t@Override\n\tprotected Class findClass(String name) throws ClassNotFoundException {\n\t\tif (name.endsWith(\"_Stub\")) {\n\t\t\tClassWriter cw = new ClassWriter(0);\n\t\t\t...\n\t\t\tbyte[] b = cw.toByteArray();\n\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t}\n\t\treturn super.findClass(name);\n\t}\n}\n```\n\n## 修改已存在的Class\n在上篇文章中我们只是单独的使用了`ClassReader`和`ClassWriter`,但是更多的应用其实应该是将其组合到一起使用\n```java\nbyte[] b1 = ...;\nClassWriter cw = new ClassWriter(0);\nClassReader cr = new ClassReader(b1);\ncr.accept(cw, 0);\nbyte[] b2 = cw.toByteArray(); // b2 represents the same class as b1\n```\n这个例子中我们什么都没有做, 只不过完成了一个copy字节码的功能, 接下来我们在这俩个过程中加入`ClassVisitor`\n```java\nbyte[] b1 = ...;\nClassWriter cw = new ClassWriter(0);\n// cv forwards all events to cw\nClassVisitor cv = new ClassVisitor(ASM4, cw) { };\nClassReader cr = new ClassReader(b1);\ncr.accept(cv, 0);\nbyte[] b2 = cw.toByteArray(); // b2 represents the same class as b1\n```\n这段代码的处理流程如下图![](https://raw.githubusercontent.com/ming15/blog-website/images/asm/transformation%20chain.jpg)\n> 方框代表我们的核心组件, 箭头代表我们的数据流.\n\n下面我们给出一个`ClassVisitor`小例子\n```java\nclass ChangeVersionAdapter extends ClassVisitor {\n\tpublic ChangeVersionAdapter(ClassVisitor cv) {\n\t\t// ASM4为ASM的版本号\n\t\tsuper(ASM4, cv);\n\t}\n\t@Override\n\tpublic void visit(int version, int access, String name,\n\t\t\t\t\t  String signature, String superName, String[] interfaces) {\n\t\t// 修改class信息\n\t\tcv.visit(V1_5,\t\t\t// 改变class的版本号\n\t\t\t\taccess,\t\t\t// 改变class的标识符\n\t\t\t\tname,\t\t\t// 改变类名\n\t\t\t\tsignature,\t\t// 泛型信息\n\t\t\t\tsuperName,\t\t// 父类信息\n\t\t\t\tinterfaces);\t// 接口信息\n\t}\n}\n```\n在上面的实现中,除了调用`visit`函数(修改类本身函数, 将class版本号转化为1.5), 其他的方法都没有重写,因此他们什么改变都不会做. 下来我们给出这个类执行的时序图\n![](https://raw.githubusercontent.com/ming15/blog-website/images/asm/Sequence%20diagram%20for%20the%20ChangeVersionAdapter.jpg)\n从这个时序图中我们可以看出, 用户调用了`accept`方法之后, 有ASM自动调用`ClassReader`的`visti(version)`方法, 接着调用`ChangeVersionAdapter`的`visti(1.5)`方法, 最后调用`ClassWriter`的相关方法. 从这个模式中我们可以看出, ASM的调用模式是链式调用的, 先调用visit, 然后调用责任链中所有的`ClassVisitor`的vist最后调用`ClassWriter`的完结方法. 当`visit`调用完之后再调用`visitSource`责任链流程, 依次类推下去.\n\n## 优化\n在上述的代码中, 其实代码的运行效率并不是高效进行的. 这是因为当`b1`字节码被`ClassReader`读取并通过`ClassVisitor`将其执行转换的时候, 我们可能只改变了class的版本号, 其他部分并没有转换, 但是在实际的执行中其他的部分也都被执行了一边, 那这就浪费了cpu计算和内存空间的占用, 其实只需要将不需要改变的字节从`b1`直接拷贝到`b2`就好了.  \n\n好在ASM为我们内部构建了这种优化过程.\n*\n\n\n## 删除成员\n如果我们想将class中的某个成员删除掉, 那么只需在执行asm责任链调用时, 中断调用过程(不调用super或者直接return)就可以了.\n\n例如我们下面的例子我们将类中的内部类和外部类以及编译成该class的源文件信息删除掉\n```java\nclass RemoveDebugAdapter extends ClassVisitor {\n\tpublic RemoveDebugAdapter(ClassVisitor cv) {\n\t\tsuper(ASM4, cv);\n\t}\n\t@Override\n\tpublic void visitSource(String source, String debug) {\n\t}\n\t@Override\n\tpublic void visitOuterClass(String owner, String name, String desc) {\n\t}\n\t@Override\n\tpublic void visitInnerClass(String name, String outerName, String innerName, int access) {\n\t}\n}\n```\n看,就是如此简单, 我们在这三个方法内部什么都不做(不进行super调用)就轻松地完成了我们需要的功能, 但是这种做法却并不适合\n字段和方法的删除, 因为在字段和方法的删除中除了不进行super调用之外还需要return null, 如下:\n```java\nclass RemoveMethodAdapter extends ClassVisitor {\n\tprivate String mName;\n\tprivate String mDesc;\n\tpublic RemoveMethodAdapter(\n\t\t\tClassVisitor cv, String mName, String mDesc) {\n\t\tsuper(ASM4, cv);\n\t\tthis.mName = mName;\n\t\tthis.mDesc = mDesc;\n\t}\n\t@Override\n\tpublic MethodVisitor visitMethod(int access, String name,\n\t\t\t\t\t\t\t\t\t String desc, String signature, String[] exceptions) {\n\t\tif (name.equals(mName) && desc.equals(mDesc)) {\n\t\t\t// do not delegate to next visitor -> this removes the method\n\t\t\treturn null;\n\t\t}\n\t\treturn cv.visitMethod(access, name, desc, signature, exceptions);\n\t}\n}\n```\n\n## 添加成员\n当我们中断方法调用的时候,会删除成员. 但是当我们在责任链中的原生方法调用(`visitXxx`方法)中新增加一些方法调用的话, 会增加成员.\n\n例如如果你想要增加一个字段, 那么你必须在`visitXxx`方法中增加一个`visitField`方法调用. 需要注意的是`visitXxx`方法只包含`visitInnerClass,visitField, visitMethod,visitEnd`这四个方法, 这是因为`visit,visitSource,visitOuterClass,visitAnnotation,visitAttribute` 这些方法正如我们在第一篇文章中给出那些顺序一样, `visitField`方法只能在这些方法之后调用.\n\n> 需要注意的是,由于`visitInnerClass,visitField, visitMethod`这些方法会进行多次调用, 因此有可能会添加N个相同的成员, 因此我们建议在`visitEnd`的时候进行成员添加, 这是因为这个方法总会有且只有一次调用.\n\n如下例\n```java\nclass AddFieldAdapter extends ClassVisitor {\n\tprivate int fAcc;\n\tprivate String fName;\n\tprivate String fDesc;\n\tprivate boolean isFieldPresent;\n\tpublic AddFieldAdapter(ClassVisitor cv, int fAcc, String fName, String fDesc) {\n\t\tsuper(ASM4, cv);\n\t\tthis.fAcc = fAcc;\n\t\tthis.fName = fName;\n\t\tthis.fDesc = fDesc;\n\t}\n\t@Override\n\tpublic FieldVisitor visitField(int access, String name, String desc, String signature, Object value) {\n\t\tif (name.equals(fName)) {\n\t\t\tisFieldPresent = true;\n\t\t}\n\t\treturn cv.visitField(access, name, desc, signature, value);\n\t}\n\t@Override\n\tpublic void visitEnd() {\n\t\tif (!isFieldPresent) {\n\t\t\tFieldVisitor fv = cv.visitField(fAcc, fName, fDesc, null, null);\n\t\t\tif (fv != null) {\n\t\t\t\tfv.visitEnd();\n\t\t\t}\n\t\t}\n\t\tcv.visitEnd();\n\t}\n}\n```\n","source":"_posts/asm/ASM Core(2) 操作.md","raw":"category: asm\ndate: 2016-01-12\ntitle: ASM Core(2) Class的增删改查\n---\n[asm4-guide](http://download.forge.objectweb.org/asm/asm4-guide.pdf)学习心得\n\n## 获取class信息\n下来的示例中我们通过重写`ClassVisitor`相关函数然后依次打印出类型信息, 字段信息和函数信息.\n```java\nclass ClassPrinter extends ClassVisitor {\n\tpublic ClassPrinter() {\n\t\tsuper(Opcodes.ASM4);\n\t}\n\tpublic void visit(int version, int access, String name, String signature, String superName, String[] interfaces) {\n\t\tSystem.out.println(name + \" extends \" + superName + \" {\");\n\t}\n\tpublic void visitSource(String source, String debug) {\n\t}\n\tpublic void visitOuterClass(String owner, String name, String desc) {\n\t}\n\tpublic AnnotationVisitor visitAnnotation(String desc, boolean visible) {\n\t\treturn null;\n\t}\n\tpublic void visitAttribute(Attribute attr) {\n\t}\n\tpublic void visitInnerClass(String name, String outerName, String innerName, int access) {\n\t}\n\tpublic FieldVisitor visitField(int access, String name, String desc, String signature, Object value) {\n\t\tSystem.out.println(\" \" + desc + \" \" + name);\n\t\treturn null;\n\t}\n\tpublic MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) {\n\t\tSystem.out.println(\" \" + name + desc);\n\t\treturn null;\n\t}\n\tpublic void visitEnd() {\n\t\tSystem.out.println(\"}\");\n\t}\n}\n```\n然后我们写一段运行代码\n```java\npublic class Test {\n\tpublic static void main(String[] args) throws IOException {\n\t\t// 读取解析二进制字节流\n\t\tClassReader cr = new ClassReader(\"Test\");\n\t\tClassPrinter cp = new ClassPrinter();\n\t\t// 开始处理字节流信息\n\t\tcr.accept(cp, 0);\n\t}\n}\n```\n结果为\n```java\nTest extends java/lang/Object {\n <init>()V\n main([Ljava/lang/String;)V\n lambda$main$22(Ljava/lang/Integer;)V\n lambda$main$21(Ljava/lang/Integer;Ljava/lang/Integer;)I\n}\n```\n在测试代码中我们首先创建了一个`ClassReader`实例用于读取`Test`字节码. 然后由`accept()`方法依次调用`ClassPrinter`的方法\n\n\n## 动态生成Class\n我们仅仅使用`ClassWriter`就可以生成一个类, 例如我们要生成一个如下的接口\n```java\npackage pkg;\npublic interface Comparable extends Mesurable {\n\tint LESS = -1;\n\tint EQUAL = 0;\n\tint GREATER = 1;\n\tint compareTo(Object o);\n}\n```\n我们仅仅需要调用`ClassVisitor`的六个方法\n```java\npublic class Test {\n\tpublic static void main(String[] args) throws IOException {\n\t\tClassWriter cw = new ClassWriter(0);\n\t\tcw.visit(V1_8,\t\t\t\t\t\t\t\t\t\t\t// 指定class文件版本号, 我们将其设置为java8\n\t\t\t\tACC_PUBLIC + ACC_ABSTRACT + ACC_INTERFACE,\t// 设置接口的修饰符, 需要指出的是由于interface是不可实例化的,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// 因此我们将其设置为ACC_ABSTRACT的\n\t\t\t\t\"pkg/Comparable\",\t\t\t\t\t\t\t\t// 我们设置classname, 需要在这里指定全限定名\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t\t// 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null\n\t\t\t\t\"java/lang/Object\",\t\t\t\t\t\t\t// 设置父类, 同时需要设定全限定名\n\t\t\t\tnew String[] { \"pkg/Mesurable\" });\t\t\t// 设置接口, 同样需要设置全限定名\n\n\t\tcw.visitField(\n\t\t\t\tACC_PUBLIC + ACC_FINAL + ACC_STATIC,\t// 设置字段的修饰符\n\t\t\t\t\"LESS\",\t\t\t\t\t\t\t\t\t\t// 设置字段名\n\t\t\t\t\"I\",\t\t\t\t\t\t\t\t\t\t// 设置字段类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnew Integer(-1))\t\t\t\t\t\t\t// 设置字面量值. (如果这个字段是常量值的话,例如 final static,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// 那么我们就必须设置这个值)\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitMethod(ACC_PUBLIC + ACC_ABSTRACT,\t\t// 设置字段的修饰符\n\t\t\t\t\"compareTo\",\t\t\t\t\t\t\t\t// 设置方法名\n\t\t\t\t\"(Ljava/lang/Object;)I\",\t\t\t\t\t// 设置返回值类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnull)\t\t\t\t\t\t\t\t\t\t// 设置异常信息\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitEnd();\n\t\tbyte[] b = cw.toByteArray();\n\t}\n}\n```\n\n## 使用生成的类\n记下来我们自定义一个`ClassLoader`来加载生成的字节码\n```java\nclass MyClassLoader extends ClassLoader {\n\tpublic Class defineClass(String name, byte[] b) {\n\t\treturn defineClass(name, b, 0, b.length);\n\t}\n}\n```\n然后使用它\n```java\nbyte[] bytes = genComparableInterface();\nMyClassLoader myClassLoader = new MyClassLoader();\nClass c = myClassLoader.defineClass(\"pkg.Comparable\", bytes);\n```\n我们直接使用`defineClass`函数来加载这个类.\n\n另外我们还可以重写`findClass`这个函数来动态的生成我们所需要的类\n```java\nclass StubClassLoader extends ClassLoader {\n\t@Override\n\tprotected Class findClass(String name) throws ClassNotFoundException {\n\t\tif (name.endsWith(\"_Stub\")) {\n\t\t\tClassWriter cw = new ClassWriter(0);\n\t\t\t...\n\t\t\tbyte[] b = cw.toByteArray();\n\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t}\n\t\treturn super.findClass(name);\n\t}\n}\n```\n\n## 修改已存在的Class\n在上篇文章中我们只是单独的使用了`ClassReader`和`ClassWriter`,但是更多的应用其实应该是将其组合到一起使用\n```java\nbyte[] b1 = ...;\nClassWriter cw = new ClassWriter(0);\nClassReader cr = new ClassReader(b1);\ncr.accept(cw, 0);\nbyte[] b2 = cw.toByteArray(); // b2 represents the same class as b1\n```\n这个例子中我们什么都没有做, 只不过完成了一个copy字节码的功能, 接下来我们在这俩个过程中加入`ClassVisitor`\n```java\nbyte[] b1 = ...;\nClassWriter cw = new ClassWriter(0);\n// cv forwards all events to cw\nClassVisitor cv = new ClassVisitor(ASM4, cw) { };\nClassReader cr = new ClassReader(b1);\ncr.accept(cv, 0);\nbyte[] b2 = cw.toByteArray(); // b2 represents the same class as b1\n```\n这段代码的处理流程如下图![](https://raw.githubusercontent.com/ming15/blog-website/images/asm/transformation%20chain.jpg)\n> 方框代表我们的核心组件, 箭头代表我们的数据流.\n\n下面我们给出一个`ClassVisitor`小例子\n```java\nclass ChangeVersionAdapter extends ClassVisitor {\n\tpublic ChangeVersionAdapter(ClassVisitor cv) {\n\t\t// ASM4为ASM的版本号\n\t\tsuper(ASM4, cv);\n\t}\n\t@Override\n\tpublic void visit(int version, int access, String name,\n\t\t\t\t\t  String signature, String superName, String[] interfaces) {\n\t\t// 修改class信息\n\t\tcv.visit(V1_5,\t\t\t// 改变class的版本号\n\t\t\t\taccess,\t\t\t// 改变class的标识符\n\t\t\t\tname,\t\t\t// 改变类名\n\t\t\t\tsignature,\t\t// 泛型信息\n\t\t\t\tsuperName,\t\t// 父类信息\n\t\t\t\tinterfaces);\t// 接口信息\n\t}\n}\n```\n在上面的实现中,除了调用`visit`函数(修改类本身函数, 将class版本号转化为1.5), 其他的方法都没有重写,因此他们什么改变都不会做. 下来我们给出这个类执行的时序图\n![](https://raw.githubusercontent.com/ming15/blog-website/images/asm/Sequence%20diagram%20for%20the%20ChangeVersionAdapter.jpg)\n从这个时序图中我们可以看出, 用户调用了`accept`方法之后, 有ASM自动调用`ClassReader`的`visti(version)`方法, 接着调用`ChangeVersionAdapter`的`visti(1.5)`方法, 最后调用`ClassWriter`的相关方法. 从这个模式中我们可以看出, ASM的调用模式是链式调用的, 先调用visit, 然后调用责任链中所有的`ClassVisitor`的vist最后调用`ClassWriter`的完结方法. 当`visit`调用完之后再调用`visitSource`责任链流程, 依次类推下去.\n\n## 优化\n在上述的代码中, 其实代码的运行效率并不是高效进行的. 这是因为当`b1`字节码被`ClassReader`读取并通过`ClassVisitor`将其执行转换的时候, 我们可能只改变了class的版本号, 其他部分并没有转换, 但是在实际的执行中其他的部分也都被执行了一边, 那这就浪费了cpu计算和内存空间的占用, 其实只需要将不需要改变的字节从`b1`直接拷贝到`b2`就好了.  \n\n好在ASM为我们内部构建了这种优化过程.\n*\n\n\n## 删除成员\n如果我们想将class中的某个成员删除掉, 那么只需在执行asm责任链调用时, 中断调用过程(不调用super或者直接return)就可以了.\n\n例如我们下面的例子我们将类中的内部类和外部类以及编译成该class的源文件信息删除掉\n```java\nclass RemoveDebugAdapter extends ClassVisitor {\n\tpublic RemoveDebugAdapter(ClassVisitor cv) {\n\t\tsuper(ASM4, cv);\n\t}\n\t@Override\n\tpublic void visitSource(String source, String debug) {\n\t}\n\t@Override\n\tpublic void visitOuterClass(String owner, String name, String desc) {\n\t}\n\t@Override\n\tpublic void visitInnerClass(String name, String outerName, String innerName, int access) {\n\t}\n}\n```\n看,就是如此简单, 我们在这三个方法内部什么都不做(不进行super调用)就轻松地完成了我们需要的功能, 但是这种做法却并不适合\n字段和方法的删除, 因为在字段和方法的删除中除了不进行super调用之外还需要return null, 如下:\n```java\nclass RemoveMethodAdapter extends ClassVisitor {\n\tprivate String mName;\n\tprivate String mDesc;\n\tpublic RemoveMethodAdapter(\n\t\t\tClassVisitor cv, String mName, String mDesc) {\n\t\tsuper(ASM4, cv);\n\t\tthis.mName = mName;\n\t\tthis.mDesc = mDesc;\n\t}\n\t@Override\n\tpublic MethodVisitor visitMethod(int access, String name,\n\t\t\t\t\t\t\t\t\t String desc, String signature, String[] exceptions) {\n\t\tif (name.equals(mName) && desc.equals(mDesc)) {\n\t\t\t// do not delegate to next visitor -> this removes the method\n\t\t\treturn null;\n\t\t}\n\t\treturn cv.visitMethod(access, name, desc, signature, exceptions);\n\t}\n}\n```\n\n## 添加成员\n当我们中断方法调用的时候,会删除成员. 但是当我们在责任链中的原生方法调用(`visitXxx`方法)中新增加一些方法调用的话, 会增加成员.\n\n例如如果你想要增加一个字段, 那么你必须在`visitXxx`方法中增加一个`visitField`方法调用. 需要注意的是`visitXxx`方法只包含`visitInnerClass,visitField, visitMethod,visitEnd`这四个方法, 这是因为`visit,visitSource,visitOuterClass,visitAnnotation,visitAttribute` 这些方法正如我们在第一篇文章中给出那些顺序一样, `visitField`方法只能在这些方法之后调用.\n\n> 需要注意的是,由于`visitInnerClass,visitField, visitMethod`这些方法会进行多次调用, 因此有可能会添加N个相同的成员, 因此我们建议在`visitEnd`的时候进行成员添加, 这是因为这个方法总会有且只有一次调用.\n\n如下例\n```java\nclass AddFieldAdapter extends ClassVisitor {\n\tprivate int fAcc;\n\tprivate String fName;\n\tprivate String fDesc;\n\tprivate boolean isFieldPresent;\n\tpublic AddFieldAdapter(ClassVisitor cv, int fAcc, String fName, String fDesc) {\n\t\tsuper(ASM4, cv);\n\t\tthis.fAcc = fAcc;\n\t\tthis.fName = fName;\n\t\tthis.fDesc = fDesc;\n\t}\n\t@Override\n\tpublic FieldVisitor visitField(int access, String name, String desc, String signature, Object value) {\n\t\tif (name.equals(fName)) {\n\t\t\tisFieldPresent = true;\n\t\t}\n\t\treturn cv.visitField(access, name, desc, signature, value);\n\t}\n\t@Override\n\tpublic void visitEnd() {\n\t\tif (!isFieldPresent) {\n\t\t\tFieldVisitor fv = cv.visitField(fAcc, fName, fDesc, null, null);\n\t\t\tif (fv != null) {\n\t\t\t\tfv.visitEnd();\n\t\t\t}\n\t\t}\n\t\tcv.visitEnd();\n\t}\n}\n```\n","slug":"asm/ASM Core(2) 操作","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iho4001jvjs6o0se5wys"},{"date":"2016-01-13T16:00:00.000Z","title":"ASM Core(5) 工具","_content":"ASM通过`org.objectweb.asm.util`对`ClassVisitor, ClassReader, ClassWriter`提供非常多有帮助的类，通过这些类可以帮助开发者简化字节码的操作过程.\n\n## Type\n在前面的文章中我们看到ASM API暴露了存储在字节码中的类型信息等等, 但是上文中的信息我们看到了可读性比较差, 因此ASM提供了`Type`这个工具类,让我们可以像源码中那样看到可读性更高的类型信息.\n\n每个`Type`对象都代表着一个java类型, 我们可以通过类型描述符或者`Class`对象中构建出一个`Type`对象. 另外`Type`中还包含一些静态成员属性用于表示原生类型, 例如`e Type.INT_TYPE`就表示int类型.\n\n`getInternalName`方法用于获取类型的全限定名, 例如`Type.getType(String.class).getInternalName()`我们会得到一个`\"java/lang/String\".`值, 需要注意的是这个方法只能用在class或者interface类型上.\n\n`getDescriptor`方法返回一个类型的描述符. 例如`\"Ljava/lang/String;\"`代表一个字符串类型, 但是我们可以在代码中使用`Type.getType(String.class).getDescriptor()`替代这种写法, 来换取更高的可读性. \n\n`Type`对象还可以表示一个方法类型. 方法类型的`Type`对象可以通过方法描述符或者`Method`对象构建出来. 同样的除了我们可以使用`getDescriptor`方法外,还可以使用`getArgumentTypes`和`getReturnType`来获取方法的参数或者返回值类型. 例如`Type.getArgumentTypes(\"(I)V\")`和`Type.getReturnType(\"(I)V\")`来获得更好的可读性.\n\n\n## TraceClassVisitor\n我们使用`ClassWriter`生成的新的class字节码是一个byte数组, 这种东西根本不具有可读性,因此ASM为我们提供了`TraceClassVisitor`, 它同样是继承自`ClassVisitor`, 他会输出一个文本格式的可读的新的类出来. 下面的例子中我们同时使用了`ClassWriter`和`TraceClassVisitor`, `TraceClassVisitor`代理了`ClassWriter`的全部方法调用\n```java\nClassWriter cw = new ClassWriter(0);\nTraceClassVisitor cv = new TraceClassVisitor(cw, printWriter);\ncv.visit(...);\n...\ncv.visitEnd();\nbyte b[] = cw.toByteArray();\n```\n\n## CheckClassAdapter\n`ClassWriter`并不会检查生成的方法在调用的时候是顺序且参数是否都是正确的. 因此当JVM加载类进行验证的时候可能会抛出异常. 因此当我们秉持着错误越早发现越好, ASM为我们提供了`CheckClassAdapter`, 这个工具类会为我们检查上述问题. 同样的`CheckClassAdapter`继承自`ClassWriter.`, 它可以代理`TraceClassVisitor`或者`ClassWriter`的全部方法. 下面我们给出一个示例\n```java\nClassWriter cw = new ClassWriter(0);\nTraceClassVisitor tcv = new TraceClassVisitor(cw, printWriter);\nCheckClassAdapter cv = new CheckClassAdapter(tcv);\ncv.visit(...);\n...\ncv.visitEnd();\nbyte b[] = cw.toByteArray();\n```\n注意, 我们要确定visitor之间的顺序关系, 如下\n```java\nClassWriter cw = new ClassWriter(0);\nCheckClassAdapter cca = new CheckClassAdapter(cw);\nTraceClassVisitor cv = new TraceClassVisitor(cca, printWriter);\n```\n上面的例子是先进行文本输出然后再进行方法检查, 这是因为相当于`TraceClassVisitor`最终代理了所有的方法调用\n\n\n\n\n\n\n\n","source":"_posts/asm/ASM Core(5) 工具.md","raw":"category: asm\ndate: 2016-01-14\ntitle: ASM Core(5) 工具\n---\nASM通过`org.objectweb.asm.util`对`ClassVisitor, ClassReader, ClassWriter`提供非常多有帮助的类，通过这些类可以帮助开发者简化字节码的操作过程.\n\n## Type\n在前面的文章中我们看到ASM API暴露了存储在字节码中的类型信息等等, 但是上文中的信息我们看到了可读性比较差, 因此ASM提供了`Type`这个工具类,让我们可以像源码中那样看到可读性更高的类型信息.\n\n每个`Type`对象都代表着一个java类型, 我们可以通过类型描述符或者`Class`对象中构建出一个`Type`对象. 另外`Type`中还包含一些静态成员属性用于表示原生类型, 例如`e Type.INT_TYPE`就表示int类型.\n\n`getInternalName`方法用于获取类型的全限定名, 例如`Type.getType(String.class).getInternalName()`我们会得到一个`\"java/lang/String\".`值, 需要注意的是这个方法只能用在class或者interface类型上.\n\n`getDescriptor`方法返回一个类型的描述符. 例如`\"Ljava/lang/String;\"`代表一个字符串类型, 但是我们可以在代码中使用`Type.getType(String.class).getDescriptor()`替代这种写法, 来换取更高的可读性. \n\n`Type`对象还可以表示一个方法类型. 方法类型的`Type`对象可以通过方法描述符或者`Method`对象构建出来. 同样的除了我们可以使用`getDescriptor`方法外,还可以使用`getArgumentTypes`和`getReturnType`来获取方法的参数或者返回值类型. 例如`Type.getArgumentTypes(\"(I)V\")`和`Type.getReturnType(\"(I)V\")`来获得更好的可读性.\n\n\n## TraceClassVisitor\n我们使用`ClassWriter`生成的新的class字节码是一个byte数组, 这种东西根本不具有可读性,因此ASM为我们提供了`TraceClassVisitor`, 它同样是继承自`ClassVisitor`, 他会输出一个文本格式的可读的新的类出来. 下面的例子中我们同时使用了`ClassWriter`和`TraceClassVisitor`, `TraceClassVisitor`代理了`ClassWriter`的全部方法调用\n```java\nClassWriter cw = new ClassWriter(0);\nTraceClassVisitor cv = new TraceClassVisitor(cw, printWriter);\ncv.visit(...);\n...\ncv.visitEnd();\nbyte b[] = cw.toByteArray();\n```\n\n## CheckClassAdapter\n`ClassWriter`并不会检查生成的方法在调用的时候是顺序且参数是否都是正确的. 因此当JVM加载类进行验证的时候可能会抛出异常. 因此当我们秉持着错误越早发现越好, ASM为我们提供了`CheckClassAdapter`, 这个工具类会为我们检查上述问题. 同样的`CheckClassAdapter`继承自`ClassWriter.`, 它可以代理`TraceClassVisitor`或者`ClassWriter`的全部方法. 下面我们给出一个示例\n```java\nClassWriter cw = new ClassWriter(0);\nTraceClassVisitor tcv = new TraceClassVisitor(cw, printWriter);\nCheckClassAdapter cv = new CheckClassAdapter(tcv);\ncv.visit(...);\n...\ncv.visitEnd();\nbyte b[] = cw.toByteArray();\n```\n注意, 我们要确定visitor之间的顺序关系, 如下\n```java\nClassWriter cw = new ClassWriter(0);\nCheckClassAdapter cca = new CheckClassAdapter(cw);\nTraceClassVisitor cv = new TraceClassVisitor(cca, printWriter);\n```\n上面的例子是先进行文本输出然后再进行方法检查, 这是因为相当于`TraceClassVisitor`最终代理了所有的方法调用\n\n\n\n\n\n\n\n","slug":"asm/ASM Core(5) 工具","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iho6001lvjs6f6t7wm5l"},{"date":"2015-11-22T16:00:00.000Z","title":"JDK4 NIO","_content":"JDK1.4 引入的NIO(Non-block IO)是为了拟补原来阻塞IO的不足,它提供了高速的,面向块的IO. \n\n## 缓冲区\n在JDK1.4的NIO中所有的数据都是通过缓冲区(Buffer)处理的. 缓冲区本质上就是一个字节数组, 但是JDK还提供了其他种类的缓冲区：\n*  ByteBuffer \n*  ByteOrder \n*  CharBuffer\n*  DoubleBuffer\n*  FloatBuffer         \n*  IntBuffer          \n*  LongBuffer         \n*  MappedByteBuffer   \n*  ShortBuffer  \n\n## channel\n在JDK1.4的NIO中还引入了如下的Channel     \n* DatagramChannel : 数据报相关的Channel\n* FileChannel : 文件Channel\n* ServerSocketChannel  : 用于接受入站连接的SocketChannel(不可进行读写)\n* SocketChannel  : 用于读写数据的Channel\n\n## NIO服务器\n使用ServerSocketChannel可以像使用`ServerSocket`一样开发网络服务器\n```java\n// 创建ServerSocketChannel,监听所有客户端连接\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n\n// 绑定监听端口\nserverSocketChannel.socket().bind(new InetSocketAddress(\"localhost\", 8085));\n\n// 设置为非阻塞模式\nserverSocketChannel.configureBlocking(false);\n\nwhile (true) {\n\tSocketChannel ssc = serverSocketChannel.accept();\n\tif (ssc == null) {\n\t\tcontinue;\n\t}\n\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\ttry {\n\t\tssc.read(byteBuffer);\n\t\tSystem.out.println(new String(byteBuffer.array(), \"utf8\"));\n\t\tssc.write(byteBuffer);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n}\n```\nSelect版本\n```java\n// 创建ServerSocketChannel,监听所有客户端连接\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n\n// 绑定监听端口\nserverSocketChannel.socket().bind(new InetSocketAddress(\"localhost\", 8085));\n\n// 设置为非阻塞模式\nserverSocketChannel.configureBlocking(false);\n\n// 创建多路复用器\nSelector selector = Selector.open();\n\n// 将ServerSocketChannel注册到多路复用器上, 监听accept事件. 然后Selector会不断的轮询(基于系统的select/poll)\n// SocketChannel是否有新的连接到达达到，selectedKeys()方法就会将准备就绪的连接作为一个集合返回.\n// 在这里我们只能注册accept事件,其他的读写事件我们要在\n// accept之后获得的SocketChannel上注册Selector,进行读写事件注册. 也就是说我们不能在ServerSocketChannel上进行读写,\n// 我们只能在SocketChannel上进行读写\nserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n\nwhile (true) {\n\t// 进行多路复用,这里对Selector进行复用,复用是对一个ServerSocketChannel和多个SocketChannel进行复用.\n\tselector.select();\n\tselector.selectedKeys().forEach(selectionKey -> {\n\t\tif (selectionKey.isConnectable()) {\n\t\t\tSystem.out.println(\"isConnectable\");\n\t\t}\n\n\t\tif (selectionKey.isAcceptable()) {\n\t\t\t// 由于在Selector上是对ServerSocketChannel进行的accept事件监听,因此此处,我们需要将Channel转换成ServerSocketChannel\n\t\t\tServerSocketChannel ssc = (ServerSocketChannel) selectionKey.channel();\n\t\t\ttry {\n\t\t\t\tSocketChannel socketChannel = ssc.accept();\n\t\t\t\tsocketChannel.configureBlocking(false);\n\t\t\t\t// 此处我们将accept的SocketChannel注册到Selector上, 进行读写处理\n\t\t\t\tsocketChannel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (selectionKey.isReadable()) {\n\t\t\t// selectionKey.isAcceptable()这个判断中我们将SocketChannel注册到Selector上接受读事件,\n\t\t\t// 因此我们在此处需要将Channel转换成SocketChannel\n\t\t\tSocketChannel ssc = (SocketChannel) selectionKey.channel();\n\t\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t\ttry {\n\t\t\t\tssc.read(byteBuffer);\n\t\t\t\tSystem.out.println(new String(byteBuffer.array(), \"utf8\"));\n\t\t\t\tssc.write(byteBuffer);\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (selectionKey.isWritable()) {\n\t\t\tSystem.out.println(\"isWritable\");\n\t\t}\n\n\t\tif (selectionKey.isValid()) {\n\t\t\t//\n\t\t\tSystem.out.println(\"isValid\");\n\t\t}\n\n\n\t});\n}\n```\n\n我们看一下`Selector`\n\n``是`SelectableChannel`的多路复用器. \n\n我们可以通过调用`Selector#open()`方法来创建一个selector. 当这个selector创建出来之后, 当我们调用`Selector#close()`方法之前, 该selector会一直存在.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/JavaSE/JavaIO NIO.md","raw":"category: JavaSE\ndate: 2015-11-23\ntitle: JDK4 NIO\n---\nJDK1.4 引入的NIO(Non-block IO)是为了拟补原来阻塞IO的不足,它提供了高速的,面向块的IO. \n\n## 缓冲区\n在JDK1.4的NIO中所有的数据都是通过缓冲区(Buffer)处理的. 缓冲区本质上就是一个字节数组, 但是JDK还提供了其他种类的缓冲区：\n*  ByteBuffer \n*  ByteOrder \n*  CharBuffer\n*  DoubleBuffer\n*  FloatBuffer         \n*  IntBuffer          \n*  LongBuffer         \n*  MappedByteBuffer   \n*  ShortBuffer  \n\n## channel\n在JDK1.4的NIO中还引入了如下的Channel     \n* DatagramChannel : 数据报相关的Channel\n* FileChannel : 文件Channel\n* ServerSocketChannel  : 用于接受入站连接的SocketChannel(不可进行读写)\n* SocketChannel  : 用于读写数据的Channel\n\n## NIO服务器\n使用ServerSocketChannel可以像使用`ServerSocket`一样开发网络服务器\n```java\n// 创建ServerSocketChannel,监听所有客户端连接\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n\n// 绑定监听端口\nserverSocketChannel.socket().bind(new InetSocketAddress(\"localhost\", 8085));\n\n// 设置为非阻塞模式\nserverSocketChannel.configureBlocking(false);\n\nwhile (true) {\n\tSocketChannel ssc = serverSocketChannel.accept();\n\tif (ssc == null) {\n\t\tcontinue;\n\t}\n\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\ttry {\n\t\tssc.read(byteBuffer);\n\t\tSystem.out.println(new String(byteBuffer.array(), \"utf8\"));\n\t\tssc.write(byteBuffer);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n}\n```\nSelect版本\n```java\n// 创建ServerSocketChannel,监听所有客户端连接\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n\n// 绑定监听端口\nserverSocketChannel.socket().bind(new InetSocketAddress(\"localhost\", 8085));\n\n// 设置为非阻塞模式\nserverSocketChannel.configureBlocking(false);\n\n// 创建多路复用器\nSelector selector = Selector.open();\n\n// 将ServerSocketChannel注册到多路复用器上, 监听accept事件. 然后Selector会不断的轮询(基于系统的select/poll)\n// SocketChannel是否有新的连接到达达到，selectedKeys()方法就会将准备就绪的连接作为一个集合返回.\n// 在这里我们只能注册accept事件,其他的读写事件我们要在\n// accept之后获得的SocketChannel上注册Selector,进行读写事件注册. 也就是说我们不能在ServerSocketChannel上进行读写,\n// 我们只能在SocketChannel上进行读写\nserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n\nwhile (true) {\n\t// 进行多路复用,这里对Selector进行复用,复用是对一个ServerSocketChannel和多个SocketChannel进行复用.\n\tselector.select();\n\tselector.selectedKeys().forEach(selectionKey -> {\n\t\tif (selectionKey.isConnectable()) {\n\t\t\tSystem.out.println(\"isConnectable\");\n\t\t}\n\n\t\tif (selectionKey.isAcceptable()) {\n\t\t\t// 由于在Selector上是对ServerSocketChannel进行的accept事件监听,因此此处,我们需要将Channel转换成ServerSocketChannel\n\t\t\tServerSocketChannel ssc = (ServerSocketChannel) selectionKey.channel();\n\t\t\ttry {\n\t\t\t\tSocketChannel socketChannel = ssc.accept();\n\t\t\t\tsocketChannel.configureBlocking(false);\n\t\t\t\t// 此处我们将accept的SocketChannel注册到Selector上, 进行读写处理\n\t\t\t\tsocketChannel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_WRITE);\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (selectionKey.isReadable()) {\n\t\t\t// selectionKey.isAcceptable()这个判断中我们将SocketChannel注册到Selector上接受读事件,\n\t\t\t// 因此我们在此处需要将Channel转换成SocketChannel\n\t\t\tSocketChannel ssc = (SocketChannel) selectionKey.channel();\n\t\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t\ttry {\n\t\t\t\tssc.read(byteBuffer);\n\t\t\t\tSystem.out.println(new String(byteBuffer.array(), \"utf8\"));\n\t\t\t\tssc.write(byteBuffer);\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (selectionKey.isWritable()) {\n\t\t\tSystem.out.println(\"isWritable\");\n\t\t}\n\n\t\tif (selectionKey.isValid()) {\n\t\t\t//\n\t\t\tSystem.out.println(\"isValid\");\n\t\t}\n\n\n\t});\n}\n```\n\n我们看一下`Selector`\n\n``是`SelectableChannel`的多路复用器. \n\n我们可以通过调用`Selector#open()`方法来创建一个selector. 当这个selector创建出来之后, 当我们调用`Selector#close()`方法之前, 该selector会一直存在.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"JavaSE/JavaIO NIO","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iho8001nvjs6sxc8ghg1"},{"date":"2015-11-20T16:00:00.000Z","title":"JAVA 内存IO","_content":"\n## ByteArrayInputStream\n从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 `IOException`。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayInputStream in = new ByteArrayInputStream(buff)) {\n\n\twhile(in.available() != 0)\n\t\tSystem.out.println(in.read());\n\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## ByteArrayOutputStream\n输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 `ByteArrayOutputStream `无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何`IOException`。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n\tout.write(buff);\n\n\tbyte[] byteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush before : \" + b);\n\t}\n\n\tout.flush();\n\n\tbyteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush after : \" + b);\n\t}\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayReader\n与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n```java\nchar[] array = {'a', 'z', 'g'};\ntry(CharArrayReader in = new CharArrayReader(array)) {\n\twhile(in.ready())\n\t\tSystem.out.println(in.read());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayWriter\n向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write\n```java\ntry(CharArrayWriter out = new CharArrayWriter()) {\n\tout.write(\"TestChararray\");\n\tSystem.out.println(out.toString());\n\tout.append(\"test_\");\n\tSystem.out.println(out.toString());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## PushbackInputStream\n拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n## PushbackReader\n允许将字符推回到流的字符流 reader。当程序调用推回输入流的unread()方法时，系统会把指定数组的内容推回到该缓冲区中，而推回输入流每次调用read()方法时，总是先从推回缓冲区读取内容，只有完全读取了推回缓冲区里的内容后，但是还没有装满read()所需要的数组时才会从原输入流中读取\n```java\ntry (\n// 创建一个PushbackReader对象，指定推回缓冲区的长度为64\nPushbackReader pr = new PushbackReader(new FileReader(\"PushBackTest.java\"), 64);\nchar[] buf = new char[32];\n// 用以保存上次读取字符串的内容\nString lastContent = \"\";\nint hasRead = 0;\n\n// 循环读取文件内容\nwhile ((hasRead = pr.read(buf)) > 0) {\n\t// 将读取的内容转化为字符串\n\tString content = new String(buf, 0, hasRead);\n\tint targetIndex = 0;\n\n\t// 将上次读取的字符串和本次读取的字符串拼接起来\n\t// 查看是否包含目标字符串，\n\t// 如果包含目标字符串\n\tif ((targetIndex = (lastContent + content)\n\t\t\t.indexOf(\"new PushbackReader\")) > 0) {\n\t\t// 将本次的内容和上次的内容一起推回缓冲区\n\t\tpr.unread((lastContent + content).toCharArray());\n\n\t\t// 重现定义一个长度为targetIndex的char类型的数组\n\t\tif (targetIndex > 32) {\n\t\t\tbuf = new char[targetIndex];\n\t\t}\n\n\t\t// 再次读取指定长度的内容，即目标字符串之前的内容\n\t\tpr.read(buf, 0, targetIndex);\n\n\t\t// 答应读取指定长度的内容\n\t\tSystem.out.println(new String(buf, 0, targetIndex));\n\t\tSystem.exit(0);\n\t} else {\n\n\t\t// 打印上次读取的内容\n\t\tSystem.out.println(lastContent);\n\t\t// 将本次读取的内容设置为上次读取的内容\n\t\tlastContent = content;\n\n\t}\n\n}\n```\n\n## PipedReader\nPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n## PipedWriter\nPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n## PipedInputStream\n管道输入流是让多线程可以通过管道进行线程间的通讯\n\n## PipedOutputStream\n管道输出流是让多线程可以通过管道进行线程间的通讯\n\n## SequenceInputStream\n从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n## StreamTokenizer\n获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n## Console\n专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n```java\nConsole cons = System.console();\nif (cons != null) {\n\t// -------------------------\n\tPrintWriter printWriter = cons.writer();\n\tprintWriter.write(\"input:\");\n\tcons.flush();\n\tString str1 = cons.readLine();\n\tcons.format(\"%s\", str1);\n}\n\n```\n","source":"_posts/JavaSE/JavaIO 内存IO.md","raw":"category: JavaSE\ndate: 2015-11-21\ntitle: JAVA 内存IO\n---\n\n## ByteArrayInputStream\n从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 `IOException`。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayInputStream in = new ByteArrayInputStream(buff)) {\n\n\twhile(in.available() != 0)\n\t\tSystem.out.println(in.read());\n\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## ByteArrayOutputStream\n输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 `ByteArrayOutputStream `无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何`IOException`。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n\tout.write(buff);\n\n\tbyte[] byteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush before : \" + b);\n\t}\n\n\tout.flush();\n\n\tbyteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush after : \" + b);\n\t}\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayReader\n与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n```java\nchar[] array = {'a', 'z', 'g'};\ntry(CharArrayReader in = new CharArrayReader(array)) {\n\twhile(in.ready())\n\t\tSystem.out.println(in.read());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayWriter\n向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write\n```java\ntry(CharArrayWriter out = new CharArrayWriter()) {\n\tout.write(\"TestChararray\");\n\tSystem.out.println(out.toString());\n\tout.append(\"test_\");\n\tSystem.out.println(out.toString());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## PushbackInputStream\n拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n## PushbackReader\n允许将字符推回到流的字符流 reader。当程序调用推回输入流的unread()方法时，系统会把指定数组的内容推回到该缓冲区中，而推回输入流每次调用read()方法时，总是先从推回缓冲区读取内容，只有完全读取了推回缓冲区里的内容后，但是还没有装满read()所需要的数组时才会从原输入流中读取\n```java\ntry (\n// 创建一个PushbackReader对象，指定推回缓冲区的长度为64\nPushbackReader pr = new PushbackReader(new FileReader(\"PushBackTest.java\"), 64);\nchar[] buf = new char[32];\n// 用以保存上次读取字符串的内容\nString lastContent = \"\";\nint hasRead = 0;\n\n// 循环读取文件内容\nwhile ((hasRead = pr.read(buf)) > 0) {\n\t// 将读取的内容转化为字符串\n\tString content = new String(buf, 0, hasRead);\n\tint targetIndex = 0;\n\n\t// 将上次读取的字符串和本次读取的字符串拼接起来\n\t// 查看是否包含目标字符串，\n\t// 如果包含目标字符串\n\tif ((targetIndex = (lastContent + content)\n\t\t\t.indexOf(\"new PushbackReader\")) > 0) {\n\t\t// 将本次的内容和上次的内容一起推回缓冲区\n\t\tpr.unread((lastContent + content).toCharArray());\n\n\t\t// 重现定义一个长度为targetIndex的char类型的数组\n\t\tif (targetIndex > 32) {\n\t\t\tbuf = new char[targetIndex];\n\t\t}\n\n\t\t// 再次读取指定长度的内容，即目标字符串之前的内容\n\t\tpr.read(buf, 0, targetIndex);\n\n\t\t// 答应读取指定长度的内容\n\t\tSystem.out.println(new String(buf, 0, targetIndex));\n\t\tSystem.exit(0);\n\t} else {\n\n\t\t// 打印上次读取的内容\n\t\tSystem.out.println(lastContent);\n\t\t// 将本次读取的内容设置为上次读取的内容\n\t\tlastContent = content;\n\n\t}\n\n}\n```\n\n## PipedReader\nPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n## PipedWriter\nPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n## PipedInputStream\n管道输入流是让多线程可以通过管道进行线程间的通讯\n\n## PipedOutputStream\n管道输出流是让多线程可以通过管道进行线程间的通讯\n\n## SequenceInputStream\n从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n## StreamTokenizer\n获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n## Console\n专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n```java\nConsole cons = System.console();\nif (cons != null) {\n\t// -------------------------\n\tPrintWriter printWriter = cons.writer();\n\tprintWriter.write(\"input:\");\n\tcons.flush();\n\tString str1 = cons.readLine();\n\tcons.format(\"%s\", str1);\n}\n\n```\n","slug":"JavaSE/JavaIO 内存IO","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihob001qvjs6rt9i59tt"},{"date":"2015-11-20T16:00:00.000Z","title":"JAVA 写文件","_content":"\n## BufferedOutputStream\n我们使用`FileOutputStream`, `BufferedOutputStream`来读取文件\n```java\ntry (BufferedOutputStream bf = new BufferedOutputStream(new FileOutputStream(new File(\"\")));) {\n\tbf.write(1);\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\nBufferedOutputStream 缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\nBufferedOutputStream只提供了输出byte数据的方式,因此这种方式只能读取二进制流\n\n> FileOutputStream 一个字节一个字节的向文件里输出数据\n\n## BufferedWriter\n1. 支持字符串输出\n2. 支持换行输出\n3. 支持文件追加输出\n```java\nBufferedWriter writer = Files.newBufferedWriter(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);\nwriter.write(\"123456\\n\"); // 换行输出\n```\n> 另外还有一点需要提到的是FileWriter, 它一个字符一个字符地输出\n\n## OutputStreamWriter\nOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n```java\n// 写入UTF-8格式编码的文件\nStringBuffer buffer = new StringBuffer();\ntry (Writer out = new BufferedWriter(new OutputStreamWriter(\n\t\tnew FileOutputStream(file), \"UTF8\"))) {\n\n\tout.append(\"Website UTF-8\").append(\"\\r\\n\");\n\tout.append(\"中文 UTF-8\").append(\"\\r\\n\");\n\n\tout.flush();\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## PrintStream\n标准IO重定向\n\n打印输出流,用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream永远不会抛出IOException；PrintStream提供了自动flush和字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\nSystem类提供了一些简单的静态方法调用,以允许我们对标准输入,输出和错误IO进行重定向IO重定向是对字节流的操纵而不是字符流,因此在该例中使用的是InputStream和OutputStream而不是Reader和Writer\n\n示例 如果在显示器上创建大量输出,而这些输出滚动地太快而无法阅读时,IO重定向就显得很有用\n```java\nPrintStream console = System.out;\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(\"Redirecting.java\"));\n\nPrintStream out = new PrintStream(new BufferedOutputStream(new FileOutputStream(\"MapDB.test.out\")));\n\nSystem.setIn(in);\nSystem.setOut(out);\nSystem.setErr(out);\n\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in));\nString s;\nwhile ((s = br.readLine()) != null)\n\tSystem.out.println(s);\n\nout.close(); // Remember this!\nSystem.setOut(console);\n```\n\n## PrintWriter\n用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\nFileWriter可以向文件输出数据. 首先创建一个与指定文件连接的FileWriter.然后使用BufferedWriter对其进行包装进行性能提升 最后使用PrintWriter提供格式化功能\n```java\ntry (PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(file)));) {\n\tout.println(string);\n}\n```\nSystem.out 是一个PrintStream,而PrintStream是一个OutputStream而PrintWriter有一个参数是接受OutputStream,因此我们可以将System.out转换成PrintWriter\n```java\ntry (PrintWriter out = new PrintWriter(System.out);) {\nout.println(string);\n}\n```\n","source":"_posts/JavaSE/JavaIO 写文件.md","raw":"category: JavaSE\ndate: 2015-11-21\ntitle: JAVA 写文件\n---\n\n## BufferedOutputStream\n我们使用`FileOutputStream`, `BufferedOutputStream`来读取文件\n```java\ntry (BufferedOutputStream bf = new BufferedOutputStream(new FileOutputStream(new File(\"\")));) {\n\tbf.write(1);\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\nBufferedOutputStream 缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\nBufferedOutputStream只提供了输出byte数据的方式,因此这种方式只能读取二进制流\n\n> FileOutputStream 一个字节一个字节的向文件里输出数据\n\n## BufferedWriter\n1. 支持字符串输出\n2. 支持换行输出\n3. 支持文件追加输出\n```java\nBufferedWriter writer = Files.newBufferedWriter(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);\nwriter.write(\"123456\\n\"); // 换行输出\n```\n> 另外还有一点需要提到的是FileWriter, 它一个字符一个字符地输出\n\n## OutputStreamWriter\nOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n```java\n// 写入UTF-8格式编码的文件\nStringBuffer buffer = new StringBuffer();\ntry (Writer out = new BufferedWriter(new OutputStreamWriter(\n\t\tnew FileOutputStream(file), \"UTF8\"))) {\n\n\tout.append(\"Website UTF-8\").append(\"\\r\\n\");\n\tout.append(\"中文 UTF-8\").append(\"\\r\\n\");\n\n\tout.flush();\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## PrintStream\n标准IO重定向\n\n打印输出流,用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream永远不会抛出IOException；PrintStream提供了自动flush和字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\nSystem类提供了一些简单的静态方法调用,以允许我们对标准输入,输出和错误IO进行重定向IO重定向是对字节流的操纵而不是字符流,因此在该例中使用的是InputStream和OutputStream而不是Reader和Writer\n\n示例 如果在显示器上创建大量输出,而这些输出滚动地太快而无法阅读时,IO重定向就显得很有用\n```java\nPrintStream console = System.out;\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(\"Redirecting.java\"));\n\nPrintStream out = new PrintStream(new BufferedOutputStream(new FileOutputStream(\"MapDB.test.out\")));\n\nSystem.setIn(in);\nSystem.setOut(out);\nSystem.setErr(out);\n\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in));\nString s;\nwhile ((s = br.readLine()) != null)\n\tSystem.out.println(s);\n\nout.close(); // Remember this!\nSystem.setOut(console);\n```\n\n## PrintWriter\n用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\nFileWriter可以向文件输出数据. 首先创建一个与指定文件连接的FileWriter.然后使用BufferedWriter对其进行包装进行性能提升 最后使用PrintWriter提供格式化功能\n```java\ntry (PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(file)));) {\n\tout.println(string);\n}\n```\nSystem.out 是一个PrintStream,而PrintStream是一个OutputStream而PrintWriter有一个参数是接受OutputStream,因此我们可以将System.out转换成PrintWriter\n```java\ntry (PrintWriter out = new PrintWriter(System.out);) {\nout.println(string);\n}\n```\n","slug":"JavaSE/JavaIO 写文件","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihoh001svjs66siiiu2x"},{"date":"2015-11-20T16:00:00.000Z","title":"JAVA 序列化","_content":"\n## Externalizable \nExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成. 如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段. \n\n## Flushable \n实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中. 写入流的所有I/O类都实现了Flushable接口. \n\n## ObjectInputValidation \n序列化流验证机制.一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题. 但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息. Java序列化提供一套验证机制. 序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n\n## ObjectStreamConstants \nJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值. Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分. 现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中.  \n\n## DataInputStream \n用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n\n从DataInputStream一次一个字节地读取字符,那么任何值都是合法的,因此返回值不能用来检测输入是否结束.但是可以使用available()函数来查看还有多少字符可供读取\n\navailable()函数的工作方式会随之所读取的媒介类不同而不同, 该函数从字面上的意思来讲就是\"在没有阻塞的情况下所能读取的字节数\".对于文件这指的是整个文件,而对于其他流可能就不是这样的\n\n格式化的内存输入 当读取格式化数据时可以使用DataInputStream，它是一个面向字节的IO类\n```java\ntry(DataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(TestDataInputStream.class.getCanonicalName())));) {\n\twhile (in.available() != 0)\n\t\tSystem.out.print((char) in.readByte());\n\t\n}\n```\n> DataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据. 同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具. 对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）. 如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException. 尤其在输入流已关闭的情况下，将抛出 IOException. \n\n## DataOutputStream \n用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”. \n\n我们可以使用DataOutputStream指定格式存储数据, 然后使用DataInputStream轻松的再次指定读取格式来恢复这些数据.\n```java\nDataOutputStream out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(\"Data.txt\")));\nout.writeDouble(3.14159);\nout.writeUTF(\"That was pi\");\nout.writeDouble(1.41413);\nout.writeUTF(\"Square root of 2\");\nout.close();\n\nDataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(\"Data.txt\")));\nSystem.out.println(in.readDouble());\n// Only readUTF() will recover the Java-UTF String properly:\nSystem.out.println(in.readUTF());\nSystem.out.println(in.readDouble());\nSystem.out.println(in.readUTF());\n\nin.close();\n```\n> DataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流. 同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具. 对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException.\n\n## ObjectInputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectOutputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。 ","source":"_posts/JavaSE/JavaIO 序列化.md","raw":"category: JavaSE\ndate: 2015-11-21\ntitle: JAVA 序列化\n---\n\n## Externalizable \nExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成. 如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段. \n\n## Flushable \n实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中. 写入流的所有I/O类都实现了Flushable接口. \n\n## ObjectInputValidation \n序列化流验证机制.一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题. 但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息. Java序列化提供一套验证机制. 序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n\n## ObjectStreamConstants \nJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值. Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分. 现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中.  \n\n## DataInputStream \n用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n\n从DataInputStream一次一个字节地读取字符,那么任何值都是合法的,因此返回值不能用来检测输入是否结束.但是可以使用available()函数来查看还有多少字符可供读取\n\navailable()函数的工作方式会随之所读取的媒介类不同而不同, 该函数从字面上的意思来讲就是\"在没有阻塞的情况下所能读取的字节数\".对于文件这指的是整个文件,而对于其他流可能就不是这样的\n\n格式化的内存输入 当读取格式化数据时可以使用DataInputStream，它是一个面向字节的IO类\n```java\ntry(DataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(TestDataInputStream.class.getCanonicalName())));) {\n\twhile (in.available() != 0)\n\t\tSystem.out.print((char) in.readByte());\n\t\n}\n```\n> DataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据. 同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具. 对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）. 如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException. 尤其在输入流已关闭的情况下，将抛出 IOException. \n\n## DataOutputStream \n用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”. \n\n我们可以使用DataOutputStream指定格式存储数据, 然后使用DataInputStream轻松的再次指定读取格式来恢复这些数据.\n```java\nDataOutputStream out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(\"Data.txt\")));\nout.writeDouble(3.14159);\nout.writeUTF(\"That was pi\");\nout.writeDouble(1.41413);\nout.writeUTF(\"Square root of 2\");\nout.close();\n\nDataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(\"Data.txt\")));\nSystem.out.println(in.readDouble());\n// Only readUTF() will recover the Java-UTF String properly:\nSystem.out.println(in.readUTF());\nSystem.out.println(in.readDouble());\nSystem.out.println(in.readUTF());\n\nin.close();\n```\n> DataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流. 同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具. 对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException.\n\n## ObjectInputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectOutputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。 ","slug":"JavaSE/JavaIO 序列化","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihok001vvjs6m0ocacqa"},{"date":"2015-11-20T16:00:00.000Z","title":"JAVA 文件操作","_content":"\n## FileFilter          \n检测文件是否存在.FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法,而FilenameFilter 是按照目录和文件名的方式来工作的.\n```java\nFileFilter fileFilter = pathname -> {\n\tSystem.out.println(pathname.getPath());\n\treturn pathname.isFile();\n};\n\nfileFilter.accept(new File(\"D:\\\\hazelcast-documentation-3.5.3.pdf\"));\n```\n\n## FilenameFilter\n```java\nFilenameFilter filenameFilter = (dir, name) -> {\n\tSystem.out.println(dir);\n\tSystem.out.println(name);\n\treturn true;\n};\n\nfilenameFilter.accept(new File(\"D\"), \"hazelcast-documentation-3.5.3.pdf\");\n```\n\n## File\nFile对象给我们提供了以下的功能\n* 删除文件\n* 文件重命名\n* 创建新的文件\n* 创建新的文件\n* 获取文件的最后修改时间\n* 设置文件只读\n* 设置文件可写\n* 获取文件长度(总字节数)\n* 获取文件路径\n* 获取绝对文件路径\n* 文件是否隐藏\n* 获得剩余磁盘空间？\n* 拷贝文件夹\n* 遍历文件夹\n* 检查文件夹是否为空？\n\n## FileDescriptor\n用来表示开放文件、开放套接字等.当FileDescriptor表示某文件时,我们可以通俗的将FileDescriptor看成是该文件.但是,我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作,则需要新创建FileDescriptor对应的FileOutputStream,再对文件进行操作.\n\n类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件,打开的套接字或其他来源或字节的接收器.以下是关于FileDescriptor要点：\n1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它.\n2. 应用程序不应创建自己的文件描述符.\n\n\n## FileLock\n锁定文件\n\nByteBuffer.allocate()语句改为ByteBuffer.allocateDirect().用来证实性能之间的差异,但是请注意程序的启动时间是否发生了明显的改变.\n\n修改{@link JGrep}让其使java的nio内存映射文件.\n\nJDK1.4引入了文件加锁机制,它允许我们同步访问某个作为共享资源的文件.不过,竞争同一文件的两个线程可能在不同的Java虚拟机上;或者一个是Java线程,另一个是操作系统中其他的某个本地线程.\n\n文件锁对其他的操作系统进程是可见的,因为Java的文件加锁直接映射到了本地操作系统的加锁工具.通过对FileChannel调用tryLock()或lock(),就可以获得整个文件的FileLock.\n\n(SocketChannel、DatagramChannel和 ServerSocketChannel不需要加锁,因为他们是从单进程实体继承而来;我们通常不在两个进程之间共享网络socket.)\n\ntryLock()是非阻塞式的,它设法获取锁,但是如果不能获得(当其他一些进程已经持有相同的锁,并且不共享时),它将直接从方法调用返回.lock()则是阻塞式的,它要阻塞进程直至锁可以获得,或调用lock()的线程中断,或调用lock()的通道关闭.\n\n使用FileLock.release()可以释放锁.\n\n也可以使用此方法对文件上锁tryLock()或者lock()其中,加锁的区域由size-position决定.第三个参数指定是否是共享锁.\n\n尽管无参数的加锁方法将根据文件尺寸的变化而变化,但是具有固定尺寸的锁不随文件尺寸的变化而变化.如果你获得了某一区域(从position到position+size)上的锁,当文件增大超出position+size时,那么在position+size之外的部分不会被锁定.无参数的加锁方法会对 整个文件进行加锁,甚至文件变大后也是如此.\n\n对独占锁或者共享锁的支持必须由底层的操作系统提供.如果操作系统不支持共享锁并为每一个请求都创建一个锁,那么它就会使用独占锁.\n\n锁的 类型(共享或独占)可以通过FileLock.isShared()进行查询.\n```java\nFileOutputStream fos = new FileOutputStream(\"file.txt\");\nFileLock fl = fos.getChannel().tryLock();\nif (fl != null) {\n\tSystem.out.println(\"Locked File\");\n\tTimeUnit.MILLISECONDS.sleep(100);\n\tfl.release();\n\tSystem.out.println(\"Released Lock\");\n}\nfos.close()\n```\n\n## DirectoryStream     \n遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n```java\nDirectoryStream<Path> paths = Files.newDirectoryStream(Paths.get(\"E:\"));\npaths.forEach(path -> {\n\tSystem.out.println(path.getFileName());\n});\n```\n> SecureDirectoryStream\n\n## FileVisitor\n遍历某个文件夹内的所有文件接口.\n\n`SimpleFileVisitor`实现了这个接口. 与`DirectoryStream` 不同的是,这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n```java\nSimpleFileVisitor visitor = new SimpleFileVisitor<Path>() {\n\t\t\t@Override\n\t\t\tpublic FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\n\t\t\t\tSystem.out.println(file.getFileName());\n\t\t\t\treturn super.visitFile(file, attrs);\n\t\t\t}\n\t\t};\n\n\t\tFiles.walkFileTree(Paths.get(\"E:\"), visitor);\n```\n\n## 监控文件变化\n```java\nWatchService service = FileSystems.getDefault().newWatchService();\n\t\tPaths.get(\"D:/\").register(service,\n\t\tENTRY_CREATE,\n\t\tENTRY_DELETE,\n\t\tENTRY_MODIFY);\n\nWatchKey watchKey = service.take();\n\nwatchKey.pollEvents().stream().forEach(watchEvent -> {\n\tSystem.out.println(watchEvent.context() + \"  \" + watchEvent.kind());\n});\nwatchKey.reset();\n```\n\n## Files\n1. copy\n2. createDirectories\n3. createDirectory\n4. createFile\n5. createLink\n6. createSymbolicLink\n7. createTempDirectory\n8. createTempFile\n9. delete\n10. deleteIfExists\n11. exists\n12. getAttribute\n13. getFileAttributeView\n14. getFileStore\n15. getLastModifiedTime\n16. getOwner\n17. getPosixFilePermissions\n18. isDirectory\n19. isExecutable\n20. isHidden\n21. isReadable\n22. isRegularFile\n23. isSameFile\n24. isSymbolicLink\n25. isWritable\n26. move\n27. newBufferedReader\n28. newBufferedWriter\n29. newByteChannel\n30. newDirectoryStream\n31. newInputStream\n32. newOutputStream\n33. notExists\n34. probeContentType\n35. readAllBytes\n36. readAllLines\n37. readAttributes\n38. readSymbolicLink\n39. setAttribute\n40. setLastModifiedTime\n41. setOwner\n42. setPosixFilePermissions\n43. walkFileTree\n44. write\n\n\n## FileStore\n代表了真正的存储设备,提供了设备的详尽信息\n\n## FileSystems   \n* FileSystems.getDefault() ：返回 JVM 默认的 FileSystem – 一般说来,也就是操作系统的默认文件系统\n* FileSystems.getFileSystem(uri) ： 可以获取远程主机的FileSystem\n```java\nFileSystem system = FileSystems.getDefault();\n// 得到文件系统支持的属性视图列表\nSet<String> views = system.supportedFileAttributeViews();\n```\n> FileSystem\n\n\n## Paths          \n> Path 类可以在任何文件系统（FileSystem）和任何存储空间 Path 类引用默认文件系统（计算机的文件系统）的文件,但是 NIO.2是完全模块化的—— FileSystem 的具体实现是在内存中的一组数据,因此在网络环境或在虚拟文件系统中,NIO.2 也完全适用.NIO.2提供给我们在文件系统中操作文件、文件夹或链接的所有方法\n","source":"_posts/JavaSE/JavaIO 文件操作.md","raw":"category: JavaSE\ndate: 2015-11-21\ntitle: JAVA 文件操作\n---\n\n## FileFilter          \n检测文件是否存在.FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法,而FilenameFilter 是按照目录和文件名的方式来工作的.\n```java\nFileFilter fileFilter = pathname -> {\n\tSystem.out.println(pathname.getPath());\n\treturn pathname.isFile();\n};\n\nfileFilter.accept(new File(\"D:\\\\hazelcast-documentation-3.5.3.pdf\"));\n```\n\n## FilenameFilter\n```java\nFilenameFilter filenameFilter = (dir, name) -> {\n\tSystem.out.println(dir);\n\tSystem.out.println(name);\n\treturn true;\n};\n\nfilenameFilter.accept(new File(\"D\"), \"hazelcast-documentation-3.5.3.pdf\");\n```\n\n## File\nFile对象给我们提供了以下的功能\n* 删除文件\n* 文件重命名\n* 创建新的文件\n* 创建新的文件\n* 获取文件的最后修改时间\n* 设置文件只读\n* 设置文件可写\n* 获取文件长度(总字节数)\n* 获取文件路径\n* 获取绝对文件路径\n* 文件是否隐藏\n* 获得剩余磁盘空间？\n* 拷贝文件夹\n* 遍历文件夹\n* 检查文件夹是否为空？\n\n## FileDescriptor\n用来表示开放文件、开放套接字等.当FileDescriptor表示某文件时,我们可以通俗的将FileDescriptor看成是该文件.但是,我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作,则需要新创建FileDescriptor对应的FileOutputStream,再对文件进行操作.\n\n类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件,打开的套接字或其他来源或字节的接收器.以下是关于FileDescriptor要点：\n1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它.\n2. 应用程序不应创建自己的文件描述符.\n\n\n## FileLock\n锁定文件\n\nByteBuffer.allocate()语句改为ByteBuffer.allocateDirect().用来证实性能之间的差异,但是请注意程序的启动时间是否发生了明显的改变.\n\n修改{@link JGrep}让其使java的nio内存映射文件.\n\nJDK1.4引入了文件加锁机制,它允许我们同步访问某个作为共享资源的文件.不过,竞争同一文件的两个线程可能在不同的Java虚拟机上;或者一个是Java线程,另一个是操作系统中其他的某个本地线程.\n\n文件锁对其他的操作系统进程是可见的,因为Java的文件加锁直接映射到了本地操作系统的加锁工具.通过对FileChannel调用tryLock()或lock(),就可以获得整个文件的FileLock.\n\n(SocketChannel、DatagramChannel和 ServerSocketChannel不需要加锁,因为他们是从单进程实体继承而来;我们通常不在两个进程之间共享网络socket.)\n\ntryLock()是非阻塞式的,它设法获取锁,但是如果不能获得(当其他一些进程已经持有相同的锁,并且不共享时),它将直接从方法调用返回.lock()则是阻塞式的,它要阻塞进程直至锁可以获得,或调用lock()的线程中断,或调用lock()的通道关闭.\n\n使用FileLock.release()可以释放锁.\n\n也可以使用此方法对文件上锁tryLock()或者lock()其中,加锁的区域由size-position决定.第三个参数指定是否是共享锁.\n\n尽管无参数的加锁方法将根据文件尺寸的变化而变化,但是具有固定尺寸的锁不随文件尺寸的变化而变化.如果你获得了某一区域(从position到position+size)上的锁,当文件增大超出position+size时,那么在position+size之外的部分不会被锁定.无参数的加锁方法会对 整个文件进行加锁,甚至文件变大后也是如此.\n\n对独占锁或者共享锁的支持必须由底层的操作系统提供.如果操作系统不支持共享锁并为每一个请求都创建一个锁,那么它就会使用独占锁.\n\n锁的 类型(共享或独占)可以通过FileLock.isShared()进行查询.\n```java\nFileOutputStream fos = new FileOutputStream(\"file.txt\");\nFileLock fl = fos.getChannel().tryLock();\nif (fl != null) {\n\tSystem.out.println(\"Locked File\");\n\tTimeUnit.MILLISECONDS.sleep(100);\n\tfl.release();\n\tSystem.out.println(\"Released Lock\");\n}\nfos.close()\n```\n\n## DirectoryStream     \n遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n```java\nDirectoryStream<Path> paths = Files.newDirectoryStream(Paths.get(\"E:\"));\npaths.forEach(path -> {\n\tSystem.out.println(path.getFileName());\n});\n```\n> SecureDirectoryStream\n\n## FileVisitor\n遍历某个文件夹内的所有文件接口.\n\n`SimpleFileVisitor`实现了这个接口. 与`DirectoryStream` 不同的是,这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n```java\nSimpleFileVisitor visitor = new SimpleFileVisitor<Path>() {\n\t\t\t@Override\n\t\t\tpublic FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\n\t\t\t\tSystem.out.println(file.getFileName());\n\t\t\t\treturn super.visitFile(file, attrs);\n\t\t\t}\n\t\t};\n\n\t\tFiles.walkFileTree(Paths.get(\"E:\"), visitor);\n```\n\n## 监控文件变化\n```java\nWatchService service = FileSystems.getDefault().newWatchService();\n\t\tPaths.get(\"D:/\").register(service,\n\t\tENTRY_CREATE,\n\t\tENTRY_DELETE,\n\t\tENTRY_MODIFY);\n\nWatchKey watchKey = service.take();\n\nwatchKey.pollEvents().stream().forEach(watchEvent -> {\n\tSystem.out.println(watchEvent.context() + \"  \" + watchEvent.kind());\n});\nwatchKey.reset();\n```\n\n## Files\n1. copy\n2. createDirectories\n3. createDirectory\n4. createFile\n5. createLink\n6. createSymbolicLink\n7. createTempDirectory\n8. createTempFile\n9. delete\n10. deleteIfExists\n11. exists\n12. getAttribute\n13. getFileAttributeView\n14. getFileStore\n15. getLastModifiedTime\n16. getOwner\n17. getPosixFilePermissions\n18. isDirectory\n19. isExecutable\n20. isHidden\n21. isReadable\n22. isRegularFile\n23. isSameFile\n24. isSymbolicLink\n25. isWritable\n26. move\n27. newBufferedReader\n28. newBufferedWriter\n29. newByteChannel\n30. newDirectoryStream\n31. newInputStream\n32. newOutputStream\n33. notExists\n34. probeContentType\n35. readAllBytes\n36. readAllLines\n37. readAttributes\n38. readSymbolicLink\n39. setAttribute\n40. setLastModifiedTime\n41. setOwner\n42. setPosixFilePermissions\n43. walkFileTree\n44. write\n\n\n## FileStore\n代表了真正的存储设备,提供了设备的详尽信息\n\n## FileSystems   \n* FileSystems.getDefault() ：返回 JVM 默认的 FileSystem – 一般说来,也就是操作系统的默认文件系统\n* FileSystems.getFileSystem(uri) ： 可以获取远程主机的FileSystem\n```java\nFileSystem system = FileSystems.getDefault();\n// 得到文件系统支持的属性视图列表\nSet<String> views = system.supportedFileAttributeViews();\n```\n> FileSystem\n\n\n## Paths          \n> Path 类可以在任何文件系统（FileSystem）和任何存储空间 Path 类引用默认文件系统（计算机的文件系统）的文件,但是 NIO.2是完全模块化的—— FileSystem 的具体实现是在内存中的一组数据,因此在网络环境或在虚拟文件系统中,NIO.2 也完全适用.NIO.2提供给我们在文件系统中操作文件、文件夹或链接的所有方法\n","slug":"JavaSE/JavaIO 文件操作","published":1,"updated":"2016-06-11T14:04:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihoq001xvjs6t40otikj"},{"date":"2015-11-20T16:00:00.000Z","title":"JAVA 读文件","_content":"## BufferedInputStream\n我们使用`FileInputStream`, `BufferedInputStream`来读取文件\n```java\n// 读取二进制文件\ntry (BufferedInputStream bf = new BufferedInputStream(\n\t\tnew FileInputStream(new File(\"\")));) {\n\n\tbyte[] data = new byte[bf.available()];\n\tbf.read(data);\n\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\n`BufferedInputStream`是一个带有缓冲区域的`InputStream`, 支持`mark()`标记和`reset()`重置方法.输入到byte[]数组里.只将数据读取进byte字节数组里, 因此这种方式只能读取二进制字节流\n> FileInputStream 一个字节一个字节的从文件里读取数据\n\n## BufferedReader\nBufferedReader 从字符输入流中读取文本,缓冲各个字符.提供字符、数组和行的高效读取.\n我们有俩种方式创建BufferedReader.\n* 使用带缓冲区的写入器 `Files.newBufferedReader(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);`;\n* 读取UTF-8格式编码的文件 `new BufferedReader(new InputStreamReader(new FileInputStream(file), StandardCharsets.UTF_8))`\n\n> InputStreamReader 是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符.将“字节输入流”转换成“字符输入流”.它继承于Reader.\n\n```java\nBufferedReader reader = Files.newBufferedReader(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);\nreader.lines().forEach(line -> System.out.println(line));\n```\n我们可以使用JAVA8中的Stream来快捷的遍历每一行\n> 从标准IO中输入. 按照标准的IO模型,Java提供了`System.out, System.out, System.err System.out,System.err` 已经被包装成了`PrintStream`对象,但是`System.in`作为原生`InputStream`却没有进行过任何包装. 所以在使用`System.in`时必须对其进行包装,下例中展示了,我们使用`InputStreamReader`将`System.in`包装`Reader`,然后再包装一层`BufferedReader`\n\n> 另外还有一点需要提到的是FileReader, 它一个字符一个字符地读取.\n\n## LineNumberInputStream\n此类是一个输入流过滤器,它提供跟踪当前行号的附加功能.行是以回车符 (`\\r`)、换行符 (`\\n`)或回车符后面紧跟换行符结尾的字节序列.在所有这三种情况下,都以单个换行符形式返回行终止字符.行号以 0 开头,并在 read 返回换行符时递增 1.\n\n## LineNumberReader\n跟踪行号的缓冲字符输入流.此类定义了方法 `setLineNumber(int)` 和 `getLineNumber()`,它们可分别用于设置和获取当前行号.默认情况下,行编号从 0 开始.该行号随数据读取在每个行结束符处递增,并且可以通过调用 `setLineNumber(int)` 更改行号.但要注意的是,`setLineNumber(int)` 不会实际更改流中的当前位置；它只更改将由`getLineNumber() `返回的值.可认为行在遇到以下符号之一时结束：换行符（`\\n`）、回车符（`\\r`）、回车后紧跟换行符.\n```java\n//  获取行数\nint lineCount = 0;\ntry (FileReader reader = new FileReader(IOUtils.newFile(\"\"));\n\t\tLineNumberReader lnr = new LineNumberReader(reader);) {\n\twhile (lnr.readLine() != null) {\n\t\tlineCount++;\n\t}\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## RandomAccessFile  \n读写随机访问文件 `RandomAccessFile`除了实现了`DataInput`和`DataOutput`接口之外,有效地与IO继承层次结构的其他部分实现了分离.\n\n因为它不支持装饰模式,所以不能将其与`InputStream`和`OutputStream`子类的任何部分组合起来而且必须假定`RandomAccessFile`已经被正确的缓冲\n\n用来访问那些保存数据记录的文件的,你就可以用`seek()`方法来访问记录,并进行读写了.这些记录的大小不必相同；但是其大小和位置必须是可知的.但是该类仅限于操作文件.\n```java\n// 读取所有的行\ntry (RandomAccessFile r = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < r.length(); i++) {\n\t\tr.read();\t// r.readLine();\n\t}\n}\n// 写入数据,第二个参数必须为 \"r\", \"rw\", \"rws\", or \"rwd\"\ntry (RandomAccessFile w = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < 1024 * 1024 * 10; i++)\n\t\tw.writeByte(1);\n}\ntry (FileChannel fc = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\").getChannel();) {\n\tIntBuffer ib = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size()).asIntBuffer();\n\tfor (int i = 1; i < 10000; i++)\n\t\tib.put(ib.get(i - 1));\n\n}\nRandomAccessFile raf = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\");\nraf.writeInt(1);\nfor (int i = 0; i < 2000000; i++) {\n\traf.seek(raf.length() - 4);\n\traf.writeInt(raf.readInt());\n}\nraf.close();\n```\n\n## getResourceAsStream\n我们还可以使用类加载器的`getResourceAsStream()`从指定路径或者jar包中加载文件资源\n1. Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。\n2. Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由ClassLoader获取资源。\n```java\npublic class TestReadFile {\n\tpublic static void main(String[] args) throws IOException {\n\n\t\tInputStream in = TestReadFile.class.getClassLoader().getResourceAsStream(\"./mybatis-config.xml\");\n\t\tBufferedReader buffer = new BufferedReader(new InputStreamReader(in));\n\t\tSystem.out.println(buffer.readLine());\n\t\tin = new TestReadFile().getClass().getResourceAsStream(\"./mybatis-config.xml\");\n\t\tbuffer = new BufferedReader(new InputStreamReader(in));\n\t\tSystem.out.println(buffer.readLine());\n\n\t\tSystem.out.println(new File(\".\").getCanonicalPath());\n\t\tSystem.out.println(new File(\".\").getAbsolutePath());\n\t\tSystem.out.println(new File(\".\").getPath());\n\t}\n}\n```\n输出结果为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\nD:\\ming\\test\nD:\\ming\\test\\.\n.\n```","source":"_posts/JavaSE/JavaIO 读文件.md","raw":"category: JavaSE\ndate: 2015-11-21\ntitle: JAVA 读文件\n---\n## BufferedInputStream\n我们使用`FileInputStream`, `BufferedInputStream`来读取文件\n```java\n// 读取二进制文件\ntry (BufferedInputStream bf = new BufferedInputStream(\n\t\tnew FileInputStream(new File(\"\")));) {\n\n\tbyte[] data = new byte[bf.available()];\n\tbf.read(data);\n\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\n`BufferedInputStream`是一个带有缓冲区域的`InputStream`, 支持`mark()`标记和`reset()`重置方法.输入到byte[]数组里.只将数据读取进byte字节数组里, 因此这种方式只能读取二进制字节流\n> FileInputStream 一个字节一个字节的从文件里读取数据\n\n## BufferedReader\nBufferedReader 从字符输入流中读取文本,缓冲各个字符.提供字符、数组和行的高效读取.\n我们有俩种方式创建BufferedReader.\n* 使用带缓冲区的写入器 `Files.newBufferedReader(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);`;\n* 读取UTF-8格式编码的文件 `new BufferedReader(new InputStreamReader(new FileInputStream(file), StandardCharsets.UTF_8))`\n\n> InputStreamReader 是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符.将“字节输入流”转换成“字符输入流”.它继承于Reader.\n\n```java\nBufferedReader reader = Files.newBufferedReader(Paths.get(\"new.txt\"), StandardCharsets.UTF_8);\nreader.lines().forEach(line -> System.out.println(line));\n```\n我们可以使用JAVA8中的Stream来快捷的遍历每一行\n> 从标准IO中输入. 按照标准的IO模型,Java提供了`System.out, System.out, System.err System.out,System.err` 已经被包装成了`PrintStream`对象,但是`System.in`作为原生`InputStream`却没有进行过任何包装. 所以在使用`System.in`时必须对其进行包装,下例中展示了,我们使用`InputStreamReader`将`System.in`包装`Reader`,然后再包装一层`BufferedReader`\n\n> 另外还有一点需要提到的是FileReader, 它一个字符一个字符地读取.\n\n## LineNumberInputStream\n此类是一个输入流过滤器,它提供跟踪当前行号的附加功能.行是以回车符 (`\\r`)、换行符 (`\\n`)或回车符后面紧跟换行符结尾的字节序列.在所有这三种情况下,都以单个换行符形式返回行终止字符.行号以 0 开头,并在 read 返回换行符时递增 1.\n\n## LineNumberReader\n跟踪行号的缓冲字符输入流.此类定义了方法 `setLineNumber(int)` 和 `getLineNumber()`,它们可分别用于设置和获取当前行号.默认情况下,行编号从 0 开始.该行号随数据读取在每个行结束符处递增,并且可以通过调用 `setLineNumber(int)` 更改行号.但要注意的是,`setLineNumber(int)` 不会实际更改流中的当前位置；它只更改将由`getLineNumber() `返回的值.可认为行在遇到以下符号之一时结束：换行符（`\\n`）、回车符（`\\r`）、回车后紧跟换行符.\n```java\n//  获取行数\nint lineCount = 0;\ntry (FileReader reader = new FileReader(IOUtils.newFile(\"\"));\n\t\tLineNumberReader lnr = new LineNumberReader(reader);) {\n\twhile (lnr.readLine() != null) {\n\t\tlineCount++;\n\t}\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## RandomAccessFile  \n读写随机访问文件 `RandomAccessFile`除了实现了`DataInput`和`DataOutput`接口之外,有效地与IO继承层次结构的其他部分实现了分离.\n\n因为它不支持装饰模式,所以不能将其与`InputStream`和`OutputStream`子类的任何部分组合起来而且必须假定`RandomAccessFile`已经被正确的缓冲\n\n用来访问那些保存数据记录的文件的,你就可以用`seek()`方法来访问记录,并进行读写了.这些记录的大小不必相同；但是其大小和位置必须是可知的.但是该类仅限于操作文件.\n```java\n// 读取所有的行\ntry (RandomAccessFile r = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < r.length(); i++) {\n\t\tr.read();\t// r.readLine();\n\t}\n}\n// 写入数据,第二个参数必须为 \"r\", \"rw\", \"rws\", or \"rwd\"\ntry (RandomAccessFile w = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < 1024 * 1024 * 10; i++)\n\t\tw.writeByte(1);\n}\ntry (FileChannel fc = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\").getChannel();) {\n\tIntBuffer ib = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size()).asIntBuffer();\n\tfor (int i = 1; i < 10000; i++)\n\t\tib.put(ib.get(i - 1));\n\n}\nRandomAccessFile raf = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\");\nraf.writeInt(1);\nfor (int i = 0; i < 2000000; i++) {\n\traf.seek(raf.length() - 4);\n\traf.writeInt(raf.readInt());\n}\nraf.close();\n```\n\n## getResourceAsStream\n我们还可以使用类加载器的`getResourceAsStream()`从指定路径或者jar包中加载文件资源\n1. Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。\n2. Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由ClassLoader获取资源。\n```java\npublic class TestReadFile {\n\tpublic static void main(String[] args) throws IOException {\n\n\t\tInputStream in = TestReadFile.class.getClassLoader().getResourceAsStream(\"./mybatis-config.xml\");\n\t\tBufferedReader buffer = new BufferedReader(new InputStreamReader(in));\n\t\tSystem.out.println(buffer.readLine());\n\t\tin = new TestReadFile().getClass().getResourceAsStream(\"./mybatis-config.xml\");\n\t\tbuffer = new BufferedReader(new InputStreamReader(in));\n\t\tSystem.out.println(buffer.readLine());\n\n\t\tSystem.out.println(new File(\".\").getCanonicalPath());\n\t\tSystem.out.println(new File(\".\").getAbsolutePath());\n\t\tSystem.out.println(new File(\".\").getPath());\n\t}\n}\n```\n输出结果为\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\nD:\\ming\\test\nD:\\ming\\test\\.\n.\n```","slug":"JavaSE/JavaIO 读文件","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihot0020vjs6pilxyjdk"},{"date":"2014-11-08T16:00:00.000Z","title":"Java加密 -- 对称加密","_content":"# 对称加密\n\n## 对称加密算法的由来\n目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\nDES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n## 分组密码\n下面介绍了分组密码的各种工作模式\n\n###  电子密码本模式-ECB\n![]()\n```java\n优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n对明文主动攻击的可能性较高\n用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n\n###  密文连接模式-CBC\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCBC.jpg)\n```java\n优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n无法完成还原;对明文的主动攻击性较低\n缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n导致加密失败;需要初始化向量\n用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n\n###  密文反馈模式-CFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCFB.jpg)\n```java\n优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n需要初始化向量.\n用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n\n###  输出反馈模式-OFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FOFB.jpg)\n```java\n优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n\n###  计数器模式-CTR\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCTR.jpg)\n```java\n优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n缺点：没有错误传播,因此不易确保数据完整性\n用途：适用于各种加密应用\n```\n\n## 流密码\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E6%B5%81%E6%A8%A1%E5%BC%8F.jpg)\n```java\n同步流密码\n自同步流密码\n主要用于军事和外交\n常用算法 ： RC4,  SEAL\n```\n\n# RCCoder\n```java\n\npublic enum RCCoder {\n\n\tINSTANCE;\n\n\tpublic byte[] encrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\n\t\treturn encoded;\n\t}\n\n\tpublic byte[] decrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\n\t\treturn encoded;\n\t}\n}\n```\n\n# PBECoder\n```java\n\n/**\n * PBE安全编码组件 * Java 6 支持以下任意一种算法\n */\npublic enum PBECoder {\n\n\tPBEWithMD5AndDES(\"PBEWithMD5AndDES\"),\n\tPBEWithMD5AndTripleDES(\"PBEWithMD5AndTripleDES\"),\n\tPBEWithSHA1AndDESede(\"PBEWithSHA1AndDESede\"),\n\tPBEWithSHA1AndRC2_40(\"PBEWithSHA1AndRC2_40\");\n\n\tPBECoder(String algothrim) {\n\t\tALGORITHM = algothrim;\n\t}\n\n\tpublic String ALGORITHM = \"PBEWithMD5AndTripleDES\";\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 盐初始化<br>\n\t * 盐长度必须为8字节\n\t *\n\t * @return byte[] 盐\n\t * @throws Exception\n\t */\n\tpublic byte[] initSalt() throws Exception {\n\n\t\tSecureRandom random = new SecureRandom();\n\n\t\treturn random.generateSeed(8);\n\t}\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param password\n\t *            密码\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(String password) throws Exception {\n\n\t\t// 密钥材料转换\n\t\tPBEKeySpec keySpec = new PBEKeySpec(password.toCharArray());\n\n\t\t// 实例化\n\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成密钥\n\t\tSecretKey secretKey = keyFactory.generateSecret(keySpec);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.ENCRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.DECRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n}\n```\n\n# IDEACoder\n```java\n\n/**\n * IDEA安全编码组件\n *\n */\npublic abstract class IDEACoder {\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"IDEA\";\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tpublic static final String CIPHER_ALGORITHM = \"IDEA/ECB/PKCS5Padding\";\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate static Key toKey(byte[] key) throws Exception {\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为解密模式\n\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为加密模式\n\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化\n\t\tKeyGenerator kg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化\n\t\tkg.init(128);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n\n# DESedeCoder\n\n```java\n\n/**\n * DESede安全编码组件\n * 加密/解密算法 / 工作模式 / 填充方式\n * Java 6支持PKCS5PADDING填充方式\n * Bouncy Castle支持PKCS7Padding填充方式\n */\npublic enum DESedeCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\n\tDESedeCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"DESede\";\n\n\tprivate String CIPHER_ALGORITHM = \"DESede/ECB/PKCS5Padding\";\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化DES密钥材料\n\t\tDESedeKeySpec dks = null;\n\t\ttry {\n\t\t\tdks = new DESedeKeySpec(key);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 实例化秘密密钥工厂\n\t\tSecretKeyFactory keyFactory = null;\n\t\ttry {\n\t\t\tkeyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (InvalidKeySpecException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为解密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (IllegalStateException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为加密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * DESede 要求密钥长度为 112位或168位\n\t\t */\n\t\tkg.init(168);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n\n# DESCoder\n\n```java\n\n/**\n * DES安全编码组件\n * 密钥算法 <br>\n * Java 6 只支持56bit密钥 <br>\n * Bouncy Castle 支持64bit密钥\n */\npublic enum DESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tDESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\tprivate final String KEY_ALGORITHM = \"DES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\t// 实例化DES密钥材料\n\t\t\tDESKeySpec dks = new DESKeySpec(key);\n\t\t\t// 实例化秘密密钥工厂\n\t\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t\t// 生成秘密密钥\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"toKey : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"decrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * 加密数据在下面几种情况下,必须满足长度和倍数关系, 否则会抛出下面异常\n\t * CTS_NoPadding\tinput is too short!\n\t * CTS_PKCS5Padding\tinput is too short!\n\t * CBC_NoPadding\tInput length not multiple of 8 bytes\n\t * PCBC_NoPadding\tInput length not multiple of 8 bytes\n\t * ECB_NoPadding\tInput length not multiple of 8 bytes\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"encrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * Java 6 只支持56bit密钥 <br>\n\t * Bouncy Castle 支持64bit密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t/*\n\t\t * 实例化密钥生成器\n\t\t *\n\t\t * 若要使用64bit密钥注意替换 将下述代码中的KeyGenerator.getInstance(CIPHER_ALGORITHM);\n\t\t * 替换为KeyGenerator.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM, \"BC\");\n\t\t} catch (NoSuchAlgorithmException | NoSuchProviderException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * 初始化密钥生成器 若要使用64bit密钥注意替换 将下述代码kg.init(56); 替换为kg.init(64);\n\t\t */\n\t\tkg.init(64, new SecureRandom());\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n\n}\n```\n\n# AESCoder\n\n```java\n\n/**\n * AES安全编码组件\n *\n */\npublic enum AESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\t;\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t * Java 6支持PKCS5Padding填充方式\n\t * Bouncy Castle支持PKCS7Padding填充方式\n\t */\n\tAESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"AES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key 二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化AES密钥材料\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data 待解密数据\n\t * @param key 密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - decrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data 待加密数据\n\t * @param key 密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - encrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"  \" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * AES 要求密钥长度为 128位、192位或 256位\n\t\t */\n\t\tkg.init(256);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n","source":"_posts/JavaSE/Java加密 对称加密.md","raw":"category: JavaSE\ndate: 2014-11-09\ntitle: Java加密 -- 对称加密\n---\n# 对称加密\n\n## 对称加密算法的由来\n目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\nDES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n## 分组密码\n下面介绍了分组密码的各种工作模式\n\n###  电子密码本模式-ECB\n![]()\n```java\n优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n对明文主动攻击的可能性较高\n用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n\n###  密文连接模式-CBC\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCBC.jpg)\n```java\n优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n无法完成还原;对明文的主动攻击性较低\n缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n导致加密失败;需要初始化向量\n用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n\n###  密文反馈模式-CFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCFB.jpg)\n```java\n优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n需要初始化向量.\n用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n\n###  输出反馈模式-OFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FOFB.jpg)\n```java\n优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n\n###  计数器模式-CTR\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCTR.jpg)\n```java\n优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n缺点：没有错误传播,因此不易确保数据完整性\n用途：适用于各种加密应用\n```\n\n## 流密码\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E6%B5%81%E6%A8%A1%E5%BC%8F.jpg)\n```java\n同步流密码\n自同步流密码\n主要用于军事和外交\n常用算法 ： RC4,  SEAL\n```\n\n# RCCoder\n```java\n\npublic enum RCCoder {\n\n\tINSTANCE;\n\n\tpublic byte[] encrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\n\t\treturn encoded;\n\t}\n\n\tpublic byte[] decrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\n\t\treturn encoded;\n\t}\n}\n```\n\n# PBECoder\n```java\n\n/**\n * PBE安全编码组件 * Java 6 支持以下任意一种算法\n */\npublic enum PBECoder {\n\n\tPBEWithMD5AndDES(\"PBEWithMD5AndDES\"),\n\tPBEWithMD5AndTripleDES(\"PBEWithMD5AndTripleDES\"),\n\tPBEWithSHA1AndDESede(\"PBEWithSHA1AndDESede\"),\n\tPBEWithSHA1AndRC2_40(\"PBEWithSHA1AndRC2_40\");\n\n\tPBECoder(String algothrim) {\n\t\tALGORITHM = algothrim;\n\t}\n\n\tpublic String ALGORITHM = \"PBEWithMD5AndTripleDES\";\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 盐初始化<br>\n\t * 盐长度必须为8字节\n\t *\n\t * @return byte[] 盐\n\t * @throws Exception\n\t */\n\tpublic byte[] initSalt() throws Exception {\n\n\t\tSecureRandom random = new SecureRandom();\n\n\t\treturn random.generateSeed(8);\n\t}\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param password\n\t *            密码\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(String password) throws Exception {\n\n\t\t// 密钥材料转换\n\t\tPBEKeySpec keySpec = new PBEKeySpec(password.toCharArray());\n\n\t\t// 实例化\n\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成密钥\n\t\tSecretKey secretKey = keyFactory.generateSecret(keySpec);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.ENCRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.DECRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n}\n```\n\n# IDEACoder\n```java\n\n/**\n * IDEA安全编码组件\n *\n */\npublic abstract class IDEACoder {\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"IDEA\";\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tpublic static final String CIPHER_ALGORITHM = \"IDEA/ECB/PKCS5Padding\";\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate static Key toKey(byte[] key) throws Exception {\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为解密模式\n\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为加密模式\n\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化\n\t\tKeyGenerator kg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化\n\t\tkg.init(128);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n\n# DESedeCoder\n\n```java\n\n/**\n * DESede安全编码组件\n * 加密/解密算法 / 工作模式 / 填充方式\n * Java 6支持PKCS5PADDING填充方式\n * Bouncy Castle支持PKCS7Padding填充方式\n */\npublic enum DESedeCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\n\tDESedeCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\t/**\n\t * 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"DESede\";\n\n\tprivate String CIPHER_ALGORITHM = \"DESede/ECB/PKCS5Padding\";\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化DES密钥材料\n\t\tDESedeKeySpec dks = null;\n\t\ttry {\n\t\t\tdks = new DESedeKeySpec(key);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 实例化秘密密钥工厂\n\t\tSecretKeyFactory keyFactory = null;\n\t\ttry {\n\t\t\tkeyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (InvalidKeySpecException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为解密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (IllegalStateException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为加密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * DESede 要求密钥长度为 112位或168位\n\t\t */\n\t\tkg.init(168);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n\n# DESCoder\n\n```java\n\n/**\n * DES安全编码组件\n * 密钥算法 <br>\n * Java 6 只支持56bit密钥 <br>\n * Bouncy Castle 支持64bit密钥\n */\npublic enum DESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tDESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\tprivate final String KEY_ALGORITHM = \"DES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\t// 实例化DES密钥材料\n\t\t\tDESKeySpec dks = new DESKeySpec(key);\n\t\t\t// 实例化秘密密钥工厂\n\t\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t\t// 生成秘密密钥\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"toKey : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"decrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * 加密数据在下面几种情况下,必须满足长度和倍数关系, 否则会抛出下面异常\n\t * CTS_NoPadding\tinput is too short!\n\t * CTS_PKCS5Padding\tinput is too short!\n\t * CBC_NoPadding\tInput length not multiple of 8 bytes\n\t * PCBC_NoPadding\tInput length not multiple of 8 bytes\n\t * ECB_NoPadding\tInput length not multiple of 8 bytes\n\t *\n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"encrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * Java 6 只支持56bit密钥 <br>\n\t * Bouncy Castle 支持64bit密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t/*\n\t\t * 实例化密钥生成器\n\t\t *\n\t\t * 若要使用64bit密钥注意替换 将下述代码中的KeyGenerator.getInstance(CIPHER_ALGORITHM);\n\t\t * 替换为KeyGenerator.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM, \"BC\");\n\t\t} catch (NoSuchAlgorithmException | NoSuchProviderException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * 初始化密钥生成器 若要使用64bit密钥注意替换 将下述代码kg.init(56); 替换为kg.init(64);\n\t\t */\n\t\tkg.init(64, new SecureRandom());\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n\n}\n```\n\n# AESCoder\n\n```java\n\n/**\n * AES安全编码组件\n *\n */\npublic enum AESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\t;\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t * Java 6支持PKCS5Padding填充方式\n\t * Bouncy Castle支持PKCS7Padding填充方式\n\t */\n\tAESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"AES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\t/**\n\t * 转换密钥\n\t *\n\t * @param key 二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化AES密钥材料\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t *\n\t * @param data 待解密数据\n\t * @param key 密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - decrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t *\n\t * @param data 待加密数据\n\t * @param key 密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - encrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t *\n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"  \" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * AES 要求密钥长度为 128位、192位或 256位\n\t\t */\n\t\tkg.init(256);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\n}\n```\n","slug":"JavaSE/Java加密 对称加密","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihov0022vjs6sp0sxpu3"},{"date":"2014-11-11T16:00:00.000Z","title":"Java加密 -- 数字证书","_content":"# 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n# 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n\n当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n\n当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n\n# 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n## 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n## PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库. 数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统. 若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统. 为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API. PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n\n\n# RSACoder\n```java\n\n/**\n * RSA安全编码组件\n * \n */\npublic abstract class RSACoder {\n\t\n\t/**\n\t * 数字签名\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withRSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 默认1024位，\n\t *  密钥长度必须是64的倍数， \n\t *  范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥对儿 Map\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ECDSACoder\n---\n```java\n\n/**\n * ECDSA安全编码组件\n * \n */\npublic enum ECDSACoder {\n\n\tNONEwithECDSA(\"NONEwithECDSA\"), \n\tRIPEMD160withECDSA(\"RIPEMD160withECDSA\"), \n\tSHA1withECDSA(\"SHA1withECDSA\"),   \n\tSHA224withECDSA(\"SHA224withECDSA\"),  \n\tSHA256withECDSA(\"SHA256withECDSA\"),\n\tSHA384withECDSA(\"SHA384withECDSA\"), \n\tSHA512withECDSA(\"SHA512withECDSA\");\n\t\n\t/**\n\t * 数字签名 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"ECDSA\";\n\n\tECDSACoder(String algo) {\n\t\tthis.SIGNATURE_ALGORITHM = algo;\n\t}\n\t\n\tprivate String SIGNATURE_ALGORITHM ;\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate final String PUBLIC_KEY = \"ECDSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate final String PRIVATE_KEY = \"ECDSAPrivateKey\";\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\tBigInteger p = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308885314476597252960362792450860609699839\");\n \n\t\tECFieldFp ecFieldFp = new ECFieldFp(p);\n\n\t\tBigInteger a = new BigInteger(\n\t\t\t\t\"7fffffffffffffffffffffff7fffffffffff8000000000007ffffffffffc\",\n\t\t\t\t16);\n \n\t\tBigInteger b = new BigInteger(\n\t\t\t\t\"6b016c3bdcf18941d0d654921475ca71a9db2fb27d1d37796185c2942c0a\",\n\t\t\t\t16);\n \n\t\tEllipticCurve ellipticCurve = new EllipticCurve(ecFieldFp, a, b);\n\n\t\tBigInteger x = new BigInteger(\n\t\t\t\t\"110282003749548856476348533541186204577905061504881242240149511594420911\");\n \n\t\tBigInteger y = new BigInteger(\n\t\t\t\t\"869078407435509378747351873793058868500210384946040694651368759217025454\");\n \n\t\tECPoint g = new ECPoint(x, y);\n\n\t\tBigInteger n = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308884807550341691627752275345424702807307\");\n\n\t\tECParameterSpec ecParameterSpec = new ECParameterSpec(ellipticCurve, g,\n\t\t\t\tn, 1);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(ecParameterSpec, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keypair = kpg.generateKeyPair();\n\n\t\tECPublicKey publicKey = (ECPublicKey) keypair.getPublic();\n\n\t\tECPrivateKey privateKey = (ECPrivateKey) keypair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n}\n```\n\n# DSACoder\n---\n```java\n/**\n * DSA安全编码组件\n * \n */\npublic abstract class DSACoder {\n\n\t/**\n\t * 数字签名密钥算法\n\t */\n\tpublic static final String ALGORITHM = \"DSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withDSA\";\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DSAPrivateKey\";\n\t\n\t/**\n\t * DSA密钥长度 \n\t * 默认1024位， \n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至1024位之间（含）\n\t */\n\tprivate static final int KEY_SIZE = 1024;\n\t\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 还原私钥\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成私钥对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 还原公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 取公钥匙对象\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例话Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return 密钥对象\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 初始化密钥对儿生成器\n\t\tKeyPairGenerator keygen = KeyPairGenerator.getInstance(ALGORITHM);\n\n\t\t// 实例化密钥对儿生成器\n\t\tkeygen.initialize(KEY_SIZE, new SecureRandom());\n\n\t\t// 实例化密钥对儿\n\t\tKeyPair keys = keygen.genKeyPair();\n\n\t\tDSAPublicKey publicKey = (DSAPublicKey) keys.getPublic();\n\n\t\tDSAPrivateKey privateKey = (DSAPrivateKey) keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","source":"_posts/JavaSE/Java加密 数字证书实现.md","raw":"category: JavaSE\ndate: 2014-11-12\ntitle: Java加密 -- 数字证书 \n---\n# 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n# 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n\n当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n\n当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n\n# 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n## 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n## PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库. 数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统. 若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统. 为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API. PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n\n\n# RSACoder\n```java\n\n/**\n * RSA安全编码组件\n * \n */\npublic abstract class RSACoder {\n\t\n\t/**\n\t * 数字签名\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withRSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 默认1024位，\n\t *  密钥长度必须是64的倍数， \n\t *  范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥对儿 Map\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ECDSACoder\n---\n```java\n\n/**\n * ECDSA安全编码组件\n * \n */\npublic enum ECDSACoder {\n\n\tNONEwithECDSA(\"NONEwithECDSA\"), \n\tRIPEMD160withECDSA(\"RIPEMD160withECDSA\"), \n\tSHA1withECDSA(\"SHA1withECDSA\"),   \n\tSHA224withECDSA(\"SHA224withECDSA\"),  \n\tSHA256withECDSA(\"SHA256withECDSA\"),\n\tSHA384withECDSA(\"SHA384withECDSA\"), \n\tSHA512withECDSA(\"SHA512withECDSA\");\n\t\n\t/**\n\t * 数字签名 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"ECDSA\";\n\n\tECDSACoder(String algo) {\n\t\tthis.SIGNATURE_ALGORITHM = algo;\n\t}\n\t\n\tprivate String SIGNATURE_ALGORITHM ;\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate final String PUBLIC_KEY = \"ECDSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate final String PRIVATE_KEY = \"ECDSAPrivateKey\";\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\tBigInteger p = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308885314476597252960362792450860609699839\");\n \n\t\tECFieldFp ecFieldFp = new ECFieldFp(p);\n\n\t\tBigInteger a = new BigInteger(\n\t\t\t\t\"7fffffffffffffffffffffff7fffffffffff8000000000007ffffffffffc\",\n\t\t\t\t16);\n \n\t\tBigInteger b = new BigInteger(\n\t\t\t\t\"6b016c3bdcf18941d0d654921475ca71a9db2fb27d1d37796185c2942c0a\",\n\t\t\t\t16);\n \n\t\tEllipticCurve ellipticCurve = new EllipticCurve(ecFieldFp, a, b);\n\n\t\tBigInteger x = new BigInteger(\n\t\t\t\t\"110282003749548856476348533541186204577905061504881242240149511594420911\");\n \n\t\tBigInteger y = new BigInteger(\n\t\t\t\t\"869078407435509378747351873793058868500210384946040694651368759217025454\");\n \n\t\tECPoint g = new ECPoint(x, y);\n\n\t\tBigInteger n = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308884807550341691627752275345424702807307\");\n\n\t\tECParameterSpec ecParameterSpec = new ECParameterSpec(ellipticCurve, g,\n\t\t\t\tn, 1);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(ecParameterSpec, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keypair = kpg.generateKeyPair();\n\n\t\tECPublicKey publicKey = (ECPublicKey) keypair.getPublic();\n\n\t\tECPrivateKey privateKey = (ECPrivateKey) keypair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n}\n```\n\n# DSACoder\n---\n```java\n/**\n * DSA安全编码组件\n * \n */\npublic abstract class DSACoder {\n\n\t/**\n\t * 数字签名密钥算法\n\t */\n\tpublic static final String ALGORITHM = \"DSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withDSA\";\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DSAPrivateKey\";\n\t\n\t/**\n\t * DSA密钥长度 \n\t * 默认1024位， \n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至1024位之间（含）\n\t */\n\tprivate static final int KEY_SIZE = 1024;\n\t\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 还原私钥\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成私钥对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 还原公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 取公钥匙对象\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例话Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return 密钥对象\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 初始化密钥对儿生成器\n\t\tKeyPairGenerator keygen = KeyPairGenerator.getInstance(ALGORITHM);\n\n\t\t// 实例化密钥对儿生成器\n\t\tkeygen.initialize(KEY_SIZE, new SecureRandom());\n\n\t\t// 实例化密钥对儿\n\t\tKeyPair keys = keygen.genKeyPair();\n\n\t\tDSAPublicKey publicKey = (DSAPublicKey) keys.getPublic();\n\n\t\tDSAPrivateKey privateKey = (DSAPrivateKey) keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","slug":"JavaSE/Java加密 数字证书实现","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihox0025vjs660iiowqy"},{"date":"2014-11-07T16:00:00.000Z","title":"Java加密 -- 概述","_content":"# Java加密\n\n## Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构). JCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包).JCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.有关JCE的实现主要在javax.crypto包(及其子包)中.\n\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包). JSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).JAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n##  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n### 安全提供者实现了两个概念的抽象:\n* 引擎:\t可以理解为操作,如加密、解密等.\n* 算法: 定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,这就意味着同一个算法可能与多个引擎的具体实现相对应.\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```java\n56(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```java\n112,168(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```java\n128(默认值),192,256\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```java\n32z至448(8的倍数,默认值128)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```java\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n* RC4\n```java\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```java\n56\nCBC\nPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```java\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```java\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```java\n40至1024(8的整数倍,默认值128)\nCBC\nPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```java\n512-1024(64的整数倍)\n```\n* RSA\n```java\n512-65536(64的整数倍)\nECB\n```\n* ECDH\n```java\n112-571\n```\n","source":"_posts/JavaSE/Java加密 概述.md","raw":"category: JavaSE\ndate: 2014-11-08\ntitle: Java加密 -- 概述\n---\n# Java加密\n\n## Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构). JCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包).JCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.有关JCE的实现主要在javax.crypto包(及其子包)中.\n\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包). JSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).JAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n##  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n### 安全提供者实现了两个概念的抽象:\n* 引擎:\t可以理解为操作,如加密、解密等.\n* 算法: 定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,这就意味着同一个算法可能与多个引擎的具体实现相对应.\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```java\n56(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```java\n112,168(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```java\n128(默认值),192,256\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```java\n32z至448(8的倍数,默认值128)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```java\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n* RC4\n```java\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```java\n56\nCBC\nPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```java\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```java\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```java\n40至1024(8的整数倍,默认值128)\nCBC\nPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```java\n512-1024(64的整数倍)\n```\n* RSA\n```java\n512-65536(64的整数倍)\nECB\n```\n* ECDH\n```java\n112-571\n```\n","slug":"JavaSE/Java加密 概述","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihoz0027vjs6ikyyaeku"},{"date":"2014-11-10T16:00:00.000Z","title":"Java加密 -- 消息摘要","_content":"\n# 消息摘要算法三大类：\n## MessageDigest 消息摘要算法\n* MD2 (1989)\n* MD4 (1990)\n* MD5 (1991)\n## SHA 安全散列算法 (基于MD4算法改进而来)\n* SHA-1 (名字简称为SHA, 长度为160)\n* SHA-2(包含SHA-224,SHA-256,SHA-384,SHA-512)\n## MAC 消息认证码算法\n* HmacMD2\t(Bouncy Castle)\n* HmacMD3\n* HmacMD4 (Bouncy Castle)\n* HmacMD5 (Sun)\n* HmacSHA1 (Sun)\n* HmacSHA224 (Bouncy Castle)\n* HmacSHA256 (Sun)\n* HmacSHA384 (Sun)\n* HmacSHA512 (Sun)\n## RipeMD(1996)\t对MD4和MD5缺陷的基础上提出的算法   (Bouncy Castle)\n* RipeMD128\n* RipeMD160\n* RipeMD256\n* RipeMD320\n## MAC+RipeMD\t(Bouncy Castle)\n* HmacRipeMD128\n* HmacRipeMD160\n## Tiger\t\n号称最快的Hash算法,专门为64位机器做了优化,其消息长度为192\n## GOST3411\t\n被列入IDO标准,由于使用了和AES算法相同的转化技术,被称为最安全的摘要算法\n## Whirlpool\t\n摘要长度为256位\n##CRC\t循环冗余校验算法\nCRC是可以根据数据产生剪短固定位数的一种散列函数 ,主要用来检测或校验数据传输/保存后出现的错误.\n\n生成的散列值在传输或储存之前计算出来并且附加到数据后面.在使用数据之前对数据的完整性做校验.\n一般来说,循环荣誉校验的值都是32位的2进制数,以8位16进制字符形式表示.它是一类重要的线性分组码.\n\n消息摘要算法和CRC算法同属散列函数,并且CRC算法很可能就是消息摘要算法的前身\n\n\n## MD系 实现选择\n* Sun：Sun提供的算法较为底层, 支持MD2和MD5俩种算法. 但缺少了缺少了相应的进制转换实现,不能讲字节数组形式的摘要信息转换为十六进制字符串\n* Bouncy Castle：提供了对MD4算法的支持. 支持多种形式的参数, 支持16进制字符串形式的摘要信息\n* Commons Codec：如果仅仅需要MD5,使用它则是一个不错的选择\n\nSHA与MD不同之处在于SHA算法的摘要更长,安全性更高. 通常作为MD5算法的继任者\n\n## MAC \n是含有密钥散列函数算法,兼容MD和SHA算法的特性,并在此基础上加入了密钥. 因为MAC算法融合了密钥散列函数(keyed-hash), 所以通常也把MAC称为HMAC\n\n\n```java\npublic enum SHACoder {\n\t\n\tINSTANCE;\n\n\tSHACoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tsha224 = MessageDigest.getInstance(\"SHA-224\");\n\t\t\tsha = MessageDigest.getInstance(\"SHA\");\n\t\t\tsha256 = MessageDigest.getInstance(\"SHA-256\");\n\t\t\tsha384 = MessageDigest.getInstance(\"SHA-384\");\n\t\t\tsha512 = MessageDigest.getInstance(\"SHA-512\");\n\t\t\t\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate MessageDigest sha224;\n\tprivate MessageDigest sha;\n\tprivate MessageDigest sha256;\n\tprivate MessageDigest sha384;\n\tprivate MessageDigest sha512;\n\t\n\t/**\n\t * SHA加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA1ByCodec(byte[] data)  {\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1(data);\n\t}\n\n\t/**\n\t * SHAHex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHAHexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1Hex(data);\n\t}\n\n\t/**\n\t * SHA256加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA256ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256(data);\n\t}\n\n\t/**\n\t * SHA256Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHA256HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256Hex(data);\n\t}\n\n\t/**\n\t * SHA384加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic byte[] encodeSHA384ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384(data);\n\t}\n\n\t/**\n\t * SHA384Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic String encodeSHA384HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384Hex(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic byte[] encodeSHA512ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic String encodeSHA512HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512Hex(data);\n\t}\n\t\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\tpublic byte[] encodeSHA224(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha224.digest(data);\n\t}\n\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t */\n\tpublic String encodeSHA224Hex(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeSHA224(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\n\t}\n\t\n\t/**\n\t * SHA-1加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha.digest(data);\n\t}\n\n\n\t/**\n\t * SHA-256加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA256(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha256.digest(data);\n\t}\n\n\t/**\n\t * SHA-384加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA384(byte[] data)  {\n\t\t\n\t\t// 执行消息摘要\n\t\treturn sha384.digest(data);\n\t}\n\n\t/**\n\t * SHA-512加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA512(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha512.digest(data);\n\t}\n}\n```\n\n# SHACoder\n```java\n/**\n * RipeMD系列消息摘要组件<br>\n * 包含RipeMD128、RipeMD160、RipeMD256和RipeMD320共4种RipeMD系列算法，<br>\n * \n */\npublic enum RipeMDCoder {\n\n\tINSTANCE;\n\t\n\tRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t// 初始化MessageDigest\n\t\ttry {\n\t\t\tripeMD160 = MessageDigest.getInstance(\"RipeMD160\");\n\t\t\tripeMD256 = MessageDigest.getInstance(\"RipeMD256\");\n\t\t\tripeMD320 = MessageDigest.getInstance(\"RipeMD320\");\n\t\t\tripeMD128 = MessageDigest.getInstance(\"RipeMD128\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate MessageDigest ripeMD128;\n\tprivate MessageDigest ripeMD160;\n\tprivate MessageDigest ripeMD256;\n\tprivate MessageDigest ripeMD320;\n\t\n\t/**\n\t * RipeMD128消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD128.digest(data);\n\t}\n\n\t/**\n\t * RipeMD128Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD128(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD160消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD160.digest(data);\n\t}\n\n\t/**\n\t * RipeMD160Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD160(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD256消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD256(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD256.digest(data);\n\t}\n\n\t/**\n\t * RipeMD256Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD256Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD256(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD320消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD320(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD320.digest(data);\n\t}\n\n\t/**\n\t * RipeMD320Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD320Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD320(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n}\n```\n# MessageDigestCoder\n```java\n\npublic enum MessageDigestCoder {\n\n\tINSTANCE;\n\t\n\tprivate MessageDigestCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tmd2 = MessageDigest.getInstance(\"MD2\");\n\t\t\tmd4 = MessageDigest.getInstance(\"MD4\");\n\t\t\tmd5 = MessageDigest.getInstance(\"MD5\");\n\t\t\ttiger = MessageDigest.getInstance(\"Tiger\");\n\t\t\tgost3411 = MessageDigest.getInstance(\"GOST3411\");\n\t\t\twhirlpool = MessageDigest.getInstance(\"Whirlpool\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate  MessageDigest md2;\n\tprivate  MessageDigest md4;\n\tprivate  MessageDigest md5;\n\tprivate  MessageDigest tiger;\n\tprivate  MessageDigest gost3411;\n\tprivate  MessageDigest whirlpool;\n\t\n\tpublic byte[] encodeMD2(byte[] input) {\n\t\treturn md2.digest(input);\n\t}\n\t\n\tpublic byte[] encodeMD4(byte[] input) {\n\t\treturn md4.digest(input);\n\t}\n\n\tpublic byte[] encodeMD5(byte[] input) {\n\t\treturn md5.digest(input);\n\t}\n\n\tpublic byte[] encodeTIGER(byte[] input) {\n\t\treturn tiger.digest(input);\n\t}\n\n\tpublic byte[] encodeGOST3411(byte[] input) {\n\t\treturn gost3411.digest(input);\n\t}\n\n\tpublic byte[] encodeWHIRLPOOL(byte[] input) {\n\t\treturn whirlpool.digest(input);\n\t}\n\n\tpublic String encodeMD2Hex(byte[] input) {\n\t\treturn Hex.toHexString(md2.digest(input));\n\t}\n\n\tpublic String encodeMD4Hex(byte[] input) {\n\t\treturn Hex.toHexString(md4.digest(input));\n\t}\n\n\tpublic String encodeMD5Hex(byte[] input) {\n\t\treturn Hex.toHexString(md5.digest(input));\n\t}\n\n\tpublic String encodeTigerHex(byte[] input) {\n\t\treturn Hex.toHexString(tiger.digest(input));\n\t}\n\n\tpublic String encodeGOST3411Hex(byte[] input) {\n\t\treturn Hex.toHexString(gost3411.digest(input));\n\t}\n\n\tpublic String encodeWhirlpoolHex(byte[] input) {\n\t\treturn Hex.toHexString(whirlpool.digest(input));\n\t}\n}\n```\n\n# MACCoder\n---\n```java\n\n/**\n * MAC消息摘要组件\n * \n */\npublic enum MACCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacMD2;\n\tprivate Mac hmacMD4;\n\tprivate Mac hmacMD5;\n\tprivate Mac hmacSHA1;\n\tprivate Mac hmacSHA224;\n\tprivate Mac hmacSHA256;\n\tprivate Mac hmacSHA384;\n\tprivate Mac hmacSHA512;\n\n\tMACCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\thmacMD2 = getMacBy(\"HmacMD2\");\n\t\thmacMD4 = getMacBy(\"HmacMD4\");\n\t\thmacMD5 = getMacBy(\"HmacMD5\");\n\t\thmacSHA1 = getMacBy(\"HmacSHA1\");\n\t\thmacSHA224 = getMacBy(\"HmacSHA224\");\n\t\thmacSHA256 = getMacBy(\"HmacSHA256\");\n\t\thmacSHA384 = getMacBy(\"HmacSHA384\");\n\t\thmacSHA512 = getMacBy(\"HmacSHA512\");\n\t}\n\n\tpublic Mac getMacBy(String ar) {\n\n\t\t// 初始化KeyGenerator\n\t\tKeyGenerator keyGenerator;\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tkeyGenerator = KeyGenerator.getInstance(ar);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 加入BouncyCastleProvider支持\n\t\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, ar);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacMD2消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD2(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD2.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD2Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD2Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD2(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD4消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD4(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD4.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD4Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD4Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD4(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacSHA224消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA224(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA224.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA224Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacSHA224Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA224(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD5加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD5(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacMD5\");\n\t\t//\n\t\t// // 实例化Mac \"SslMacMD5\"\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD5.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA1加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HMacTiger\");\n\t\t//\n\t\t// // 实例化Mac SslMacMD5\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA1.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA256加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA256(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA256\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA256.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA384加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA384(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA384\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA384.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA512加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA512(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA512\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA512.doFinal(data);\n\t}\n\n\tpublic String encodeHmacMD5Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD5(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA1Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA256Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA256(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA384Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA384(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA512Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA512(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# HmacRipeMDCoder\n```java\n\n/**\n * HmacRipeMD系列加密组件<br>\n * HmacRipeMD128、HmacRipeMD160共2种算法。<br>\n * \n */\npublic enum HmacRipeMDCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacRipeMD128;\n\tprivate Mac hmacRipeMD160;\n\n\tHmacRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\thmacRipeMD128 = getMac(\"HmacRipeMD128\");\n\t\thmacRipeMD160 = getMac(\"HmacRipeMD160\");\n\t}\n\n\t/**\n\t * 初始化HmacRipeMD128密钥\n\t * \n\t * @return byte[] 密钥\n\t * \n\t */\n\tpublic Mac getMac(String key1) {\n\n\t\t// 初始化KeyGenerator\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tKeyGenerator keyGenerator;\n\t\t\tkeyGenerator = KeyGenerator.getInstance(key1);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, key1);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacRipeMD128消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD128.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD128Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD128(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacRipeMD160消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD160.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD160Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD160(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# CRCCoder\n---\n```java\n\npublic enum CRCCoder {\n\n\tINSTANCE;\n\t\n\tprivate final CRC32 crc32 = new CRC32();\n\t\n\tpublic synchronized long encodeByCRC32(byte[] input) {\n\t\tcrc32.update(input);\n\t\t\n\t\tfinal long value = crc32.getValue();\n\t\tcrc32.reset();\n\t\t\n\t\treturn value;\n\t}\n\t\n\tpublic String encodeByCRC32Hex(byte[] input) {\n\t\tlong value = encodeByCRC32(input);\n\t\t\n\t\treturn Long.toHexString(value);\n\t}\n}\n```","source":"_posts/JavaSE/Java加密 消息摘要实现.md","raw":"category: JavaSE\ndate: 2014-11-11\ntitle: Java加密 -- 消息摘要\n---\n\n# 消息摘要算法三大类：\n## MessageDigest 消息摘要算法\n* MD2 (1989)\n* MD4 (1990)\n* MD5 (1991)\n## SHA 安全散列算法 (基于MD4算法改进而来)\n* SHA-1 (名字简称为SHA, 长度为160)\n* SHA-2(包含SHA-224,SHA-256,SHA-384,SHA-512)\n## MAC 消息认证码算法\n* HmacMD2\t(Bouncy Castle)\n* HmacMD3\n* HmacMD4 (Bouncy Castle)\n* HmacMD5 (Sun)\n* HmacSHA1 (Sun)\n* HmacSHA224 (Bouncy Castle)\n* HmacSHA256 (Sun)\n* HmacSHA384 (Sun)\n* HmacSHA512 (Sun)\n## RipeMD(1996)\t对MD4和MD5缺陷的基础上提出的算法   (Bouncy Castle)\n* RipeMD128\n* RipeMD160\n* RipeMD256\n* RipeMD320\n## MAC+RipeMD\t(Bouncy Castle)\n* HmacRipeMD128\n* HmacRipeMD160\n## Tiger\t\n号称最快的Hash算法,专门为64位机器做了优化,其消息长度为192\n## GOST3411\t\n被列入IDO标准,由于使用了和AES算法相同的转化技术,被称为最安全的摘要算法\n## Whirlpool\t\n摘要长度为256位\n##CRC\t循环冗余校验算法\nCRC是可以根据数据产生剪短固定位数的一种散列函数 ,主要用来检测或校验数据传输/保存后出现的错误.\n\n生成的散列值在传输或储存之前计算出来并且附加到数据后面.在使用数据之前对数据的完整性做校验.\n一般来说,循环荣誉校验的值都是32位的2进制数,以8位16进制字符形式表示.它是一类重要的线性分组码.\n\n消息摘要算法和CRC算法同属散列函数,并且CRC算法很可能就是消息摘要算法的前身\n\n\n## MD系 实现选择\n* Sun：Sun提供的算法较为底层, 支持MD2和MD5俩种算法. 但缺少了缺少了相应的进制转换实现,不能讲字节数组形式的摘要信息转换为十六进制字符串\n* Bouncy Castle：提供了对MD4算法的支持. 支持多种形式的参数, 支持16进制字符串形式的摘要信息\n* Commons Codec：如果仅仅需要MD5,使用它则是一个不错的选择\n\nSHA与MD不同之处在于SHA算法的摘要更长,安全性更高. 通常作为MD5算法的继任者\n\n## MAC \n是含有密钥散列函数算法,兼容MD和SHA算法的特性,并在此基础上加入了密钥. 因为MAC算法融合了密钥散列函数(keyed-hash), 所以通常也把MAC称为HMAC\n\n\n```java\npublic enum SHACoder {\n\t\n\tINSTANCE;\n\n\tSHACoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tsha224 = MessageDigest.getInstance(\"SHA-224\");\n\t\t\tsha = MessageDigest.getInstance(\"SHA\");\n\t\t\tsha256 = MessageDigest.getInstance(\"SHA-256\");\n\t\t\tsha384 = MessageDigest.getInstance(\"SHA-384\");\n\t\t\tsha512 = MessageDigest.getInstance(\"SHA-512\");\n\t\t\t\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate MessageDigest sha224;\n\tprivate MessageDigest sha;\n\tprivate MessageDigest sha256;\n\tprivate MessageDigest sha384;\n\tprivate MessageDigest sha512;\n\t\n\t/**\n\t * SHA加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA1ByCodec(byte[] data)  {\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1(data);\n\t}\n\n\t/**\n\t * SHAHex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHAHexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1Hex(data);\n\t}\n\n\t/**\n\t * SHA256加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA256ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256(data);\n\t}\n\n\t/**\n\t * SHA256Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHA256HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256Hex(data);\n\t}\n\n\t/**\n\t * SHA384加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic byte[] encodeSHA384ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384(data);\n\t}\n\n\t/**\n\t * SHA384Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic String encodeSHA384HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384Hex(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic byte[] encodeSHA512ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic String encodeSHA512HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512Hex(data);\n\t}\n\t\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\tpublic byte[] encodeSHA224(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha224.digest(data);\n\t}\n\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t */\n\tpublic String encodeSHA224Hex(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeSHA224(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\n\t}\n\t\n\t/**\n\t * SHA-1加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha.digest(data);\n\t}\n\n\n\t/**\n\t * SHA-256加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA256(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha256.digest(data);\n\t}\n\n\t/**\n\t * SHA-384加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA384(byte[] data)  {\n\t\t\n\t\t// 执行消息摘要\n\t\treturn sha384.digest(data);\n\t}\n\n\t/**\n\t * SHA-512加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA512(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha512.digest(data);\n\t}\n}\n```\n\n# SHACoder\n```java\n/**\n * RipeMD系列消息摘要组件<br>\n * 包含RipeMD128、RipeMD160、RipeMD256和RipeMD320共4种RipeMD系列算法，<br>\n * \n */\npublic enum RipeMDCoder {\n\n\tINSTANCE;\n\t\n\tRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t// 初始化MessageDigest\n\t\ttry {\n\t\t\tripeMD160 = MessageDigest.getInstance(\"RipeMD160\");\n\t\t\tripeMD256 = MessageDigest.getInstance(\"RipeMD256\");\n\t\t\tripeMD320 = MessageDigest.getInstance(\"RipeMD320\");\n\t\t\tripeMD128 = MessageDigest.getInstance(\"RipeMD128\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate MessageDigest ripeMD128;\n\tprivate MessageDigest ripeMD160;\n\tprivate MessageDigest ripeMD256;\n\tprivate MessageDigest ripeMD320;\n\t\n\t/**\n\t * RipeMD128消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD128.digest(data);\n\t}\n\n\t/**\n\t * RipeMD128Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD128(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD160消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD160.digest(data);\n\t}\n\n\t/**\n\t * RipeMD160Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD160(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD256消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD256(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD256.digest(data);\n\t}\n\n\t/**\n\t * RipeMD256Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD256Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD256(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD320消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD320(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD320.digest(data);\n\t}\n\n\t/**\n\t * RipeMD320Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD320Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD320(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n}\n```\n# MessageDigestCoder\n```java\n\npublic enum MessageDigestCoder {\n\n\tINSTANCE;\n\t\n\tprivate MessageDigestCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tmd2 = MessageDigest.getInstance(\"MD2\");\n\t\t\tmd4 = MessageDigest.getInstance(\"MD4\");\n\t\t\tmd5 = MessageDigest.getInstance(\"MD5\");\n\t\t\ttiger = MessageDigest.getInstance(\"Tiger\");\n\t\t\tgost3411 = MessageDigest.getInstance(\"GOST3411\");\n\t\t\twhirlpool = MessageDigest.getInstance(\"Whirlpool\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate  MessageDigest md2;\n\tprivate  MessageDigest md4;\n\tprivate  MessageDigest md5;\n\tprivate  MessageDigest tiger;\n\tprivate  MessageDigest gost3411;\n\tprivate  MessageDigest whirlpool;\n\t\n\tpublic byte[] encodeMD2(byte[] input) {\n\t\treturn md2.digest(input);\n\t}\n\t\n\tpublic byte[] encodeMD4(byte[] input) {\n\t\treturn md4.digest(input);\n\t}\n\n\tpublic byte[] encodeMD5(byte[] input) {\n\t\treturn md5.digest(input);\n\t}\n\n\tpublic byte[] encodeTIGER(byte[] input) {\n\t\treturn tiger.digest(input);\n\t}\n\n\tpublic byte[] encodeGOST3411(byte[] input) {\n\t\treturn gost3411.digest(input);\n\t}\n\n\tpublic byte[] encodeWHIRLPOOL(byte[] input) {\n\t\treturn whirlpool.digest(input);\n\t}\n\n\tpublic String encodeMD2Hex(byte[] input) {\n\t\treturn Hex.toHexString(md2.digest(input));\n\t}\n\n\tpublic String encodeMD4Hex(byte[] input) {\n\t\treturn Hex.toHexString(md4.digest(input));\n\t}\n\n\tpublic String encodeMD5Hex(byte[] input) {\n\t\treturn Hex.toHexString(md5.digest(input));\n\t}\n\n\tpublic String encodeTigerHex(byte[] input) {\n\t\treturn Hex.toHexString(tiger.digest(input));\n\t}\n\n\tpublic String encodeGOST3411Hex(byte[] input) {\n\t\treturn Hex.toHexString(gost3411.digest(input));\n\t}\n\n\tpublic String encodeWhirlpoolHex(byte[] input) {\n\t\treturn Hex.toHexString(whirlpool.digest(input));\n\t}\n}\n```\n\n# MACCoder\n---\n```java\n\n/**\n * MAC消息摘要组件\n * \n */\npublic enum MACCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacMD2;\n\tprivate Mac hmacMD4;\n\tprivate Mac hmacMD5;\n\tprivate Mac hmacSHA1;\n\tprivate Mac hmacSHA224;\n\tprivate Mac hmacSHA256;\n\tprivate Mac hmacSHA384;\n\tprivate Mac hmacSHA512;\n\n\tMACCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\thmacMD2 = getMacBy(\"HmacMD2\");\n\t\thmacMD4 = getMacBy(\"HmacMD4\");\n\t\thmacMD5 = getMacBy(\"HmacMD5\");\n\t\thmacSHA1 = getMacBy(\"HmacSHA1\");\n\t\thmacSHA224 = getMacBy(\"HmacSHA224\");\n\t\thmacSHA256 = getMacBy(\"HmacSHA256\");\n\t\thmacSHA384 = getMacBy(\"HmacSHA384\");\n\t\thmacSHA512 = getMacBy(\"HmacSHA512\");\n\t}\n\n\tpublic Mac getMacBy(String ar) {\n\n\t\t// 初始化KeyGenerator\n\t\tKeyGenerator keyGenerator;\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tkeyGenerator = KeyGenerator.getInstance(ar);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 加入BouncyCastleProvider支持\n\t\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, ar);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacMD2消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD2(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD2.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD2Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD2Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD2(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD4消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD4(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD4.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD4Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD4Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD4(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacSHA224消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA224(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA224.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA224Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacSHA224Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA224(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD5加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD5(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacMD5\");\n\t\t//\n\t\t// // 实例化Mac \"SslMacMD5\"\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD5.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA1加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HMacTiger\");\n\t\t//\n\t\t// // 实例化Mac SslMacMD5\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA1.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA256加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA256(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA256\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA256.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA384加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA384(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA384\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA384.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA512加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA512(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA512\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA512.doFinal(data);\n\t}\n\n\tpublic String encodeHmacMD5Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD5(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA1Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA256Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA256(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA384Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA384(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA512Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA512(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# HmacRipeMDCoder\n```java\n\n/**\n * HmacRipeMD系列加密组件<br>\n * HmacRipeMD128、HmacRipeMD160共2种算法。<br>\n * \n */\npublic enum HmacRipeMDCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacRipeMD128;\n\tprivate Mac hmacRipeMD160;\n\n\tHmacRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\thmacRipeMD128 = getMac(\"HmacRipeMD128\");\n\t\thmacRipeMD160 = getMac(\"HmacRipeMD160\");\n\t}\n\n\t/**\n\t * 初始化HmacRipeMD128密钥\n\t * \n\t * @return byte[] 密钥\n\t * \n\t */\n\tpublic Mac getMac(String key1) {\n\n\t\t// 初始化KeyGenerator\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tKeyGenerator keyGenerator;\n\t\t\tkeyGenerator = KeyGenerator.getInstance(key1);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, key1);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacRipeMD128消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD128.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD128Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD128(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacRipeMD160消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD160.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD160Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD160(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# CRCCoder\n---\n```java\n\npublic enum CRCCoder {\n\n\tINSTANCE;\n\t\n\tprivate final CRC32 crc32 = new CRC32();\n\t\n\tpublic synchronized long encodeByCRC32(byte[] input) {\n\t\tcrc32.update(input);\n\t\t\n\t\tfinal long value = crc32.getValue();\n\t\tcrc32.reset();\n\t\t\n\t\treturn value;\n\t}\n\t\n\tpublic String encodeByCRC32Hex(byte[] input) {\n\t\tlong value = encodeByCRC32(input);\n\t\t\n\t\treturn Long.toHexString(value);\n\t}\n}\n```","slug":"JavaSE/Java加密 消息摘要实现","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihp2002avjs665in9mj6"},{"date":"2014-11-12T16:00:00.000Z","title":"Java加密 -- 辅助工具","_content":"## Bouncy Castle\n在[官网](http://www.bouncycastle.org/latest_releases.html) 下载 `bcprov-jdk15on-151.jar` 和 `bcprov-ext-jdk15on-151.jar`\n\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n* 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n> 1. 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n  2. 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n* 调用方式 : 直接将`bcprov-ext-jdk15on-151.jar` 导入到项目工程文件\n\nJCE工具将其拓展包：仅包括`org.bouncycastle.jce`包. 这是对JCE框架的支持\n\n\n## Base64\n\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种形式不易被人直接识别.经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n\n###实现原理\n\n1. 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2. 将获得的字符编码转换为二进制码\n3. 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4. 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5. 将获得的4个8位二进制码转换为10进制码\n6. 将获得的十进制码转换为base64字符表中对应的字符\n\n```java\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n\n\n### 代码举例\n\n```java\npublic class TestBase64 {\n\n\tstatic final String base64 = \"base64编码!@#$%^&*()+_=-{}[];:'<>,./?|\";\n\n\t@before\n\tpublic void before () {\n\t\tSystem.out.println(base64);\n\t}\n\n\t@Test\n\tpublic void testUrlBase64() {\n\t\t// 不能编码空格\n\t\tbyte[] encode = UrlBase64.encode(base64.getBytes());\n\t\tSystem.out.println(\"UrlBase64 : \" + new String(encode));\n\n\t\tbyte[] decode = UrlBase64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t@Test\n\tpublic void testJavaBase64() {\n\t\tSystem.out.println();\n\t\tbyte[] encode = java.util.Base64.getEncoder().encode(base64.getBytes());\n\t\tSystem.out.println(\"JavaBase64 : \" + new String(encode));\n\t\tbyte[] decode = java.util.Base64.getDecoder().decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t@Test\n\tpublic void testApacheBase64() {\n\t\tString encode = org.apache.commons.codec.binary.Base64.encodeBase64String(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 : \" + encode);\n\t\tbyte[] decode = org.apache.commons.codec.binary.Base64.decodeBase64(encode.getBytes());\n\t\tAssert.assertEquals(base64, new String(decode));\n\n\t\tString url = org.apache.commons.codec.binary.Base64.encodeBase64URLSafeString(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 url : \" + url);\n\t\tbyte[] decoded = org.apache.commons.codec.binary.Base64.decodeBase64(url);\n\t\tAssert.assertEquals(base64, new String(decoded));\n\t}\n\n\n\t@Test\n\tpublic void testBouncycastleBase64() {\n\t\tbyte[] encode = org.bouncycastle.util.encoders.Base64.encode(base64.getBytes());\n\t\tSystem.out.println(\"BouncycastleBase64 : \" + new String(encode));\n\t\tbyte[] decode = org.bouncycastle.util.encoders.Base64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t// 解码由x-www-form-url-encoded格式编码的字符串\n\t@Test\n\tpublic void testSpace() {\n\t\tString base64 = \"wKOS4FsxiFvE48KGGSuSkRui9Iap1ukgl1+eVqZiGhXQYYiP8KGCV%2FRIeTEyMLsWxE%2FEx6jhuW3DPUt4JYX+cohUOqFVVaQ%2FioGZCAge3ygaCz%2Fe4q8o9XQzOEtcdXPywGZ0e5sgE787ij4dRZy2ILK2cxsVvC8yrlIPGZ3LUg8nOj8oEg5l2AnQnA3i+Sxbgqmwe1OjIXVZqPZWb+Y4SVQL8EpWlmEjXb4HjgmGTgVYzwJ64QO7HUPP1yuQHkS0PLS%2FpbPrgL5vqTF7h%2FPvMw=%3D\";\n\t\tString decoded = null;\n\t\ttry {\n\t\t\tdecoded = URLDecoder.decode(base64);\n\t\t} catch (UnsupportedEncodingException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (IllegalArgumentException e) {\n\t\t\t// 如果url包含一个%而后却没有2个16进制数字 抛出该异常\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(decoded);\n\t\tbyte[] decode = UrlBase64.decode(base64);\n\t\tSystem.out.println(new String(decode));\n\t}\n}\n\n```\n> URL使用的字符必须来自ASCII的子集(大写字母`A-Z`,小写字母`a-z`,数字`0-9`, 标点字符 `- _ . ! ~ * ' ,`) 需要注意的是`/ & ? @ # ; $ + = %` 也可以使用,但是必须转换为字节(每个字节为%后跟俩个16进制数字)(空格编码为+) 所以URL组成的内容是ASCII的子集 + 经过转换后的字节 但是URL不会自动地进行编码和解码因此我们需要URLEncoder来进行编码\n```java\n// 需要注意额是= 和 & URLEncoder会进行盲目地编码 因此在使用URLEncoder编码时避免将整个url字串都编码\nprint(\"  : \" + URLEncoder.encode(\" \", \"UTF-8\"));\nprint(\"= : \" + URLEncoder.encode(\"=\", \"UTF-8\"));\nprint(\"& : \" + URLEncoder.encode(\"&\", \"UTF-8\"));\nprint(\"* : \" + URLEncoder.encode(\"*\", \"UTF-8\"));\nprint(\"% : \" + URLEncoder.encode(\"%\", \"UTF-8\"));\nprint(\"+ : \" + URLEncoder.encode(\"+\", \"UTF-8\"));\nprint(\"/ : \" + URLEncoder.encode(\"/\", \"UTF-8\"));\nprint(\". : \" + URLEncoder.encode(\".\", \"UTF-8\"));\nprint(\": : \" + URLEncoder.encode(\":\", \"UTF-8\"));\nprint(\"~ : \" + URLEncoder.encode(\"~\", \"UTF-8\"));\nprint(\"\\\" : \" + URLEncoder.encode(\"\\\"\", \"UTF-8\"));\nprint(\"() : \" + URLEncoder.encode(\"(url)\", \"UTF-8\"));\n```\n","source":"_posts/JavaSE/Java加密 辅助工具.md","raw":"category: JavaSE\ndate: 2014-11-13\ntitle: Java加密 -- 辅助工具\n---\n## Bouncy Castle\n在[官网](http://www.bouncycastle.org/latest_releases.html) 下载 `bcprov-jdk15on-151.jar` 和 `bcprov-ext-jdk15on-151.jar`\n\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n* 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n> 1. 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n  2. 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n* 调用方式 : 直接将`bcprov-ext-jdk15on-151.jar` 导入到项目工程文件\n\nJCE工具将其拓展包：仅包括`org.bouncycastle.jce`包. 这是对JCE框架的支持\n\n\n## Base64\n\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种形式不易被人直接识别.经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n\n###实现原理\n\n1. 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2. 将获得的字符编码转换为二进制码\n3. 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4. 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5. 将获得的4个8位二进制码转换为10进制码\n6. 将获得的十进制码转换为base64字符表中对应的字符\n\n```java\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n\n\n### 代码举例\n\n```java\npublic class TestBase64 {\n\n\tstatic final String base64 = \"base64编码!@#$%^&*()+_=-{}[];:'<>,./?|\";\n\n\t@before\n\tpublic void before () {\n\t\tSystem.out.println(base64);\n\t}\n\n\t@Test\n\tpublic void testUrlBase64() {\n\t\t// 不能编码空格\n\t\tbyte[] encode = UrlBase64.encode(base64.getBytes());\n\t\tSystem.out.println(\"UrlBase64 : \" + new String(encode));\n\n\t\tbyte[] decode = UrlBase64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t@Test\n\tpublic void testJavaBase64() {\n\t\tSystem.out.println();\n\t\tbyte[] encode = java.util.Base64.getEncoder().encode(base64.getBytes());\n\t\tSystem.out.println(\"JavaBase64 : \" + new String(encode));\n\t\tbyte[] decode = java.util.Base64.getDecoder().decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t@Test\n\tpublic void testApacheBase64() {\n\t\tString encode = org.apache.commons.codec.binary.Base64.encodeBase64String(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 : \" + encode);\n\t\tbyte[] decode = org.apache.commons.codec.binary.Base64.decodeBase64(encode.getBytes());\n\t\tAssert.assertEquals(base64, new String(decode));\n\n\t\tString url = org.apache.commons.codec.binary.Base64.encodeBase64URLSafeString(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 url : \" + url);\n\t\tbyte[] decoded = org.apache.commons.codec.binary.Base64.decodeBase64(url);\n\t\tAssert.assertEquals(base64, new String(decoded));\n\t}\n\n\n\t@Test\n\tpublic void testBouncycastleBase64() {\n\t\tbyte[] encode = org.bouncycastle.util.encoders.Base64.encode(base64.getBytes());\n\t\tSystem.out.println(\"BouncycastleBase64 : \" + new String(encode));\n\t\tbyte[] decode = org.bouncycastle.util.encoders.Base64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\n\t// 解码由x-www-form-url-encoded格式编码的字符串\n\t@Test\n\tpublic void testSpace() {\n\t\tString base64 = \"wKOS4FsxiFvE48KGGSuSkRui9Iap1ukgl1+eVqZiGhXQYYiP8KGCV%2FRIeTEyMLsWxE%2FEx6jhuW3DPUt4JYX+cohUOqFVVaQ%2FioGZCAge3ygaCz%2Fe4q8o9XQzOEtcdXPywGZ0e5sgE787ij4dRZy2ILK2cxsVvC8yrlIPGZ3LUg8nOj8oEg5l2AnQnA3i+Sxbgqmwe1OjIXVZqPZWb+Y4SVQL8EpWlmEjXb4HjgmGTgVYzwJ64QO7HUPP1yuQHkS0PLS%2FpbPrgL5vqTF7h%2FPvMw=%3D\";\n\t\tString decoded = null;\n\t\ttry {\n\t\t\tdecoded = URLDecoder.decode(base64);\n\t\t} catch (UnsupportedEncodingException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (IllegalArgumentException e) {\n\t\t\t// 如果url包含一个%而后却没有2个16进制数字 抛出该异常\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(decoded);\n\t\tbyte[] decode = UrlBase64.decode(base64);\n\t\tSystem.out.println(new String(decode));\n\t}\n}\n\n```\n> URL使用的字符必须来自ASCII的子集(大写字母`A-Z`,小写字母`a-z`,数字`0-9`, 标点字符 `- _ . ! ~ * ' ,`) 需要注意的是`/ & ? @ # ; $ + = %` 也可以使用,但是必须转换为字节(每个字节为%后跟俩个16进制数字)(空格编码为+) 所以URL组成的内容是ASCII的子集 + 经过转换后的字节 但是URL不会自动地进行编码和解码因此我们需要URLEncoder来进行编码\n```java\n// 需要注意额是= 和 & URLEncoder会进行盲目地编码 因此在使用URLEncoder编码时避免将整个url字串都编码\nprint(\"  : \" + URLEncoder.encode(\" \", \"UTF-8\"));\nprint(\"= : \" + URLEncoder.encode(\"=\", \"UTF-8\"));\nprint(\"& : \" + URLEncoder.encode(\"&\", \"UTF-8\"));\nprint(\"* : \" + URLEncoder.encode(\"*\", \"UTF-8\"));\nprint(\"% : \" + URLEncoder.encode(\"%\", \"UTF-8\"));\nprint(\"+ : \" + URLEncoder.encode(\"+\", \"UTF-8\"));\nprint(\"/ : \" + URLEncoder.encode(\"/\", \"UTF-8\"));\nprint(\". : \" + URLEncoder.encode(\".\", \"UTF-8\"));\nprint(\": : \" + URLEncoder.encode(\":\", \"UTF-8\"));\nprint(\"~ : \" + URLEncoder.encode(\"~\", \"UTF-8\"));\nprint(\"\\\" : \" + URLEncoder.encode(\"\\\"\", \"UTF-8\"));\nprint(\"() : \" + URLEncoder.encode(\"(url)\", \"UTF-8\"));\n```\n","slug":"JavaSE/Java加密 辅助工具","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihp5002cvjs6xgdv93kx"},{"date":"2014-11-09T16:00:00.000Z","title":"Java加密 -- 非对称加密","_content":"# 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n# RSACoder\n\n```java\n/**\n * RSA安全编码组件\n * \n */\npublic enum RSACoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 \n\t * 默认1024位，\n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 私钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ElGamalCoder\n\n```java\n\n/**\n * ElGamal安全编码组件\n * \n */\npublic enum ElGamalCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"ElGamal\";\n\n\t/**\n\t * 密钥长度\n\t * \n\t * ElGamal算法默认密钥长度为1024 \n\t * 密钥长度范围在160位至16,384位不等。\n\t */\n\tprivate static final int KEY_SIZE = 256;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"ElGamalPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"ElGamalPrivateKey\";\n\n\t/**\n\t * 用私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 私钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 用公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 公钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化算法参数生成器\n\t\tAlgorithmParameterGenerator apg = AlgorithmParameterGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化算法参数生成器\n\t\tapg.init(KEY_SIZE);\n\n\t\t// 生成算法参数\n\t\tAlgorithmParameters params = apg.generateParameters();\n\n\t\t// 构建参数材料\n\t\tDHParameterSpec elParams = (DHParameterSpec) params.getParameterSpec(DHParameterSpec.class);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(elParams, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keys = kpg.genKeyPair();\n\n\t\t// 取得密钥\n\t\tPublicKey publicKey = keys.getPublic();\n\n\t\tPrivateKey privateKey = keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```\n\n# DHCoder\n\n```java\n\n/**\n * DH安全编码组件\n * \n */\npublic enum DHCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"DH\";\n\n\t/**\n\t * 本地密钥算法，即对称加密密钥算法，可选DES、DESede和AES算法\n\t */\n\tprivate static final String SECRET_KEY_ALGORITHM = \"AES\";\n\n\t/**\n\t * 默认密钥长度\n\t * \n\t * DH算法默认密钥长度为1024 密钥长度必须是64的倍数，其范围在512到1024位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DHPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DHPrivateKey\";\n\n\t/**\n\t * 初始化甲方密钥\n\t * \n\t * @return Map 甲方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGenerator.generateKeyPair();\n\n\t\t// 甲方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 甲方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 初始化乙方密钥\n\t * \n\t * @param key\n\t *            甲方公钥\n\t * @return Map 乙方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey(byte[] key) throws Exception {\n\n\t\t// 解析甲方公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 由甲方公钥构建乙方密钥\n\t\tDHParameterSpec dhParamSpec = ((DHPublicKey) pubKey).getParams();\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(keyFactory.getAlgorithm());\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(dhParamSpec);\n\n\t\t// 产生密钥对\n\t\tKeyPair keyPair = keyPairGenerator.genKeyPair();\n\n\t\t// 乙方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 乙方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据加密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 解密<br>\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据解密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 构建密钥\n\t * \n\t * @param publicKey\n\t *            公钥\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 本地密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getSecretKey(byte[] publicKey, byte[] privateKey)\n\t\t\tthrows Exception {\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化公钥\n\t\t// 密钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 初始化私钥\n\t\t// 密钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 产生私钥\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化\n\t\tKeyAgreement keyAgree = KeyAgreement.getInstance(keyFactory\n\t\t\t\t.getAlgorithm());\n\n\t\t// 初始化\n\t\tkeyAgree.init(priKey);\n\n\t\tkeyAgree.doPhase(pubKey, true);\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = keyAgree.generateSecret(SECRET_KEY_ALGORITHM);\n\n\t\treturn secretKey.getEncoded();\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","source":"_posts/JavaSE/Java加密 非对称加密实现.md","raw":"category: JavaSE\ndate: 2014-11-010\ntitle: Java加密 -- 非对称加密\n---\n# 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n# RSACoder\n\n```java\n/**\n * RSA安全编码组件\n * \n */\npublic enum RSACoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 \n\t * 默认1024位，\n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 私钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ElGamalCoder\n\n```java\n\n/**\n * ElGamal安全编码组件\n * \n */\npublic enum ElGamalCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"ElGamal\";\n\n\t/**\n\t * 密钥长度\n\t * \n\t * ElGamal算法默认密钥长度为1024 \n\t * 密钥长度范围在160位至16,384位不等。\n\t */\n\tprivate static final int KEY_SIZE = 256;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"ElGamalPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"ElGamalPrivateKey\";\n\n\t/**\n\t * 用私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 私钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 用公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 公钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化算法参数生成器\n\t\tAlgorithmParameterGenerator apg = AlgorithmParameterGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化算法参数生成器\n\t\tapg.init(KEY_SIZE);\n\n\t\t// 生成算法参数\n\t\tAlgorithmParameters params = apg.generateParameters();\n\n\t\t// 构建参数材料\n\t\tDHParameterSpec elParams = (DHParameterSpec) params.getParameterSpec(DHParameterSpec.class);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(elParams, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keys = kpg.genKeyPair();\n\n\t\t// 取得密钥\n\t\tPublicKey publicKey = keys.getPublic();\n\n\t\tPrivateKey privateKey = keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```\n\n# DHCoder\n\n```java\n\n/**\n * DH安全编码组件\n * \n */\npublic enum DHCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"DH\";\n\n\t/**\n\t * 本地密钥算法，即对称加密密钥算法，可选DES、DESede和AES算法\n\t */\n\tprivate static final String SECRET_KEY_ALGORITHM = \"AES\";\n\n\t/**\n\t * 默认密钥长度\n\t * \n\t * DH算法默认密钥长度为1024 密钥长度必须是64的倍数，其范围在512到1024位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DHPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DHPrivateKey\";\n\n\t/**\n\t * 初始化甲方密钥\n\t * \n\t * @return Map 甲方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGenerator.generateKeyPair();\n\n\t\t// 甲方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 甲方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 初始化乙方密钥\n\t * \n\t * @param key\n\t *            甲方公钥\n\t * @return Map 乙方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey(byte[] key) throws Exception {\n\n\t\t// 解析甲方公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 由甲方公钥构建乙方密钥\n\t\tDHParameterSpec dhParamSpec = ((DHPublicKey) pubKey).getParams();\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(keyFactory.getAlgorithm());\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(dhParamSpec);\n\n\t\t// 产生密钥对\n\t\tKeyPair keyPair = keyPairGenerator.genKeyPair();\n\n\t\t// 乙方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 乙方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据加密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 解密<br>\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据解密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 构建密钥\n\t * \n\t * @param publicKey\n\t *            公钥\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 本地密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getSecretKey(byte[] publicKey, byte[] privateKey)\n\t\t\tthrows Exception {\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化公钥\n\t\t// 密钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 初始化私钥\n\t\t// 密钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 产生私钥\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化\n\t\tKeyAgreement keyAgree = KeyAgreement.getInstance(keyFactory\n\t\t\t\t.getAlgorithm());\n\n\t\t// 初始化\n\t\tkeyAgree.init(priKey);\n\n\t\tkeyAgree.doPhase(pubKey, true);\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = keyAgree.generateSecret(SECRET_KEY_ALGORITHM);\n\n\t\treturn secretKey.getEncoded();\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","slug":"JavaSE/Java加密 非对称加密实现","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihp7002fvjs6tvjknl9d"},{"date":"2014-09-25T16:00:00.000Z","title":"java BIO服务器","_content":"一个Java阻塞服务器实现\n```java\ntry(ServerSocket server =  new ServerSocket(9090)) {\n\twhile (true) {\n\t\ttry(final Socket finalSocket = server.accept();) {\n\t\t\tRunnable runnable = () -> {\n\n\t\t\t\ttry(BufferedReader in = new BufferedReader(new InputStreamReader(finalSocket.getInputStream()));\n\t\t\t\t\tPrintWriter out = new PrintWriter(finalSocket.getOutputStream(), true);) {\n\n\t\t\t\t\tString body = null;\n\t\t\t\t\twhile ((body = in.readLine()) != null) {\n\t\t\t\t\t\tSystem.out.println(\"Server Revice： \" + body);\n\t\t\t\t\t\tout.println(\"Server -> client\");\n\t\t\t\t\t}\n\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t};\n\t\t\tnew Thread(runnable).start();\n\t\t}\n\t}\n}\n```\n\n客户端测试代码\n```java\ntry(Socket socket = new Socket(\"127.0.0.1\", 9090);\n\tBufferedReader in = new BufferedReader(new InputStreamReader(\n\t\t\tsocket.getInputStream()));\n\tPrintWriter out = new PrintWriter(socket.getOutputStream(), true);) {\n\tSystem.out.println(\"Server Revice： \" + in.readLine());\n\tout.println(\"client -> Server\");\n\n} catch (Exception e) {\n\te.printStackTrace();\n}\n\n```","source":"_posts/JavaSE/Java网络 BIO server.md","raw":"category: JavaSE\ndate: 2014-09-26\ntitle: java BIO服务器\n---\n一个Java阻塞服务器实现\n```java\ntry(ServerSocket server =  new ServerSocket(9090)) {\n\twhile (true) {\n\t\ttry(final Socket finalSocket = server.accept();) {\n\t\t\tRunnable runnable = () -> {\n\n\t\t\t\ttry(BufferedReader in = new BufferedReader(new InputStreamReader(finalSocket.getInputStream()));\n\t\t\t\t\tPrintWriter out = new PrintWriter(finalSocket.getOutputStream(), true);) {\n\n\t\t\t\t\tString body = null;\n\t\t\t\t\twhile ((body = in.readLine()) != null) {\n\t\t\t\t\t\tSystem.out.println(\"Server Revice： \" + body);\n\t\t\t\t\t\tout.println(\"Server -> client\");\n\t\t\t\t\t}\n\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t};\n\t\t\tnew Thread(runnable).start();\n\t\t}\n\t}\n}\n```\n\n客户端测试代码\n```java\ntry(Socket socket = new Socket(\"127.0.0.1\", 9090);\n\tBufferedReader in = new BufferedReader(new InputStreamReader(\n\t\t\tsocket.getInputStream()));\n\tPrintWriter out = new PrintWriter(socket.getOutputStream(), true);) {\n\tSystem.out.println(\"Server Revice： \" + in.readLine());\n\tout.println(\"client -> Server\");\n\n} catch (Exception e) {\n\te.printStackTrace();\n}\n\n```","slug":"JavaSE/Java网络 BIO server","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpa002hvjs6qg9zj9ci"},{"date":"2014-09-22T16:00:00.000Z","title":"Java IP","_content":"InetAddress是对IP的高级表示\n\nInetAddress将equals方法重写,如果俩个InetAddress对象的ip地址相同则判断这俩个对象相等.但是并不判断主机名是否相等\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nInetAddress i2 = InetAddress.getByName(\"helios.metalab.unc.edu\");\n```\n\nInetAddress将hashCode方法重写,只对ip地址进行hashCode计算.如果俩个InetAddress对象的ip地址相同则判断这俩个对象的hashCode相等\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nInetAddress i2 = InetAddress.getByName(\"helios.metalab.unc.edu\");\nAssert.assertEquals(true, i1.hashCode() == i2.hashCode());\n```\n下例中toString将主机名一起打印了出来. 但不是所有的InetAddress都含有主机名.java 1.4之后,如果没有主机名就会将其打印成空字符串,而不是像1.3之前的打印点分四段式ip地址\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nAssert.assertEquals(\"www.ibiblio.org/152.19.134.40\", i1.toString());\n```\n\n使用DNS查找主机IP地址,该方法会试图连接本地DNS服务器. 如果没有找到主机会抛出UnknownHostException异常\n```java\nInetAddress address = InetAddress.getByName(\"localhost\");\nAssert.assertEquals(\"localhost/127.0.0.1\", address.toString());\n```\n\n直接为IP地址创建一个InetAddress对象,但是它不会检查DNS服务器(不会主动查找主机名). 如果没有找到主机也不会抛出UnknownHostException异常. 只有当使用getHostName() 或者使用toString()时才会通过DNS查找主机名.如果没有找到主机名,那它会使用默认值(即点分四段或者16进制式地址)\n```java\nInetAddress address = InetAddress.getByName(\"180.149.131.98\");\nAssert.assertEquals(\"/180.149.131.98\", address.toString());\nAssert.assertEquals(\"180.149.131.98\", address.getHostName());\n```\n\n返回对应该主机名的所有地址,该方法会试图连接本地DNS服务器\n```java\nInetAddress[] address = InetAddress.getAllByName(\"www.baidu.com\");\nfor (InetAddress inetAddress : address) {\nSystem.out.println(\"testGetAllByName_ok : \" + inetAddress);\n}\n```\n\n显示当前机器的IP地址.该方法会试图连接本地DNS服务器.just-PC 为本地DSN服务器为本地域中主机返回的主机名.该地址是路由分配地址(即内网使用的路由地址)\n```java\nInetAddress address = InetAddress.getLocalHost();\nAssert.assertEquals(\"just-PC/192.168.1.101\", address.toString());\n```\n\n该方法会试图连接本地DNS服务器\n```\nInetAddress address = InetAddress.getByName(\"\");\nAssert.assertEquals(\"localhost/127.0.0.1\", address.toString());\n```\n\n该方法会试图连接本地DNS服务器, 无法找到抛出UnknownHostException异常\n```java\nInetAddress.getByName(\"asd\");\n```\n\n获取一个主机的字符串形式的主机名. 如果该主机没有主机名(没有在DNS注册)或者安全管理器(SecurityManager)确定阻止该主机名,就会返回点分四段式ip地址\n```java\nInetAddress address = InetAddress.getLocalHost();\nSystem.out.println(\"Host Name : \" + address.getHostName()); // 本地主机名取决于本地NDS在解析本地主机名时的行为\nInetAddress address1 = InetAddress.getByName(\"180.149.131.98\");\nAssert.assertEquals(\"180.149.131.98\", address1.getHostName());  // 为什么没有返回主机名？？\n```\n\n返回点分四段式ip地址\n```java\nInetAddress address = InetAddress.getLocalHost();\nAssert.assertEquals(\"192.168.1.101\", address.getHostAddress());\n```\n\n主要是用来测试地址类型是ipv4还是ipv6\n```java\nInetAddress address = InetAddress.getLocalHost();\n// 返回网络字节顺序(最高位是数组的第一个字节)的字节数组形式的ip地址\nbyte[] arr = address.getAddress();  \nif(arr.length == 4)\nSystem.out.print(\"Address Type : IPv4---\");\nelse if(arr.length == 16)\nSystem.out.print(\"Address Type : IPv6---\");\nfor (byte b : arr) {\nSystem.out.print(b);\n}\n```\n\n测试地址可达性,尝试连接远程主机的echo接口,查看是否可达. 该方法在全球Internet上并不可靠,防火墙会拦截java用于查看主机是否可大的网络协议\n```java\nInetAddress address = InetAddress.getByName(\"180.149.131.98\");\nSystem.out.println(\"is Rechable : \" + address.isReachable(5));\nSystem.out.println(address.isReachable(InetAddress., ttl, timeout));\n```\n\n测试是否是通配符地址. 通配符地址可匹配本地系统中所有地址. IPv4中通配符地址是0.0.0.0 IPv6是::\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isAnyLocalAddress();\n```\n测试是否是回路地址. 回路地址在IP层连接同一台电脑,不使用任何物理硬件. 这就绕过了可能有问题的硬件设备进行测试  地址是127.0.0.1\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isLoopbackAddress();\n```\n\n测试是否是IPv6本地连接地址(以FE80开头地址,后8个字节用以太网mac地址(本地地址)填充). 这个地址有助于实现IPv6网络自动配置 ,并且不会将包转发出本地子网\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isLinkLocalAddress();\n```\n\n测试是否是IPv6本地网站地址(以FEC0开头地址,后8个字节用以太网mac地址(本地地址)填充). 这个地址只会被路由器在网站内转发\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isSiteLocalAddress();\n```\n是否是组广播地址(IPV4:224.0.0.0-239.255.255.255) 向预定计算机进行广播\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMulticastAddress();\n```\n\n测试是否是全球广播地\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCGlobal();\n```\n组织范围内广播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCOrgLocal();\n```\n\n是否是网站内组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCSiteLocal();\n```\n子网范围内组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCLinkLocal();\n```\n本地接口组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCNodeLocal();\n```\n","source":"_posts/JavaSE/Java网络 IP.md","raw":"category: JavaSE\ndate: 2014-09-23\ntitle: Java IP\n---\nInetAddress是对IP的高级表示\n\nInetAddress将equals方法重写,如果俩个InetAddress对象的ip地址相同则判断这俩个对象相等.但是并不判断主机名是否相等\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nInetAddress i2 = InetAddress.getByName(\"helios.metalab.unc.edu\");\n```\n\nInetAddress将hashCode方法重写,只对ip地址进行hashCode计算.如果俩个InetAddress对象的ip地址相同则判断这俩个对象的hashCode相等\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nInetAddress i2 = InetAddress.getByName(\"helios.metalab.unc.edu\");\nAssert.assertEquals(true, i1.hashCode() == i2.hashCode());\n```\n下例中toString将主机名一起打印了出来. 但不是所有的InetAddress都含有主机名.java 1.4之后,如果没有主机名就会将其打印成空字符串,而不是像1.3之前的打印点分四段式ip地址\n```java\nInetAddress i1 = InetAddress.getByName(\"www.ibiblio.org\");\nAssert.assertEquals(\"www.ibiblio.org/152.19.134.40\", i1.toString());\n```\n\n使用DNS查找主机IP地址,该方法会试图连接本地DNS服务器. 如果没有找到主机会抛出UnknownHostException异常\n```java\nInetAddress address = InetAddress.getByName(\"localhost\");\nAssert.assertEquals(\"localhost/127.0.0.1\", address.toString());\n```\n\n直接为IP地址创建一个InetAddress对象,但是它不会检查DNS服务器(不会主动查找主机名). 如果没有找到主机也不会抛出UnknownHostException异常. 只有当使用getHostName() 或者使用toString()时才会通过DNS查找主机名.如果没有找到主机名,那它会使用默认值(即点分四段或者16进制式地址)\n```java\nInetAddress address = InetAddress.getByName(\"180.149.131.98\");\nAssert.assertEquals(\"/180.149.131.98\", address.toString());\nAssert.assertEquals(\"180.149.131.98\", address.getHostName());\n```\n\n返回对应该主机名的所有地址,该方法会试图连接本地DNS服务器\n```java\nInetAddress[] address = InetAddress.getAllByName(\"www.baidu.com\");\nfor (InetAddress inetAddress : address) {\nSystem.out.println(\"testGetAllByName_ok : \" + inetAddress);\n}\n```\n\n显示当前机器的IP地址.该方法会试图连接本地DNS服务器.just-PC 为本地DSN服务器为本地域中主机返回的主机名.该地址是路由分配地址(即内网使用的路由地址)\n```java\nInetAddress address = InetAddress.getLocalHost();\nAssert.assertEquals(\"just-PC/192.168.1.101\", address.toString());\n```\n\n该方法会试图连接本地DNS服务器\n```\nInetAddress address = InetAddress.getByName(\"\");\nAssert.assertEquals(\"localhost/127.0.0.1\", address.toString());\n```\n\n该方法会试图连接本地DNS服务器, 无法找到抛出UnknownHostException异常\n```java\nInetAddress.getByName(\"asd\");\n```\n\n获取一个主机的字符串形式的主机名. 如果该主机没有主机名(没有在DNS注册)或者安全管理器(SecurityManager)确定阻止该主机名,就会返回点分四段式ip地址\n```java\nInetAddress address = InetAddress.getLocalHost();\nSystem.out.println(\"Host Name : \" + address.getHostName()); // 本地主机名取决于本地NDS在解析本地主机名时的行为\nInetAddress address1 = InetAddress.getByName(\"180.149.131.98\");\nAssert.assertEquals(\"180.149.131.98\", address1.getHostName());  // 为什么没有返回主机名？？\n```\n\n返回点分四段式ip地址\n```java\nInetAddress address = InetAddress.getLocalHost();\nAssert.assertEquals(\"192.168.1.101\", address.getHostAddress());\n```\n\n主要是用来测试地址类型是ipv4还是ipv6\n```java\nInetAddress address = InetAddress.getLocalHost();\n// 返回网络字节顺序(最高位是数组的第一个字节)的字节数组形式的ip地址\nbyte[] arr = address.getAddress();  \nif(arr.length == 4)\nSystem.out.print(\"Address Type : IPv4---\");\nelse if(arr.length == 16)\nSystem.out.print(\"Address Type : IPv6---\");\nfor (byte b : arr) {\nSystem.out.print(b);\n}\n```\n\n测试地址可达性,尝试连接远程主机的echo接口,查看是否可达. 该方法在全球Internet上并不可靠,防火墙会拦截java用于查看主机是否可大的网络协议\n```java\nInetAddress address = InetAddress.getByName(\"180.149.131.98\");\nSystem.out.println(\"is Rechable : \" + address.isReachable(5));\nSystem.out.println(address.isReachable(InetAddress., ttl, timeout));\n```\n\n测试是否是通配符地址. 通配符地址可匹配本地系统中所有地址. IPv4中通配符地址是0.0.0.0 IPv6是::\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isAnyLocalAddress();\n```\n测试是否是回路地址. 回路地址在IP层连接同一台电脑,不使用任何物理硬件. 这就绕过了可能有问题的硬件设备进行测试  地址是127.0.0.1\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isLoopbackAddress();\n```\n\n测试是否是IPv6本地连接地址(以FE80开头地址,后8个字节用以太网mac地址(本地地址)填充). 这个地址有助于实现IPv6网络自动配置 ,并且不会将包转发出本地子网\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isLinkLocalAddress();\n```\n\n测试是否是IPv6本地网站地址(以FEC0开头地址,后8个字节用以太网mac地址(本地地址)填充). 这个地址只会被路由器在网站内转发\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isSiteLocalAddress();\n```\n是否是组广播地址(IPV4:224.0.0.0-239.255.255.255) 向预定计算机进行广播\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMulticastAddress();\n```\n\n测试是否是全球广播地\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCGlobal();\n```\n组织范围内广播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCOrgLocal();\n```\n\n是否是网站内组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCSiteLocal();\n```\n子网范围内组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCLinkLocal();\n```\n本地接口组播地址\n```java\nInetAddress address = InetAddress.getLocalHost();\naddress.isMCNodeLocal();\n```\n","slug":"JavaSE/Java网络 IP","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpe002kvjs62gyq7ack"},{"date":"2014-09-21T16:00:00.000Z","title":"Java Socket","_content":"\n## socket api\n\n### `Socket(String, int, InetAddress, int)`\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.它连接到前俩个参数指定的主机上,从后俩个参数指定的本地网络接口和端口进行连接.本地网络接口\n可以是物理的(如不同的以太网卡)或者虚拟的(一个多宿主主机).如果本地端口为0,会从1024-65535之间随机可用端口.之所以希望显示选择本地地址,这种情况可能出现在使用双以太网端口的路由器/防火墙上.入站连接会在一个接口接受,处理并通过另一个接口转发到本地网络.\n\n> `Socket(InetAddress, int, InetAddress, int)`作用与`Socket(String, int, InetAddress, int)`相同,只不过连接地址是通过InteAdderss进行连接\n\n### `Socket()`\n如果要要派生`Socket`子类或者实现一种特殊的socket,从而能加密事务或者理解本地代理服务器,此时就要用到这个函数.新的socket类的大部分实现要在一个`SocketImpl`对象中编写.该构造函数安装默认的`SocketImpl`(来自工厂方法或者`PlainSocketImpl`).\n\n### `Socket(String, int)`\n\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.\n\n### `Socket(InetAddress, int)`\n\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.在很少的情况下,当你向相同的主机打开很多socket时,先将主机名转换为InetAddress,然后重复使用此InetAddress是更有效的.\n\n### `connect(SocketAddress)`\n\n我们一般使用INetSocketAddress\n\n### `close()`\n对于socket敏感的程序,在垃圾回收器介入之前,系统会很快达到所能打开socket的上限.关闭一个`Socket`之后,其`InetAddress`,端口号,本地地址,本地端口号仍然可以通过`getInetAddress(),getPort(),getLocalAddress(),getLocalPort()`\n\n方法访问.不过虽然扔可以调用`getInputStream`或`getOutputStream()`,但试图从`InputStream`读取数据或者`OutputStream`写入数据抛出一个`IOException`异常.\n\n### `getInputStream()`\n\n\n返回一个输入流,可以将socket的数据读入程序\n\n### `getPort()`\n获取Socket连接(或过去连接或将要连接)远程主机的哪个端口返回一个原始的`OutputStream`,用于将应用程序的数据写入socket另一端.出于性能原因,将其缓冲也是个好主意.\n\n### `getInetAddress()`\nsocket连接哪台远程服务器,或者当连接已关闭时,告知它连接时所连接的是哪台主机\n\n### `getLocalAddress()`\n\n获取socket绑定于哪个网络接口,一般会在多宿主主机或有多个网络接口的主机使用此方法\n\n### `setTcpNoDelay(boolean)`\n设置`TCP_NODELAY`为`true`,可确保包会尽快地发送,而无论包的大小.正常情况下,小的包(1byte)在发送前会组合为大点的包.在发送另一个包之前,本地主机要等待远程系统对前一个包的响应,这称为`Nagle`算法.`Nagle`算法的问题是,如果远程系统没有尽可能快地将回应发送回本地系统,那么依赖于小数据量信息稳定传输的应用程序会变得很慢.为true关闭socket缓冲,为false再次打开socket缓冲.\n\n\n### `setSoLinger(boolean, int)`\n该设置规定了当socket关闭时如何处理尚未发送的数据报.如果socket关闭(close方法)系统仍会将剩余的数据发送出去.如果延迟时间为0,那所有未发送的数据都会被丢弃.如果延迟时间为任意正数,close方法会被堵塞指定秒数,等待数据发送和接受回应,该段时间过去后socket被关闭,将会关闭输出输入流,既不会接收到数据也不会在发送数据.\n\n### `sendUrgentData(int)`\n\n\n### `setOOBInline(boolean)`\n用于发送紧急数据\n\n### `setSoTimeout(int)`\n当socket尝试读取数据时,`read`方法会阻塞尽可能长的时间来得到足够的字节.该选项就是确保此次调用阻塞的时间不会大于某个固定的毫秒数,如果阻塞时间长于固定毫秒数就会抛出`InterruptedIoException`.尽管抛出了该异常但是socket仍然是连接的.此次read失败,但是仍然可以尝试再次读取该socket\n\n### `setSendBufferSize(int)`\n设置socket网络输出的缓冲区字节数\n\n### `setReceiveBufferSize(int)`\n设置socket网络输入的缓冲区的字节数.大多数TCP栈使用缓冲区提升网络性能,较大的缓冲区会提升快速连接(比如10M或更快)的网络性能,而较慢的拨号连接在较小的缓冲区下表现更加.一般来讲,传输大的连续的数据块(在FTP和HTTP很常见),这可以从大缓冲区收益;而大缓冲区对交互式会话如`telnet`和许多游戏则没有多大帮助.\n\n### `setKeepAlive(boolean)`\n启用`SO_KEEPALIVE`客户端会偶尔(一般俩个小时)利用一个空闲连接发送一个数据包,确保服务器没有崩溃.如果服务器没有响应,客户端会在11分钟之内持续发送此包,直到接受到服务器的回馈或者到12分钟左右直接将客户端关闭.\n\n### `setTrafficClass(int)`\n\n\n### `setReuseAddress(boolean)`\n\n设置主机地址可重用\n\n### `getReuseAddress()`\n\nsocket关闭时,可能不会立即释放本地地址,一般会等待一段时间,确保所有寻址到待端口在网络上传输的数据接受到.关闭后一般接收到的数据报不会再进行任何处理,这么做是为了当有新的进程关联到该端口的时候不会接受到莫名其妙的数据.要想使用这个设置必须将老的socket如下设置\n\n### `shutdownInput()`\n\n半关闭连接.关闭socket的输入流,实际上这并不会关闭socket,但是它会影响与之连接的流认为已经到了流的末尾.即使半关闭了连接,甚至关闭了俩次,仍需要在结束使用时关闭socket.该方法只影响输出流,他们不释放与socket关联的资源,如占用的端口.\n\n### `shutdownOutput()`\n\n\n\n### `isConnected()`\n指向远端服务器.这个方法不能告诉你socket当前是否连接到远程主机,而是告知socket是否曾经连接过主机.如果socket能够连接到远程主机,则此主机返回为`true`,即使此时socket已被关闭.要判断socket当前是否打开,需要检查`isConnected()`返回`true`,并且`isClosed()`返回`false`.\n\n### `isBound()`\n\n 指的是本地端,它告知socket是否绑定于本地系统的向外端口.\n\n### `isClosed()`\n\n 在socket已经关闭时返回`true`,未关闭时返回`false`.但是如果socket从未连接过也降返回`false`.\n\n### `isInputShutdown()`\n\n\n\n### `isOutputShutdown()`\n\n\n\n### `setPerformancePreferences(int, int, int)`\n\n\n## ServerSocket api\nsocket实现进程通信(实质上提供了进程通信的端点). 每一个socket用一个半相关描述:(协议，本地地址，本地端口). 一个完整的socket有一个本地唯一的socket号，由操作系统分配。于一个网络连接来说，套接字是平等的，并没有差别，不因为在服务器端或在客户端而产生不同级别.\n\n适用于在绑定端口前设置服务器socket选项\n```\nServerSocket socket = new ServerSocket();\n// 设置socket选项\nSocketAddress address = new InetSocketAddress(port);\nsocket.bind(address); // 绑定端口\n```\n\n在当前主机的所有网络接口或者所有IP地址的指定port上进行入站监听,如果port为0系统会随意指定一个端口\n```\nnew ServerSocket(port);\n```\n\n在当前主机的所有网络接口或者所以IP地址的该指定port上进行入站监听.如果port为0系统会随意指定一个端口,queueLenght设置入栈请求的队列长度(如果队列超过最大值,会使用系统最大值)\n\n第二个参数为backlog参数,accept()方法，该方法从队列中取出连接请求，使得队列能够及时的腾出空间，以容纳新的连接请求。 即ServerSocket构造函数中的backlog参数时，是可以serverSocket在不调用accept方法取出连接时，能接受的最大连接数\n```\nreturn new ServerSocket(port, queueLenght);\n```\n\n在当前主机的指定的IP地址的指定port上进行入站监听(适用于多IP地址系统上运行的服务器)如果port为0系统会随意指定一个端口queueLenght设置入栈请求的队列长度(如果队列超过最大值,会使用系统最大值)\n```\nnew ServerSocket(port, queueLenght, address);\n```\n\n关闭ServerSocket ：释放本地主机的绑定端口,允许其他程序继续使用释放掉的端口。终端ServerSocket接受的目前处于打开状态的所以Socket 关闭Socket .尽管在程序结束时ServerSocket会自动关闭但是尽量还是在程序中保证,当ServerSocket结束时将其手动关闭\n```\nconnect.close();\n```\n\n检查ServerSocket是否打开.当关闭后isClosed会返回true, isBound指的是是否曾经绑定过端口,但是并不指现在的状态\n\n```\nif(!connect.isClosed() && connect.isBound())\n\treturn false;\n```\n\n该选项是在accept抛出java.ioInterruptedIOException前等待入栈连接的时间,以毫秒计\n```\nsetSoTimeout(timeout)\n```\n\n指定如果仍有旧的数据在网络上传输,新的程序是否可以绑定到该端口\n```\nconnect.setReuseAddress(isSet);\n```\n\n\n这相当于调用accept()返回的socket的socket.setReceiveBufferSize(size);可以在绑定服务器socket之前或之后设置此选项 除非要设置大于64K的缓冲区大小,这时对于未绑定的ServerSocket必须在绑定他之前设置这个选项\n```java\npublic static void setRcvBuf(ServerSocket connect) {\n\tint size;\n\ttry {\n\t\tsize = connect.getReceiveBufferSize();\n\t\tif(size < 131072)\n\t\t\tconnect.setReceiveBufferSize(131072);\n\t\tconnect.bind(new InetSocketAddress(8080));\n\t} catch (final Exception e) {\n\t\te.printStackTrace();\n\t}\n\n}\n```\n","source":"_posts/JavaSE/Java网络 Socket.md","raw":"category: JavaSE\ndate: 2014-09-22\ntitle: Java Socket\n---\n\n## socket api\n\n### `Socket(String, int, InetAddress, int)`\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.它连接到前俩个参数指定的主机上,从后俩个参数指定的本地网络接口和端口进行连接.本地网络接口\n可以是物理的(如不同的以太网卡)或者虚拟的(一个多宿主主机).如果本地端口为0,会从1024-65535之间随机可用端口.之所以希望显示选择本地地址,这种情况可能出现在使用双以太网端口的路由器/防火墙上.入站连接会在一个接口接受,处理并通过另一个接口转发到本地网络.\n\n> `Socket(InetAddress, int, InetAddress, int)`作用与`Socket(String, int, InetAddress, int)`相同,只不过连接地址是通过InteAdderss进行连接\n\n### `Socket()`\n如果要要派生`Socket`子类或者实现一种特殊的socket,从而能加密事务或者理解本地代理服务器,此时就要用到这个函数.新的socket类的大部分实现要在一个`SocketImpl`对象中编写.该构造函数安装默认的`SocketImpl`(来自工厂方法或者`PlainSocketImpl`).\n\n### `Socket(String, int)`\n\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.\n\n### `Socket(InetAddress, int)`\n\n这个构造函数创建一个指向指定主机指定端口的TCP socket,并尝试连接远程socket.在很少的情况下,当你向相同的主机打开很多socket时,先将主机名转换为InetAddress,然后重复使用此InetAddress是更有效的.\n\n### `connect(SocketAddress)`\n\n我们一般使用INetSocketAddress\n\n### `close()`\n对于socket敏感的程序,在垃圾回收器介入之前,系统会很快达到所能打开socket的上限.关闭一个`Socket`之后,其`InetAddress`,端口号,本地地址,本地端口号仍然可以通过`getInetAddress(),getPort(),getLocalAddress(),getLocalPort()`\n\n方法访问.不过虽然扔可以调用`getInputStream`或`getOutputStream()`,但试图从`InputStream`读取数据或者`OutputStream`写入数据抛出一个`IOException`异常.\n\n### `getInputStream()`\n\n\n返回一个输入流,可以将socket的数据读入程序\n\n### `getPort()`\n获取Socket连接(或过去连接或将要连接)远程主机的哪个端口返回一个原始的`OutputStream`,用于将应用程序的数据写入socket另一端.出于性能原因,将其缓冲也是个好主意.\n\n### `getInetAddress()`\nsocket连接哪台远程服务器,或者当连接已关闭时,告知它连接时所连接的是哪台主机\n\n### `getLocalAddress()`\n\n获取socket绑定于哪个网络接口,一般会在多宿主主机或有多个网络接口的主机使用此方法\n\n### `setTcpNoDelay(boolean)`\n设置`TCP_NODELAY`为`true`,可确保包会尽快地发送,而无论包的大小.正常情况下,小的包(1byte)在发送前会组合为大点的包.在发送另一个包之前,本地主机要等待远程系统对前一个包的响应,这称为`Nagle`算法.`Nagle`算法的问题是,如果远程系统没有尽可能快地将回应发送回本地系统,那么依赖于小数据量信息稳定传输的应用程序会变得很慢.为true关闭socket缓冲,为false再次打开socket缓冲.\n\n\n### `setSoLinger(boolean, int)`\n该设置规定了当socket关闭时如何处理尚未发送的数据报.如果socket关闭(close方法)系统仍会将剩余的数据发送出去.如果延迟时间为0,那所有未发送的数据都会被丢弃.如果延迟时间为任意正数,close方法会被堵塞指定秒数,等待数据发送和接受回应,该段时间过去后socket被关闭,将会关闭输出输入流,既不会接收到数据也不会在发送数据.\n\n### `sendUrgentData(int)`\n\n\n### `setOOBInline(boolean)`\n用于发送紧急数据\n\n### `setSoTimeout(int)`\n当socket尝试读取数据时,`read`方法会阻塞尽可能长的时间来得到足够的字节.该选项就是确保此次调用阻塞的时间不会大于某个固定的毫秒数,如果阻塞时间长于固定毫秒数就会抛出`InterruptedIoException`.尽管抛出了该异常但是socket仍然是连接的.此次read失败,但是仍然可以尝试再次读取该socket\n\n### `setSendBufferSize(int)`\n设置socket网络输出的缓冲区字节数\n\n### `setReceiveBufferSize(int)`\n设置socket网络输入的缓冲区的字节数.大多数TCP栈使用缓冲区提升网络性能,较大的缓冲区会提升快速连接(比如10M或更快)的网络性能,而较慢的拨号连接在较小的缓冲区下表现更加.一般来讲,传输大的连续的数据块(在FTP和HTTP很常见),这可以从大缓冲区收益;而大缓冲区对交互式会话如`telnet`和许多游戏则没有多大帮助.\n\n### `setKeepAlive(boolean)`\n启用`SO_KEEPALIVE`客户端会偶尔(一般俩个小时)利用一个空闲连接发送一个数据包,确保服务器没有崩溃.如果服务器没有响应,客户端会在11分钟之内持续发送此包,直到接受到服务器的回馈或者到12分钟左右直接将客户端关闭.\n\n### `setTrafficClass(int)`\n\n\n### `setReuseAddress(boolean)`\n\n设置主机地址可重用\n\n### `getReuseAddress()`\n\nsocket关闭时,可能不会立即释放本地地址,一般会等待一段时间,确保所有寻址到待端口在网络上传输的数据接受到.关闭后一般接收到的数据报不会再进行任何处理,这么做是为了当有新的进程关联到该端口的时候不会接受到莫名其妙的数据.要想使用这个设置必须将老的socket如下设置\n\n### `shutdownInput()`\n\n半关闭连接.关闭socket的输入流,实际上这并不会关闭socket,但是它会影响与之连接的流认为已经到了流的末尾.即使半关闭了连接,甚至关闭了俩次,仍需要在结束使用时关闭socket.该方法只影响输出流,他们不释放与socket关联的资源,如占用的端口.\n\n### `shutdownOutput()`\n\n\n\n### `isConnected()`\n指向远端服务器.这个方法不能告诉你socket当前是否连接到远程主机,而是告知socket是否曾经连接过主机.如果socket能够连接到远程主机,则此主机返回为`true`,即使此时socket已被关闭.要判断socket当前是否打开,需要检查`isConnected()`返回`true`,并且`isClosed()`返回`false`.\n\n### `isBound()`\n\n 指的是本地端,它告知socket是否绑定于本地系统的向外端口.\n\n### `isClosed()`\n\n 在socket已经关闭时返回`true`,未关闭时返回`false`.但是如果socket从未连接过也降返回`false`.\n\n### `isInputShutdown()`\n\n\n\n### `isOutputShutdown()`\n\n\n\n### `setPerformancePreferences(int, int, int)`\n\n\n## ServerSocket api\nsocket实现进程通信(实质上提供了进程通信的端点). 每一个socket用一个半相关描述:(协议，本地地址，本地端口). 一个完整的socket有一个本地唯一的socket号，由操作系统分配。于一个网络连接来说，套接字是平等的，并没有差别，不因为在服务器端或在客户端而产生不同级别.\n\n适用于在绑定端口前设置服务器socket选项\n```\nServerSocket socket = new ServerSocket();\n// 设置socket选项\nSocketAddress address = new InetSocketAddress(port);\nsocket.bind(address); // 绑定端口\n```\n\n在当前主机的所有网络接口或者所有IP地址的指定port上进行入站监听,如果port为0系统会随意指定一个端口\n```\nnew ServerSocket(port);\n```\n\n在当前主机的所有网络接口或者所以IP地址的该指定port上进行入站监听.如果port为0系统会随意指定一个端口,queueLenght设置入栈请求的队列长度(如果队列超过最大值,会使用系统最大值)\n\n第二个参数为backlog参数,accept()方法，该方法从队列中取出连接请求，使得队列能够及时的腾出空间，以容纳新的连接请求。 即ServerSocket构造函数中的backlog参数时，是可以serverSocket在不调用accept方法取出连接时，能接受的最大连接数\n```\nreturn new ServerSocket(port, queueLenght);\n```\n\n在当前主机的指定的IP地址的指定port上进行入站监听(适用于多IP地址系统上运行的服务器)如果port为0系统会随意指定一个端口queueLenght设置入栈请求的队列长度(如果队列超过最大值,会使用系统最大值)\n```\nnew ServerSocket(port, queueLenght, address);\n```\n\n关闭ServerSocket ：释放本地主机的绑定端口,允许其他程序继续使用释放掉的端口。终端ServerSocket接受的目前处于打开状态的所以Socket 关闭Socket .尽管在程序结束时ServerSocket会自动关闭但是尽量还是在程序中保证,当ServerSocket结束时将其手动关闭\n```\nconnect.close();\n```\n\n检查ServerSocket是否打开.当关闭后isClosed会返回true, isBound指的是是否曾经绑定过端口,但是并不指现在的状态\n\n```\nif(!connect.isClosed() && connect.isBound())\n\treturn false;\n```\n\n该选项是在accept抛出java.ioInterruptedIOException前等待入栈连接的时间,以毫秒计\n```\nsetSoTimeout(timeout)\n```\n\n指定如果仍有旧的数据在网络上传输,新的程序是否可以绑定到该端口\n```\nconnect.setReuseAddress(isSet);\n```\n\n\n这相当于调用accept()返回的socket的socket.setReceiveBufferSize(size);可以在绑定服务器socket之前或之后设置此选项 除非要设置大于64K的缓冲区大小,这时对于未绑定的ServerSocket必须在绑定他之前设置这个选项\n```java\npublic static void setRcvBuf(ServerSocket connect) {\n\tint size;\n\ttry {\n\t\tsize = connect.getReceiveBufferSize();\n\t\tif(size < 131072)\n\t\t\tconnect.setReceiveBufferSize(131072);\n\t\tconnect.bind(new InetSocketAddress(8080));\n\t} catch (final Exception e) {\n\t\te.printStackTrace();\n\t}\n\n}\n```\n","slug":"JavaSE/Java网络 Socket","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpf002mvjs6rxnj3wzj"},{"date":"2014-09-24T16:00:00.000Z","title":"java代理","_content":"## java 代理\n通过系统属性来指出本地代理服务器地址。 采用的参数有`http.proxyHost,http.proxyPort,http.nonProxyHost`以及三个相同的ftp协议开头的代理参数。 java不支持其他任何应用层协议,但如果对所有TCP连接都使用socks代理则可以使用`socksProxyHost`和`socksProxyPort`系统属性来确定\n```java\n// 设置代理服务器的ip地址\nSystem.setProperty(\"http.proxyHost\", \"192.168.254.254\");\n// 设置代理服务器的端口\nSystem.setProperty(\"http.proxyPort\", \"9000\");\n// 设置java.oreilly.com和xml.oreilly.com主机不被代理而是直接连接\nSystem.setProperty(\"http.nonProxyHost\", \"java.oreilly.com|xml.oreilly.com\");\n\nSocketAddress add = new InetSocketAddress(\"proxy.example.com\", 80);\nProxy proxy = new Proxy(Proxy.Type.HTTP, add);\n```\n\n虚拟机都有一个为不同连接定位代理服务器的`ProxySelector` 对象. 默认的`ProxySelector`只检查各种系统属性和URL协议,决定如何连接到不同的主机.\n\n下面`LocalProxySelect`是一个自己实现的选择器\n```java\npublic void testLocalProxySelect() {\n\tProxySelector select = new LocalProxySelect();\n\t// 每个虚拟机只运行着一个ProxySelector对象.setDefault之后所以的连接都会询问这个代理\n\t// 因此不能在公共的环境下改变代理连接.  那ProxySelector要如何使用\n\tProxySelector.setDefault(select);\n}\n\npublic static class LocalProxySelect extends ProxySelector {\n\n\tprivate List<Object> failed = new ArrayList<>();\n\n\t@Override\n\tpublic List<Proxy> select(URI uri) {\n\t\t// uri 连接所需的主机\n\n\t\tList<Proxy> result = new ArrayList<>();\n\t\tif(failed.contains(uri) || \"http\".equalsIgnoreCase(uri.getScheme())) {\n\t\t\tresult.add(Proxy.NO_PROXY);\n\t\t} else {\n\t\t\t// 所有的连接都会使用proxy.example.com 进行代理\n\t\t\tSocketAddress address = new InetSocketAddress(\"proxy.example.com\", 8000);\n\t\t\tProxy proxy = new Proxy(Proxy.Type.HTTP, address);\n\t\t\tresult.add(proxy);\n\t\t}\n\t\treturn result;\n\t}\n\n\t@Override\n\tpublic void connectFailed(URI uri, SocketAddress sa, IOException ioe) {\n\t\tfailed.add(uri);\n\t}\n\n}\n```\n下面实现一个socket代理\n```java\nSocket socket = null;\ntry {\n\tSocketAddress proxyAddress = new InetSocketAddress(\"myproxy.example.com\", 1080);\n\tProxy  proxy = new Proxy(Proxy.Type.SOCKS, proxyAddress);\n\tsocket = new Socket(proxy);\n\tSocketAddress remote = new InetSocketAddress(\"login.ibiblio.org\", 25);\n\tsocket.connect(remote);\n} catch (IOException e) {\n\te.printStackTrace();\n} finally {\n\tif(socket != null)\n\t\ttry {\n\t\t\tsocket.close();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n}\n```\n","source":"_posts/JavaSE/Java网络 代理.md","raw":"category: JavaSE\ndate: 2014-09-25\ntitle: java代理\n---\n## java 代理\n通过系统属性来指出本地代理服务器地址。 采用的参数有`http.proxyHost,http.proxyPort,http.nonProxyHost`以及三个相同的ftp协议开头的代理参数。 java不支持其他任何应用层协议,但如果对所有TCP连接都使用socks代理则可以使用`socksProxyHost`和`socksProxyPort`系统属性来确定\n```java\n// 设置代理服务器的ip地址\nSystem.setProperty(\"http.proxyHost\", \"192.168.254.254\");\n// 设置代理服务器的端口\nSystem.setProperty(\"http.proxyPort\", \"9000\");\n// 设置java.oreilly.com和xml.oreilly.com主机不被代理而是直接连接\nSystem.setProperty(\"http.nonProxyHost\", \"java.oreilly.com|xml.oreilly.com\");\n\nSocketAddress add = new InetSocketAddress(\"proxy.example.com\", 80);\nProxy proxy = new Proxy(Proxy.Type.HTTP, add);\n```\n\n虚拟机都有一个为不同连接定位代理服务器的`ProxySelector` 对象. 默认的`ProxySelector`只检查各种系统属性和URL协议,决定如何连接到不同的主机.\n\n下面`LocalProxySelect`是一个自己实现的选择器\n```java\npublic void testLocalProxySelect() {\n\tProxySelector select = new LocalProxySelect();\n\t// 每个虚拟机只运行着一个ProxySelector对象.setDefault之后所以的连接都会询问这个代理\n\t// 因此不能在公共的环境下改变代理连接.  那ProxySelector要如何使用\n\tProxySelector.setDefault(select);\n}\n\npublic static class LocalProxySelect extends ProxySelector {\n\n\tprivate List<Object> failed = new ArrayList<>();\n\n\t@Override\n\tpublic List<Proxy> select(URI uri) {\n\t\t// uri 连接所需的主机\n\n\t\tList<Proxy> result = new ArrayList<>();\n\t\tif(failed.contains(uri) || \"http\".equalsIgnoreCase(uri.getScheme())) {\n\t\t\tresult.add(Proxy.NO_PROXY);\n\t\t} else {\n\t\t\t// 所有的连接都会使用proxy.example.com 进行代理\n\t\t\tSocketAddress address = new InetSocketAddress(\"proxy.example.com\", 8000);\n\t\t\tProxy proxy = new Proxy(Proxy.Type.HTTP, address);\n\t\t\tresult.add(proxy);\n\t\t}\n\t\treturn result;\n\t}\n\n\t@Override\n\tpublic void connectFailed(URI uri, SocketAddress sa, IOException ioe) {\n\t\tfailed.add(uri);\n\t}\n\n}\n```\n下面实现一个socket代理\n```java\nSocket socket = null;\ntry {\n\tSocketAddress proxyAddress = new InetSocketAddress(\"myproxy.example.com\", 1080);\n\tProxy  proxy = new Proxy(Proxy.Type.SOCKS, proxyAddress);\n\tsocket = new Socket(proxy);\n\tSocketAddress remote = new InetSocketAddress(\"login.ibiblio.org\", 25);\n\tsocket.connect(remote);\n} catch (IOException e) {\n\te.printStackTrace();\n} finally {\n\tif(socket != null)\n\t\ttry {\n\t\t\tsocket.close();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n}\n```\n","slug":"JavaSE/Java网络 代理","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihph002ovjs6eyr75yw8"},{"date":"2014-09-19T16:00:00.000Z","title":"Java网络接口","_content":"网络接口的命名\n* eth0: ethernet的简写，一般用于以太网接口。\n* wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n* ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n* lo: local的简写，一般指本地环回接口。\n\nlo:虚拟网络接口,其并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。\n假如包是由一个本地进程为另一个本地进程产生的, 它们将通过外出链的’lo’接口,然后返回进入链的’lo’接口\n\nJava网络接口相关主要用到`java.net.NetworkInterface`这个类，其表示一个本地IP地址,该类可以是一个物理接口或者绑定于同一个物理接口的虚拟接口.\n\n获取某个名的网络接口对象\n```java\nNetworkInterface net = NetworkInterface.getByName(\"eth0\");\n```\n获取一个绑定于制定ip地址的网络接口对象\n```java\nInetAddress address = InetAddress.getLocalHost();\nNetworkInterface net = NetworkInterface.getByInetAddress(address);\n```\n\n列出本机所有的网络接口  包括物理或者虚拟网络接口\n```java\nEnumeration<NetworkInterface> nets = NetworkInterface.getNetworkInterfaces();\nwhile(nets.hasMoreElements()) {\n System.out.println(\"网络接口 ： \" + nets.nextElement());\n}\n```\n\n列出本机所有绑定到该网络接口上的ip地址\n```java\nNetworkInterface net = NetworkInterface.getByName(\"eth0\");\n Enumeration<InetAddress> address = net.getInetAddresses();\n\n while(address.hasMoreElements()) {\n\t System.out.println(\"IP 地址 ： \" + address.nextElement());\n }\n```\n\n\n```java\n\nimport java.net.Inet4Address;\nimport java.net.InetAddress;\nimport java.net.NetworkInterface;\nimport java.util.Enumeration;\n\npublic class PrintNet {\n\n\n\tpublic static void main() throws Exception {\n\t\t// 获取全部的网络接口(由操作系统设置,每个硬件网卡(一个MAC)对应一个网络接口)\n\t\tEnumeration<?> nets = NetworkInterface.getNetworkInterfaces();\n\t\twhile (nets.hasMoreElements()) {\n\t\t\tNetworkInterface net = (NetworkInterface) nets.nextElement();\n\t\t\tprintNetworkInterface(net);\n\t\t\tEnumeration<?> addresses = net.getInetAddresses();  // 返回该接口中所有绑定的ip\n\t\t\tSystem.out.println(\"该接口下所有的ip:\");\n\t\t\twhile (addresses.hasMoreElements()) {\n\t\t\t\tInetAddress ip = (InetAddress) addresses.nextElement();\n                pickUpHosyAddress(ip);\n\t\t\t\tprintInetAddress(ip);\n\t\t\t}\n\t\t\tSystem.out.println();\n\t\t\tSystem.out.println();\n\t\t}\n\t}\n\n\tprivate static void printNetworkInterface(NetworkInterface net) throws Exception{\n\t\tSystem.out.println(\"网络接口的显示名称   :\" + net.getDisplayName());\n\t\tSystem.out.println(\"网络接口的名称       :\" + net.getName());\n\t\tSystem.out.println(\"idx                \t:\" + net.getIndex());\n\t\tSystem.out.println(\"最大传输单元         :\" + net.getMTU());\n\t\tSystem.out.println(\"mac地址              :\" + displayMac(net.getHardwareAddress()));\n\t\tSystem.out.println(\"是否是回送接口       :\" + net.isLoopback());\n\t\tSystem.out.println(\"是否是点对点接口     :\" + net.isPointToPoint());\n\t\tSystem.out.println(\"是否已经开启并运行   :\" + net.isUp());\n\t}\n\n\t/**\n\t * 输出ip地址\n\t * @param ip\n\t */\n\tprivate static void pickUpHosyAddress(InetAddress ip) {\n\t\tif (!ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"外网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"内网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip != null && !ip.isLoopbackAddress() && ip instanceof Inet4Address) {\n\t\t\tSystem.out.println(\"HostAddress        :\" + ip.getHostAddress());\n\t\t}\n\t}\n\n\t/**\n\t * 打印InetAddress 相关信息\n\t * @param ip\n\t * @throws Exception\n\t */\n\tprivate static void printInetAddress(InetAddress ip) throws Exception{\n\t\tSystem.out.println(\"远程主机的主机名         :\" + ip.getCanonicalHostName());\n\t\tSystem.out.println(\"主机地址                 :\" + ip.getHostAddress());\n\t\tSystem.out.println(\"远程主机的别名           :\" + ip.getHostName());\n\t\tSystem.out.println(\"mac Address             :\" + displayMac(ip.getAddress()));\n\t\tSystem.out.println(\"本机主机名               :\" + ip.getLocalHost().getHostName());\n\t\tSystem.out.println(\"回环地址 主机名          :\" + ip.getLoopbackAddress().getHostName());\n\t\t// (127.0.0.0 ~ 127.255.255.255)\n\t\tSystem.out.println(\"是否是本机的IP地址       :\" + ip.isLoopbackAddress());\n\t\t//(10.0.0.0 ~ 10.255.255.255)(172.16.0.0 ~ 172.31.255.255)(192.168.0.0 ~ 192.168.255.255)\n\t\tSystem.out.println(\"是否是地区本地地址       :\" + ip.isSiteLocalAddress());\n\t\t// 允许服务器主机接受来自任何网络接口的客户端连接\n\t\tSystem.out.println(\"是否是通配符地址         :\" + ip.isAnyLocalAddress());\n\t\t// (169.254.0.0 ~ 169.254.255.255)\n\t\tSystem.out.println(\"是否是本地连接地址       :\" + ip.isLinkLocalAddress());\n\t\t// (224.0.0.0 ~ 239.255.255.255)广播地址可以向网络中的所有计算机发送信息\n\t\tSystem.out.println(\"是否是 广播地址           :\" + ip.isMulticastAddress());\n\t\t//  除了(224.0.0.0)和第一个字节是239的IP地址都是全球范围的广播地址\n\t\tSystem.out.println(\"是否是全球范围的广播地址:\" + ip.isMCGlobal());\n\t\t// (224.0.0.0 ~ 224.0.0.255)\n\t\tSystem.out.println(\"是否是子网广播地址         :\" + ip.isMCLinkLocal());\n\t\t// 本地接口广播地址不能将广播信息发送到产生广播信息的网络接口\n\t\t// 所有的IPv4广播地址都不是本地接口广播地址。\n\t\tSystem.out.println(\"是否是本地接口广播地址      :\" + ip.isMCNodeLocal());\n\t\t// 可以向公司或企业内部的所有的计算机发送广播信息\n\t\t// IPv4的组织范围广播地址的第一个字节是239，第二个字节不小于192，第三个字节不大于195\n\t\tSystem.out.println(\"是否是组织范围的广播地址:\" + ip.isMCOrgLocal());\n\t}\n\n\tprivate static String displayMac(byte[] mac) {\n\t\tif (mac == null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tStringBuilder bufferBuilder = new StringBuilder();\n\t\tfor (int i = 0; i < mac.length; i++) {\n\t\t\tbyte b = mac[i];\n\t\t\tint intValue = 0;\n\t\t\tif (b >= 0)\n\t\t\t\tintValue = b;\n\t\t\telse\n\t\t\t\tintValue = 256 + b;\n\t\t\tbufferBuilder.append(Integer.toHexString(intValue));\n\n\t\t\tif (i != mac.length - 1)\n\t\t\t\tbufferBuilder.append(\"-\");\n\t\t}\n\t\treturn bufferBuilder.toString();\n\t}\n}\n\n```\n","source":"_posts/JavaSE/Java网络 网卡.md","raw":"category: JavaSE\ndate: 2014-09-20\ntitle: Java网络接口\n---\n网络接口的命名\n* eth0: ethernet的简写，一般用于以太网接口。\n* wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n* ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n* lo: local的简写，一般指本地环回接口。\n\nlo:虚拟网络接口,其并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。\n假如包是由一个本地进程为另一个本地进程产生的, 它们将通过外出链的’lo’接口,然后返回进入链的’lo’接口\n\nJava网络接口相关主要用到`java.net.NetworkInterface`这个类，其表示一个本地IP地址,该类可以是一个物理接口或者绑定于同一个物理接口的虚拟接口.\n\n获取某个名的网络接口对象\n```java\nNetworkInterface net = NetworkInterface.getByName(\"eth0\");\n```\n获取一个绑定于制定ip地址的网络接口对象\n```java\nInetAddress address = InetAddress.getLocalHost();\nNetworkInterface net = NetworkInterface.getByInetAddress(address);\n```\n\n列出本机所有的网络接口  包括物理或者虚拟网络接口\n```java\nEnumeration<NetworkInterface> nets = NetworkInterface.getNetworkInterfaces();\nwhile(nets.hasMoreElements()) {\n System.out.println(\"网络接口 ： \" + nets.nextElement());\n}\n```\n\n列出本机所有绑定到该网络接口上的ip地址\n```java\nNetworkInterface net = NetworkInterface.getByName(\"eth0\");\n Enumeration<InetAddress> address = net.getInetAddresses();\n\n while(address.hasMoreElements()) {\n\t System.out.println(\"IP 地址 ： \" + address.nextElement());\n }\n```\n\n\n```java\n\nimport java.net.Inet4Address;\nimport java.net.InetAddress;\nimport java.net.NetworkInterface;\nimport java.util.Enumeration;\n\npublic class PrintNet {\n\n\n\tpublic static void main() throws Exception {\n\t\t// 获取全部的网络接口(由操作系统设置,每个硬件网卡(一个MAC)对应一个网络接口)\n\t\tEnumeration<?> nets = NetworkInterface.getNetworkInterfaces();\n\t\twhile (nets.hasMoreElements()) {\n\t\t\tNetworkInterface net = (NetworkInterface) nets.nextElement();\n\t\t\tprintNetworkInterface(net);\n\t\t\tEnumeration<?> addresses = net.getInetAddresses();  // 返回该接口中所有绑定的ip\n\t\t\tSystem.out.println(\"该接口下所有的ip:\");\n\t\t\twhile (addresses.hasMoreElements()) {\n\t\t\t\tInetAddress ip = (InetAddress) addresses.nextElement();\n                pickUpHosyAddress(ip);\n\t\t\t\tprintInetAddress(ip);\n\t\t\t}\n\t\t\tSystem.out.println();\n\t\t\tSystem.out.println();\n\t\t}\n\t}\n\n\tprivate static void printNetworkInterface(NetworkInterface net) throws Exception{\n\t\tSystem.out.println(\"网络接口的显示名称   :\" + net.getDisplayName());\n\t\tSystem.out.println(\"网络接口的名称       :\" + net.getName());\n\t\tSystem.out.println(\"idx                \t:\" + net.getIndex());\n\t\tSystem.out.println(\"最大传输单元         :\" + net.getMTU());\n\t\tSystem.out.println(\"mac地址              :\" + displayMac(net.getHardwareAddress()));\n\t\tSystem.out.println(\"是否是回送接口       :\" + net.isLoopback());\n\t\tSystem.out.println(\"是否是点对点接口     :\" + net.isPointToPoint());\n\t\tSystem.out.println(\"是否已经开启并运行   :\" + net.isUp());\n\t}\n\n\t/**\n\t * 输出ip地址\n\t * @param ip\n\t */\n\tprivate static void pickUpHosyAddress(InetAddress ip) {\n\t\tif (!ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"外网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"内网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip != null && !ip.isLoopbackAddress() && ip instanceof Inet4Address) {\n\t\t\tSystem.out.println(\"HostAddress        :\" + ip.getHostAddress());\n\t\t}\n\t}\n\n\t/**\n\t * 打印InetAddress 相关信息\n\t * @param ip\n\t * @throws Exception\n\t */\n\tprivate static void printInetAddress(InetAddress ip) throws Exception{\n\t\tSystem.out.println(\"远程主机的主机名         :\" + ip.getCanonicalHostName());\n\t\tSystem.out.println(\"主机地址                 :\" + ip.getHostAddress());\n\t\tSystem.out.println(\"远程主机的别名           :\" + ip.getHostName());\n\t\tSystem.out.println(\"mac Address             :\" + displayMac(ip.getAddress()));\n\t\tSystem.out.println(\"本机主机名               :\" + ip.getLocalHost().getHostName());\n\t\tSystem.out.println(\"回环地址 主机名          :\" + ip.getLoopbackAddress().getHostName());\n\t\t// (127.0.0.0 ~ 127.255.255.255)\n\t\tSystem.out.println(\"是否是本机的IP地址       :\" + ip.isLoopbackAddress());\n\t\t//(10.0.0.0 ~ 10.255.255.255)(172.16.0.0 ~ 172.31.255.255)(192.168.0.0 ~ 192.168.255.255)\n\t\tSystem.out.println(\"是否是地区本地地址       :\" + ip.isSiteLocalAddress());\n\t\t// 允许服务器主机接受来自任何网络接口的客户端连接\n\t\tSystem.out.println(\"是否是通配符地址         :\" + ip.isAnyLocalAddress());\n\t\t// (169.254.0.0 ~ 169.254.255.255)\n\t\tSystem.out.println(\"是否是本地连接地址       :\" + ip.isLinkLocalAddress());\n\t\t// (224.0.0.0 ~ 239.255.255.255)广播地址可以向网络中的所有计算机发送信息\n\t\tSystem.out.println(\"是否是 广播地址           :\" + ip.isMulticastAddress());\n\t\t//  除了(224.0.0.0)和第一个字节是239的IP地址都是全球范围的广播地址\n\t\tSystem.out.println(\"是否是全球范围的广播地址:\" + ip.isMCGlobal());\n\t\t// (224.0.0.0 ~ 224.0.0.255)\n\t\tSystem.out.println(\"是否是子网广播地址         :\" + ip.isMCLinkLocal());\n\t\t// 本地接口广播地址不能将广播信息发送到产生广播信息的网络接口\n\t\t// 所有的IPv4广播地址都不是本地接口广播地址。\n\t\tSystem.out.println(\"是否是本地接口广播地址      :\" + ip.isMCNodeLocal());\n\t\t// 可以向公司或企业内部的所有的计算机发送广播信息\n\t\t// IPv4的组织范围广播地址的第一个字节是239，第二个字节不小于192，第三个字节不大于195\n\t\tSystem.out.println(\"是否是组织范围的广播地址:\" + ip.isMCOrgLocal());\n\t}\n\n\tprivate static String displayMac(byte[] mac) {\n\t\tif (mac == null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tStringBuilder bufferBuilder = new StringBuilder();\n\t\tfor (int i = 0; i < mac.length; i++) {\n\t\t\tbyte b = mac[i];\n\t\t\tint intValue = 0;\n\t\t\tif (b >= 0)\n\t\t\t\tintValue = b;\n\t\t\telse\n\t\t\t\tintValue = 256 + b;\n\t\t\tbufferBuilder.append(Integer.toHexString(intValue));\n\n\t\t\tif (i != mac.length - 1)\n\t\t\t\tbufferBuilder.append(\"-\");\n\t\t}\n\t\treturn bufferBuilder.toString();\n\t}\n}\n\n```\n","slug":"JavaSE/Java网络 网卡","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpl002qvjs63zbiuimx"},{"date":"2014-09-18T16:00:00.000Z","title":"java网络基础","_content":"\nJava里使用的是TCP/IP\n* 应用层协议：(例如Http协议) 该层数据由下三层协议共同制定\n* 传输层协议：(常用TCP,UDP)(ICMP Ping命令基于该协议). 该层协议用于确保数据报以发送时的顺序接受,并且不会丢包. 如果发现顺序有误,或者数据丢失,则可要求对方重新发送数据(TCP会要求这一点, 但是UDP协议只是检查数据发送顺序,以及数据是否丢失并不要求对方重传数据)\n* 网络层协议：(使用最广泛的是IP协议)\n> 网络层第一任务是对数据位或者字节进行分组,打成包(包内数据称为数据报).网络层第二任务定义了主机彼此间的寻址方式(例如IPV4用四个字节来标识一个地址).在JAVA里,IP协议是它唯一理解的网络层协议.\n\nIP数据报格式\n链路层协议：定义了网络接口(以太网接口或者环牌接口)\n\n谈一下Internet地址分类 (具体定义参考 WIKI IP地址), IP地址分为A,B,C,D,E,F类 (E,F分别作为广播地址这里不说了)\n* A类地址 第一个字节固定\n* B类地址 前俩个地址固定\n* C类地址 前三个地址固定\n这里所说的固定指的是ISP给你的时候就固定了,你只能使用固定之后几位的地址.例如给了你一个C类地址 那么你只有256个地址可以使用.\n\n后来为了节约地址,出现了CIDR  用/nn 指定前几位为固定的.例如/24 为前24位即前三个字节是固定的也就是一个c类地址.这么着就拟补了有的组织使用的IP大于c类却远远小于B类而造成的地址浪费.\n\n在这里需要特殊说明的是有一些非路由地址,例如10; 192.16或者172.16到172.31 开头的地址.这些地址用于构建组织内部网路(例如家里只有一个IP但是却有很多设备,这时就需要通过路由为这些设备分配IP地址了),或者一些大型组织使用C类地址时非常有用\n路由器会将非路由地址转换为外部地址\n\nURI\n```java\nscheme:scheme-specific-part (模式:模式特有部分)\n```\nURI模式包含 data, file, ftp, http, news, telnet, urn (还有基于JAVA的rmi, jndi 等非标准模式,也称为protocol)\n例如：`http://www.ming15.wang/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`这个例子中模式为`http`, 负责解析该URI的机构`ming15.wang` 负责将`/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`地址映射到主机资源\n\n还有的URI路径中含有? 这是URI的查询部分.后面紧跟查询参数,多个参数用&分割. 例如：`git@github.com:ming15/VertxServer.git`该URI中模式为`git` 解析结构为`github.com` 还可以在git和@之间加上用户名和密码`git://username:password@github.com:ming15/VertxServer.git`\n\nURI一般由以下组成\n* 模式\n* URI解析结构\n* 资源路径\n* 查询参数构成\n\n\n### URI分为类\n1. URL ： 指向Internet上某个位置的某个文件.用于标识Internet上的资源位置. 指定访问服务器的协议, 服务器名, 文件在次服务器上的位置`protocol://username@hostname:port/path/filename?query##fragment`协议可以看成是模式但是它不包含URN.\n2. URN ：不指向位置的资源名.  (具体的内容参考例子磁力链接)`urn:namespace:resource_name`. `namespace`:某个授权机构维护的某类资源的集合名.  `resource_name` 集合中的资源名\n\n\n这里简述一下相对URL. 举例来说`<a href=\"java.html\">` 这个超链接会继承父文档(当前文档)的协议, 主机名, 资源路径`.java.html`会替换掉,父文档里最后的文件名,还有例如`<a href=\"/demo/java.html\"> `那这个超链接会将主机名后的资源路径一起换掉 ，用该路径替换\n","source":"_posts/JavaSE/Java网络.md","raw":"category: JavaSE\ndate: 2014-09-019\ntitle: java网络基础\n---\n\nJava里使用的是TCP/IP\n* 应用层协议：(例如Http协议) 该层数据由下三层协议共同制定\n* 传输层协议：(常用TCP,UDP)(ICMP Ping命令基于该协议). 该层协议用于确保数据报以发送时的顺序接受,并且不会丢包. 如果发现顺序有误,或者数据丢失,则可要求对方重新发送数据(TCP会要求这一点, 但是UDP协议只是检查数据发送顺序,以及数据是否丢失并不要求对方重传数据)\n* 网络层协议：(使用最广泛的是IP协议)\n> 网络层第一任务是对数据位或者字节进行分组,打成包(包内数据称为数据报).网络层第二任务定义了主机彼此间的寻址方式(例如IPV4用四个字节来标识一个地址).在JAVA里,IP协议是它唯一理解的网络层协议.\n\nIP数据报格式\n链路层协议：定义了网络接口(以太网接口或者环牌接口)\n\n谈一下Internet地址分类 (具体定义参考 WIKI IP地址), IP地址分为A,B,C,D,E,F类 (E,F分别作为广播地址这里不说了)\n* A类地址 第一个字节固定\n* B类地址 前俩个地址固定\n* C类地址 前三个地址固定\n这里所说的固定指的是ISP给你的时候就固定了,你只能使用固定之后几位的地址.例如给了你一个C类地址 那么你只有256个地址可以使用.\n\n后来为了节约地址,出现了CIDR  用/nn 指定前几位为固定的.例如/24 为前24位即前三个字节是固定的也就是一个c类地址.这么着就拟补了有的组织使用的IP大于c类却远远小于B类而造成的地址浪费.\n\n在这里需要特殊说明的是有一些非路由地址,例如10; 192.16或者172.16到172.31 开头的地址.这些地址用于构建组织内部网路(例如家里只有一个IP但是却有很多设备,这时就需要通过路由为这些设备分配IP地址了),或者一些大型组织使用C类地址时非常有用\n路由器会将非路由地址转换为外部地址\n\nURI\n```java\nscheme:scheme-specific-part (模式:模式特有部分)\n```\nURI模式包含 data, file, ftp, http, news, telnet, urn (还有基于JAVA的rmi, jndi 等非标准模式,也称为protocol)\n例如：`http://www.ming15.wang/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`这个例子中模式为`http`, 负责解析该URI的机构`ming15.wang` 负责将`/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`地址映射到主机资源\n\n还有的URI路径中含有? 这是URI的查询部分.后面紧跟查询参数,多个参数用&分割. 例如：`git@github.com:ming15/VertxServer.git`该URI中模式为`git` 解析结构为`github.com` 还可以在git和@之间加上用户名和密码`git://username:password@github.com:ming15/VertxServer.git`\n\nURI一般由以下组成\n* 模式\n* URI解析结构\n* 资源路径\n* 查询参数构成\n\n\n### URI分为类\n1. URL ： 指向Internet上某个位置的某个文件.用于标识Internet上的资源位置. 指定访问服务器的协议, 服务器名, 文件在次服务器上的位置`protocol://username@hostname:port/path/filename?query##fragment`协议可以看成是模式但是它不包含URN.\n2. URN ：不指向位置的资源名.  (具体的内容参考例子磁力链接)`urn:namespace:resource_name`. `namespace`:某个授权机构维护的某类资源的集合名.  `resource_name` 集合中的资源名\n\n\n这里简述一下相对URL. 举例来说`<a href=\"java.html\">` 这个超链接会继承父文档(当前文档)的协议, 主机名, 资源路径`.java.html`会替换掉,父文档里最后的文件名,还有例如`<a href=\"/demo/java.html\"> `那这个超链接会将主机名后的资源路径一起换掉 ，用该路径替换\n","slug":"JavaSE/Java网络","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpn002svjs6zfive1rf"},{"date":"2016-03-04T16:00:00.000Z","title":"List VS Map","_content":"在日常的使用中, 使用的最多的结构就是List和Map了. 其中又以ArrayList和HashMap使用的最多. 今天特意找了一些时间来看一下他们各自的实现以及添加索引数据时的性能.\n\n首先看一下ArrayList.\n```java\ntransient Object[] elementData;\n\npublic boolean add(E e) {\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    elementData[size++] = e;\n    return true;\n}\n\npublic E get(int index) {\n    rangeCheck(index);\n\n    return elementData(index);\n}\n```\n它的内部就是一个Object类型的数组, 在添加数据时首先确保数组不会越界, 如果会产生越界则内部进行数组扩容拷贝操作.\n\n\n对于`HashMap`它的Javadoc中是如此说的:\n\n`HashMap`是hash table的一个实现。它与`HashTable`不同之处就是它是非同步的而且键值都支持null.对于put和get操作，HashMap的耗时都是固定的，不会因为Map的大小而变化。因为hash函数会将元素分配到不同的bucket里面取. HashMap的迭代操作与它的容量（bucket数量+键值对数量）成正比关系.\n\n一般情况下, load factor的默认值0.75, 这个值在空间和时间上找到较为平衡的查找性能。 如果高于这个值的话，会减少空间占用但是会增加查询的消耗(这点反应在了大多数的hashMap操作中，包括get和put操作).\n\n下来我们首先看一下它的数据成员\n```java\n// load factor 默认值\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n// hash表存储数据的数据结构, 每个Node都是一个散列桶, 每个桶里是一个链表\ntransient Node<K,V>[] table;\n\n// hash表散列桶的大小阀值, 如果超过这个值就对hash表进行拓容 (大小为: capacity * load factor)\nint threshold;\n\n// hash表使用的loadFactor\nfinal float loadFactor;\n```\n\n然后我们看一下`put()`方法的实现\n```java\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,                    boolean evict) {\n        Node<K,V>[] tab;\n        Node<K,V> p;\n        int n, i;\n        // 如果table不存在或者table大小为0, 则重新生成一个table\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        // 根据与hash值与操作找到要插入的元素所在的散列桶的位置\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            // 发现当前位置上的散列桶上没有Node则,重新生成一个Node\n            tab[i] = newNode(hash, key, value, null);\n        else {\n            // 发现当前散列桶已经有元素了\n            Node<K,V> e; K k;\n            // 判断插入key是否与找到的Node的key是否相等, 如果相等则将p赋值给e, 进行value的赋值操作\n            if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n            else if (p instanceof TreeNode)\n                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else {\n                // 插入的key与散列桶链表中的第一个元素不相符, 则遍历整个链表\n                for (int binCount = 0; ; ++binCount) {\n                    // 在连表中找不到存在的元素, 则生成一个新的Node插入进来\n                    if ((e = p.next) == null) {\n                        p.next = newNode(hash, key, value, null);\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    // 找到了与要插入的key相等的散列表的元素, 则停止继续查找\n                    if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n\n            // 在散列表里找到了相同的key的hash值, 就直接插入了, 不再需要进行下面的hash表拓容操作\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        // 占有了一个新的hash桶, 判断如果超过了Hash表散列桶的阀值,则对hash表进行拓容\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n从上面的逻辑我们可以看出,`HashMap`在插入元素的时候,首先是根据key的hash值找到散列桶的位置, 然后再根据key与散列桶中的散列表的数据进行便利查找.\n\n因此我们应该尽量的调大HashMap的容量, 尽可能的让桶的容量大于元素的个数, 同时尽可能的保证key值hash函数的正确性, 否则如果元素过多但是桶的数量太少, 会将hash 表退化到链表结构, 将O(1)的查找复杂度变成O(N). 说完HashMap的查找复杂度, 我们再来看一下HashMap的内存占有, 每当我们插入一个新的元素的时候都会生成一个`Node`对象\n```java\nstatic class Node<K,V> implements Map.Entry<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n}\n```\n","source":"_posts/JavaSE/ListVSMap.md","raw":"category: JavaSE\ndate: 2016-03-05\ntitle: List VS Map\n---\n在日常的使用中, 使用的最多的结构就是List和Map了. 其中又以ArrayList和HashMap使用的最多. 今天特意找了一些时间来看一下他们各自的实现以及添加索引数据时的性能.\n\n首先看一下ArrayList.\n```java\ntransient Object[] elementData;\n\npublic boolean add(E e) {\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    elementData[size++] = e;\n    return true;\n}\n\npublic E get(int index) {\n    rangeCheck(index);\n\n    return elementData(index);\n}\n```\n它的内部就是一个Object类型的数组, 在添加数据时首先确保数组不会越界, 如果会产生越界则内部进行数组扩容拷贝操作.\n\n\n对于`HashMap`它的Javadoc中是如此说的:\n\n`HashMap`是hash table的一个实现。它与`HashTable`不同之处就是它是非同步的而且键值都支持null.对于put和get操作，HashMap的耗时都是固定的，不会因为Map的大小而变化。因为hash函数会将元素分配到不同的bucket里面取. HashMap的迭代操作与它的容量（bucket数量+键值对数量）成正比关系.\n\n一般情况下, load factor的默认值0.75, 这个值在空间和时间上找到较为平衡的查找性能。 如果高于这个值的话，会减少空间占用但是会增加查询的消耗(这点反应在了大多数的hashMap操作中，包括get和put操作).\n\n下来我们首先看一下它的数据成员\n```java\n// load factor 默认值\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n// hash表存储数据的数据结构, 每个Node都是一个散列桶, 每个桶里是一个链表\ntransient Node<K,V>[] table;\n\n// hash表散列桶的大小阀值, 如果超过这个值就对hash表进行拓容 (大小为: capacity * load factor)\nint threshold;\n\n// hash表使用的loadFactor\nfinal float loadFactor;\n```\n\n然后我们看一下`put()`方法的实现\n```java\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,                    boolean evict) {\n        Node<K,V>[] tab;\n        Node<K,V> p;\n        int n, i;\n        // 如果table不存在或者table大小为0, 则重新生成一个table\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        // 根据与hash值与操作找到要插入的元素所在的散列桶的位置\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            // 发现当前位置上的散列桶上没有Node则,重新生成一个Node\n            tab[i] = newNode(hash, key, value, null);\n        else {\n            // 发现当前散列桶已经有元素了\n            Node<K,V> e; K k;\n            // 判断插入key是否与找到的Node的key是否相等, 如果相等则将p赋值给e, 进行value的赋值操作\n            if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n            else if (p instanceof TreeNode)\n                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else {\n                // 插入的key与散列桶链表中的第一个元素不相符, 则遍历整个链表\n                for (int binCount = 0; ; ++binCount) {\n                    // 在连表中找不到存在的元素, 则生成一个新的Node插入进来\n                    if ((e = p.next) == null) {\n                        p.next = newNode(hash, key, value, null);\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    // 找到了与要插入的key相等的散列表的元素, 则停止继续查找\n                    if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n\n            // 在散列表里找到了相同的key的hash值, 就直接插入了, 不再需要进行下面的hash表拓容操作\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        // 占有了一个新的hash桶, 判断如果超过了Hash表散列桶的阀值,则对hash表进行拓容\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n从上面的逻辑我们可以看出,`HashMap`在插入元素的时候,首先是根据key的hash值找到散列桶的位置, 然后再根据key与散列桶中的散列表的数据进行便利查找.\n\n因此我们应该尽量的调大HashMap的容量, 尽可能的让桶的容量大于元素的个数, 同时尽可能的保证key值hash函数的正确性, 否则如果元素过多但是桶的数量太少, 会将hash 表退化到链表结构, 将O(1)的查找复杂度变成O(N). 说完HashMap的查找复杂度, 我们再来看一下HashMap的内存占有, 每当我们插入一个新的元素的时候都会生成一个`Node`对象\n```java\nstatic class Node<K,V> implements Map.Entry<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n}\n```\n","slug":"JavaSE/ListVSMap","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpp002uvjs6zpba78sf"},{"date":"2015-06-07T16:00:00.000Z","title":"Java equals和hashcode","_content":"Effective Java学习总结\n\n## euqals\n如果类不具有自己的逻辑相等概念，那么就没有必要自己去覆盖`euqals()`方法. 在这种情况下,每个类的实例都和自身相等.\n\n但是如果程序里也关心逻辑上是否是相等,那么在实现`equals()`时就要考虑它的通用约定：\n* 自反性: 对于任何非null的引用值x,`x.equals(x)`必须返回true. 这一点保证的是对象的自身必须等于其自身.\n* 对称性: 对于任何非null的引用值x和y,当且仅当`y.equals(x)`返回true时,`x.equals(y)`必须返回true.\n* 传递性: 对于任何非null的引用值x，y和z,如果`y.equals(x)`返回true且`y.equals(z)`返回true,则`z.equals(x)`也必须返回true\n* 一致性: 对于任何非null的引用值x和y,只要equals的比较操作在对象中的信息没有被修改,多次调用`x.equals(y)`则一致地返回true或者返回false. 这也就是说如果俩个对象相等,那么他们就应该始终保持着相等.\n* 非空性: 对于任何非null的引用值,`x.euqals(null)`都必须返回false\n\n下面依次是违反上面几个特性的例子：\n\n违反自反性:\n```java\n@Override\npublic boolean equals(Object obj) {\n\treturn !super.equals(obj);\n}\n```\n\n违反对称性\n```java\npublic static void main(String str1[]) {\n\n\tN n1 = new N();\n\tn1.id = 123;\n\tInteger id = 123;\n\tSystem.out.println(n1.equals(id));\n\tSystem.out.println(id.equals(n1));\n}\n\nclass N{\n\n\tpublic Integer id;\n\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\tif (obj instanceof Integer) {\n\t\t\treturn obj.equals(id);\n\t\t}\n\t\treturn super.equals(obj);\n\t}\n}\n```\n\n违反传递性\n```java\n\n```\n\n\n违反一致性\n```java\npublic static void main(String str1[]) {\n\t\tN n1 = new N();\n\t\tn1.id = 123;\n\t\tN n2 = new N();\n\t\tn2.id = 123;\n\t\tSystem.out.println(n1.equals(n2));\n\t\tn2.id = 12;\n\t\tSystem.out.println(n1.equals(n2));\n\t}\n}\n\nclass N{\n\tpublic int id;\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\tif (!(obj instanceof N)) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn ((N) obj).id == id;\n\t}\n}\n```\n\n违反非空性： 这个一般我们不会犯错，因为我们一般都有下面这样的语法,当obj为null时,就会自动返回false\n```java\nif (obj instanceof N) {\n\treturn false;\n}\n```\n一般在实现equals方法时,我们要做到以下几点\n```java\nclass N{\n\n\tpublic int id;\n\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\t// 检查参数是否是这个对象的引用,当equals操作代价昂贵时,这么做会达到性能的提升\n\t\tif (obj == this) {\n\t\t\treturn true;\n\t\t}\n\n\t\t// 检查是否是正确的类型\n\t\tif (!(obj instanceof N)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// 把参数转换为正确的类型\n\t\tN target = (N)obj;\n\n\t\t// 对于该类中的每个关键域都对其进行匹配\n\t\treturn target.id == id;\n\t}\n}\n```\n对于对每个关键域进行判断的时候,除了`float`和`double`都可使用`==`进行判断\n* float采用`Float.compare()`进行判断\n* double采用`Double.compare()`进行判断\n如果是数组可以使用`Arrays.equals()`进行判断.\n\n当equals完成了上述之后,还要对其进行对称性,传递性,一致性进行单元测试.\n\n\n## hashCode\n当覆盖`equals()`时总要覆盖`hashCode()`.\n\n对于hashCode的通俗约定：\n* 在运行期,如果对象的`equals()`方法的用到的关键域没有被修改，那么多次调用对象的hashCode方法每次必须都返回同一个整数。\n* 如果俩个对象调用`equals()`方法比较是相等的,那么调用这俩个对象的`hashCode()`方法,它们返回的整数也必须相等\n* 如果俩个对象调用`equals()`方法比较是不相等的,那么调用这俩个对象的`hashCode()`方法,它们返回的整数也可能是相等的.\n\n下面给出了一个计算散列值的一个规则：\n将`equals()`方法中涉及到的每个关键域`f`进行如下计算,然后得出一个散列值c：\n* 如果域是`boolean`，则计算`f ? 1 : 0`\n* 如果域是`byte,char,short,int`，则计算`(int)f`\n* 如果域是`long`，则计算`(int)(f^(f>>32))`\n* 如果域是`float`，则计算`Float.floatToIntBits(f)`\n* 如果域是`double`，则计算`Double.doubleToLongBits(f)`,接着调用long类型的计算\n* 如果域是引用类型，则按照`equals()`递归方式,依次递归调用`hashCode()`,如果引用是个`null`,则返回0\n计算完每个关键域的散列值之后,依次进行如下计算\n```java\nint result = 17;\nresult = 31 * result + c;\n```\n","source":"_posts/JavaSE/java equals hashcode.md","raw":"category: JavaSE\ndate: 2015-06-08\ntitle: Java equals和hashcode\n---\nEffective Java学习总结\n\n## euqals\n如果类不具有自己的逻辑相等概念，那么就没有必要自己去覆盖`euqals()`方法. 在这种情况下,每个类的实例都和自身相等.\n\n但是如果程序里也关心逻辑上是否是相等,那么在实现`equals()`时就要考虑它的通用约定：\n* 自反性: 对于任何非null的引用值x,`x.equals(x)`必须返回true. 这一点保证的是对象的自身必须等于其自身.\n* 对称性: 对于任何非null的引用值x和y,当且仅当`y.equals(x)`返回true时,`x.equals(y)`必须返回true.\n* 传递性: 对于任何非null的引用值x，y和z,如果`y.equals(x)`返回true且`y.equals(z)`返回true,则`z.equals(x)`也必须返回true\n* 一致性: 对于任何非null的引用值x和y,只要equals的比较操作在对象中的信息没有被修改,多次调用`x.equals(y)`则一致地返回true或者返回false. 这也就是说如果俩个对象相等,那么他们就应该始终保持着相等.\n* 非空性: 对于任何非null的引用值,`x.euqals(null)`都必须返回false\n\n下面依次是违反上面几个特性的例子：\n\n违反自反性:\n```java\n@Override\npublic boolean equals(Object obj) {\n\treturn !super.equals(obj);\n}\n```\n\n违反对称性\n```java\npublic static void main(String str1[]) {\n\n\tN n1 = new N();\n\tn1.id = 123;\n\tInteger id = 123;\n\tSystem.out.println(n1.equals(id));\n\tSystem.out.println(id.equals(n1));\n}\n\nclass N{\n\n\tpublic Integer id;\n\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\tif (obj instanceof Integer) {\n\t\t\treturn obj.equals(id);\n\t\t}\n\t\treturn super.equals(obj);\n\t}\n}\n```\n\n违反传递性\n```java\n\n```\n\n\n违反一致性\n```java\npublic static void main(String str1[]) {\n\t\tN n1 = new N();\n\t\tn1.id = 123;\n\t\tN n2 = new N();\n\t\tn2.id = 123;\n\t\tSystem.out.println(n1.equals(n2));\n\t\tn2.id = 12;\n\t\tSystem.out.println(n1.equals(n2));\n\t}\n}\n\nclass N{\n\tpublic int id;\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\tif (!(obj instanceof N)) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn ((N) obj).id == id;\n\t}\n}\n```\n\n违反非空性： 这个一般我们不会犯错，因为我们一般都有下面这样的语法,当obj为null时,就会自动返回false\n```java\nif (obj instanceof N) {\n\treturn false;\n}\n```\n一般在实现equals方法时,我们要做到以下几点\n```java\nclass N{\n\n\tpublic int id;\n\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\t// 检查参数是否是这个对象的引用,当equals操作代价昂贵时,这么做会达到性能的提升\n\t\tif (obj == this) {\n\t\t\treturn true;\n\t\t}\n\n\t\t// 检查是否是正确的类型\n\t\tif (!(obj instanceof N)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// 把参数转换为正确的类型\n\t\tN target = (N)obj;\n\n\t\t// 对于该类中的每个关键域都对其进行匹配\n\t\treturn target.id == id;\n\t}\n}\n```\n对于对每个关键域进行判断的时候,除了`float`和`double`都可使用`==`进行判断\n* float采用`Float.compare()`进行判断\n* double采用`Double.compare()`进行判断\n如果是数组可以使用`Arrays.equals()`进行判断.\n\n当equals完成了上述之后,还要对其进行对称性,传递性,一致性进行单元测试.\n\n\n## hashCode\n当覆盖`equals()`时总要覆盖`hashCode()`.\n\n对于hashCode的通俗约定：\n* 在运行期,如果对象的`equals()`方法的用到的关键域没有被修改，那么多次调用对象的hashCode方法每次必须都返回同一个整数。\n* 如果俩个对象调用`equals()`方法比较是相等的,那么调用这俩个对象的`hashCode()`方法,它们返回的整数也必须相等\n* 如果俩个对象调用`equals()`方法比较是不相等的,那么调用这俩个对象的`hashCode()`方法,它们返回的整数也可能是相等的.\n\n下面给出了一个计算散列值的一个规则：\n将`equals()`方法中涉及到的每个关键域`f`进行如下计算,然后得出一个散列值c：\n* 如果域是`boolean`，则计算`f ? 1 : 0`\n* 如果域是`byte,char,short,int`，则计算`(int)f`\n* 如果域是`long`，则计算`(int)(f^(f>>32))`\n* 如果域是`float`，则计算`Float.floatToIntBits(f)`\n* 如果域是`double`，则计算`Double.doubleToLongBits(f)`,接着调用long类型的计算\n* 如果域是引用类型，则按照`equals()`递归方式,依次递归调用`hashCode()`,如果引用是个`null`,则返回0\n计算完每个关键域的散列值之后,依次进行如下计算\n```java\nint result = 17;\nresult = 31 * result + c;\n```\n","slug":"JavaSE/java equals hashcode","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpr002wvjs6r7d1mrcg"},{"date":"2015-03-07T16:00:00.000Z","title":"JAVA钩子程序","_content":"\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```java\nnohup java HookTest &\n```\n#### 关闭程序\n```java\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\n\tpublic static void exec() {\n\t\texec();\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\n\t\tSystem.out.println(\"Main over\");\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n","source":"_posts/JavaSE/java hook.md","raw":"category: JavaSE\ndate: 2015-03-08\ntitle: JAVA钩子程序\n---\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```java\nnohup java HookTest &\n```\n#### 关闭程序\n```java\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\n\tpublic static void exec() {\n\t\texec();\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\n\t\tSystem.out.println(\"Main over\");\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n","slug":"JavaSE/java hook","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpt002yvjs66nq60aqq"},{"date":"2016-02-01T16:00:00.000Z","title":"volatile 使用","_content":"在讲`volatile`的之前,我们先看一下java的内存模型. 我们知道当我们`new`出来一个对象的时候,这个对象会被直接分配到堆上(暂不考虑栈上分配等技术). 而程序的逻辑是在方法中定义的,方法运行在线程里也就是栈上. 因此JVM会将线程里使用的数据从堆上拷贝到线程的本地存储上. 这个过程涉及了下列8个操作\n1. lock: 将堆上的变量标志为某个线程独享的状态\n2. unlock: 将堆上的变量释放出来, 以便被其他线程锁定\n3. read: 将某个变量从堆上拷贝到线程的工作内存上\n4. load: 将已经从堆上拷贝到线程的工作内存上的变量放入到变量副本中\n5. use: 将线程变量副本中的变量传递给虚拟机执行引擎. (每当虚拟机遇到一个需要使用该变量的字节码指令时,都会执行该操作)\n6. assign: 将虚拟机执行引擎返回的变量的值赋值到工作变量中\n7. store: 将工作变量值传递到堆内存中.\n8. write: 将从线程工作变量中接受到的值写入到主内存变量中\n\n当一个变量被`volatile`修饰后, 每次`load`操作都是从堆中获取值, `assign`的时候也是直接写回到堆中内存变量中, 而不是在线程本地变量中操作.\n\nvolatile变量具备俩种特性\n* 线程可见性: 某个线程修改了被`volatile`修饰的变量后,其他线程可以里面看见这个最新的值.\n* 禁止指令重排序优化\n\n\n> `volatile`最适用的场景是一个线程写,多个线程读的场景. 如果有多个线程同时写的话还是需要锁或者并发容器等等进行保护\n\n下面我们看一个指令重排序的例子\n```java\npublic class Test {\n\n\tprivate static boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\twhile (!stop) {\n\t\t\t\ti++;\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n上面的这段代码会被优化成(这种优化也被称为提升优化)\n```java\npublic class Test {\n\n\tprivate static boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\tif (!stop) {\n\t\t\t\twhile (true) {\n\t\t\t\t\ti++;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n但是如果`stop`变量被`volatile`修饰后\n```java\npublic class Test {\n\n\tprivate static volatile boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\twhile (!stop) {\n\t\t\t\ti++;\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n程序就能正确的停止运行了\n\n> Java中对于重排序是这样规定的, 只要在单线程环境中, 重排序前后代码的运行结果总是一致的, 那么这段代码的重排序就是合法的. 但是当在多线程的环境中, 重排序就会影响到程序的执行, 就像刚才我们的例子展示的那样. 例外还有一点值得说明的是, 当代码中运行时包含`native`方法时, 会打断编译器的重排序(例如`System.out.println()`或者`Threads.sleep()`)\n\n`volatile`并不能解决并发写的情况, 正如我们开头所说的`volatile`最适用的场景是一个线程写,多个线程读的场景. 例如下面的程序, 无论我是否对`counter`进行`volatile`修饰都不能解决并发异常的问题\n```java\npublic class Test {\n\n\tprivate static volatile int counter = 0;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tList<Thread> threads = new ArrayList<>();\n\t\tfor (int i = 0; i < 100000; i++) {\n\t\t\tThread thread = new Thread(() -> {\n\t\t\t\t// 并发写counter\n\t\t\t\ttry {\n\t\t\t\t\tTimeUnit.MILLISECONDS.sleep(50);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t\tcounter++;\n\t\t\t});\n\n\t\t\tthread.start();\n\t\t\tthreads.add(thread);\n\t\t}\n\n\t\tthreads.forEach(thread -> {\n\t\t\ttry {\n\t\t\t\tthread.join();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t});\n\t\tSystem.out.println(counter);\n\t}\n}\n```\n上面的程序最后的输出结果, 总是小于100000.\n\n> 还有一点需要说明的是,`volatile`修饰的数组,只能保证数组本身的内存可见性,但是对于其中的元素的修改是不会保证的.\n","source":"_posts/JavaSE/java volatile.md","raw":"category: JavaSE\ndate: 2016-02-02\ntitle: volatile 使用\n---\n在讲`volatile`的之前,我们先看一下java的内存模型. 我们知道当我们`new`出来一个对象的时候,这个对象会被直接分配到堆上(暂不考虑栈上分配等技术). 而程序的逻辑是在方法中定义的,方法运行在线程里也就是栈上. 因此JVM会将线程里使用的数据从堆上拷贝到线程的本地存储上. 这个过程涉及了下列8个操作\n1. lock: 将堆上的变量标志为某个线程独享的状态\n2. unlock: 将堆上的变量释放出来, 以便被其他线程锁定\n3. read: 将某个变量从堆上拷贝到线程的工作内存上\n4. load: 将已经从堆上拷贝到线程的工作内存上的变量放入到变量副本中\n5. use: 将线程变量副本中的变量传递给虚拟机执行引擎. (每当虚拟机遇到一个需要使用该变量的字节码指令时,都会执行该操作)\n6. assign: 将虚拟机执行引擎返回的变量的值赋值到工作变量中\n7. store: 将工作变量值传递到堆内存中.\n8. write: 将从线程工作变量中接受到的值写入到主内存变量中\n\n当一个变量被`volatile`修饰后, 每次`load`操作都是从堆中获取值, `assign`的时候也是直接写回到堆中内存变量中, 而不是在线程本地变量中操作.\n\nvolatile变量具备俩种特性\n* 线程可见性: 某个线程修改了被`volatile`修饰的变量后,其他线程可以里面看见这个最新的值.\n* 禁止指令重排序优化\n\n\n> `volatile`最适用的场景是一个线程写,多个线程读的场景. 如果有多个线程同时写的话还是需要锁或者并发容器等等进行保护\n\n下面我们看一个指令重排序的例子\n```java\npublic class Test {\n\n\tprivate static boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\twhile (!stop) {\n\t\t\t\ti++;\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n上面的这段代码会被优化成(这种优化也被称为提升优化)\n```java\npublic class Test {\n\n\tprivate static boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\tif (!stop) {\n\t\t\t\twhile (true) {\n\t\t\t\t\ti++;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n但是如果`stop`变量被`volatile`修饰后\n```java\npublic class Test {\n\n\tprivate static volatile boolean stop = false;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tThread thread = new Thread(() -> {\n\t\t\tint i = 0;\n\t\t\twhile (!stop) {\n\t\t\t\ti++;\n\t\t\t}\n\t\t});\n\t\tthread.start();\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tstop = true;\n\t}\n}\n```\n程序就能正确的停止运行了\n\n> Java中对于重排序是这样规定的, 只要在单线程环境中, 重排序前后代码的运行结果总是一致的, 那么这段代码的重排序就是合法的. 但是当在多线程的环境中, 重排序就会影响到程序的执行, 就像刚才我们的例子展示的那样. 例外还有一点值得说明的是, 当代码中运行时包含`native`方法时, 会打断编译器的重排序(例如`System.out.println()`或者`Threads.sleep()`)\n\n`volatile`并不能解决并发写的情况, 正如我们开头所说的`volatile`最适用的场景是一个线程写,多个线程读的场景. 例如下面的程序, 无论我是否对`counter`进行`volatile`修饰都不能解决并发异常的问题\n```java\npublic class Test {\n\n\tprivate static volatile int counter = 0;\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tList<Thread> threads = new ArrayList<>();\n\t\tfor (int i = 0; i < 100000; i++) {\n\t\t\tThread thread = new Thread(() -> {\n\t\t\t\t// 并发写counter\n\t\t\t\ttry {\n\t\t\t\t\tTimeUnit.MILLISECONDS.sleep(50);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t\tcounter++;\n\t\t\t});\n\n\t\t\tthread.start();\n\t\t\tthreads.add(thread);\n\t\t}\n\n\t\tthreads.forEach(thread -> {\n\t\t\ttry {\n\t\t\t\tthread.join();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t});\n\t\tSystem.out.println(counter);\n\t}\n}\n```\n上面的程序最后的输出结果, 总是小于100000.\n\n> 还有一点需要说明的是,`volatile`修饰的数组,只能保证数组本身的内存可见性,但是对于其中的元素的修改是不会保证的.\n","slug":"JavaSE/java volatile","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpx0030vjs6cre864q0"},{"date":"2016-03-19T16:00:00.000Z","title":"JAVA 初始化","_content":"最近面试的时候遇到很多人都在问java初始化的东西, 今天就写个测试程序来个JAVA初始化大揭秘.\n```java\npublic class TestInit {\n    public static void main(String[] args) {\n        new B();\n        new B();\n    }\n}\n\nclass A {\n\n    public A() {\n        System.out.println(\"A\");\n    }\n\n    {\n        System.out.println(\"A init\");\n    }\n\n    static {\n        System.out.println(\"A static init\");\n    }\n}\n\nclass B extends A {\n    public B() {\n        System.out.println(\"B\");\n    }\n\n    {\n        System.out.println(\"B init\");\n    }\n\n    static {\n        System.out.println(\"B static init\");\n    }\n}\n```\n这个程序的输出结果为\n```bash\nA static init\nB static init\nA init\nA\nB init\nB\nA init\nA\nB init\nB\n```\n\n下面我用javap命令反编译一下TestInit的class字节码\n```java\n➜  classes  javap -c TestInit\nCompiled from \"TestInit.java\"\npublic class TestInit {\n  public TestInit();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       4: return\n\n  public static void main(java.lang.String[]);\n    Code:\n       0: new           #2                  // class B\n       3: dup\n       4: invokespecial #3                  // Method B.\"<init>\":()V\n       7: pop\n       8: new           #2                  // class B\n      11: dup\n      12: invokespecial #3                  // Method B.\"<init>\":()V\n      15: pop\n      16: return\n}\n```\n然后看一下A的class字节码\n```java\n➜  classes  javap -c A\nCompiled from \"TestInit.java\"\nclass A {\n  public A();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       7: ldc           #3                  // String A init\n       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      12: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n      15: ldc           #5                  // String A\n      17: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      20: return\n\n  static {};\n    Code:\n       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       3: ldc           #6                  // String A static init\n       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n       8: return\n}\n```\n从上面代码的执行结果我们也可以看出, A的代码是先执行的`static`静态初始化的(这段代码只有在类被加载进虚拟机中时才会执行一次). 那么我们就先从它分析入手\n1. `getstatic` 访问`java/lang/System.out`这个实例熟悉\n2. `ldc` 从常量池里加载一个常亮进入操作数栈, 这里加载的是`A static init`字符串\n3. `invokevirtual` 然后调用`java/io/PrintStream.println`方法, 输出`A static init`字符串\n\n构造器的代码开始执行\n1. `aload_0` : 从局部变量表加载一个reference类型值到操作数栈, 这个变量应该是this\n2. `invokespecial` : 用于需要特殊处理的实例方法(实例初始化方法, 私有方法和父类方法). 这里是调用A的实例化方法, 也就是`{}`这中的代码\n3. `getstatic` 实例化方法访问`java/lang/System.out`属性\n4. `ldc` 实例化方法从常量池里加载一个常亮进入操作数栈, 这里加载的是`A init`字符串\n5. `invokevirtual` 实例化方法调用`java/io/PrintStream.println`方法, 输出`A init`字符串\n6. `getstatic` 构造器访问`java/lang/System.out`属性\n7. `ldc`构造器从常量池里加载一个常亮进入操作数栈, 这里加载的是`A`字符串\n8. `invokevirtual` 构造器调用`java/io/PrintStream.println`方法, 输出`A`字符串\n\n\n然后我们看一下B的claa字节码\n```java\n➜  classes  javap -c B\nCompiled from \"TestInit.java\"\nclass B extends A {\n  public B();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method A.\"<init>\":()V\n       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       7: ldc           #3                  // String B init\n       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      12: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n      15: ldc           #5                  // String B\n      17: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      20: return\n\n  static {};\n    Code:\n       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       3: ldc           #6                  // String B static init\n       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n       8: return\n}\n```\n与A类似, B同样是从类的初始化开始代码执行的\n1. `getstatic` 访问`java/lang/System.out`这个实例熟悉\n2. `ldc` 从常量池里加载一个常亮进入操作数栈, 这里加载的是`B static init`字符串\n3. `invokevirtual` 然后调用`java/io/PrintStream.println`方法, 输出`B static init`字符串\n\n然后是构造器方法执行\n1. `aload_0`同样的是加载`this`进虚拟机栈\n2. `invokespecial` 调用父类A的实例初始化方法\n3. 然后就开死像A一样, 调用自己的实例化过程\n","source":"_posts/JavaSE/java 初始化.md","raw":"category: JavaSE\ndate: 2016-03-20\ntitle: JAVA 初始化\n---\n最近面试的时候遇到很多人都在问java初始化的东西, 今天就写个测试程序来个JAVA初始化大揭秘.\n```java\npublic class TestInit {\n    public static void main(String[] args) {\n        new B();\n        new B();\n    }\n}\n\nclass A {\n\n    public A() {\n        System.out.println(\"A\");\n    }\n\n    {\n        System.out.println(\"A init\");\n    }\n\n    static {\n        System.out.println(\"A static init\");\n    }\n}\n\nclass B extends A {\n    public B() {\n        System.out.println(\"B\");\n    }\n\n    {\n        System.out.println(\"B init\");\n    }\n\n    static {\n        System.out.println(\"B static init\");\n    }\n}\n```\n这个程序的输出结果为\n```bash\nA static init\nB static init\nA init\nA\nB init\nB\nA init\nA\nB init\nB\n```\n\n下面我用javap命令反编译一下TestInit的class字节码\n```java\n➜  classes  javap -c TestInit\nCompiled from \"TestInit.java\"\npublic class TestInit {\n  public TestInit();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       4: return\n\n  public static void main(java.lang.String[]);\n    Code:\n       0: new           #2                  // class B\n       3: dup\n       4: invokespecial #3                  // Method B.\"<init>\":()V\n       7: pop\n       8: new           #2                  // class B\n      11: dup\n      12: invokespecial #3                  // Method B.\"<init>\":()V\n      15: pop\n      16: return\n}\n```\n然后看一下A的class字节码\n```java\n➜  classes  javap -c A\nCompiled from \"TestInit.java\"\nclass A {\n  public A();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       7: ldc           #3                  // String A init\n       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      12: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n      15: ldc           #5                  // String A\n      17: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      20: return\n\n  static {};\n    Code:\n       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       3: ldc           #6                  // String A static init\n       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n       8: return\n}\n```\n从上面代码的执行结果我们也可以看出, A的代码是先执行的`static`静态初始化的(这段代码只有在类被加载进虚拟机中时才会执行一次). 那么我们就先从它分析入手\n1. `getstatic` 访问`java/lang/System.out`这个实例熟悉\n2. `ldc` 从常量池里加载一个常亮进入操作数栈, 这里加载的是`A static init`字符串\n3. `invokevirtual` 然后调用`java/io/PrintStream.println`方法, 输出`A static init`字符串\n\n构造器的代码开始执行\n1. `aload_0` : 从局部变量表加载一个reference类型值到操作数栈, 这个变量应该是this\n2. `invokespecial` : 用于需要特殊处理的实例方法(实例初始化方法, 私有方法和父类方法). 这里是调用A的实例化方法, 也就是`{}`这中的代码\n3. `getstatic` 实例化方法访问`java/lang/System.out`属性\n4. `ldc` 实例化方法从常量池里加载一个常亮进入操作数栈, 这里加载的是`A init`字符串\n5. `invokevirtual` 实例化方法调用`java/io/PrintStream.println`方法, 输出`A init`字符串\n6. `getstatic` 构造器访问`java/lang/System.out`属性\n7. `ldc`构造器从常量池里加载一个常亮进入操作数栈, 这里加载的是`A`字符串\n8. `invokevirtual` 构造器调用`java/io/PrintStream.println`方法, 输出`A`字符串\n\n\n然后我们看一下B的claa字节码\n```java\n➜  classes  javap -c B\nCompiled from \"TestInit.java\"\nclass B extends A {\n  public B();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method A.\"<init>\":()V\n       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       7: ldc           #3                  // String B init\n       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      12: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n      15: ldc           #5                  // String B\n      17: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      20: return\n\n  static {};\n    Code:\n       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       3: ldc           #6                  // String B static init\n       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n       8: return\n}\n```\n与A类似, B同样是从类的初始化开始代码执行的\n1. `getstatic` 访问`java/lang/System.out`这个实例熟悉\n2. `ldc` 从常量池里加载一个常亮进入操作数栈, 这里加载的是`B static init`字符串\n3. `invokevirtual` 然后调用`java/io/PrintStream.println`方法, 输出`B static init`字符串\n\n然后是构造器方法执行\n1. `aload_0`同样的是加载`this`进虚拟机栈\n2. `invokespecial` 调用父类A的实例初始化方法\n3. 然后就开死像A一样, 调用自己的实例化过程\n","slug":"JavaSE/java 初始化","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihpz0032vjs6w5g7f1wz"},{"date":"2015-06-07T16:00:00.000Z","title":"java泛型","_content":"\n泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类.\n\n### 泛型类\n我们定义一个简单的泛型类, `T`称为泛型参数, `G`被称为泛型化了\n```java\nclass G<T> {\n\n}\n```\n接着我们在内部定义一个泛型变量\n```\nclass G<T> {\n\tT t;\n}\n```\n然后我们再添加一个泛型方法泛型方法\n```java\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n```\n下来我们来使用一下这个泛型类\n```java\nG<String> g = new G<>();\ng.setValue(\"value\");\n```\n\n\n### 泛型方法\n在一个非泛化的类中我们也可以直接定义泛化的方法\n\n\n### 类型擦除\n说到java中的泛型就不得不提泛型参数的类型擦除. 当java源码文件被编译成class文件的时候,编译器会将泛型中的类型参数擦除掉(其实class文件中还是会保留部分的泛型信息, 具体参考java虚拟机规范).\n\n类定义的泛型参数`T`会被替换成具体类型, 一般为Object. 而`<T>`信息则会被擦除掉, 例如G就会替换成\n```java\nclass G {\n\tObject t;\n\n\tpublic void setValue(Object t) {\n\t\tthis.t = t;\n\t}\n}\n```\n而在引用该类型的时候则会擦除成\n```java\nG g = new G();\ng.setValue(\"value\");\n```\n因此，java里的泛型类型安全是由编译器保证的, 在运行期是无法保证类型的安全的.\n\n### 泛型类的继承关系\n如果类被泛型化之后, 会对类本身的继承关系造成影响\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\n\n\t\tSubG1 subG1 = new SubG1();\n\t\tsubG1.setValue(1);\n\t\tsubG1.printValue(\"SubG1 printValue\");\n\t\tsubG1.print();\n\n\t\tSubG2 subG2 = new SubG2();\n\t\tsubG2.setValue(\"SubG2 setValue\");\n\t\tsubG2.printValue(\"SubG2 printValue\");\n\t\tsubG2.print();\n\n\t\tSubG3<Integer> subG3 = new SubG3<>();\n\t\tsubG3.setValue(\"SubG3 setValue\");\n\t\tsubG3.printValue(\"SubG3 printValue\");\n\t\tsubG3.print(3);\n\n\t\tSubG4<Integer> subG4 = new SubG4();\n\t\tsubG4.setValue(\"SubG4 setValue\");\n\t\tsubG4.printValue(\"SubG4 printValue\");\n\t\tsubG4.print(4);\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic void printValue(T t) {\n\t\tSystem.out.println(t);\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\n// SubG1继承了G的泛型参数. 但是SubG1本身是没有泛化的\nclass SubG1 extends G {\n\tpublic void print() {\n\t\tSystem.out.println(t);\n\t}\n}\n\n// 强制指定继承过来的T的类型为String\nclass SubG2 extends G<String> {\n\tpublic void print() {\n\t\tSystem.out.println(\"Super:\" + t);\n\t}\n}\n\n// G的类型由继承过来的方法指定, SubG3则再次由本类自己指定类型\nclass SubG3<T> extends G {\n\tpublic void print(T t1) {\n\t\tSystem.out.println(\"Super:\" + t + \". this:\" + t1);\n\t}\n}\n\n// 指定G的类型为String, SubG4则仍然由本类进行泛型化\nclass SubG4<T> extends G<String> {\n\tpublic void print(T t1) {\n\t\tSystem.out.println(\"Super:\" + t + \". this:\" + t1);\n\t}\n}\n\nclass SuperParam {\n\tpublic String toString() {\n\t\treturn \"SuperParam\";\n\t}\n}\n```\n结果为\n```java\nSubG1 printValue\n1\nSubG2 printValue\nSuper:SubG2 setValue\nSubG3 printValue\nSuper:SubG3 setValue. this:3\nSubG4 printValue\nSuper:SubG4 setValue. this:4\n```\n需要特别指出的是, 在`SubG1`对象分别调用`setValue()`和`printValue()`方法时分别使用了`Integer`和`String`俩个类型, 但是却没有产生任何异常信息.\n\n\n### 泛型参数的继承关系\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\t\tParam param = new Param();\n\n\t\tG<SuperParam> gSuperParam = new G<>();\n\t\tgSuperParam.setValue(superParam);\n\t\tgSuperParam.setValue(param);\n\t\tSuperParam t = gSuperParam.getT();\n\n\t\tG<Param> gParam = new G<>();\n\t\tgParam.setValue(param);\n\t\tgParam.setValue(superParam);\t// compile error\n\n\t\tSubParam subParam = new SubParam();\n\t\tgParam.setValue(subParam);\n\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n\nclass SubParam extends Param {}\n```\n从这一行`gParam.setValue(subParam);`我们可以看到类型参数的继承结构和普通类型的继承结构的规则是一样的.\n\n### 泛化在方法中的应用\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\n\t\tprint(new G<>());\n\t\tprint(new G<SuperParam>());\t\t// compile Error\n\t\tprint(new SubG1());\n\t\tprint(new SubG2());\n\t\tprint(new SubG3());\n\t\tprint(new SubG3<SuperParam>());\n\t\tprint(new SubG4());\n\t\tprint(new SubG4<SuperParam>());\n\n\t\tprintSuperParam(new G<>());\n\t\tprintSuperParam(new G<SuperParam>());\n\t\tprintSuperParam(new G<Param>());\t\t// compile Error\n\t}\n\n\tpublic static void print(G<String> gs) {}\n\n\tpublic static void printSuperParam(G<SuperParam> gs) {}\n}\n```\n从上面的例子中我们可以看出, 泛化的类的泛型参数并没有对其类型判断造成影响, 子类化的参数仍然是编译通过的. 但是类型参数的继承再传递到方法时, 却被认为不是相同的类型.\n\n### 通配符\n`?`在泛型参数中作为通配符存在, 它一般和`extends`和`super`关键字一起使用. 它表示不确定的一组类型, 例如和`extends`关键字一起使用就是表示继承自某个类的所有类型\n\n### extends\n`extends`关键字是用来定义泛型参数的继承关系. 它表示我们的泛型参数继承自某个类型, 也被我们称为上界符.\n\n我们修改一下G的类型定义,我们引入`extends`关键字\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\n\n\t\tSubG1 subG1 = new SubG1();\n\t\tsubG1.setValue(1);\n\t\tsubG1.printValue(\"SubG1 printValue\");\n\t\tsubG1.print();\n\n\t}\n}\n\nclass G<T extends SuperParam> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic void printValue(T t) {\n\t\tSystem.out.println(t);\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n```\n当使用`extends`关键字之后, 我们就将这个类的泛化信息固定了下来, 在实例化的时候, 其类型参数必须是继承自某类的子类型\n\n\n如果我们在实例化的时候指定`extends`会发生什么呢?\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<? extends SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\t\t// compile error\n\t\tg.setValue(new Param());\t\t// compile error\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\nclass Param1 extends SuperParam {}\n```\n不推荐这种用法, 因为这种情况下如果我们可以对其使用`Param`或者`Param1`的类型, 那么这就和不使用泛型是一样的, 会引起类型转化异常.\n\n但是我们却可以在另外一种情况下使用这个关键字\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tprint(new G<>());\t// 默认的是SuperParam类型\n\t\tprint(new G<Param>());\n\t}\n\n\tpublic static void print(G<? extends SuperParam> g) {\n\t\tSuperParam t = g.getT();\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n\n### super\n`super`作为一种下界符存在. 也就在具体使用时的参数都必须是泛型参数的父类才行.\n```java\nG<? super SuperParam> g = new G<>();\ng.setValue(new SuperParam());\ng.setValue(new Param());\n```\n同样我们可以在方法中如此使用\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tprint(new G<SuperParam>());\n\t\tprint(new G<>());\t// 默认是Param\n\t}\n\n\tpublic static void print(G<? super Param> g) {\n\t\tObject t = g.getT();\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n","source":"_posts/JavaSE/java 泛型.md","raw":"category: JavaSE\ndate: 2015-06-08\ntitle: java泛型\n---\n\n泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类.\n\n### 泛型类\n我们定义一个简单的泛型类, `T`称为泛型参数, `G`被称为泛型化了\n```java\nclass G<T> {\n\n}\n```\n接着我们在内部定义一个泛型变量\n```\nclass G<T> {\n\tT t;\n}\n```\n然后我们再添加一个泛型方法泛型方法\n```java\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n```\n下来我们来使用一下这个泛型类\n```java\nG<String> g = new G<>();\ng.setValue(\"value\");\n```\n\n\n### 泛型方法\n在一个非泛化的类中我们也可以直接定义泛化的方法\n\n\n### 类型擦除\n说到java中的泛型就不得不提泛型参数的类型擦除. 当java源码文件被编译成class文件的时候,编译器会将泛型中的类型参数擦除掉(其实class文件中还是会保留部分的泛型信息, 具体参考java虚拟机规范).\n\n类定义的泛型参数`T`会被替换成具体类型, 一般为Object. 而`<T>`信息则会被擦除掉, 例如G就会替换成\n```java\nclass G {\n\tObject t;\n\n\tpublic void setValue(Object t) {\n\t\tthis.t = t;\n\t}\n}\n```\n而在引用该类型的时候则会擦除成\n```java\nG g = new G();\ng.setValue(\"value\");\n```\n因此，java里的泛型类型安全是由编译器保证的, 在运行期是无法保证类型的安全的.\n\n### 泛型类的继承关系\n如果类被泛型化之后, 会对类本身的继承关系造成影响\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\n\n\t\tSubG1 subG1 = new SubG1();\n\t\tsubG1.setValue(1);\n\t\tsubG1.printValue(\"SubG1 printValue\");\n\t\tsubG1.print();\n\n\t\tSubG2 subG2 = new SubG2();\n\t\tsubG2.setValue(\"SubG2 setValue\");\n\t\tsubG2.printValue(\"SubG2 printValue\");\n\t\tsubG2.print();\n\n\t\tSubG3<Integer> subG3 = new SubG3<>();\n\t\tsubG3.setValue(\"SubG3 setValue\");\n\t\tsubG3.printValue(\"SubG3 printValue\");\n\t\tsubG3.print(3);\n\n\t\tSubG4<Integer> subG4 = new SubG4();\n\t\tsubG4.setValue(\"SubG4 setValue\");\n\t\tsubG4.printValue(\"SubG4 printValue\");\n\t\tsubG4.print(4);\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic void printValue(T t) {\n\t\tSystem.out.println(t);\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\n// SubG1继承了G的泛型参数. 但是SubG1本身是没有泛化的\nclass SubG1 extends G {\n\tpublic void print() {\n\t\tSystem.out.println(t);\n\t}\n}\n\n// 强制指定继承过来的T的类型为String\nclass SubG2 extends G<String> {\n\tpublic void print() {\n\t\tSystem.out.println(\"Super:\" + t);\n\t}\n}\n\n// G的类型由继承过来的方法指定, SubG3则再次由本类自己指定类型\nclass SubG3<T> extends G {\n\tpublic void print(T t1) {\n\t\tSystem.out.println(\"Super:\" + t + \". this:\" + t1);\n\t}\n}\n\n// 指定G的类型为String, SubG4则仍然由本类进行泛型化\nclass SubG4<T> extends G<String> {\n\tpublic void print(T t1) {\n\t\tSystem.out.println(\"Super:\" + t + \". this:\" + t1);\n\t}\n}\n\nclass SuperParam {\n\tpublic String toString() {\n\t\treturn \"SuperParam\";\n\t}\n}\n```\n结果为\n```java\nSubG1 printValue\n1\nSubG2 printValue\nSuper:SubG2 setValue\nSubG3 printValue\nSuper:SubG3 setValue. this:3\nSubG4 printValue\nSuper:SubG4 setValue. this:4\n```\n需要特别指出的是, 在`SubG1`对象分别调用`setValue()`和`printValue()`方法时分别使用了`Integer`和`String`俩个类型, 但是却没有产生任何异常信息.\n\n\n### 泛型参数的继承关系\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\t\tParam param = new Param();\n\n\t\tG<SuperParam> gSuperParam = new G<>();\n\t\tgSuperParam.setValue(superParam);\n\t\tgSuperParam.setValue(param);\n\t\tSuperParam t = gSuperParam.getT();\n\n\t\tG<Param> gParam = new G<>();\n\t\tgParam.setValue(param);\n\t\tgParam.setValue(superParam);\t// compile error\n\n\t\tSubParam subParam = new SubParam();\n\t\tgParam.setValue(subParam);\n\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n\nclass SubParam extends Param {}\n```\n从这一行`gParam.setValue(subParam);`我们可以看到类型参数的继承结构和普通类型的继承结构的规则是一样的.\n\n### 泛化在方法中的应用\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\n\t\tprint(new G<>());\n\t\tprint(new G<SuperParam>());\t\t// compile Error\n\t\tprint(new SubG1());\n\t\tprint(new SubG2());\n\t\tprint(new SubG3());\n\t\tprint(new SubG3<SuperParam>());\n\t\tprint(new SubG4());\n\t\tprint(new SubG4<SuperParam>());\n\n\t\tprintSuperParam(new G<>());\n\t\tprintSuperParam(new G<SuperParam>());\n\t\tprintSuperParam(new G<Param>());\t\t// compile Error\n\t}\n\n\tpublic static void print(G<String> gs) {}\n\n\tpublic static void printSuperParam(G<SuperParam> gs) {}\n}\n```\n从上面的例子中我们可以看出, 泛化的类的泛型参数并没有对其类型判断造成影响, 子类化的参数仍然是编译通过的. 但是类型参数的继承再传递到方法时, 却被认为不是相同的类型.\n\n### 通配符\n`?`在泛型参数中作为通配符存在, 它一般和`extends`和`super`关键字一起使用. 它表示不确定的一组类型, 例如和`extends`关键字一起使用就是表示继承自某个类的所有类型\n\n### extends\n`extends`关键字是用来定义泛型参数的继承关系. 它表示我们的泛型参数继承自某个类型, 也被我们称为上界符.\n\n我们修改一下G的类型定义,我们引入`extends`关键字\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\n\n\t\tSubG1 subG1 = new SubG1();\n\t\tsubG1.setValue(1);\n\t\tsubG1.printValue(\"SubG1 printValue\");\n\t\tsubG1.print();\n\n\t}\n}\n\nclass G<T extends SuperParam> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic void printValue(T t) {\n\t\tSystem.out.println(t);\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n```\n当使用`extends`关键字之后, 我们就将这个类的泛化信息固定了下来, 在实例化的时候, 其类型参数必须是继承自某类的子类型\n\n\n如果我们在实例化的时候指定`extends`会发生什么呢?\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tG<? extends SuperParam> g = new G<>();\n\t\tg.setValue(superParam);\t\t// compile error\n\t\tg.setValue(new Param());\t\t// compile error\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\nclass Param1 extends SuperParam {}\n```\n不推荐这种用法, 因为这种情况下如果我们可以对其使用`Param`或者`Param1`的类型, 那么这就和不使用泛型是一样的, 会引起类型转化异常.\n\n但是我们却可以在另外一种情况下使用这个关键字\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tSuperParam superParam = new SuperParam();\n\n\t\tprint(new G<>());\t// 默认的是SuperParam类型\n\t\tprint(new G<Param>());\n\t}\n\n\tpublic static void print(G<? extends SuperParam> g) {\n\t\tSuperParam t = g.getT();\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n\n### super\n`super`作为一种下界符存在. 也就在具体使用时的参数都必须是泛型参数的父类才行.\n```java\nG<? super SuperParam> g = new G<>();\ng.setValue(new SuperParam());\ng.setValue(new Param());\n```\n同样我们可以在方法中如此使用\n```java\npublic class TestGeneric {\n\n\tpublic static void main(String[] args) {\n\t\tprint(new G<SuperParam>());\n\t\tprint(new G<>());\t// 默认是Param\n\t}\n\n\tpublic static void print(G<? super Param> g) {\n\t\tObject t = g.getT();\n\t}\n}\n\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n\n\tpublic T getT() {\n\t\treturn t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n","slug":"JavaSE/java 泛型","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq00034vjs6g942nmzx"},{"date":"2015-09-07T16:00:00.000Z","title":"java lambda","_content":"\n## 函数接口\n\n### 函数接口定义\n函数接口只是一个抽象方法的接口,用作lambda表达式类型.\n\n注意, 上面这个定义有三个需要注意的地方\n1. 函数接口是一个接口\n2. 函数接口有且只有一个抽象方法(只有一个表示数量上是唯一的,重载也是不可以)\n3. 函数接口用作lambda表达式类型\n\n### 函数接口示例:\n```java\n// 定义一个非泛型没有返回值没有参数的函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n// 定义一个非泛型没有返回值有参数的函数接口\ninterface Run2 {\n\tpublic void runFast(int seconds);\n}\n// 定义一个非泛型有返回值有参数的函数接口\ninterface Run3 {\n\tpublic int runFast(int seconds);\n}\n// 定义一个泛型有返回值有参数的函数接口\ninterface Run4<T> {\n\tpublic int runFast(T t, int seconds);\n}\n```\n\n### 默认方法\n我们知道java8对核心集合类进行了大幅度修改,例如`Collection`接口添加了`stream()`方法. 那么所有的`Collection`实现类都必须来实现该方法. 为了保持二进制接口的兼容性,java8提供了默认方法,来保证这一兼容性(例如来源在java1到jav7平台写出的代码仍然可以在java8平台上编译运行)\n```java\ninterface Run10 {\n\tpublic void runFast();\n\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run11  extends Run10 {\n\n}\n\n// 调用\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\n```\n那么所有的子类都可以来调用这个默认方法, 而不必实现它。\n\n> 如果接口中只有一个默认方法,那么这个接口就不是接口函数.\n\n#### 继承默认方法\n```java\ninterface Run11 extends Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run11 runAt9Clock\");\n\t}\n}\n\nclass Run12 implements Run10 {\n\t@Override\n\tpublic void runFast() {}\n\n\tpublic void runAt9Clock() {\n\t\tSystem.out.println(\"run12 runAt9Clock\");\n\t}\n}\n```\n从上面的例子中我们可以看到如果接口`Run11`继承了接口`Run10`, 同时重载了默认方法, 那么`Run11`中的默认方法也必须含有`default`关键字. 但是在类中重载的话,就可以不必存在了.\n```java\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\nRun12 run12 = new Run12();\nrun12.runAt9Clock();\n\n//result\nrun11 runAt9Clock\nrun12 runAt9Clock\n```\n接着我们都调用默认方法,我们发现当调用默认方法时都会优先调用子类中的方法.\n\n#### 多重继承\n```java\ninterface Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run13 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run13 runAt9Clock\");\n\t}\n}\n\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\n\t}\n}\n```\n在上面这个情况下,我们需要手动在`Run14`这个类中指定重载哪个方法, 否则会产生编译错误：\n```java\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\t\tRun10.super.runAt9Clock();\n\t}\n}\n```\n\n### 接口静态方法\n我们定义一个接口静态方法\n```java\ninterface Run1 {\n\tpublic void runFast();\n\n\tpublic static void runSlowly() {\n\t\tSystem.out.println(\"run1 run slowly\");\n\t}\n}\n\n//\nRun1.runSlowly();\n```\n需要注意的是：\n* 接口静态方法不会被继承到子接口或者子类中\n\n### @FunctionalInterface\n所有的函数接口都应该添加`@FunctionalInterface`注释. 该注释会强制检查javac检查一个接口是否符合函数接口的标准. 如果将这个注释添加给类，枚举，多个方法的接口都会产生编译错误.\n\n## lambda表达式\n\n### lambda表达式定义\n接下来我们根据上面定义的函数接口来定义一下lambda表达式\n```java\n// 不带参数的版本\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n\n// 参数要指定\nRun2 run2 = seconds -> {\n\tSystem.out.println(\"I am running \" + seconds + \" seconds\");\n};\n\n// 下面这个版本就必须要有个返回值了\nRun3 run3 = seconds -> {\n\tSystem.out.println(\"I am running\");\n\treturn 0;\n};\n\n// 我们在下面的版本中指定了它的泛型信息\nRun4<String> run4 = (name, seconds) -> {\n\tSystem.out.println(name + \" is running\");\n\treturn 0;\n};\n```\n\n### lambda表达式使用\n\n接下来我们使用上面定义的lambda表达式\n```java\nrun1.runFast();\n-> I am running\n\nrun2.runFast(10);\n-> I am running 10 seconds\n\nint result = run3.runFast(10);\n-> I am running\n\nrun4.runFast(\"小狗\", 10); 小狗 is running\n->\n```\n\n#### 注意\n\n我们引用lambda表达式外部的一个变量\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n\n编译运行通过没有问题,但是如果我们将name在lambda表达式内部重新赋值的话\n\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tname = \"\";\n\tSystem.out.println(name + \" am running\");\n};\n```\n会提示`variable used in lambda expression shouble be final`, 这说明lambda其实内部引用的是值而不是变量.\n\n好,接下来我们换种方式再次验证一下我们的结果：\n```java\nString name = \"sam\";\nname = \"Jams\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n同样的产生了编译错误.\n\n#### java中重要的函数接口\n* `Predicate<T>`: `boolean test(T t)` 判断输入的对象是否符合某个条件\n* `Consumer<T>`: `void accept(T t);`  接收一个输入参数并且没有返回值\n* `Supplier<T>`: `T get();`  可以看成一个对象的工厂，每次调用返回一个给定类型的对象\n* `UnaryOperator<T>`: ``\n* `BinaryOperator<T>`: ``\n\n## 函数\n在Java8中什么是函数呢？\n```java\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n```\n上面`run1`这个就代表一个函数. 一般我们把属于某个类的函数称为方法, 而不依赖于类而存在的函数称之为方法.\n\n### 高阶函数\n如果某个函数A作为函数B的参数或者返回值, 那么我们称函数B为高阶函数,像下面的`run6`就是一个高级函数\n```java\ninterface Run6 {\n\tpublic void run(Run1 run1);\n}\n\nRun6 run6 = run1Param -> {\n\t\t\tSystem.out.println(\"run6\");\n\t\t\trun1Param.runFast();\n\t\t};\n\nrun6.run(run1);\n```\n我们将`run1`这个函数作为方法传递给了`run6`.\n\n#### 返回函数\n```java\ninterface Run8 {\n\tpublic void run(String name, int second, int mils);\n}\n\ninterface Run9 {\n\tpublic Run8 run(Run8 run8);\n}\n\nRun8 run8 = (name, second, mils) -> {\n\tSystem.out.println();\n};\n\nRun9 run9 = run8Param -> {\n\treturn run8Param.run(\"lily\");\n};\n```\n在上述的例子中产生了编译错误, 在`Haskell`这种纯FP语言中可以将一个调用函数但是参数不完整的函数从某个参数中返回或者定义一个参数不完整的函数值.\n\n### 重载解析\n我们使用函数接口作为方法参数,然后进行重载\n```java\n// 定义函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 {\n\tpublic void runFast();\n}\n\n\n// 定义重载代码\n\tpublic static void run(Run1 run1){\n\t\tSystem.out.println(\"run1\");\n\t}\n\n\tpublic static void run(Run2 run2){\n\t\tSystem.out.println(\"run2\");\n\t}\n\n// 定义运行代码\npublic static void main(String[] args) {\n\trun(() -> System.out.println());\n}\n```\n当我们进行如上定义时,javac提示了编译错误：不确定的方法调用,`run(Run1 run1)`和`run(Run2 run2)`都符合.\n\n但是如果`Run2`继承了`Run1`这个接口之后\n```java\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 extends Run1 {\n\tpublic void runFast();\n}\n```\n当我们运行测试代码之后,我们发现输出的`run2`.\n\n当Lambda表达式作为参数时,其类型由它的目标类型推导得出,推导过程遵循如下规则：\n* 如果只有一个可能的目标类型,由相应的函数接口里的参数类型推导得出\n* 如果有多个可能的目标类型，由最具体的类型推导得出\n* 如果有多个可能的目标类型且最具体的类型不明确，则需要人为指定类型\n\n## 方法引用\n方法引用是简洁的Lambda表达式，能够用于已经拥有名称的方法。\n\n* 静态方法 (ClassName::methName)\n* 对象实例方法 (instanceRef::methName)\n* 类型的实例方法 (ClassName::methName, 引用时和静态方法是一样的，但这里的 methName 是个实例方法)\n* 构造方法 (ClassName::new)\n* 数组的构造方法 (TypeName[]::new)\n\n### 静态方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::p;\n\t\tf.m();\n\t}\n\n\tpublic static void p() {\n\t\tSystem.out.println(\"Print\");\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tvoid m();\n}\n\n```\n\n### 类型实例方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = String::length;\n\t\tint len = f.m(\"12\");\n\t\tSystem.out.println(len);\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tint m(String p);\n}\n```\n\n### 构造方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::new;\n\t\tPrint p = f.m();\n\t\tSystem.out.println(p == null);\t// 结果为null\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tPrint m();\n}\n```\n\n### 闭包\nJava8还提供了闭包这个特性,虽然我不知道闭包这个特性有啥用,但是还是实验了一下\n```java\npublic class Java8 {\n\n\tpublic static void main(String[] args) {\n\t\tI i = () -> {\n\t\t\tC c = new C();\n\t\t\tc.count = 10;\n\n\t\t\tJ j = () -> {\n\t\t\t\tSystem.out.println(\"J print c:\" + c.count);\n\t\t\t\treturn c;\n\t\t\t};\n\n\t\t\tSystem.out.println(\"I print c:\" + c.count);\n\t\t\treturn j;\n\t\t};\n\n\t\tJ j = i.r();\n\t\tC c = j.c();\n\t\tc.count = 20;\n\t\tSystem.out.println(\"main print c:\" + c.count);\n\t}\n}\n\n\ninterface I {\n\tpublic J r();\n}\n\ninterface J {\n\tpublic C c();\n}\n\nclass C {\n\tpublic int count;\n}\n```\n我们定义了俩个接口, `I`和`J`, 我们在I的lambada中调用J的lambada, 然后让J返回一个定义在I的对象C, 最后我们在main函数中成功的返回了这个对象.\n","source":"_posts/JavaSE/java8 lambda.md","raw":"category: JavaSE\ndate: 2015-09-08\ntitle: java lambda\n---\n\n## 函数接口\n\n### 函数接口定义\n函数接口只是一个抽象方法的接口,用作lambda表达式类型.\n\n注意, 上面这个定义有三个需要注意的地方\n1. 函数接口是一个接口\n2. 函数接口有且只有一个抽象方法(只有一个表示数量上是唯一的,重载也是不可以)\n3. 函数接口用作lambda表达式类型\n\n### 函数接口示例:\n```java\n// 定义一个非泛型没有返回值没有参数的函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n// 定义一个非泛型没有返回值有参数的函数接口\ninterface Run2 {\n\tpublic void runFast(int seconds);\n}\n// 定义一个非泛型有返回值有参数的函数接口\ninterface Run3 {\n\tpublic int runFast(int seconds);\n}\n// 定义一个泛型有返回值有参数的函数接口\ninterface Run4<T> {\n\tpublic int runFast(T t, int seconds);\n}\n```\n\n### 默认方法\n我们知道java8对核心集合类进行了大幅度修改,例如`Collection`接口添加了`stream()`方法. 那么所有的`Collection`实现类都必须来实现该方法. 为了保持二进制接口的兼容性,java8提供了默认方法,来保证这一兼容性(例如来源在java1到jav7平台写出的代码仍然可以在java8平台上编译运行)\n```java\ninterface Run10 {\n\tpublic void runFast();\n\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run11  extends Run10 {\n\n}\n\n// 调用\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\n```\n那么所有的子类都可以来调用这个默认方法, 而不必实现它。\n\n> 如果接口中只有一个默认方法,那么这个接口就不是接口函数.\n\n#### 继承默认方法\n```java\ninterface Run11 extends Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run11 runAt9Clock\");\n\t}\n}\n\nclass Run12 implements Run10 {\n\t@Override\n\tpublic void runFast() {}\n\n\tpublic void runAt9Clock() {\n\t\tSystem.out.println(\"run12 runAt9Clock\");\n\t}\n}\n```\n从上面的例子中我们可以看到如果接口`Run11`继承了接口`Run10`, 同时重载了默认方法, 那么`Run11`中的默认方法也必须含有`default`关键字. 但是在类中重载的话,就可以不必存在了.\n```java\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\nRun12 run12 = new Run12();\nrun12.runAt9Clock();\n\n//result\nrun11 runAt9Clock\nrun12 runAt9Clock\n```\n接着我们都调用默认方法,我们发现当调用默认方法时都会优先调用子类中的方法.\n\n#### 多重继承\n```java\ninterface Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run13 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run13 runAt9Clock\");\n\t}\n}\n\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\n\t}\n}\n```\n在上面这个情况下,我们需要手动在`Run14`这个类中指定重载哪个方法, 否则会产生编译错误：\n```java\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\t\tRun10.super.runAt9Clock();\n\t}\n}\n```\n\n### 接口静态方法\n我们定义一个接口静态方法\n```java\ninterface Run1 {\n\tpublic void runFast();\n\n\tpublic static void runSlowly() {\n\t\tSystem.out.println(\"run1 run slowly\");\n\t}\n}\n\n//\nRun1.runSlowly();\n```\n需要注意的是：\n* 接口静态方法不会被继承到子接口或者子类中\n\n### @FunctionalInterface\n所有的函数接口都应该添加`@FunctionalInterface`注释. 该注释会强制检查javac检查一个接口是否符合函数接口的标准. 如果将这个注释添加给类，枚举，多个方法的接口都会产生编译错误.\n\n## lambda表达式\n\n### lambda表达式定义\n接下来我们根据上面定义的函数接口来定义一下lambda表达式\n```java\n// 不带参数的版本\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n\n// 参数要指定\nRun2 run2 = seconds -> {\n\tSystem.out.println(\"I am running \" + seconds + \" seconds\");\n};\n\n// 下面这个版本就必须要有个返回值了\nRun3 run3 = seconds -> {\n\tSystem.out.println(\"I am running\");\n\treturn 0;\n};\n\n// 我们在下面的版本中指定了它的泛型信息\nRun4<String> run4 = (name, seconds) -> {\n\tSystem.out.println(name + \" is running\");\n\treturn 0;\n};\n```\n\n### lambda表达式使用\n\n接下来我们使用上面定义的lambda表达式\n```java\nrun1.runFast();\n-> I am running\n\nrun2.runFast(10);\n-> I am running 10 seconds\n\nint result = run3.runFast(10);\n-> I am running\n\nrun4.runFast(\"小狗\", 10); 小狗 is running\n->\n```\n\n#### 注意\n\n我们引用lambda表达式外部的一个变量\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n\n编译运行通过没有问题,但是如果我们将name在lambda表达式内部重新赋值的话\n\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tname = \"\";\n\tSystem.out.println(name + \" am running\");\n};\n```\n会提示`variable used in lambda expression shouble be final`, 这说明lambda其实内部引用的是值而不是变量.\n\n好,接下来我们换种方式再次验证一下我们的结果：\n```java\nString name = \"sam\";\nname = \"Jams\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n同样的产生了编译错误.\n\n#### java中重要的函数接口\n* `Predicate<T>`: `boolean test(T t)` 判断输入的对象是否符合某个条件\n* `Consumer<T>`: `void accept(T t);`  接收一个输入参数并且没有返回值\n* `Supplier<T>`: `T get();`  可以看成一个对象的工厂，每次调用返回一个给定类型的对象\n* `UnaryOperator<T>`: ``\n* `BinaryOperator<T>`: ``\n\n## 函数\n在Java8中什么是函数呢？\n```java\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n```\n上面`run1`这个就代表一个函数. 一般我们把属于某个类的函数称为方法, 而不依赖于类而存在的函数称之为方法.\n\n### 高阶函数\n如果某个函数A作为函数B的参数或者返回值, 那么我们称函数B为高阶函数,像下面的`run6`就是一个高级函数\n```java\ninterface Run6 {\n\tpublic void run(Run1 run1);\n}\n\nRun6 run6 = run1Param -> {\n\t\t\tSystem.out.println(\"run6\");\n\t\t\trun1Param.runFast();\n\t\t};\n\nrun6.run(run1);\n```\n我们将`run1`这个函数作为方法传递给了`run6`.\n\n#### 返回函数\n```java\ninterface Run8 {\n\tpublic void run(String name, int second, int mils);\n}\n\ninterface Run9 {\n\tpublic Run8 run(Run8 run8);\n}\n\nRun8 run8 = (name, second, mils) -> {\n\tSystem.out.println();\n};\n\nRun9 run9 = run8Param -> {\n\treturn run8Param.run(\"lily\");\n};\n```\n在上述的例子中产生了编译错误, 在`Haskell`这种纯FP语言中可以将一个调用函数但是参数不完整的函数从某个参数中返回或者定义一个参数不完整的函数值.\n\n### 重载解析\n我们使用函数接口作为方法参数,然后进行重载\n```java\n// 定义函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 {\n\tpublic void runFast();\n}\n\n\n// 定义重载代码\n\tpublic static void run(Run1 run1){\n\t\tSystem.out.println(\"run1\");\n\t}\n\n\tpublic static void run(Run2 run2){\n\t\tSystem.out.println(\"run2\");\n\t}\n\n// 定义运行代码\npublic static void main(String[] args) {\n\trun(() -> System.out.println());\n}\n```\n当我们进行如上定义时,javac提示了编译错误：不确定的方法调用,`run(Run1 run1)`和`run(Run2 run2)`都符合.\n\n但是如果`Run2`继承了`Run1`这个接口之后\n```java\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 extends Run1 {\n\tpublic void runFast();\n}\n```\n当我们运行测试代码之后,我们发现输出的`run2`.\n\n当Lambda表达式作为参数时,其类型由它的目标类型推导得出,推导过程遵循如下规则：\n* 如果只有一个可能的目标类型,由相应的函数接口里的参数类型推导得出\n* 如果有多个可能的目标类型，由最具体的类型推导得出\n* 如果有多个可能的目标类型且最具体的类型不明确，则需要人为指定类型\n\n## 方法引用\n方法引用是简洁的Lambda表达式，能够用于已经拥有名称的方法。\n\n* 静态方法 (ClassName::methName)\n* 对象实例方法 (instanceRef::methName)\n* 类型的实例方法 (ClassName::methName, 引用时和静态方法是一样的，但这里的 methName 是个实例方法)\n* 构造方法 (ClassName::new)\n* 数组的构造方法 (TypeName[]::new)\n\n### 静态方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::p;\n\t\tf.m();\n\t}\n\n\tpublic static void p() {\n\t\tSystem.out.println(\"Print\");\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tvoid m();\n}\n\n```\n\n### 类型实例方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = String::length;\n\t\tint len = f.m(\"12\");\n\t\tSystem.out.println(len);\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tint m(String p);\n}\n```\n\n### 构造方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::new;\n\t\tPrint p = f.m();\n\t\tSystem.out.println(p == null);\t// 结果为null\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tPrint m();\n}\n```\n\n### 闭包\nJava8还提供了闭包这个特性,虽然我不知道闭包这个特性有啥用,但是还是实验了一下\n```java\npublic class Java8 {\n\n\tpublic static void main(String[] args) {\n\t\tI i = () -> {\n\t\t\tC c = new C();\n\t\t\tc.count = 10;\n\n\t\t\tJ j = () -> {\n\t\t\t\tSystem.out.println(\"J print c:\" + c.count);\n\t\t\t\treturn c;\n\t\t\t};\n\n\t\t\tSystem.out.println(\"I print c:\" + c.count);\n\t\t\treturn j;\n\t\t};\n\n\t\tJ j = i.r();\n\t\tC c = j.c();\n\t\tc.count = 20;\n\t\tSystem.out.println(\"main print c:\" + c.count);\n\t}\n}\n\n\ninterface I {\n\tpublic J r();\n}\n\ninterface J {\n\tpublic C c();\n}\n\nclass C {\n\tpublic int count;\n}\n```\n我们定义了俩个接口, `I`和`J`, 我们在I的lambada中调用J的lambada, 然后让J返回一个定义在I的对象C, 最后我们在main函数中成功的返回了这个对象.\n","slug":"JavaSE/java8 lambda","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq20036vjs62tgeiuiw"},{"date":"2015-09-07T16:00:00.000Z","title":"Java8 时间处理","_content":"LocalDate表示日期的不可变类型，不包含时间和时区。\n```java\n// 获取当天的日期\nLocalDate now = LocalDate.now();\n// 2015-09-21\nSystem.out.println(now.toString());\n// 获取当前日期的月份,注意这个值是一个英文月份：例如,SEPTEMBER\nSystem.out.println(now.getMonth());\n// 这个方式用来获取数字月份\nSystem.out.println(now.getMonth().getValue());\n// 获取今天是这个月中的第几天\nSystem.out.println(now.getDayOfMonth());\n// 获取今天是这周中的第几天\nSystem.out.println(now.getDayOfWeek());\n// 获取今天是今年当中第几天\nSystem.out.println(now.getDayOfYear());\n// 这个方式用来获取数字月份 等同于 System.out.println(now.getMonth().getValue());\nSystem.out.println(now.getMonthValue());\n// 获取今年年份\nSystem.out.println(now.getYear());\n// 根据指定日期生成一个LocalDate 对象\nLocalDate someDay = LocalDate.of(2015, 8, 16);\nSystem.out.println(someDay.toString());\n\n// 在当前日期行指定一个时间\nSystem.out.println(now.atTime(12, 59, 59));\n\nLocalDate someDay1 = LocalDate.of(2015, 8, 16);\nLocalDate someDay2 = LocalDate.of(2015, 8, 17);\n// 判断俩天是否是同一天\nSystem.out.println(someDay1.equals(someDay2));\n\n// 我们获取明天的日期\nLocalDate tomorrow = now.plusDays(1);\n// 判断今天是否在明天之前\nSystem.out.println(now.isBefore(tomorrow));\n```\n\n* LocalTime\n* LocalDateTime\n* Period\n* DateTimeFormatter\n","source":"_posts/JavaSE/java8 time.md","raw":"category: JavaSE\ndate: 2015-09-08\ntitle: Java8 时间处理\n---\nLocalDate表示日期的不可变类型，不包含时间和时区。\n```java\n// 获取当天的日期\nLocalDate now = LocalDate.now();\n// 2015-09-21\nSystem.out.println(now.toString());\n// 获取当前日期的月份,注意这个值是一个英文月份：例如,SEPTEMBER\nSystem.out.println(now.getMonth());\n// 这个方式用来获取数字月份\nSystem.out.println(now.getMonth().getValue());\n// 获取今天是这个月中的第几天\nSystem.out.println(now.getDayOfMonth());\n// 获取今天是这周中的第几天\nSystem.out.println(now.getDayOfWeek());\n// 获取今天是今年当中第几天\nSystem.out.println(now.getDayOfYear());\n// 这个方式用来获取数字月份 等同于 System.out.println(now.getMonth().getValue());\nSystem.out.println(now.getMonthValue());\n// 获取今年年份\nSystem.out.println(now.getYear());\n// 根据指定日期生成一个LocalDate 对象\nLocalDate someDay = LocalDate.of(2015, 8, 16);\nSystem.out.println(someDay.toString());\n\n// 在当前日期行指定一个时间\nSystem.out.println(now.atTime(12, 59, 59));\n\nLocalDate someDay1 = LocalDate.of(2015, 8, 16);\nLocalDate someDay2 = LocalDate.of(2015, 8, 17);\n// 判断俩天是否是同一天\nSystem.out.println(someDay1.equals(someDay2));\n\n// 我们获取明天的日期\nLocalDate tomorrow = now.plusDays(1);\n// 判断今天是否在明天之前\nSystem.out.println(now.isBefore(tomorrow));\n```\n\n* LocalTime\n* LocalDateTime\n* Period\n* DateTimeFormatter\n","slug":"JavaSE/java8 time","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq40038vjs69z2br1i9"},{"date":"2015-09-07T16:00:00.000Z","title":"java8 流","_content":"# 流\njava8中新添加的流又称为`Streams API`. 它是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation).\n\n接下来我们构建一个流:\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .count();\n```\n我们通过上述代码构建流一个流,这里有俩个概念要说:\n* 惰性求值方法:像`filter`方法,它只是在刻画Stream,它并不会被调用.(在Stream方法中凡事返回Stream对象的都是这种方法)\n* 及早求值方法:像`count`方法,它会从Stream中最终产生值.(在Stream方法中凡事返回空或者另一个值都是这种方法)\n\n## 常用的流操作\n\n### collect()\n\n该方法会产生一个列表,是一个及早求值方法.\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .collect(Collectors.toList());\n```\n当然我们还可以调用`Collectors.toSet()`等其他方法,构建其他集合\n\n### map\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/map.jpg)\n该操作会将一个流中的值转换为一个新的流\n```java\nStream.of(1, 2, 3)\n      .map(num -> {\n          if (num > 1) {\n             return 0;\n          } else {\n             return 1;\n          }\n       })\n       .collect(Collectors.toSet())\n       .forEach(ele -> System.out.println(ele));\n```\n\n### filter\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/filter.jpg)\n遍历数据并检查其中的元素是否符合某种条件\n\n这个操作看起来和`map`很像, 但是`map`是根据操作的结果产生新的流,而`filter`是判断流中的数据是否符合条件保留下来\n```java\n Stream.of(1, 2, 3)\n                .filter(ele -> {\n                    if (ele > 1) {\n                        return true;\n                    } else {\n                        return false;\n                    }\n                })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n\n### flatMap\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/flatMap.jpg)\n用于Stream替换值然后将多个流连接到一起\n\n首先我们看一种情况,流里有俩个列表\n```java\n Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n\n输出的结果是:\n[1, 2, 3]\n[7, 8, 9]\n```\n如果我们想将这俩个列表组合到一起呢?\n```java\nStream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                    .flatMap(list -> {\n                        return list.stream();\n                    })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n看到了吧,我们首先讲列表转换成流,然后由`flatMap`操作将流组合到一起\n\n### max\n查找流中的最大值\n```java\nInteger max = Stream.of(1, 2, 3)\n                .max(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(max);\n```\n我们需要向`max`操作中传递一个排序的动作. `Comparator.comparing()`这个静态方法是java8新添加的方法,它实现流一个方便的比较器.以前我们需要比较俩个对象的某项属性的值,现在只需要提供一个取值方法就好了.\n\n\n### min\n查找流中的最小值\n```java\nInteger min = Stream.of(1, 2, 3)\n                .min(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(min);\n```\n和`max`相似\n\n\n### reduce\n从一组值生成一个值.\n```java\nInteger sum = Stream.of(1, 2, 3)\n                .reduce((inSum, element) -> {\n                    return inSum + element;\n                }).get();\n        System.out.println(sum);\n```\n`reduce`中的`BinaryOperator`类型的lambda表达式第一个参数是上个元素执行`reduce`操作的结果, 第二个参数是流中的每个元素.\n\n另外Stream中还有其他的`reduce`操作,可以指定开始结束的的位置\n\n\n# 元素顺序\n在一个有序集合中创建一个流时，流中元素就按照出现的顺序进行排列:\n```java\nArrays.asList(1, 2, 3).stream().forEach(ele -> System.out.println(ele));\n```\n上面这个输出顺序总是`1, 2, 3`.\n\n而如果一个集合本身是无序的话，那么生成的流也是无序的，最后由流生成的集合也是无序的\n\n\n# 使用收集器\n`java.util.stream.Collectors`这是java提供的一种通用的，从流生成复杂值结构的收集器.\n\n## 转换成其他集合\nCollectors提供了转换成其他集合的方式\n\n* `Collectors.toCollection()`： 接受一个函数作为参数，来创建集合\n* `Collectors.toConcurrentMap()`\n* `Collectors.toList()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n* `Collectors.toMap()`\n* `Collectors.toSet()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n\n## groupingBy\n数据分组\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\n\t\tMap<Integer, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\treturn 2;\n\t\t\t}\n\t\t}));\n\n// 最后结果为\n{1:[\n\t\t10,\n\t\t9,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\n 2:[\n\t\t1,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t4,\n\t\t5\n\t]\n}\n```\n当然分组的key,我们还可以取其他的类型,这完全取决于我们的返回值\n```java\nMap<String, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn \"1\";\n\t\t\t} else {\n\t\t\t\treturn \"2\";\n\t\t\t}\n\t\t}));\n```\n\n## groupingByConcurrent\n并发版本的`group by`实现\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nConcurrentMap<Integer, List<Integer>> result = list.stream().collect(Collectors.groupingByConcurrent(ele -> ele - 3));\n\n// 结果\n{-2:[1],\n -1:[\n\t\t2,\n\t\t2\n\t],\n  0:[3],\n  7:[10]\n}\n```\n\n## partitioningBy\n数据分组,key为`True`和`False`\n\nlambda表达式类型\n```java\npublic interface Predicate<T> {\n    boolean test(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nMap<Boolean, List<Integer>> result = list.stream().collect(Collectors.partitioningBy(ele -> ele == 1));\nSystem.out.println(JSON.toJSONString(result, true));\n\n// 结果为\n{false:[\n\t\t10,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t9,\n\t\t4,\n\t\t5,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\ntrue:[1]\n}\n```\n\n## averagingDouble\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingDouble(ele -> ele - 3));\n\n// 结果\n0.6\n```\n\n## averagingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingInt(ele -> ele - 3));\n// 结果\n0.6\n```\n\n## averagingLong\n对流中数据进行进行平均数操作\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.averagingLong(ele -> ele));\n```\n\n## summarizingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nIntSummaryStatistics result = list.stream().collect(Collectors.summarizingInt(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingLong\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLongSummaryStatistics result = list.stream().collect(Collectors.summarizingLong(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingDouble\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDoubleSummaryStatistics result = list.stream().collect(Collectors.summarizingDouble(ele -> ele));\n\n// 结果\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## counting\n统计流中数据数量\n\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.counting());\n```\n\n## maxBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.maxBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## minBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.minBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## summingDouble\n对列表数据取和操作,结果为`Double`\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.summingDouble(ele -> ele));\n// 结果为68\n\n```\n\n## summingInt\n对列表数据取和操作,结果为`Int`\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nInteger result = list.stream().collect(Collectors.summingInt(ele -> ele));\n```\n\n## summingLong\n对列表数据取和操作,结果为`Long`\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.summingLong(ele -> ele));\n```\n\n## joining\n将流中的数据拼接成一个字符串. 需要注意的是如果流中的数据不是`String`类型的数据,可以通过`map`操作将流中数据转换成`String`类型\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nString result = list.stream().collect(Collectors.joining(\",\", \"(\", \")\"));\n// 结果\n\"(1,10,2,3,2)\"\n```\n\n## reducing\n\nlambda表达式类型\n```java\nR apply(T t, U u);\n```\n示例：\n```java\n\n```\n\n\n## mapping\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nList<String> result = list.stream().collect(Collectors.mapping(ele -> ele + 1, Collectors.toList()));\n// 结果\n[\n\t\"11\",\n\t\"101\",\n\t\"21\",\n\t\"31\",\n\t\"21\"\n]\n```\n\n## distinct\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/distinct.jpg)\n\n## limit\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/limit.jpg)\n\n## peek\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/peek.jpg)\n\n## skip\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/skip.jpg)\n","source":"_posts/JavaSE/java8 流.md","raw":"category: JavaSE\ndate: 2015-09-08\ntitle: java8 流\n---\n# 流\njava8中新添加的流又称为`Streams API`. 它是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation).\n\n接下来我们构建一个流:\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .count();\n```\n我们通过上述代码构建流一个流,这里有俩个概念要说:\n* 惰性求值方法:像`filter`方法,它只是在刻画Stream,它并不会被调用.(在Stream方法中凡事返回Stream对象的都是这种方法)\n* 及早求值方法:像`count`方法,它会从Stream中最终产生值.(在Stream方法中凡事返回空或者另一个值都是这种方法)\n\n## 常用的流操作\n\n### collect()\n\n该方法会产生一个列表,是一个及早求值方法.\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .collect(Collectors.toList());\n```\n当然我们还可以调用`Collectors.toSet()`等其他方法,构建其他集合\n\n### map\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/map.jpg)\n该操作会将一个流中的值转换为一个新的流\n```java\nStream.of(1, 2, 3)\n      .map(num -> {\n          if (num > 1) {\n             return 0;\n          } else {\n             return 1;\n          }\n       })\n       .collect(Collectors.toSet())\n       .forEach(ele -> System.out.println(ele));\n```\n\n### filter\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/filter.jpg)\n遍历数据并检查其中的元素是否符合某种条件\n\n这个操作看起来和`map`很像, 但是`map`是根据操作的结果产生新的流,而`filter`是判断流中的数据是否符合条件保留下来\n```java\n Stream.of(1, 2, 3)\n                .filter(ele -> {\n                    if (ele > 1) {\n                        return true;\n                    } else {\n                        return false;\n                    }\n                })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n\n### flatMap\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/flatMap.jpg)\n用于Stream替换值然后将多个流连接到一起\n\n首先我们看一种情况,流里有俩个列表\n```java\n Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n\n输出的结果是:\n[1, 2, 3]\n[7, 8, 9]\n```\n如果我们想将这俩个列表组合到一起呢?\n```java\nStream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                    .flatMap(list -> {\n                        return list.stream();\n                    })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n看到了吧,我们首先讲列表转换成流,然后由`flatMap`操作将流组合到一起\n\n### max\n查找流中的最大值\n```java\nInteger max = Stream.of(1, 2, 3)\n                .max(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(max);\n```\n我们需要向`max`操作中传递一个排序的动作. `Comparator.comparing()`这个静态方法是java8新添加的方法,它实现流一个方便的比较器.以前我们需要比较俩个对象的某项属性的值,现在只需要提供一个取值方法就好了.\n\n\n### min\n查找流中的最小值\n```java\nInteger min = Stream.of(1, 2, 3)\n                .min(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(min);\n```\n和`max`相似\n\n\n### reduce\n从一组值生成一个值.\n```java\nInteger sum = Stream.of(1, 2, 3)\n                .reduce((inSum, element) -> {\n                    return inSum + element;\n                }).get();\n        System.out.println(sum);\n```\n`reduce`中的`BinaryOperator`类型的lambda表达式第一个参数是上个元素执行`reduce`操作的结果, 第二个参数是流中的每个元素.\n\n另外Stream中还有其他的`reduce`操作,可以指定开始结束的的位置\n\n\n# 元素顺序\n在一个有序集合中创建一个流时，流中元素就按照出现的顺序进行排列:\n```java\nArrays.asList(1, 2, 3).stream().forEach(ele -> System.out.println(ele));\n```\n上面这个输出顺序总是`1, 2, 3`.\n\n而如果一个集合本身是无序的话，那么生成的流也是无序的，最后由流生成的集合也是无序的\n\n\n# 使用收集器\n`java.util.stream.Collectors`这是java提供的一种通用的，从流生成复杂值结构的收集器.\n\n## 转换成其他集合\nCollectors提供了转换成其他集合的方式\n\n* `Collectors.toCollection()`： 接受一个函数作为参数，来创建集合\n* `Collectors.toConcurrentMap()`\n* `Collectors.toList()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n* `Collectors.toMap()`\n* `Collectors.toSet()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n\n## groupingBy\n数据分组\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\n\t\tMap<Integer, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\treturn 2;\n\t\t\t}\n\t\t}));\n\n// 最后结果为\n{1:[\n\t\t10,\n\t\t9,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\n 2:[\n\t\t1,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t4,\n\t\t5\n\t]\n}\n```\n当然分组的key,我们还可以取其他的类型,这完全取决于我们的返回值\n```java\nMap<String, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn \"1\";\n\t\t\t} else {\n\t\t\t\treturn \"2\";\n\t\t\t}\n\t\t}));\n```\n\n## groupingByConcurrent\n并发版本的`group by`实现\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nConcurrentMap<Integer, List<Integer>> result = list.stream().collect(Collectors.groupingByConcurrent(ele -> ele - 3));\n\n// 结果\n{-2:[1],\n -1:[\n\t\t2,\n\t\t2\n\t],\n  0:[3],\n  7:[10]\n}\n```\n\n## partitioningBy\n数据分组,key为`True`和`False`\n\nlambda表达式类型\n```java\npublic interface Predicate<T> {\n    boolean test(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nMap<Boolean, List<Integer>> result = list.stream().collect(Collectors.partitioningBy(ele -> ele == 1));\nSystem.out.println(JSON.toJSONString(result, true));\n\n// 结果为\n{false:[\n\t\t10,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t9,\n\t\t4,\n\t\t5,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\ntrue:[1]\n}\n```\n\n## averagingDouble\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingDouble(ele -> ele - 3));\n\n// 结果\n0.6\n```\n\n## averagingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingInt(ele -> ele - 3));\n// 结果\n0.6\n```\n\n## averagingLong\n对流中数据进行进行平均数操作\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.averagingLong(ele -> ele));\n```\n\n## summarizingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nIntSummaryStatistics result = list.stream().collect(Collectors.summarizingInt(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingLong\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLongSummaryStatistics result = list.stream().collect(Collectors.summarizingLong(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingDouble\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDoubleSummaryStatistics result = list.stream().collect(Collectors.summarizingDouble(ele -> ele));\n\n// 结果\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## counting\n统计流中数据数量\n\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.counting());\n```\n\n## maxBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.maxBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## minBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.minBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## summingDouble\n对列表数据取和操作,结果为`Double`\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.summingDouble(ele -> ele));\n// 结果为68\n\n```\n\n## summingInt\n对列表数据取和操作,结果为`Int`\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nInteger result = list.stream().collect(Collectors.summingInt(ele -> ele));\n```\n\n## summingLong\n对列表数据取和操作,结果为`Long`\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.summingLong(ele -> ele));\n```\n\n## joining\n将流中的数据拼接成一个字符串. 需要注意的是如果流中的数据不是`String`类型的数据,可以通过`map`操作将流中数据转换成`String`类型\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nString result = list.stream().collect(Collectors.joining(\",\", \"(\", \")\"));\n// 结果\n\"(1,10,2,3,2)\"\n```\n\n## reducing\n\nlambda表达式类型\n```java\nR apply(T t, U u);\n```\n示例：\n```java\n\n```\n\n\n## mapping\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nList<String> result = list.stream().collect(Collectors.mapping(ele -> ele + 1, Collectors.toList()));\n// 结果\n[\n\t\"11\",\n\t\"101\",\n\t\"21\",\n\t\"31\",\n\t\"21\"\n]\n```\n\n## distinct\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/distinct.jpg)\n\n## limit\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/limit.jpg)\n\n## peek\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/peek.jpg)\n\n## skip\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/skip.jpg)\n","slug":"JavaSE/java8 流","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq6003avjs6lop1j1f6"},{"date":"2015-11-18T16:00:00.000Z","title":"Java 常用技能","_content":"\n## 控制台乱码\n在windows系统里,我的cmd控制台的代码页是`65001(UTF)`,但是当我在指向java命令时却会发生乱码现象,只需要指向`chcp 936`这个命令,改变一下代码页就好了\n\n## java命令\n`java  -jar ./tools-1.0-SNAPSHOT.jar` 从某个jar运行, mainfest文件必须指定MainClass属性,如果不指定的话,在运行`java`命令的时候就会产生 xxx.jar中没有主清单属性\n\n`java  -jar ./ App` 从指定的classpath下所有的jar中,寻找App主类运行\n\n## 获取周数\n通过`Calendar`我们可以知道某个日期处于一年中第几周\n```java\nCalendar calendar = Calendar.getInstance();\ncalendar.setTime(new Date());\nSystem.out.println(calendar.get(Calendar.WEEK_OF_YEAR));\n```\n\n## 在Jar包读取文件\n我们使用Maven构建一个工程, 然后在资源目录(resources)下放置一个文件input.file, 然后我们写一个测试类\n```java\npublic class Test {\n\n    public static void main(String[] args) throws InterruptedException, IOException {\n        InputStream in = Test.class.getResourceAsStream(\"input.file\");\n        BufferedReader reader = new BufferedReader((new InputStreamReader(in)));\n        System.out.println(reader.readLine());\n    }\n}\n```\n在Idea里运行该程序, 可以成功看到input.file文件里的hi, how are you?的输出. 这是因为idea将resources设置在了cleasspath里, 而类加载器的`getResourceAsStream()`就是从classpath中进行文件查找, 因此可以找到的.\n\n而当我们将测试工程打包, 然后在target下执行命令\n```java\njava -cp .;./* Test\n```\n同样可以看到输出, 这是因为`getResourceAsStream()`会在jar包内部进行文件查找\n\n> 注意: 如果想要在jar内加载文件的话, 只能使用类加载器的`getResourceAsStream()`方法\n\n## 便利jar包中文件\n我们知道我们可以使用`ClassLoader`的`getResourceAsStream()`读取jar包中的文件, 那么如何知道jar包中有哪些文件, 也就是如何便利jar包中的文件呢？\n```java\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\t\tJarFile jar = new JarFile(\"D:\\\\premain\\\\target\\\\agent-1.0-SNAPSHOT.jar\");\n\t\tEnumeration<JarEntry> jarEntrys = jar.entries();\n\t\twhile (jarEntrys.hasMoreElements()) {\n\t\t\tJarEntry jarEntry = jarEntrys.nextElement();\n\t\t\tSystem.out.println(jarEntry.getName());\n\t\t}\n\t}\n}\n```\n## goto\n```java\npublic class TestBreak {\n\n\tpublic static void main(String[] args) {\n\t\tstep1:\n\t\tfor (int i = 0; i < 3; i++) {\n\t\t\tSystem.out.println(\"I is \" + i);\n\t\t\tfor (int j = 0; j < 3; j++) {\n\t\t\t\tif (j == i) {\n\t\t\t\t\tSystem.out.println(\"\tJ is \" + j);\n\t\t\t\t\tcontinue step1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```","source":"_posts/JavaSE/java小常识.md","raw":"category: JavaSE\ndate: 2015-11-19\ntitle: Java 常用技能\n---\n\n## 控制台乱码\n在windows系统里,我的cmd控制台的代码页是`65001(UTF)`,但是当我在指向java命令时却会发生乱码现象,只需要指向`chcp 936`这个命令,改变一下代码页就好了\n\n## java命令\n`java  -jar ./tools-1.0-SNAPSHOT.jar` 从某个jar运行, mainfest文件必须指定MainClass属性,如果不指定的话,在运行`java`命令的时候就会产生 xxx.jar中没有主清单属性\n\n`java  -jar ./ App` 从指定的classpath下所有的jar中,寻找App主类运行\n\n## 获取周数\n通过`Calendar`我们可以知道某个日期处于一年中第几周\n```java\nCalendar calendar = Calendar.getInstance();\ncalendar.setTime(new Date());\nSystem.out.println(calendar.get(Calendar.WEEK_OF_YEAR));\n```\n\n## 在Jar包读取文件\n我们使用Maven构建一个工程, 然后在资源目录(resources)下放置一个文件input.file, 然后我们写一个测试类\n```java\npublic class Test {\n\n    public static void main(String[] args) throws InterruptedException, IOException {\n        InputStream in = Test.class.getResourceAsStream(\"input.file\");\n        BufferedReader reader = new BufferedReader((new InputStreamReader(in)));\n        System.out.println(reader.readLine());\n    }\n}\n```\n在Idea里运行该程序, 可以成功看到input.file文件里的hi, how are you?的输出. 这是因为idea将resources设置在了cleasspath里, 而类加载器的`getResourceAsStream()`就是从classpath中进行文件查找, 因此可以找到的.\n\n而当我们将测试工程打包, 然后在target下执行命令\n```java\njava -cp .;./* Test\n```\n同样可以看到输出, 这是因为`getResourceAsStream()`会在jar包内部进行文件查找\n\n> 注意: 如果想要在jar内加载文件的话, 只能使用类加载器的`getResourceAsStream()`方法\n\n## 便利jar包中文件\n我们知道我们可以使用`ClassLoader`的`getResourceAsStream()`读取jar包中的文件, 那么如何知道jar包中有哪些文件, 也就是如何便利jar包中的文件呢？\n```java\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\t\tJarFile jar = new JarFile(\"D:\\\\premain\\\\target\\\\agent-1.0-SNAPSHOT.jar\");\n\t\tEnumeration<JarEntry> jarEntrys = jar.entries();\n\t\twhile (jarEntrys.hasMoreElements()) {\n\t\t\tJarEntry jarEntry = jarEntrys.nextElement();\n\t\t\tSystem.out.println(jarEntry.getName());\n\t\t}\n\t}\n}\n```\n## goto\n```java\npublic class TestBreak {\n\n\tpublic static void main(String[] args) {\n\t\tstep1:\n\t\tfor (int i = 0; i < 3; i++) {\n\t\t\tSystem.out.println(\"I is \" + i);\n\t\t\tfor (int j = 0; j < 3; j++) {\n\t\t\t\tif (j == i) {\n\t\t\t\t\tSystem.out.println(\"\tJ is \" + j);\n\t\t\t\t\tcontinue step1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```","slug":"JavaSE/java小常识","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq7003cvjs6basbmbca"},{"date":"2014-09-20T16:00:00.000Z","title":"Java URL","_content":"\nJava支持的传输协议：\n* 超文本传输协议: `http://www.baidu.com`\t\t\n* 安全http协议: `https://www.amazon.com/exec/obidos/order2`\n* 文件传输协议: `ftp://metalab.unc.edu/pub/languages/java/javafaq`\n* 简单邮件传输协议: `mailto:elharo@metalab.unc.edu`\n* telnet协议: `telnet://dibner.poly.edu`\n* 本地文件访问协议: `file:`\n* gopher: `gopher://gopher.anc.org.za`\n* 轻量级目录访问协议: `ldap://ldap.itd.umich.edu`\n* jar: `jar://`\n* NFS,网络文件协议: `nfs://utopia.poly.edu/usr/tmp`\n* JDBC 定制协议   通过java.sql包支持: `jdbc:mysql://luna.matalab.unc.edu:3306/NEWS`\n* rmi  远程方法的调用协议   通过java.rmi包支持: `rmi://metalab.unc.edu/RenderEngine`\n* HotJava的定制协议: `doc:/UserGuide/release.html`,`netdoc:/UserGuide/release.html`, `systemresource://www.adc.org/+/index.html`, `verbatim:http://www.adc.org`\n\n\n不带端口构造`URL`(需要注意的是：该构造器生成的URL端口为-1,所以回使用该协议的默认端口   第三个参数加反斜线也是需要注意的)\n```java\nURL url = new URL(\"http\" , \"www.eff.org\", \"/blueribbon.html#intro\");\n```\n\n带端口构造`URL`\n```java\nURL url = new URL(\"http\" , \"www.eff.org\", 8080, \"/blueribbon.html#intro\");\n```\n\n根据相对URL和基础URL构建一个绝对URL,当希望迭代处理位于相同目录下的一组文件时, 可以考虑使用该构造器\n```java\nURL url = new URL(\"http://ibiblio.org/javafaq/index.html\");\nURL newURL = new URL(url, \"mailinglists.html\");\nAssert.assertEquals(\"http://ibiblio.org/javafaq/mailinglists.html\", newURL.toString());\n```\n\n利用ClassLoader可以加载资源,例如图片 音频等\n```java\nURL url = ClassLoader.getSystemResource(\"resource/simple.txt\");\nAssert.assertEquals(null, url);\n```\n\n利用ClassLoader可以加载资源,例如图片 音频等\n```java\nURL url = getClass().getResource(\"resource/simple.txt\");\nAssert.assertEquals(null, url);\n```\n\n查看URL中的模式\n```java\nURL url = new URL(\"http://ibiblio.org/javafaq/index.html\");\nAssert.assertEquals(\"http\", url.getProtocol());\nURL url = new URL(\"http://www.ibiblio.org/javafaq/index.html\");\nAssert.assertEquals(\"www.ibiblio.org\", url.getHost());\n```\n\n查看URL中的路径 (范围：主机名后面的第一个/ 到片段标示符# 之前) 包含查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"/nywc/compositions.pthml?category=Piano\", url.getFile());\n```\n\n查看URL中的路径 (范围：主机名后面的第一个/ 到片段标示符# 之前)  不包含查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"/nywc/compositions.pthml\", url.getPath());\n```\n\n查看URL中的查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"category=Piano\", url.getQuery());\n```\n\n查看URL中的查询字符串\n```java\nURL url = new URL(\"ftp://mp3:secret@ftp.example.com/c%3a/stuff/mp3\");\nAssert.assertEquals(\"mp3:secret\", url.getUserInfo());\n```\n\n查看URL中的Authority(授权机构,包含用户信息,主机和端口.一般都回返回主机信息,但是不一定包含用户信息和端口)\n```java\nURL url = new URL(\"ftp://mp3:secret@ftp.example.com/c%3a/stuff/mp3\");\nAssert.assertEquals(\"mp3:secret@ftp.example.com\", url.getAuthority());\n```\n\nsameFile 只是简单的测试url中的主机名是否是别名, 需要更细致的测试, sameFile 与 equals的区别是sameFile不考虑标示符儿equals需要考虑标示符\n```java\nURL u1 = new URL(\"http://www.ncsa.uiuc.edu/HTMLPrimer.html#GS\");\nURL u2 = new URL(\"http://www.ncsa.uiuc.edu/HTMLPrimer.html#HD\");\nif(u1.sameFile(u2))\n\tSystem.out.println(u1 + \" is same file with \" + u2);\nelse\n\tSystem.out.println(u1 + \" is not same file with \" + u2);\n```\n\n连接URl所指向的资源.执行客户端和服务器之间任何必要的握手.返回一个可以读取数据的`InputStream`,该流读取文件里的原始内容,不包括任何HTTP首部或者任何与协议有关的信息\n```java\ntry(InputStream in = new URL(\"http://www.baidu.com\").openStream()) {\n\tint c = 0;\n\twhile((c = in.read()) != -1) {\n\tif(c == '<') System.out.println();\n\t\tSystem.out.write(c);\n\t}\n}\n```\n\n`openConnection`打开指定URL的socket,返回URLConnection对象(一个打开网络资源的连接)\n```java\nURLConnection conn = new URL(\"http://www.baidu.com\").openConnection();\ntry(InputStream in = conn.getInputStream()) {\n\tint c = 0;\n\twhile((c = in.read()) != -1) {\n\t\tSystem.out.write(c);\n\t}\n}\n```\n","source":"_posts/JavaSE/java网络 URL.md","raw":"category: JavaSE\ndate: 2014-09-21\ntitle: Java URL\n---\n\nJava支持的传输协议：\n* 超文本传输协议: `http://www.baidu.com`\t\t\n* 安全http协议: `https://www.amazon.com/exec/obidos/order2`\n* 文件传输协议: `ftp://metalab.unc.edu/pub/languages/java/javafaq`\n* 简单邮件传输协议: `mailto:elharo@metalab.unc.edu`\n* telnet协议: `telnet://dibner.poly.edu`\n* 本地文件访问协议: `file:`\n* gopher: `gopher://gopher.anc.org.za`\n* 轻量级目录访问协议: `ldap://ldap.itd.umich.edu`\n* jar: `jar://`\n* NFS,网络文件协议: `nfs://utopia.poly.edu/usr/tmp`\n* JDBC 定制协议   通过java.sql包支持: `jdbc:mysql://luna.matalab.unc.edu:3306/NEWS`\n* rmi  远程方法的调用协议   通过java.rmi包支持: `rmi://metalab.unc.edu/RenderEngine`\n* HotJava的定制协议: `doc:/UserGuide/release.html`,`netdoc:/UserGuide/release.html`, `systemresource://www.adc.org/+/index.html`, `verbatim:http://www.adc.org`\n\n\n不带端口构造`URL`(需要注意的是：该构造器生成的URL端口为-1,所以回使用该协议的默认端口   第三个参数加反斜线也是需要注意的)\n```java\nURL url = new URL(\"http\" , \"www.eff.org\", \"/blueribbon.html#intro\");\n```\n\n带端口构造`URL`\n```java\nURL url = new URL(\"http\" , \"www.eff.org\", 8080, \"/blueribbon.html#intro\");\n```\n\n根据相对URL和基础URL构建一个绝对URL,当希望迭代处理位于相同目录下的一组文件时, 可以考虑使用该构造器\n```java\nURL url = new URL(\"http://ibiblio.org/javafaq/index.html\");\nURL newURL = new URL(url, \"mailinglists.html\");\nAssert.assertEquals(\"http://ibiblio.org/javafaq/mailinglists.html\", newURL.toString());\n```\n\n利用ClassLoader可以加载资源,例如图片 音频等\n```java\nURL url = ClassLoader.getSystemResource(\"resource/simple.txt\");\nAssert.assertEquals(null, url);\n```\n\n利用ClassLoader可以加载资源,例如图片 音频等\n```java\nURL url = getClass().getResource(\"resource/simple.txt\");\nAssert.assertEquals(null, url);\n```\n\n查看URL中的模式\n```java\nURL url = new URL(\"http://ibiblio.org/javafaq/index.html\");\nAssert.assertEquals(\"http\", url.getProtocol());\nURL url = new URL(\"http://www.ibiblio.org/javafaq/index.html\");\nAssert.assertEquals(\"www.ibiblio.org\", url.getHost());\n```\n\n查看URL中的路径 (范围：主机名后面的第一个/ 到片段标示符# 之前) 包含查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"/nywc/compositions.pthml?category=Piano\", url.getFile());\n```\n\n查看URL中的路径 (范围：主机名后面的第一个/ 到片段标示符# 之前)  不包含查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"/nywc/compositions.pthml\", url.getPath());\n```\n\n查看URL中的查询字符串\n```java\nURL url = new URL(\"http://ibiblio.org/nywc/compositions.pthml?category=Piano\");\nAssert.assertEquals(\"category=Piano\", url.getQuery());\n```\n\n查看URL中的查询字符串\n```java\nURL url = new URL(\"ftp://mp3:secret@ftp.example.com/c%3a/stuff/mp3\");\nAssert.assertEquals(\"mp3:secret\", url.getUserInfo());\n```\n\n查看URL中的Authority(授权机构,包含用户信息,主机和端口.一般都回返回主机信息,但是不一定包含用户信息和端口)\n```java\nURL url = new URL(\"ftp://mp3:secret@ftp.example.com/c%3a/stuff/mp3\");\nAssert.assertEquals(\"mp3:secret@ftp.example.com\", url.getAuthority());\n```\n\nsameFile 只是简单的测试url中的主机名是否是别名, 需要更细致的测试, sameFile 与 equals的区别是sameFile不考虑标示符儿equals需要考虑标示符\n```java\nURL u1 = new URL(\"http://www.ncsa.uiuc.edu/HTMLPrimer.html#GS\");\nURL u2 = new URL(\"http://www.ncsa.uiuc.edu/HTMLPrimer.html#HD\");\nif(u1.sameFile(u2))\n\tSystem.out.println(u1 + \" is same file with \" + u2);\nelse\n\tSystem.out.println(u1 + \" is not same file with \" + u2);\n```\n\n连接URl所指向的资源.执行客户端和服务器之间任何必要的握手.返回一个可以读取数据的`InputStream`,该流读取文件里的原始内容,不包括任何HTTP首部或者任何与协议有关的信息\n```java\ntry(InputStream in = new URL(\"http://www.baidu.com\").openStream()) {\n\tint c = 0;\n\twhile((c = in.read()) != -1) {\n\tif(c == '<') System.out.println();\n\t\tSystem.out.write(c);\n\t}\n}\n```\n\n`openConnection`打开指定URL的socket,返回URLConnection对象(一个打开网络资源的连接)\n```java\nURLConnection conn = new URL(\"http://www.baidu.com\").openConnection();\ntry(InputStream in = conn.getInputStream()) {\n\tint c = 0;\n\twhile((c = in.read()) != -1) {\n\t\tSystem.out.write(c);\n\t}\n}\n```\n","slug":"JavaSE/java网络 URL","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihq9003evjs6qvqulrww"},{"date":"2015-03-08T16:00:00.000Z","title":"ForkJoin框架简介","_content":"## Fork/Join\n\nFork/Join框架是ExecutorService接口的另一种实现,用来解决特殊问题.\nFork/Join框架是用来解决  能够通过分治技术将问题拆分成小任务的  问题.\n\nFork/Join框架 与 执行器框架 的区别在于invokeAll()方法.(线程F)使用Join操作让一个主任务A等待它所创建的子任务B的完成,执行这个任务的线程F称为工作者线程.工作者线程寻找其他仍未被执行的任务,然后开始执行.在执行器框架中,所有的任务必须发送给执行器,在ForkJoin框架中,执行器包含了待执行的方法,任务的控制也是在执行器中执行的\n\n\nFork/Join框架基于以下俩种操作：\n* 分解(Fork) : 当需要将一个任务拆分成若干个小任务时,在框架中执行这些任务\n* 合并(Join) : 当一个主任务等待其创建的更多个子任务的完成执行\n\n\nFork/Join框架的组成\n1. ForkJoinPool  这个实现了ExecutorService接口,并实现了工作窃取算法.它管理工作者线程,并提供任务的状态信息,执行信息\n2. ForkJoinTask\t这个是在ForkJoinPool里执行任务的基类\n3. RecusiveAction\t用于没有返回结果的任务\n4. RecusiveTask\t\t用于有返回结果的任务\n\n\n在使用Fork/Join框架需要注意以下几点：\n1. 任务只能使用fork()/join()操作当作同步机制.如果使用其他的同步机制,工作者线程就不能执行其他(需要同步的)任务.\n2. 任务里不能执行IO操作\n3. 任务不能抛出运行时异常\n\n\nForkJoinPool可以接受Runnable对象或者ForkJoinTask对象.但是当接受Runnable对象的时候,ForkJoinPool不再采用工作窃取算法.同样地当调用ForkJoinPool#invokeALL(),invokeAny()时传进Callable对象也是允许的,但是如此ForkJoinPool也就不再采用工作窃取算法.\n\n## 创建Fork/Join线程池\n\n## 取消任务\nForkJoinTask 提供的cancel()方法允许取消一个仍没有被执行的任务.如果任务已经执行,那么调用cancel()方法也无法取消.ForkJoin框架的局限性在于,ForkJoinPool线程池里的任务不允许被取消.为了克服这种局限性,我们将ForkJoinTask任务存储在TaskManager里.\n\n## 合并任务的结果\n\n## 在任务中抛出异常\n\n## 异步运行任务\n一旦主任务处理完指定文件夹里的所有内容,它将调用join()方法等待发送到线程池里的所以子任务执行完成\n\n* join()方法在主任务中被调用,然后等待任务执行结束,并通过compute()方法返回值.\n* 主任务将所以的子任务结果进行合并,这些子任务发送到线程池中时带有自己的结果列表,\n* 通过调用compute()方法返回这个列表并作为主任务的返回值.\n","source":"_posts/JavaSE/并发 ForkJoin.md","raw":"category: JavaSE\ndate: 2015-03-09\ntitle: ForkJoin框架简介\n---\n## Fork/Join\n\nFork/Join框架是ExecutorService接口的另一种实现,用来解决特殊问题.\nFork/Join框架是用来解决  能够通过分治技术将问题拆分成小任务的  问题.\n\nFork/Join框架 与 执行器框架 的区别在于invokeAll()方法.(线程F)使用Join操作让一个主任务A等待它所创建的子任务B的完成,执行这个任务的线程F称为工作者线程.工作者线程寻找其他仍未被执行的任务,然后开始执行.在执行器框架中,所有的任务必须发送给执行器,在ForkJoin框架中,执行器包含了待执行的方法,任务的控制也是在执行器中执行的\n\n\nFork/Join框架基于以下俩种操作：\n* 分解(Fork) : 当需要将一个任务拆分成若干个小任务时,在框架中执行这些任务\n* 合并(Join) : 当一个主任务等待其创建的更多个子任务的完成执行\n\n\nFork/Join框架的组成\n1. ForkJoinPool  这个实现了ExecutorService接口,并实现了工作窃取算法.它管理工作者线程,并提供任务的状态信息,执行信息\n2. ForkJoinTask\t这个是在ForkJoinPool里执行任务的基类\n3. RecusiveAction\t用于没有返回结果的任务\n4. RecusiveTask\t\t用于有返回结果的任务\n\n\n在使用Fork/Join框架需要注意以下几点：\n1. 任务只能使用fork()/join()操作当作同步机制.如果使用其他的同步机制,工作者线程就不能执行其他(需要同步的)任务.\n2. 任务里不能执行IO操作\n3. 任务不能抛出运行时异常\n\n\nForkJoinPool可以接受Runnable对象或者ForkJoinTask对象.但是当接受Runnable对象的时候,ForkJoinPool不再采用工作窃取算法.同样地当调用ForkJoinPool#invokeALL(),invokeAny()时传进Callable对象也是允许的,但是如此ForkJoinPool也就不再采用工作窃取算法.\n\n## 创建Fork/Join线程池\n\n## 取消任务\nForkJoinTask 提供的cancel()方法允许取消一个仍没有被执行的任务.如果任务已经执行,那么调用cancel()方法也无法取消.ForkJoin框架的局限性在于,ForkJoinPool线程池里的任务不允许被取消.为了克服这种局限性,我们将ForkJoinTask任务存储在TaskManager里.\n\n## 合并任务的结果\n\n## 在任务中抛出异常\n\n## 异步运行任务\n一旦主任务处理完指定文件夹里的所有内容,它将调用join()方法等待发送到线程池里的所以子任务执行完成\n\n* join()方法在主任务中被调用,然后等待任务执行结束,并通过compute()方法返回值.\n* 主任务将所以的子任务结果进行合并,这些子任务发送到线程池中时带有自己的结果列表,\n* 通过调用compute()方法返回这个列表并作为主任务的返回值.\n","slug":"JavaSE/并发 ForkJoin","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihqf003gvjs6gapsiz2i"},{"date":"2016-06-06T16:00:00.000Z","title":"ThreadLocal","_content":"项目中使用了`java.text.SimpleDateFormat`, 但是却将其声明为`static`. 在Oracle的Java API文档中是这样说明的\n```bash\nSynchronization\n\nDate formats are not synchronized. It is recommended to create separate format instances for each thread. If multiple threads access a format concurrently, it must be synchronized externally.\n```\n`Date`对象的format操作并不是同步进行的. 我们应该为每个线程都创建一个`SimpleDateFormat`对象, 或者为format操作进行加锁处理.\n\n那么`ThreadLocal`就可以成为这种场景下的替代方案. 我们看一下替换后的代码\n```java\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Test {\n\n\tprivate static ThreadLocal<byte[]> simpleDateFormatThreadLocal = new ThreadLocal<>();\n\tprivate static AtomicInteger count = new AtomicInteger();\n\n    public static void main(String[] args) throws InterruptedException {\n\t\tfor (int j = 0; j < 5; j++) {\n\t\t\tfor (int i = 0; i < 50; i++) {\n\t\t\t\tThread thread = new Thread(() -> {\n\t\t\t\t\tbyte[] bytes = simpleDateFormatThreadLocal.get();\n\t\t\t\t\tif (bytes == null) {\n\t\t\t\t\t\tbytes = new byte[1024 * 1024 * 3];\n\t\t\t\t\t\tsimpleDateFormatThreadLocal.set(bytes);\n\t\t\t\t\t\tcount.incrementAndGet();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tthread.start();\n\t\t\t\tthread.join();\n\t\t\t}\n\t\t\tSystem.out.println(\"Active Thread Count : \" + Thread.activeCount());\n\t        TimeUnit.MILLISECONDS.sleep(50);\n\t\t}\n\t\tSystem.out.println(\"set count ; \" + count);\n\t}\n}\n```\n我们看到了ThreadLocal的使用很简单, 首先是分配一个ThreadLocal对象, 然后接下来就通关get, set进行操作就ok了\n\n下来看一下ThreadLocal的实现(我们不详细剖析源码, 只是大概看一下流程)\n```java\npublic T get() {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n\t\nThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n\t\nprivate Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n```\n通过上面的源码我们可以看出, 每个和线程相关的数据最终都是保存到了各自的线程对象里, 然后使用`ThreadLocal`作为key存储. \n\n原理我们就简单地说道这里, 在网上有人说, `ThreadLocal`可能会引起内存泄漏, 于是我使用`-Xmx10M -Xms10M -XX:+PrintGC`这几个JVM参数运行上面程序, 结果为\n```bash\n[GC (Allocation Failure)  2048K->905K(9728K), 0.0061875 secs]\n[GC (Allocation Failure)  7854K->7113K(9728K), 0.0011924 secs]\n[GC (Allocation Failure)  7113K->7129K(9728K), 0.0031599 secs]\n[Full GC (Allocation Failure)  7129K->873K(9728K), 0.0409086 secs]\n[GC (Allocation Failure)  7140K->7081K(9728K), 0.0311850 secs]\n[Full GC (Ergonomics)  7081K->1024K(9728K), 0.0355878 secs]\n[GC (Allocation Failure)  4150K->4128K(9728K), 0.0130218 secs]\n[GC (Allocation Failure)  4128K->4128K(8704K), 0.0009429 secs]\n[Full GC (Allocation Failure)  4128K->872K(8704K), 0.0158858 secs]\n[GC (Allocation Failure)  7057K->7112K(9216K), 0.0064885 secs]\n[Full GC (Ergonomics)  7112K->872K(9216K), 0.0088626 secs]\n[GC (Allocation Failure)  7057K->7112K(9216K), 0.0037829 secs]\n[Full GC (Ergonomics)  7112K->872K(9216K), 0.0174345 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0180387 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0508169 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0088642 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0328227 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0008523 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0093823 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0024455 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0128421 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0021433 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0258585 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0103034 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0180950 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0039267 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0271081 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0034688 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0447428 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0305456 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0096426 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0235708 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0158089 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0047044 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0751059 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0263666 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0258460 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0007790 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0045719 secs]\n[GC (Allocation Failure)  7057K->7048K(9728K), 0.0104715 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.0954287 secs]\n[GC (Allocation Failure)  7077K->7048K(9216K), 0.0019624 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0063389 secs]\n[GC (Allocation Failure)  7077K->7048K(9728K), 0.0005325 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.0049442 secs]\n[GC (Allocation Failure)  7098K->7048K(9728K), 0.0689382 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.1766215 secs]\n[GC (Allocation Failure)  7098K->7048K(9728K), 0.0874764 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.1878922 secs]\n[GC (Allocation Failure)  7098K->7080K(9728K), 0.0003881 secs]\n[Full GC (Ergonomics)  7080K->872K(9728K), 0.0051255 secs]\n[GC (Allocation Failure)  7098K->7080K(9728K), 0.0024052 secs]\n[Full GC (Ergonomics)  7080K->872K(9728K), 0.0169504 secs]\nActive Thread Count : 2\n\n......\n\n[GC (Allocation Failure)  7099K->7082K(9728K), 0.0032137 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0046686 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002209 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041828 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0082536 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0078358 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002834 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041227 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0014373 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0061177 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0002350 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0037189 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0001963 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0053307 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0101613 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0134271 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0004623 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0164586 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002421 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0131758 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0002529 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0060754 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0077007 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0065586 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0026729 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041649 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0004726 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0085271 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0010665 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0058990 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0022381 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0074711 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0006106 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0066310 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0005725 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0055843 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0002894 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0209747 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0002878 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0034925 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0003256 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0057511 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0003378 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0037080 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0001761 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0040176 secs]\n[GC (Allocation Failure)  7120K->7050K(9728K), 0.0005024 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0051379 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0021276 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0060047 secs]\nActive Thread Count : 2\nset count ; 250\n```\n由于篇幅的原因, 我并没有将全部的日志输出, 但是通过上面的日志我们还是可以看出, 随着线程运行的结束, 分配到线程里的对象也被GC掉了, 因此对`ThreadLocal`的一个简单应用, 只要我们写的线程代码没有问题, 我们并不需要对内存泄漏担心太多.","source":"_posts/JavaSE/并发 ThreadLocal.md","raw":"category: JavaSE\ndate: 2016-06-07\ntitle: ThreadLocal\n---\n项目中使用了`java.text.SimpleDateFormat`, 但是却将其声明为`static`. 在Oracle的Java API文档中是这样说明的\n```bash\nSynchronization\n\nDate formats are not synchronized. It is recommended to create separate format instances for each thread. If multiple threads access a format concurrently, it must be synchronized externally.\n```\n`Date`对象的format操作并不是同步进行的. 我们应该为每个线程都创建一个`SimpleDateFormat`对象, 或者为format操作进行加锁处理.\n\n那么`ThreadLocal`就可以成为这种场景下的替代方案. 我们看一下替换后的代码\n```java\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Test {\n\n\tprivate static ThreadLocal<byte[]> simpleDateFormatThreadLocal = new ThreadLocal<>();\n\tprivate static AtomicInteger count = new AtomicInteger();\n\n    public static void main(String[] args) throws InterruptedException {\n\t\tfor (int j = 0; j < 5; j++) {\n\t\t\tfor (int i = 0; i < 50; i++) {\n\t\t\t\tThread thread = new Thread(() -> {\n\t\t\t\t\tbyte[] bytes = simpleDateFormatThreadLocal.get();\n\t\t\t\t\tif (bytes == null) {\n\t\t\t\t\t\tbytes = new byte[1024 * 1024 * 3];\n\t\t\t\t\t\tsimpleDateFormatThreadLocal.set(bytes);\n\t\t\t\t\t\tcount.incrementAndGet();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tthread.start();\n\t\t\t\tthread.join();\n\t\t\t}\n\t\t\tSystem.out.println(\"Active Thread Count : \" + Thread.activeCount());\n\t        TimeUnit.MILLISECONDS.sleep(50);\n\t\t}\n\t\tSystem.out.println(\"set count ; \" + count);\n\t}\n}\n```\n我们看到了ThreadLocal的使用很简单, 首先是分配一个ThreadLocal对象, 然后接下来就通关get, set进行操作就ok了\n\n下来看一下ThreadLocal的实现(我们不详细剖析源码, 只是大概看一下流程)\n```java\npublic T get() {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n\t\nThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n\t\nprivate Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n```\n通过上面的源码我们可以看出, 每个和线程相关的数据最终都是保存到了各自的线程对象里, 然后使用`ThreadLocal`作为key存储. \n\n原理我们就简单地说道这里, 在网上有人说, `ThreadLocal`可能会引起内存泄漏, 于是我使用`-Xmx10M -Xms10M -XX:+PrintGC`这几个JVM参数运行上面程序, 结果为\n```bash\n[GC (Allocation Failure)  2048K->905K(9728K), 0.0061875 secs]\n[GC (Allocation Failure)  7854K->7113K(9728K), 0.0011924 secs]\n[GC (Allocation Failure)  7113K->7129K(9728K), 0.0031599 secs]\n[Full GC (Allocation Failure)  7129K->873K(9728K), 0.0409086 secs]\n[GC (Allocation Failure)  7140K->7081K(9728K), 0.0311850 secs]\n[Full GC (Ergonomics)  7081K->1024K(9728K), 0.0355878 secs]\n[GC (Allocation Failure)  4150K->4128K(9728K), 0.0130218 secs]\n[GC (Allocation Failure)  4128K->4128K(8704K), 0.0009429 secs]\n[Full GC (Allocation Failure)  4128K->872K(8704K), 0.0158858 secs]\n[GC (Allocation Failure)  7057K->7112K(9216K), 0.0064885 secs]\n[Full GC (Ergonomics)  7112K->872K(9216K), 0.0088626 secs]\n[GC (Allocation Failure)  7057K->7112K(9216K), 0.0037829 secs]\n[Full GC (Ergonomics)  7112K->872K(9216K), 0.0174345 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0180387 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0508169 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0088642 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0328227 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0008523 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0093823 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0024455 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0128421 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0021433 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0258585 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0103034 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0180950 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0039267 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0271081 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0034688 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0447428 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0305456 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0096426 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0235708 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0158089 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0047044 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0751059 secs]\n[GC (Allocation Failure)  7057K->7048K(9216K), 0.0263666 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0258460 secs]\n[GC (Allocation Failure)  7057K->7080K(9216K), 0.0007790 secs]\n[Full GC (Ergonomics)  7080K->872K(9216K), 0.0045719 secs]\n[GC (Allocation Failure)  7057K->7048K(9728K), 0.0104715 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.0954287 secs]\n[GC (Allocation Failure)  7077K->7048K(9216K), 0.0019624 secs]\n[Full GC (Ergonomics)  7048K->872K(9216K), 0.0063389 secs]\n[GC (Allocation Failure)  7077K->7048K(9728K), 0.0005325 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.0049442 secs]\n[GC (Allocation Failure)  7098K->7048K(9728K), 0.0689382 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.1766215 secs]\n[GC (Allocation Failure)  7098K->7048K(9728K), 0.0874764 secs]\n[Full GC (Ergonomics)  7048K->872K(9728K), 0.1878922 secs]\n[GC (Allocation Failure)  7098K->7080K(9728K), 0.0003881 secs]\n[Full GC (Ergonomics)  7080K->872K(9728K), 0.0051255 secs]\n[GC (Allocation Failure)  7098K->7080K(9728K), 0.0024052 secs]\n[Full GC (Ergonomics)  7080K->872K(9728K), 0.0169504 secs]\nActive Thread Count : 2\n\n......\n\n[GC (Allocation Failure)  7099K->7082K(9728K), 0.0032137 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0046686 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002209 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041828 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0082536 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0078358 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002834 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041227 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0014373 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0061177 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0002350 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0037189 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0001963 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0053307 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0101613 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0134271 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0004623 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0164586 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0002421 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0131758 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0002529 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0060754 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0077007 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0065586 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0026729 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0041649 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0004726 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0085271 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0010665 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0058990 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0022381 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0074711 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0006106 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0066310 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0005725 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0055843 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0002894 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0209747 secs]\n[GC (Allocation Failure)  7100K->7114K(9728K), 0.0002878 secs]\n[Full GC (Ergonomics)  7114K->874K(9728K), 0.0034925 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0003256 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0057511 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0003378 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0037080 secs]\n[GC (Allocation Failure)  7100K->7050K(9728K), 0.0001761 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0040176 secs]\n[GC (Allocation Failure)  7120K->7050K(9728K), 0.0005024 secs]\n[Full GC (Ergonomics)  7050K->874K(9728K), 0.0051379 secs]\n[GC (Allocation Failure)  7100K->7082K(9728K), 0.0021276 secs]\n[Full GC (Ergonomics)  7082K->874K(9728K), 0.0060047 secs]\nActive Thread Count : 2\nset count ; 250\n```\n由于篇幅的原因, 我并没有将全部的日志输出, 但是通过上面的日志我们还是可以看出, 随着线程运行的结束, 分配到线程里的对象也被GC掉了, 因此对`ThreadLocal`的一个简单应用, 只要我们写的线程代码没有问题, 我们并不需要对内存泄漏担心太多.","slug":"JavaSE/并发 ThreadLocal","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihqi003ivjs62rz9jrea"},{"date":"2015-03-11T16:00:00.000Z","title":"线程同步辅助类","_content":"\n## 在集合点的同步\nCyclicBarrier使用一个整数进行初始化,这个数是需要在某个点上同步线程数.当线程完成工作,它可以调用await()方法等待其他线程.当最后一个线程完成工作调用await()方法时,CyclicBarrier将唤醒所有等待的线程,然后这些线程将继续执行\n\n还有一点值得说明的是：可以在CyclicBarrier的构造参数里传入Runnable对象.当所有线程都达到集合点后,CyclicBarrier将这个Runnable对象作为线程执行.\n\nCyclicBarrier还有一种await()方式,就是指定结束时间点.\n如果CyclicBarrier的内部计数器不为0,但是时间到后,就可以唤醒现在被中断的线程\n\n可以通过reset()方法重置CyclicBarrier\n\n如果已经在阻塞的线程,被其他的线程中断了,CyclicBarrier将会抛出BrokenBarrierException状态\n可以通过isBroken()来检查CyclicBarrier是否处于Broken状态\n\n## 并发任务间的数据交换\n\n## 并发阶段任务中的阶段切换\n\n## 并发阶段任务的运行\nPhaser提供了onAdvance()方法,它在phaser阶段改变的时候会自动运行.\nPhaser允许执行并发任务多阶段任务.在每一步结束的位置进行同步,当所有线程都完成了这一步,才允许执行下一步\n\nnew Phaser(3),初始化3个线程参与的Phaser对象.个数字通知Phaser对象在唤醒所以休眠线程以进行下一个阶段之前,须执行arriveAndAwaitAdvance()的次数\n\nPhaser有俩种状态：\n1.活跃态. 当存在参与同步的线程的时候,Phaser对象就是活跃的,并且在每个阶段结束的时候进行同步\n2.终止态. 当所有参与同步的线程都取消注册的时候,Phaser就处于终止状态,在这种状态下,Phaser没有任何参与者当Phaser对象的onAdvance()方法返回true,Phaser就处于终止态.覆盖通过onAdvance()方法可以改变默认的行为,当Phaser处于终止态,同步方法arriveAndAwaitAdvance()会立即返回,而且不会做任何同步的操作\n\narriveAndAwaitAdvance() Phaser对象计数器减一,并且把这个线程置为休眠状态,直到其他线程完成了这个阶段arriveAndDeregister()  通知Phaser对象,当前线程已经完成了当前任务,并且不会在下一个阶段中参与,因而Phaser对象在开始下一个阶段不会等待这个线程\n\narrive()\nawaitAdvance(phase)\nawaitAdvanceInterruptibly(phase)\nregister()\nbulkRegister(parties)\n\n## 等待多个并发事件的完成\nCountDownLatch是一个同步辅助类. 在完成一组正在其他线程执行的操作之前,它允许线程一直等待.\n\n该类使用一个整数初始化,这个整数就是线程要等待完成的操作数目.\n\n当一个线程要等待某些操作先执行时,需要调用await()方法,这个方法让线程进行睡眠,直到所有的操作都完成\n\n当某一个操作完成后,他它将调用countDown(),将CountDownLatch里的计数器减一.\n\n当计数器为0时,CountDownLatch将唤醒所有调用await()方法而进入休眠的线程\n\nCountDownLatch对象内部的计数器被初始化之后就不能再次初始化或者修改. 而且当计数器为0后也不能在调用countDown()方法\n\n对比同步方法 1.CountDownLatch不是用来保护共享资源或者临界区的.它是用来同步执行多个任务的一个或者多个线程\n2.CountDownLatch只准许进入一次\n,一旦CountDownLatch的内部计数器为0,就不可再调用countDown(),如果想要做类似的同步,必须再重新创建一个对象\n\n## 资源的多副本的并发访问控制\n\n## 资源的并发访问控制\n\n\n本例中使用Semaphore来实现二进制信号量(一种特殊信号量,用来保护唯一共享资源的访问).\n本例使用了Java提供的信号量机制.信号量是一种计数器,用来保护一个或者多个共享资源的访问.\n\n如果线程要访问一个共享资源,它必须首先获得它的信号量(内含计数器C).C > 0 --> C--,然后允许线程访问该共享变量(C>0 有可用资源,线程被允许使用其中一个资源)C== 0 --> 信号量将线程置为睡眠,直至C<0(C=0, 所以的共享资源都被其他线程使用了,以想要访问该共享资源的线程必须等待).\n\n当线程使用完某个共享资源,信号量必须被释放(C++),以便其他的线程能够访问共享资源.\n\n获取信号量\n1.acquire()\n2.acqu\n","source":"_posts/JavaSE/并发 线程同步辅助类.md","raw":"category: JavaSE\ndate: 2015-03-12\ntitle: 线程同步辅助类\n---\n\n## 在集合点的同步\nCyclicBarrier使用一个整数进行初始化,这个数是需要在某个点上同步线程数.当线程完成工作,它可以调用await()方法等待其他线程.当最后一个线程完成工作调用await()方法时,CyclicBarrier将唤醒所有等待的线程,然后这些线程将继续执行\n\n还有一点值得说明的是：可以在CyclicBarrier的构造参数里传入Runnable对象.当所有线程都达到集合点后,CyclicBarrier将这个Runnable对象作为线程执行.\n\nCyclicBarrier还有一种await()方式,就是指定结束时间点.\n如果CyclicBarrier的内部计数器不为0,但是时间到后,就可以唤醒现在被中断的线程\n\n可以通过reset()方法重置CyclicBarrier\n\n如果已经在阻塞的线程,被其他的线程中断了,CyclicBarrier将会抛出BrokenBarrierException状态\n可以通过isBroken()来检查CyclicBarrier是否处于Broken状态\n\n## 并发任务间的数据交换\n\n## 并发阶段任务中的阶段切换\n\n## 并发阶段任务的运行\nPhaser提供了onAdvance()方法,它在phaser阶段改变的时候会自动运行.\nPhaser允许执行并发任务多阶段任务.在每一步结束的位置进行同步,当所有线程都完成了这一步,才允许执行下一步\n\nnew Phaser(3),初始化3个线程参与的Phaser对象.个数字通知Phaser对象在唤醒所以休眠线程以进行下一个阶段之前,须执行arriveAndAwaitAdvance()的次数\n\nPhaser有俩种状态：\n1.活跃态. 当存在参与同步的线程的时候,Phaser对象就是活跃的,并且在每个阶段结束的时候进行同步\n2.终止态. 当所有参与同步的线程都取消注册的时候,Phaser就处于终止状态,在这种状态下,Phaser没有任何参与者当Phaser对象的onAdvance()方法返回true,Phaser就处于终止态.覆盖通过onAdvance()方法可以改变默认的行为,当Phaser处于终止态,同步方法arriveAndAwaitAdvance()会立即返回,而且不会做任何同步的操作\n\narriveAndAwaitAdvance() Phaser对象计数器减一,并且把这个线程置为休眠状态,直到其他线程完成了这个阶段arriveAndDeregister()  通知Phaser对象,当前线程已经完成了当前任务,并且不会在下一个阶段中参与,因而Phaser对象在开始下一个阶段不会等待这个线程\n\narrive()\nawaitAdvance(phase)\nawaitAdvanceInterruptibly(phase)\nregister()\nbulkRegister(parties)\n\n## 等待多个并发事件的完成\nCountDownLatch是一个同步辅助类. 在完成一组正在其他线程执行的操作之前,它允许线程一直等待.\n\n该类使用一个整数初始化,这个整数就是线程要等待完成的操作数目.\n\n当一个线程要等待某些操作先执行时,需要调用await()方法,这个方法让线程进行睡眠,直到所有的操作都完成\n\n当某一个操作完成后,他它将调用countDown(),将CountDownLatch里的计数器减一.\n\n当计数器为0时,CountDownLatch将唤醒所有调用await()方法而进入休眠的线程\n\nCountDownLatch对象内部的计数器被初始化之后就不能再次初始化或者修改. 而且当计数器为0后也不能在调用countDown()方法\n\n对比同步方法 1.CountDownLatch不是用来保护共享资源或者临界区的.它是用来同步执行多个任务的一个或者多个线程\n2.CountDownLatch只准许进入一次\n,一旦CountDownLatch的内部计数器为0,就不可再调用countDown(),如果想要做类似的同步,必须再重新创建一个对象\n\n## 资源的多副本的并发访问控制\n\n## 资源的并发访问控制\n\n\n本例中使用Semaphore来实现二进制信号量(一种特殊信号量,用来保护唯一共享资源的访问).\n本例使用了Java提供的信号量机制.信号量是一种计数器,用来保护一个或者多个共享资源的访问.\n\n如果线程要访问一个共享资源,它必须首先获得它的信号量(内含计数器C).C > 0 --> C--,然后允许线程访问该共享变量(C>0 有可用资源,线程被允许使用其中一个资源)C== 0 --> 信号量将线程置为睡眠,直至C<0(C=0, 所以的共享资源都被其他线程使用了,以想要访问该共享资源的线程必须等待).\n\n当线程使用完某个共享资源,信号量必须被释放(C++),以便其他的线程能够访问共享资源.\n\n获取信号量\n1.acquire()\n2.acqu\n","slug":"JavaSE/并发 线程同步辅助类","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihqs003kvjs6e5nt1die"},{"date":"2015-03-14T16:00:00.000Z","title":"线程执行器原理","_content":"\n## Executor\n我们首先从`Executor`接口看起.\n\n`Executor`定义了执行`Runnable`类型任务的接口. 这个接口实现了对任务的提交和执行(包含任务的线程执行细节以及线程调度等等)的解耦.\n\n`Executor`接口一般不会显式地创建线程(例如`new Thread(new(RunnableTask())).start()`), 而是会采取如下方式\n```java\nExecutor executor = <em>anExecutor</em>;\nexecutor.execute(new RunnableTask1());\nexecutor.execute(new RunnableTask2());\n```\n在`Executor`接口中并没有强制要求, 任务的执行必须是异步的, 因此在`Executor`接口的最简单实现中, 我们可以直接在调用线程中执行任务, 例如\n```java\nclass DirectExecutor implements Executor {\n public void execute(Runnable r) {\n   r.run();\n }\n}}\n```\n但是在一般情况下, 任务会在非调用线程中执行, 例如\n```java\nclass SerialExecutor implements Executor {\n final Queue<Runnable> tasks = new ArrayDeque<Runnable>();\n final Executor executor;\n Runnable active;\n\n SerialExecutor(Executor executor) {\n   this.executor = executor;\n }\n\n public synchronized void execute(final Runnable r) {\n   tasks.offer(new Runnable() {\n     public void run() {\n       try {\n         r.run();\n       } finally {\n         scheduleNext();\n       }\n     }\n   });\n   if (active == null) {\n     scheduleNext();\n   }\n }\n\n protected synchronized void scheduleNext() {\n   if ((active = tasks.poll()) != null) {\n     executor.execute(active);\n   }\n }\n}\n```\n\n> 内存一致性影响:\n\n## ExecutorService\n","source":"_posts/JavaSE/并发 线程执行器原理.md","raw":"category: JavaSE\ndate: 2015-03-15\ntitle: 线程执行器原理\n---\n\n## Executor\n我们首先从`Executor`接口看起.\n\n`Executor`定义了执行`Runnable`类型任务的接口. 这个接口实现了对任务的提交和执行(包含任务的线程执行细节以及线程调度等等)的解耦.\n\n`Executor`接口一般不会显式地创建线程(例如`new Thread(new(RunnableTask())).start()`), 而是会采取如下方式\n```java\nExecutor executor = <em>anExecutor</em>;\nexecutor.execute(new RunnableTask1());\nexecutor.execute(new RunnableTask2());\n```\n在`Executor`接口中并没有强制要求, 任务的执行必须是异步的, 因此在`Executor`接口的最简单实现中, 我们可以直接在调用线程中执行任务, 例如\n```java\nclass DirectExecutor implements Executor {\n public void execute(Runnable r) {\n   r.run();\n }\n}}\n```\n但是在一般情况下, 任务会在非调用线程中执行, 例如\n```java\nclass SerialExecutor implements Executor {\n final Queue<Runnable> tasks = new ArrayDeque<Runnable>();\n final Executor executor;\n Runnable active;\n\n SerialExecutor(Executor executor) {\n   this.executor = executor;\n }\n\n public synchronized void execute(final Runnable r) {\n   tasks.offer(new Runnable() {\n     public void run() {\n       try {\n         r.run();\n       } finally {\n         scheduleNext();\n       }\n     }\n   });\n   if (active == null) {\n     scheduleNext();\n   }\n }\n\n protected synchronized void scheduleNext() {\n   if ((active = tasks.poll()) != null) {\n     executor.execute(active);\n   }\n }\n}\n```\n\n> 内存一致性影响:\n\n## ExecutorService\n","slug":"JavaSE/并发 线程执行器原理","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihqu003mvjs643dutwr7"},{"date":"2015-03-17T16:00:00.000Z","title":"线程执行器应用","_content":"\n* 创建固定大小的线程执行器\n* 创建线程执行器\n* 在执行器中分离任务的启动与结果的处理\n* 在执行器中取消任务\n* 在执行器中周期执行任务\n* 在执行器中延迟执行任务\n* 运行并发任务并返回结果\n* 在执行器中控制任务的完成\n* 处理在执行器中被拒绝的任务\n* 运行多个任务并处理所有结果\n* 运行多个任务并处理第一个结果\n\n## 在执行器中延迟执行任务\n```java\n// 创建执行器线程数量最大为1的执行器\nScheduledExecutorService executor = Executors.newScheduledThreadPool(1);\n\nSystem.out.println(\"start:\" + new Date());\n\nfor (int i = 0; i < 5; i++) {\n\t// 每个线程延迟i + 1秒执行\n\texecutor.schedule(() -> {\n\t\tSystem.out.println(new Date());\n\t\treturn \"finish\";\n\t}, i + 1, TimeUnit.SECONDS);\n}\n\n// 在默认的情况下,调用shutdown()之后不论执行器是否结束,待处理的任务仍将被执行\nexecutor.shutdown();\n\n// 等待所有任务结束\ntry {\n\texecutor.awaitTermination(1, TimeUnit.DAYS);\n} catch (InterruptedException e) {\n\te.printStackTrace();\n}\n\nSystem.out.println(\"end:\" + new Date());\n```\n\n## 运行并发任务并返回结果\nCallable 接口声明了call()方法,可以在这个方法里实现任务的具体逻辑\n\n1.控制任务状态,可以取消任务和检查任务是否完成.(通过isDone()检查任务是否完成)\n2.使用get()方法获取call()方法返回的结果,这个方法一直等到call()方法执行完成并返回结果.   如果在等待过程中线程中断了,则抛出一个InterruptedException 如果call()方法抛出异常,get()则抛出ExecutionException\n","source":"_posts/JavaSE/并发 线程执行器应用.md","raw":"category: JavaSE\ndate: 2015-03-18\ntitle: 线程执行器应用\n---\n\n* 创建固定大小的线程执行器\n* 创建线程执行器\n* 在执行器中分离任务的启动与结果的处理\n* 在执行器中取消任务\n* 在执行器中周期执行任务\n* 在执行器中延迟执行任务\n* 运行并发任务并返回结果\n* 在执行器中控制任务的完成\n* 处理在执行器中被拒绝的任务\n* 运行多个任务并处理所有结果\n* 运行多个任务并处理第一个结果\n\n## 在执行器中延迟执行任务\n```java\n// 创建执行器线程数量最大为1的执行器\nScheduledExecutorService executor = Executors.newScheduledThreadPool(1);\n\nSystem.out.println(\"start:\" + new Date());\n\nfor (int i = 0; i < 5; i++) {\n\t// 每个线程延迟i + 1秒执行\n\texecutor.schedule(() -> {\n\t\tSystem.out.println(new Date());\n\t\treturn \"finish\";\n\t}, i + 1, TimeUnit.SECONDS);\n}\n\n// 在默认的情况下,调用shutdown()之后不论执行器是否结束,待处理的任务仍将被执行\nexecutor.shutdown();\n\n// 等待所有任务结束\ntry {\n\texecutor.awaitTermination(1, TimeUnit.DAYS);\n} catch (InterruptedException e) {\n\te.printStackTrace();\n}\n\nSystem.out.println(\"end:\" + new Date());\n```\n\n## 运行并发任务并返回结果\nCallable 接口声明了call()方法,可以在这个方法里实现任务的具体逻辑\n\n1.控制任务状态,可以取消任务和检查任务是否完成.(通过isDone()检查任务是否完成)\n2.使用get()方法获取call()方法返回的结果,这个方法一直等到call()方法执行完成并返回结果.   如果在等待过程中线程中断了,则抛出一个InterruptedException 如果call()方法抛出异常,get()则抛出ExecutionException\n","slug":"JavaSE/并发 线程执行器应用","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihqz003ovjs6uqy064p6"},{"date":"2015-03-19T16:00:00.000Z","title":"线程执行器简介","_content":"在生产环境中为每一个任务分配一个线程存在着一些缺陷,尤其是需要创建大量的线程时：\n\n* 线程生命周期的开销非常高 : 线程的创建都需要时间,延迟处理的请求，并且需要JVM和操作系统提供一些辅助操作.如果请求的达到率非常高而且处理的任务都是轻量级的,那么为每一个任务都创建一个线程将消耗大量的资源\n* 资源消耗 : 活跃的线程会消耗资源,尤其是内存。如果可运行的小吃数量多余可用处理器的数量,那么这些线程将闲置。大量的线程闲置会占用许多内存，给垃圾收集器带来压力，而且大量线程在竞争CPU资源时还将产生其他性能开销.\n* 稳定性\n\nExecutor框架为灵活且强大的异步任务执行框架提供了基础,该框架能支持多种不同类型的任务执行策略. 它提供了一种标准的方法将任务的提交过程与执行过程解耦出来，并用Runnable表示任务.Executor框架还提供了对声明周期的支持,\n以及统计信息收集,应用程序管理机制和性能监视等机制.\n\nExecutor基于生产者-消费者模式,提交任务相当于生产者,执行任务相当于消费者.\n\n下来我们看一下异步执行任务\n```java\nclass AsynExecutor implements Executor {\n\t\t@Override\n\t\tpublic void execute(Runnable command) {\n\t\t\tnew Thread(command).start();\n\t\t}\n}\n```\n\n下面的示例是同步执行任务\n```java\nclass SynExecutor implements Executor {\n\t\t@Override\n\t\tpublic void execute(Runnable command) {\n\t\t\tcommand.run();\n\t\t}\n}\n```\n\n下面我们看几种创建线程池快捷方式\n* `newScheduledThreadPool` : 创建一个固定长度的线程池,而且以定时或者延时的方式来执行任务\n* `newCachedThreadPool` : 创建一个可缓存的线程池,如果线程池的规模超过了处理需求时,那么将回收空闲的线程,而当需求增加时,\n则添加新的线程,线程池的规模不受任何限制\n* `newFixedThreadPool` : 创建一个固定长度的线程池,每当提交一个任务时就创建一个线程,直到达到线程池最大数量,这时线程池的规模.不再发生变化,(如果某个线程由于发生了未预期的Exception而结束,则再补充一个新的线程)\n* `newSingleThreadScheduledExecutor`\n* `newSingleThreadExecutor` : 是一个单线程的Executor,它创建单个工作者线程来执行任务,如果这个任务异常结束,会创建另一个线程来代替. 根据FIFO/LIFO/优先级 等策略来顺序化地执行队列中的任务\n\n\n为了解决执行任务的生命周期问题,Executor拓展了ExecutorService接口,添加了一些用于管理生命周期的方法.\n\nExecutorService有三种状态：\n* 运行\n* 关闭\n* 已终止\n\nExecutorService在初始创建时处于运行状态.\n* shutdown 方法将执行平缓的关闭任务：不再接受新的任务，同时等待已经提交的任务等待完成(包括那些还未开始执行的任务)\n* shutdownNow 将粗暴地 执行关闭过程。它将尝试取消所有的运行中的任务，并且不再启动队列中等待执行的任务。\n\n在ExecutorService关闭后提交的任务将由拒绝执行处理器(Rejected Execution handler)来处理.\n\n\n测试在执行器框架中逻辑代码的异常抛出不会影响执行器框架\n```java\n\tpublic static void main(String[] args) {\n\t\tExecutorService exec = Executors.newSingleThreadExecutor();\n\t\tfor (int i = 0; i < 100; i++) {\n\t\t\texec.execute(new R(i));\n\t\t}\n\t}\n\n\tpublic static class R implements Runnable {\n\t\tR(int i) {\n\t\t\tthis.i = i;\n\t\t}\n\t\tint i ;\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tif(i%3 == 0)\n\t\t\t\tthrow new RuntimeException(i + \"\");\n\t\t}\n\t}\n```\n下面是部分结果输出\n```java\nException in thread \"pool-1-thread-1\" java.lang.RuntimeException: 0\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\nException in thread \"pool-1-thread-2\" java.lang.RuntimeException: 3\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\nException in thread \"pool-1-thread-3\" java.lang.RuntimeException: 6\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\n```\n","source":"_posts/JavaSE/并发 线程执行器简介.md","raw":"category: JavaSE\ndate: 2015-03-20\ntitle: 线程执行器简介\n---\n在生产环境中为每一个任务分配一个线程存在着一些缺陷,尤其是需要创建大量的线程时：\n\n* 线程生命周期的开销非常高 : 线程的创建都需要时间,延迟处理的请求，并且需要JVM和操作系统提供一些辅助操作.如果请求的达到率非常高而且处理的任务都是轻量级的,那么为每一个任务都创建一个线程将消耗大量的资源\n* 资源消耗 : 活跃的线程会消耗资源,尤其是内存。如果可运行的小吃数量多余可用处理器的数量,那么这些线程将闲置。大量的线程闲置会占用许多内存，给垃圾收集器带来压力，而且大量线程在竞争CPU资源时还将产生其他性能开销.\n* 稳定性\n\nExecutor框架为灵活且强大的异步任务执行框架提供了基础,该框架能支持多种不同类型的任务执行策略. 它提供了一种标准的方法将任务的提交过程与执行过程解耦出来，并用Runnable表示任务.Executor框架还提供了对声明周期的支持,\n以及统计信息收集,应用程序管理机制和性能监视等机制.\n\nExecutor基于生产者-消费者模式,提交任务相当于生产者,执行任务相当于消费者.\n\n下来我们看一下异步执行任务\n```java\nclass AsynExecutor implements Executor {\n\t\t@Override\n\t\tpublic void execute(Runnable command) {\n\t\t\tnew Thread(command).start();\n\t\t}\n}\n```\n\n下面的示例是同步执行任务\n```java\nclass SynExecutor implements Executor {\n\t\t@Override\n\t\tpublic void execute(Runnable command) {\n\t\t\tcommand.run();\n\t\t}\n}\n```\n\n下面我们看几种创建线程池快捷方式\n* `newScheduledThreadPool` : 创建一个固定长度的线程池,而且以定时或者延时的方式来执行任务\n* `newCachedThreadPool` : 创建一个可缓存的线程池,如果线程池的规模超过了处理需求时,那么将回收空闲的线程,而当需求增加时,\n则添加新的线程,线程池的规模不受任何限制\n* `newFixedThreadPool` : 创建一个固定长度的线程池,每当提交一个任务时就创建一个线程,直到达到线程池最大数量,这时线程池的规模.不再发生变化,(如果某个线程由于发生了未预期的Exception而结束,则再补充一个新的线程)\n* `newSingleThreadScheduledExecutor`\n* `newSingleThreadExecutor` : 是一个单线程的Executor,它创建单个工作者线程来执行任务,如果这个任务异常结束,会创建另一个线程来代替. 根据FIFO/LIFO/优先级 等策略来顺序化地执行队列中的任务\n\n\n为了解决执行任务的生命周期问题,Executor拓展了ExecutorService接口,添加了一些用于管理生命周期的方法.\n\nExecutorService有三种状态：\n* 运行\n* 关闭\n* 已终止\n\nExecutorService在初始创建时处于运行状态.\n* shutdown 方法将执行平缓的关闭任务：不再接受新的任务，同时等待已经提交的任务等待完成(包括那些还未开始执行的任务)\n* shutdownNow 将粗暴地 执行关闭过程。它将尝试取消所有的运行中的任务，并且不再启动队列中等待执行的任务。\n\n在ExecutorService关闭后提交的任务将由拒绝执行处理器(Rejected Execution handler)来处理.\n\n\n测试在执行器框架中逻辑代码的异常抛出不会影响执行器框架\n```java\n\tpublic static void main(String[] args) {\n\t\tExecutorService exec = Executors.newSingleThreadExecutor();\n\t\tfor (int i = 0; i < 100; i++) {\n\t\t\texec.execute(new R(i));\n\t\t}\n\t}\n\n\tpublic static class R implements Runnable {\n\t\tR(int i) {\n\t\t\tthis.i = i;\n\t\t}\n\t\tint i ;\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tif(i%3 == 0)\n\t\t\t\tthrow new RuntimeException(i + \"\");\n\t\t}\n\t}\n```\n下面是部分结果输出\n```java\nException in thread \"pool-1-thread-1\" java.lang.RuntimeException: 0\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\nException in thread \"pool-1-thread-2\" java.lang.RuntimeException: 3\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\nException in thread \"pool-1-thread-3\" java.lang.RuntimeException: 6\n\tat g.TestExecutor$R.run(TestExecutor.java:27)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\n```\n","slug":"JavaSE/并发 线程执行器简介","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihr2003qvjs6xpin2z6w"},{"date":"2015-03-08T16:00:00.000Z","title":"线程管理","_content":"## 线程的创建和运行\n创建一个线程\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tfor (int i = 1; i <= 10; i++) {\n\t\t\tCalculator calculator = new Calculator(i);\n\t\t\tThread thread = new Thread(calculator);\n\t\t\tthread.start();\n\t\t}\n\t}\n}\n\nclass Calculator implements Runnable {\n\n\tprivate int number;\n\n\tpublic Calculator(int number) {\n\t\tthis.number = number;\n\t}\n\n\t@Override\n\tpublic void run() {\n\n\t\tfor (int i = 1; i <= 10; i++) {\n\t\t\tSystem.out.printf(\"%s: %d * %d = %d\\n\", Thread.currentThread()\n\t\t\t\t\t.getName(), number, i, i * number);\n\t\t}\n\t}\n\n}\n```\n\n## 使用工厂类创建线程\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThreadFactory factory = new ThreadFactory() {\n\t\t\t@Override\n\t\t\tpublic Thread newThread(Runnable r) {\n\t\t\t\tThread t = new Thread(r);\n\t\t\t\treturn t;\n\t\t\t}\n\t\t};\n\n\t\tRunnable task = new Runnable() {\n\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(\"1\");\n\t\t\t}\n\t\t};\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tThread thread = factory.newThread(task);\n\t\t\tthread.start();\n\t\t}\n\t}\n}\n```\n\n## 守护线程的创建和运行\n守护线程的优先级很低,通常来说,同一个应用程序中没有其他的线程运行,守护线程才运行. 当守护线程运行结束后,JVM也就结束了这个应用程序\n\n守护线程通常用来作为同一程序中普通线程的服务提供者,因为没有办法确定守护线程什么时候才能获取CPU时钟, 而且在没有其他线程运行的时候,守护线程随时可能会结束\n\n>  一个典型的守护线程就是java的垃圾回收器\n\n`setDeamon()`方法只能在`start()`方法之前被调用,一旦线程开始运行,将不能再修改其状态\n\n> 注: 需要注意的是,只有在没有用户线程运行的时候,而不是没有用户线程存在的时候守护线程才运行. 例如当所有用户线程多沉睡后,也会被视为没有用户线程执行\n\n1. hread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。\n2. 在Daemon线程中产生的新线程也是Daemon的\n3. 不是所有的应用都可以分配给Daemon线程来进行服务，比如读写操作或者计算逻辑。因为在Daemon Thread还没来的及进行操作时，虚拟机可能已经退出了。\n4. 当用户线程都运行完后,守护线程也就跟着结束了\n\n```java\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tDeameanThread dt = new DeameanThread();\n\t\tNormalThread nt = new NormalThread();\n\t\tnt.start();\n\t\tdt.start();\n\t\tSystem.out.println(\"main\");\n\t}\n}\n\nclass NormalThread extends Thread {\n\tNormalThread() {\n\t\tsetDaemon(false);\n\t}\n\t@Override\n\tpublic void run() {\n\t\tlong old = System.currentTimeMillis();\n\t\twhile((System.currentTimeMillis() - old) < 3000) {}\n\t\tSystem.out.println(\"NormalThread\");\n\t}\n}\n\nclass DeameanThread extends Thread {\n\tDeameanThread() {\n\t\tsetDaemon(true);\n\t}\n\t@Override\n\tpublic void run() {\n\t\twhile(true){}\n\t}\n}\n\n```\n\n## 线程中断的控制\n\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThread thread = new Thread(new Check());\n\t\tthread.start();\n\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(10);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\tthread.interrupt();\n\t}\n}\n\nclass Check implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\t\ttry {\n\t\t\tcheckProcess();\n\t\t} catch (InterruptedException e) {\n\t\t\tSystem.out.printf(\"%s: Check has been interrupted\", Thread\n\t\t\t\t\t.currentThread().getName());\n\t\t}\n\t}\n\n\tprivate void checkProcess() throws InterruptedException {\n\n\t\twhile(true) {\n\t\t\tString str = System.currentTimeMillis() / 1000 + \"\";\n\t\t\tint last = str.indexOf(str.length() - 1);\n\t\t\tif (last % 2 == 0) {\n\t\t\t\tcheckProcess();\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tSystem.out.println(System.currentTimeMillis());\n\t\t\tif (Thread.interrupted()) {\n\t\t\t\tthrow new InterruptedException();\n\t\t\t}\n\t\t}\n\n\t}\n\n}\n```\n\n## 线程局部变量\nThreead类的join()方法被调用时,调用它的线程将被挂起,直到这个线程对象完成它的任务join(long millseconds)如果使用这种方法,被挂起的线程只要满足指定的毫秒数到,或者join线程运行完,被挂起线程恢复运行\n\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThread dataThread = new Thread(new DataSourcesLoader(), \"Data\");\n\t\tThread netThread = new Thread(new NetworkConnectionsLoader(), \"Network\");\n\n\t\ttry {\n\t\t\tdataThread.start();\n\t\t\tdataThread.join();\n\t\t\tSystem.out.println(\"Network join\");\n\t\t\tnetThread.start();\n\t\t\tnetThread.join();\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\tSystem.out.println(\"Main\");\n\t}\n}\n\nclass DataSourcesLoader implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tSystem.out.println(\"Data run\");\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"Data over\");\n\t}\n}\n\nclass NetworkConnectionsLoader implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tSystem.out.println(\"Network run\");\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"Network over\");\n\t}\n}\n\n```\n\n\n## 线程中断\nJava 提供了中断机制,可以使用中断来结束一个线程.\n\n```java\n/**\n * 使用PrimeGenerator线程生成素数,当主线程sleep 3秒之后,打断PrimeGenerator线程\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\t// 开始执行素数生成器线程\n\t\tThread task = new PrimeGenerator();\n\t\ttask.start();\n\n\t\t// 主线程沉睡5秒\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\t// 打断素数生成器线程\n\t\ttask.interrupt();\n\t\tSystem.out.println(\"PrimeGenerator state : \" + task.getState());\n\t}\n\n}\n\nclass PrimeGenerator extends Thread {\n\n\t@Override\n\tpublic void run() {\n\t\tlong number = 1L;\n\n\t\twhile (true) {\n\t\t\tif (isPrime(number)) {\n\t\t\t\tSystem.out.printf(\"Number %d is Prime\\n\", number);\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * 使用中断来结束一个线程,要求线程检查它是否被中断了,然后决定是否响应这个中断请求.\n\t\t\t * 线程允许忽略中断并继续执行(将if语句注掉就可忽略中断请求)\n\t\t\t */\n\t\t\tif (isInterrupted()) {\n\t\t\t\tSystem.out.printf(\"素数生成器被Interrupte. state: \" + getState());\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tnumber++;\n\t\t}\n\t}\n\n\t/**\n\t * 检查数字是否是素数\n\t */\n\tprivate boolean isPrime(long number) {\n\t\tif (number <= 2) {\n\t\t\treturn true;\n\t\t}\n\t\tfor (long i = 2; i < number; i++) {\n\t\t\tif ((number % i) == 0) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n}\n```\n\n## 线程休眠和恢复\n使用sleep()方法中断线程的运行. sleep()中断线程后,直到CPU时钟来临JVM选中它继续执行的这段期间, 该线程不会占用任何资源\n\nsleep()方法接受整型数值作为参数,以表明线程挂起执行的毫秒数. sleep()还可使用TimeUnit枚举元素来进行调用\n\nyield()方法通知JVM该线程对象可以释放CPU了\n\n```java\n\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\tThread thread = new Thread(new FileClock());\n\t\tthread.start();\n\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t};\n\n\t\t// 发送中断线程\n\t\tSystem.out.println(\"send interrupt\");\n\t\tthread.interrupt();\n\t}\n}\n\nclass FileClock implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tfor (int i = 0; i < 10; i++) {\n\n\t\t\tSystem.out.printf(\"%s\\n\", new Date());\n\t\t\ttry {\n\t\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tSystem.out.println(\"The FileClock has been interrupted : \" + i);\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n## 线程的分组\nJava提供了ThreadGroup类表示一组线程, 线程组可以包含线程对象,可以包含线程组对象,也可以其他线程组对象 它是一个树形结构\n","source":"_posts/JavaSE/并发 线程管理.md","raw":"category: JavaSE\ndate: 2015-03-09\ntitle: 线程管理\n---\n## 线程的创建和运行\n创建一个线程\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tfor (int i = 1; i <= 10; i++) {\n\t\t\tCalculator calculator = new Calculator(i);\n\t\t\tThread thread = new Thread(calculator);\n\t\t\tthread.start();\n\t\t}\n\t}\n}\n\nclass Calculator implements Runnable {\n\n\tprivate int number;\n\n\tpublic Calculator(int number) {\n\t\tthis.number = number;\n\t}\n\n\t@Override\n\tpublic void run() {\n\n\t\tfor (int i = 1; i <= 10; i++) {\n\t\t\tSystem.out.printf(\"%s: %d * %d = %d\\n\", Thread.currentThread()\n\t\t\t\t\t.getName(), number, i, i * number);\n\t\t}\n\t}\n\n}\n```\n\n## 使用工厂类创建线程\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThreadFactory factory = new ThreadFactory() {\n\t\t\t@Override\n\t\t\tpublic Thread newThread(Runnable r) {\n\t\t\t\tThread t = new Thread(r);\n\t\t\t\treturn t;\n\t\t\t}\n\t\t};\n\n\t\tRunnable task = new Runnable() {\n\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(\"1\");\n\t\t\t}\n\t\t};\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tThread thread = factory.newThread(task);\n\t\t\tthread.start();\n\t\t}\n\t}\n}\n```\n\n## 守护线程的创建和运行\n守护线程的优先级很低,通常来说,同一个应用程序中没有其他的线程运行,守护线程才运行. 当守护线程运行结束后,JVM也就结束了这个应用程序\n\n守护线程通常用来作为同一程序中普通线程的服务提供者,因为没有办法确定守护线程什么时候才能获取CPU时钟, 而且在没有其他线程运行的时候,守护线程随时可能会结束\n\n>  一个典型的守护线程就是java的垃圾回收器\n\n`setDeamon()`方法只能在`start()`方法之前被调用,一旦线程开始运行,将不能再修改其状态\n\n> 注: 需要注意的是,只有在没有用户线程运行的时候,而不是没有用户线程存在的时候守护线程才运行. 例如当所有用户线程多沉睡后,也会被视为没有用户线程执行\n\n1. hread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。\n2. 在Daemon线程中产生的新线程也是Daemon的\n3. 不是所有的应用都可以分配给Daemon线程来进行服务，比如读写操作或者计算逻辑。因为在Daemon Thread还没来的及进行操作时，虚拟机可能已经退出了。\n4. 当用户线程都运行完后,守护线程也就跟着结束了\n\n```java\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tDeameanThread dt = new DeameanThread();\n\t\tNormalThread nt = new NormalThread();\n\t\tnt.start();\n\t\tdt.start();\n\t\tSystem.out.println(\"main\");\n\t}\n}\n\nclass NormalThread extends Thread {\n\tNormalThread() {\n\t\tsetDaemon(false);\n\t}\n\t@Override\n\tpublic void run() {\n\t\tlong old = System.currentTimeMillis();\n\t\twhile((System.currentTimeMillis() - old) < 3000) {}\n\t\tSystem.out.println(\"NormalThread\");\n\t}\n}\n\nclass DeameanThread extends Thread {\n\tDeameanThread() {\n\t\tsetDaemon(true);\n\t}\n\t@Override\n\tpublic void run() {\n\t\twhile(true){}\n\t}\n}\n\n```\n\n## 线程中断的控制\n\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThread thread = new Thread(new Check());\n\t\tthread.start();\n\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(10);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\tthread.interrupt();\n\t}\n}\n\nclass Check implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\t\ttry {\n\t\t\tcheckProcess();\n\t\t} catch (InterruptedException e) {\n\t\t\tSystem.out.printf(\"%s: Check has been interrupted\", Thread\n\t\t\t\t\t.currentThread().getName());\n\t\t}\n\t}\n\n\tprivate void checkProcess() throws InterruptedException {\n\n\t\twhile(true) {\n\t\t\tString str = System.currentTimeMillis() / 1000 + \"\";\n\t\t\tint last = str.indexOf(str.length() - 1);\n\t\t\tif (last % 2 == 0) {\n\t\t\t\tcheckProcess();\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tSystem.out.println(System.currentTimeMillis());\n\t\t\tif (Thread.interrupted()) {\n\t\t\t\tthrow new InterruptedException();\n\t\t\t}\n\t\t}\n\n\t}\n\n}\n```\n\n## 线程局部变量\nThreead类的join()方法被调用时,调用它的线程将被挂起,直到这个线程对象完成它的任务join(long millseconds)如果使用这种方法,被挂起的线程只要满足指定的毫秒数到,或者join线程运行完,被挂起线程恢复运行\n\n```java\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\tThread dataThread = new Thread(new DataSourcesLoader(), \"Data\");\n\t\tThread netThread = new Thread(new NetworkConnectionsLoader(), \"Network\");\n\n\t\ttry {\n\t\t\tdataThread.start();\n\t\t\tdataThread.join();\n\t\t\tSystem.out.println(\"Network join\");\n\t\t\tnetThread.start();\n\t\t\tnetThread.join();\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\tSystem.out.println(\"Main\");\n\t}\n}\n\nclass DataSourcesLoader implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tSystem.out.println(\"Data run\");\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"Data over\");\n\t}\n}\n\nclass NetworkConnectionsLoader implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tSystem.out.println(\"Network run\");\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"Network over\");\n\t}\n}\n\n```\n\n\n## 线程中断\nJava 提供了中断机制,可以使用中断来结束一个线程.\n\n```java\n/**\n * 使用PrimeGenerator线程生成素数,当主线程sleep 3秒之后,打断PrimeGenerator线程\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\n\t\t// 开始执行素数生成器线程\n\t\tThread task = new PrimeGenerator();\n\t\ttask.start();\n\n\t\t// 主线程沉睡5秒\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\t// 打断素数生成器线程\n\t\ttask.interrupt();\n\t\tSystem.out.println(\"PrimeGenerator state : \" + task.getState());\n\t}\n\n}\n\nclass PrimeGenerator extends Thread {\n\n\t@Override\n\tpublic void run() {\n\t\tlong number = 1L;\n\n\t\twhile (true) {\n\t\t\tif (isPrime(number)) {\n\t\t\t\tSystem.out.printf(\"Number %d is Prime\\n\", number);\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * 使用中断来结束一个线程,要求线程检查它是否被中断了,然后决定是否响应这个中断请求.\n\t\t\t * 线程允许忽略中断并继续执行(将if语句注掉就可忽略中断请求)\n\t\t\t */\n\t\t\tif (isInterrupted()) {\n\t\t\t\tSystem.out.printf(\"素数生成器被Interrupte. state: \" + getState());\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tnumber++;\n\t\t}\n\t}\n\n\t/**\n\t * 检查数字是否是素数\n\t */\n\tprivate boolean isPrime(long number) {\n\t\tif (number <= 2) {\n\t\t\treturn true;\n\t\t}\n\t\tfor (long i = 2; i < number; i++) {\n\t\t\tif ((number % i) == 0) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n}\n```\n\n## 线程休眠和恢复\n使用sleep()方法中断线程的运行. sleep()中断线程后,直到CPU时钟来临JVM选中它继续执行的这段期间, 该线程不会占用任何资源\n\nsleep()方法接受整型数值作为参数,以表明线程挂起执行的毫秒数. sleep()还可使用TimeUnit枚举元素来进行调用\n\nyield()方法通知JVM该线程对象可以释放CPU了\n\n```java\n\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\tThread thread = new Thread(new FileClock());\n\t\tthread.start();\n\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t};\n\n\t\t// 发送中断线程\n\t\tSystem.out.println(\"send interrupt\");\n\t\tthread.interrupt();\n\t}\n}\n\nclass FileClock implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\n\t\tfor (int i = 0; i < 10; i++) {\n\n\t\t\tSystem.out.printf(\"%s\\n\", new Date());\n\t\t\ttry {\n\t\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tSystem.out.println(\"The FileClock has been interrupted : \" + i);\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n## 线程的分组\nJava提供了ThreadGroup类表示一组线程, 线程组可以包含线程对象,可以包含线程组对象,也可以其他线程组对象 它是一个树形结构\n","slug":"JavaSE/并发 线程管理","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihr4003svjs672ekuzvq"},{"date":"2015-03-09T16:00:00.000Z","title":"JavaSE 锁实现","_content":"# ReadWriteLock\n读写锁只有一个实现ReentrantReadWriteLock(可重入读写锁)\n\n读写锁有俩个锁\n* 读操作锁,使用读操作锁的时候可以允许多个线程同时访问\n* 写操作锁,只允许一个线程运行,即其他线程既不能执行读操作也不能执行写操作\n\n\n# ReentrantLock\n\nJava提供了同步代码块的另一种机制,它比synchronized关键字更加强大也更加灵活. 这种机制基于Lock接口以及其实现类.\n\nLock相比Synchronized：\n1. 更灵活的同步代码块结构.使用synchronized关键字只能在同一个synchronized块结构中获取和释放控制. Lock接口允许实现更复杂的临界区结构.(例如可以在不同的方法中加锁和释放锁)\n2. Lock接口提供了tryLock()方法.这个方法试图获取锁,如果锁已被其他线程获取,它将返回false并继续往下执行代码. 但在使用synchronized关键字时,如果A想要执行一个同步块,但是B恰好在使用她,A就会一直被堵塞到B执行完该同步块\n3. Lock接口允许分离读操作和写操作,允许多个读线程和一个写线程\n4. 而且Lock接口拥有更好的性能\n\nlock(): A尝试获取锁的时候,如果B在执行同步块,A将被锁住,直到B执行完 tryLock():\n\n在本例中我们使用ReentrantLock锁(重入锁)(synchronized本身是支持重入的)\n\nReentrantLock的实现不仅可以替代隐式的synchronized关键字,而且能够提供超过关键字本身的多种功能。这里提到一个锁获取的公平性问题,如果在绝对时间上,先对锁进行获取的请求一定被先满足, 那么这个锁是公平的,反之,是不公平的,也就是说等待时间最长的线程最有机会获取锁,也可以说锁的获取是有序的。\n\nReentrantLock这个锁提供了一个构造函数,能够控制这个锁是否是公平的。而锁的名字也是说明了这个锁具备了重复进入的可能,也就是说能够让当前线程多次的进行对锁的获取操作,\n这样的最大次数限制是Integer.MAX_VALUE,约21亿次左右。\n\n事实上公平的锁机制往往没有非公平的效率高,因为公平的获取锁没有考虑到操作系统对线程的调度因素,这样造成JVM对于等待中的线程调度次序和操作系统对线程的调度之间的不匹配\n\n对于锁的快速且重复的获取过程中,连续获取的概率是非常高的,而公平锁会压制这种情况, 虽然公平性得以保障,但是响应比却下降了,但是并不是任何场景都是以TPS作为唯一指标的,因为公平锁能够减少“饥饿”发生的概率,等待越久的请求越是能够得到优先满足。\n\n```java\npublic class Main {\n\n\tpublic static void main(String args[]) {\n\t\tfinal Lock queueLock = new ReentrantLock();\n\t\tList<Integer> list = new ArrayList<>();\n\t\tfor (int i = 0; i < 100; i++) {\n\t\t\tJob job = new Job(queueLock, list);\n\t\t\tjob.start();\n\t\t}\n\n\t\twhile(list.size() < 100){\n\t\t\tSystem.out.println(list.size());\n\t\t}\n\t\tSystem.out.println(list.size());\n\t}\n}\n\nclass Job extends Thread {\n\n\tJob(Lock queueLock, List<Integer> count) {\n\t\tthis.count = count;\n\t\tthis.queueLock = queueLock;\n\t}\n\tList<Integer> count;\n\tLock queueLock;\n\n\t@Override\n\tpublic void run() {\n\t\t// 使用锁实现一个临界区,并且保证同一时间只有一个执行线程访问这个临界区.\n\t\tqueueLock.lock();\n\t\ttry {\n\t\t\tint random = ThreadLocalRandom.current().nextInt(2);\n\t\t\tTimeUnit.SECONDS.sleep(random);\n\t\t\tcount.add(random);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t} finally { // 在执行完的最后必须释放锁,否则将\n\t\t\tqueueLock.unlock();\n\t\t}\n\t}\n}\n```\n\n修改锁的公平性\n---\n`ReentrantLock`和`ReentrantReadWriteLock` 类的构造器都含有一个布尔参数fair\n\n* fair --> true : 公平模式,当有很多线程在等待锁的时候,锁将选择它们中的一个来访问临界区,选择的是等待时间最长的\n* fair --> false: 非公平模式,当有很多线程在等待锁的时候,锁将选择它们中的一个来访问临界区,该选择是没有任何约束的\n\n这俩种模式只适用于lock(),unlock()方法.\n\n`Lock`接口的`tryLock()`方法并没有将线程置为睡眠,所以fair属性并不影响这个方法\n```java\npublic class Main {\n\n\tpublic static void main(String args[]) {\n\t\tfinal PrintQueue printQueue = new PrintQueue();\n\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tRunnable r = new Runnable() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tSystem.out.printf(\"%s:begin print\\n\", Thread\n\t\t\t\t\t\t\t.currentThread().getName());\n\t\t\t\t\tprintQueue.printJob(new Object());\n\t\t\t\t\tSystem.out.printf(\"%s:print over\\n\", Thread.currentThread()\n\t\t\t\t\t\t\t.getName());\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread t = new Thread(r);\n\t\t\tt.start();\n\n\t\t\ttry {\n\t\t\t\tThread.sleep(100);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\n}\n\nclass PrintQueue {\n\n\tprivate final Lock queueLock = new ReentrantLock(false);\n\n\tpublic void printJob(Object document) {\n\t\tqueueLock.lock();\n\n\t\ttry {\n\t\t\tLong duration = (long) (Math.random() * 10000);\n\t\t\tSystem.out.printf(\"%s:Printing a Job during %d seconds\\n\", Thread\n\t\t\t\t\t.currentThread().getName(), (duration / 1000));\n\t\t\tThread.sleep(duration);\n\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\tqueueLock.unlock();\n\t\t}\n\t}\n}\n```\n","source":"_posts/JavaSE/并发 锁实现.md","raw":"category: JavaSE\ndate: 2015-03-10\ntitle: JavaSE 锁实现\n---\n# ReadWriteLock\n读写锁只有一个实现ReentrantReadWriteLock(可重入读写锁)\n\n读写锁有俩个锁\n* 读操作锁,使用读操作锁的时候可以允许多个线程同时访问\n* 写操作锁,只允许一个线程运行,即其他线程既不能执行读操作也不能执行写操作\n\n\n# ReentrantLock\n\nJava提供了同步代码块的另一种机制,它比synchronized关键字更加强大也更加灵活. 这种机制基于Lock接口以及其实现类.\n\nLock相比Synchronized：\n1. 更灵活的同步代码块结构.使用synchronized关键字只能在同一个synchronized块结构中获取和释放控制. Lock接口允许实现更复杂的临界区结构.(例如可以在不同的方法中加锁和释放锁)\n2. Lock接口提供了tryLock()方法.这个方法试图获取锁,如果锁已被其他线程获取,它将返回false并继续往下执行代码. 但在使用synchronized关键字时,如果A想要执行一个同步块,但是B恰好在使用她,A就会一直被堵塞到B执行完该同步块\n3. Lock接口允许分离读操作和写操作,允许多个读线程和一个写线程\n4. 而且Lock接口拥有更好的性能\n\nlock(): A尝试获取锁的时候,如果B在执行同步块,A将被锁住,直到B执行完 tryLock():\n\n在本例中我们使用ReentrantLock锁(重入锁)(synchronized本身是支持重入的)\n\nReentrantLock的实现不仅可以替代隐式的synchronized关键字,而且能够提供超过关键字本身的多种功能。这里提到一个锁获取的公平性问题,如果在绝对时间上,先对锁进行获取的请求一定被先满足, 那么这个锁是公平的,反之,是不公平的,也就是说等待时间最长的线程最有机会获取锁,也可以说锁的获取是有序的。\n\nReentrantLock这个锁提供了一个构造函数,能够控制这个锁是否是公平的。而锁的名字也是说明了这个锁具备了重复进入的可能,也就是说能够让当前线程多次的进行对锁的获取操作,\n这样的最大次数限制是Integer.MAX_VALUE,约21亿次左右。\n\n事实上公平的锁机制往往没有非公平的效率高,因为公平的获取锁没有考虑到操作系统对线程的调度因素,这样造成JVM对于等待中的线程调度次序和操作系统对线程的调度之间的不匹配\n\n对于锁的快速且重复的获取过程中,连续获取的概率是非常高的,而公平锁会压制这种情况, 虽然公平性得以保障,但是响应比却下降了,但是并不是任何场景都是以TPS作为唯一指标的,因为公平锁能够减少“饥饿”发生的概率,等待越久的请求越是能够得到优先满足。\n\n```java\npublic class Main {\n\n\tpublic static void main(String args[]) {\n\t\tfinal Lock queueLock = new ReentrantLock();\n\t\tList<Integer> list = new ArrayList<>();\n\t\tfor (int i = 0; i < 100; i++) {\n\t\t\tJob job = new Job(queueLock, list);\n\t\t\tjob.start();\n\t\t}\n\n\t\twhile(list.size() < 100){\n\t\t\tSystem.out.println(list.size());\n\t\t}\n\t\tSystem.out.println(list.size());\n\t}\n}\n\nclass Job extends Thread {\n\n\tJob(Lock queueLock, List<Integer> count) {\n\t\tthis.count = count;\n\t\tthis.queueLock = queueLock;\n\t}\n\tList<Integer> count;\n\tLock queueLock;\n\n\t@Override\n\tpublic void run() {\n\t\t// 使用锁实现一个临界区,并且保证同一时间只有一个执行线程访问这个临界区.\n\t\tqueueLock.lock();\n\t\ttry {\n\t\t\tint random = ThreadLocalRandom.current().nextInt(2);\n\t\t\tTimeUnit.SECONDS.sleep(random);\n\t\t\tcount.add(random);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t} finally { // 在执行完的最后必须释放锁,否则将\n\t\t\tqueueLock.unlock();\n\t\t}\n\t}\n}\n```\n\n修改锁的公平性\n---\n`ReentrantLock`和`ReentrantReadWriteLock` 类的构造器都含有一个布尔参数fair\n\n* fair --> true : 公平模式,当有很多线程在等待锁的时候,锁将选择它们中的一个来访问临界区,选择的是等待时间最长的\n* fair --> false: 非公平模式,当有很多线程在等待锁的时候,锁将选择它们中的一个来访问临界区,该选择是没有任何约束的\n\n这俩种模式只适用于lock(),unlock()方法.\n\n`Lock`接口的`tryLock()`方法并没有将线程置为睡眠,所以fair属性并不影响这个方法\n```java\npublic class Main {\n\n\tpublic static void main(String args[]) {\n\t\tfinal PrintQueue printQueue = new PrintQueue();\n\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tRunnable r = new Runnable() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tSystem.out.printf(\"%s:begin print\\n\", Thread\n\t\t\t\t\t\t\t.currentThread().getName());\n\t\t\t\t\tprintQueue.printJob(new Object());\n\t\t\t\t\tSystem.out.printf(\"%s:print over\\n\", Thread.currentThread()\n\t\t\t\t\t\t\t.getName());\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread t = new Thread(r);\n\t\t\tt.start();\n\n\t\t\ttry {\n\t\t\t\tThread.sleep(100);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\n}\n\nclass PrintQueue {\n\n\tprivate final Lock queueLock = new ReentrantLock(false);\n\n\tpublic void printJob(Object document) {\n\t\tqueueLock.lock();\n\n\t\ttry {\n\t\t\tLong duration = (long) (Math.random() * 10000);\n\t\t\tSystem.out.printf(\"%s:Printing a Job during %d seconds\\n\", Thread\n\t\t\t\t\t.currentThread().getName(), (duration / 1000));\n\t\t\tThread.sleep(duration);\n\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\tqueueLock.unlock();\n\t\t}\n\t}\n}\n```\n","slug":"JavaSE/并发 锁实现","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihr6003uvjs606ullasd"},{"date":"2015-03-07T16:00:00.000Z","title":"JavaSE 并发安全集合","_content":"\n## Queues\n* ConcurrentLinkedQueue: 可高效拓展且线程安全的非阻塞FIFO队列\n* ConcurrentLinkedDeque : 和`ConcurrentLinkedQueue`很像, 不过是实现了`Deque`接口\n\n支持`BlockingQueue`的接口\n* LinkedBlockingQueue\n* ArrayBlockingQueue\n* SynchronousQueue\n* PriorityBlockingQueue\n* DelayQueue\n\nTransferQueue\n* LinkedTransferQueue : TransferQueue的默认实现\n\nBlockingDeque\n* LinkedBlockingDeque ; BlockingDeque的默认实现\n\n## Concurrent Collections\n除了`Queue`之外, `java.util.concurrent`包内还定义了一些并发集合\n* ConcurrentHashMap : `HashMap`的线程安全版本\n* ConcurrentSkipListMap : `TreeMap`的线程安全版本\n* ConcurrentSkipListSet\n* CopyOnWriteArrayList : `ArrayList`的线程安全版本\n* CopyOnWriteArraySet :\n","source":"_posts/JavaSE/并发 集合.md","raw":"category: JavaSE\ndate: 2015-03-08\ntitle: JavaSE 并发安全集合\n---\n\n## Queues\n* ConcurrentLinkedQueue: 可高效拓展且线程安全的非阻塞FIFO队列\n* ConcurrentLinkedDeque : 和`ConcurrentLinkedQueue`很像, 不过是实现了`Deque`接口\n\n支持`BlockingQueue`的接口\n* LinkedBlockingQueue\n* ArrayBlockingQueue\n* SynchronousQueue\n* PriorityBlockingQueue\n* DelayQueue\n\nTransferQueue\n* LinkedTransferQueue : TransferQueue的默认实现\n\nBlockingDeque\n* LinkedBlockingDeque ; BlockingDeque的默认实现\n\n## Concurrent Collections\n除了`Queue`之外, `java.util.concurrent`包内还定义了一些并发集合\n* ConcurrentHashMap : `HashMap`的线程安全版本\n* ConcurrentSkipListMap : `TreeMap`的线程安全版本\n* ConcurrentSkipListSet\n* CopyOnWriteArrayList : `ArrayList`的线程安全版本\n* CopyOnWriteArraySet :\n","slug":"JavaSE/并发 集合","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihr9003wvjs6vjoehcmy"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice 注入","_content":"\n## 构造器注入\n对构造器进行注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\t// A类型的变量都使用B的实例值进行注入. 也就是说当我们对A类型的变量注入值的时候, 其实注入的是B类型\n\t\t\t\t// B一定要继承A或者实现A接口\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t});\n\t\t\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\nclass A {\n\tvoid print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n\nclass B extends A{\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\tprivate A a;\n\n\t@Inject\n\tPrint(A a) {\n\t\tthis.a = a;\n\t}\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n输出结果为B, 注入成功\n\n## 方法参数注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\n\tprivate A a;\n\t@Inject\n\tpublic void setA(A a) {\n\t\tthis.a = a;\n\t}\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n输出结果同样是B\n\n## 方法注入\n当一个方法使用`Inject`注解时, 如果getInstance该类的实例就会调用该方法一次\n```java\npublic class TestStaticInjection {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t}\n\t\t});\n\t\tPrint b1 = injector.getInstance(Print.class);\n\t}\n}\n\nclass Print {\n\t@Inject\n\tpublic void print() {\n\t\tSystem.out.println(\"Hello world\");\n\t}\n}\n```\n\n## 成员属性注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\t@Inject\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).to(B.class);\n\t}\n}\n```\nGuice会对被`Inject`注解过的属性赋值\n\n## Optional Injections\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\t@Inject(optional=true)\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n//\t\tbind(A.class).to(B.class);\n\t}\n}\n```\n如果我将要被`Inject`注解的属性设置为`optional=true`的话,当我注释掉绑定代码,在运行代码时会产生一个空指针异常,这是因为当找不到绑定的时候,就不进行注解\n```\nException in thread \"main\" java.lang.NullPointerException\n```\n但是如果我将`Inject`注解的属性设置为`optional=false`的话,在运行代码会产生\n```java\nException in thread \"main\" com.google.inject.ConfigurationException: Guice configuration errors:\n\n1) No implementation for guice.A was bound.\n  while locating guice.A\n    for field at guice.Print.a(TestInject.java:37)\n  while locating guice.Print\n```\n说明如果可选值如果是false的话就必须对其进行绑定\n\n## 静态属性注入\n对类中的静态字段进行注入\n```java\npublic class TestStaticInjection {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\trequestStaticInjection(Print.class);\n\t\t\t}\n\t\t});\n\t\tPrint b1 = injector.getInstance(Print.class);\n\t\tb1.print();\n\t}\n}\n\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n\nclass Print {\n\t@Inject\n\tprivate static A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n> 但是我们应该避免静态属性注入","source":"_posts/guice/Injections.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice 注入\n---\n\n## 构造器注入\n对构造器进行注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\t// A类型的变量都使用B的实例值进行注入. 也就是说当我们对A类型的变量注入值的时候, 其实注入的是B类型\n\t\t\t\t// B一定要继承A或者实现A接口\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t});\n\t\t\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\nclass A {\n\tvoid print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n\nclass B extends A{\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\tprivate A a;\n\n\t@Inject\n\tPrint(A a) {\n\t\tthis.a = a;\n\t}\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n输出结果为B, 注入成功\n\n## 方法参数注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\n\tprivate A a;\n\t@Inject\n\tpublic void setA(A a) {\n\t\tthis.a = a;\n\t}\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n输出结果同样是B\n\n## 方法注入\n当一个方法使用`Inject`注解时, 如果getInstance该类的实例就会调用该方法一次\n```java\npublic class TestStaticInjection {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t}\n\t\t});\n\t\tPrint b1 = injector.getInstance(Print.class);\n\t}\n}\n\nclass Print {\n\t@Inject\n\tpublic void print() {\n\t\tSystem.out.println(\"Hello world\");\n\t}\n}\n```\n\n## 成员属性注入\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\t@Inject\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).to(B.class);\n\t}\n}\n```\nGuice会对被`Inject`注解过的属性赋值\n\n## Optional Injections\n```java\npublic class TestInject {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass Print {\n\t@Inject(optional=true)\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n//\t\tbind(A.class).to(B.class);\n\t}\n}\n```\n如果我将要被`Inject`注解的属性设置为`optional=true`的话,当我注释掉绑定代码,在运行代码时会产生一个空指针异常,这是因为当找不到绑定的时候,就不进行注解\n```\nException in thread \"main\" java.lang.NullPointerException\n```\n但是如果我将`Inject`注解的属性设置为`optional=false`的话,在运行代码会产生\n```java\nException in thread \"main\" com.google.inject.ConfigurationException: Guice configuration errors:\n\n1) No implementation for guice.A was bound.\n  while locating guice.A\n    for field at guice.Print.a(TestInject.java:37)\n  while locating guice.Print\n```\n说明如果可选值如果是false的话就必须对其进行绑定\n\n## 静态属性注入\n对类中的静态字段进行注入\n```java\npublic class TestStaticInjection {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\trequestStaticInjection(Print.class);\n\t\t\t}\n\t\t});\n\t\tPrint b1 = injector.getInstance(Print.class);\n\t\tb1.print();\n\t}\n}\n\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n\nclass Print {\n\t@Inject\n\tprivate static A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n> 但是我们应该避免静态属性注入","slug":"guice/Injections","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrd003yvjs6thfhoir0"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice 绑定","_content":"\n## 单绑定\n```java\npublic class TestBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(BindingA.class);\n\t\t\t}\n\t\t});\n\t\tBindingA a = injector.getInstance(BindingA.class);\n\t\ta.print();\n\t}\n}\n\nclass BindingA {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n```\n输出结果为\n```xml\nA\n```\n我们可以将`BindingA`绑定到Guice里, 当我们getInstance时会直接获得该实例\n\n> 注意如果单邦定时, BindingA必须为class, 如果为接口的话会产生No implementation for testGuice.BindingA was bound.异常\n\n> 参考@ImplementedBy or @ProvidedBy\n\n## 链式绑定\n```java\npublic class TestBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(BindingA.class).to(BindingB.class);\n\t\t\t\tbind(BindingB.class).to(BindingC.class);\n\t\t\t}\n\t\t});\n\n\t\tBindingC c = injector.getInstance(BindingC.class);\n\t\tc.print();\n\t\tBindingB b = injector.getInstance(BindingB.class);\n\t\tb.print();\n\t\tBindingA a = injector.getInstance(BindingA.class);\n\t\ta.print();\n\t}\n}\n\nclass BindingA {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass BindingB extends BindingA {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass BindingC extends BindingB {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"c\");\n\t}\n}\n```\n这段代码的最后调用结果都是\n```java\nc\nc\nc\n```\n这就是Guice的Linked Bindings, 当binding形成一条链之后,会以最终的绑定为最终绑定\n\n> 注意绑定关系必须是继承关系\n\n## 命名绑定\n这种特性是为了,当某个接口有多种实现时,我们可以通过`@Named`指定我们具体使用哪种实现\n```java\npublic class TestNamedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).annotatedWith(Names.named(\"BType\")).to(B.class);\n\t\t\t\tbind(A.class).annotatedWith(Names.named(\"CType\")).to(C.class);\n\t\t\t}\n\t\t});\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.printB();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\n\nclass Print {\n\tpublic void printB() {\n\t\tb.print();\n\t}\n\tpublic void printC() {\n\t\tc.print();\n\t}\n\t@Inject\n\t@Named(\"BType\")\n\tprivate A b;\n\t@Inject\n\t@Named(\"CType\")\n\tprivate A c;\n}\n```\n输出结果为\n```xml\nB\nC\nB\n```\n我们还可以使用`BindingAnnotation`来实现相同的功能\n```java\npublic class TestNamedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).annotatedWith(BType.class).to(B.class);\n\t\t\t\tbind(A.class).annotatedWith(CType.class).to(C.class);\n\t\t\t}\n\t\t});\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.printB();\n\t\tprint.printC();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\n\n@BindingAnnotation\n@Target({ FIELD, PARAMETER, METHOD }) @Retention(RUNTIME)\n@interface BType {}\n\n@BindingAnnotation\n@Target({ FIELD, PARAMETER, METHOD }) @Retention(RUNTIME)\n@interface CType {}\n\nclass Print {\n\tpublic void printB() {\n\t\tb.print();\n\t}\n\tpublic void printC() {\n\t\tc.print();\n\t}\n\t@Inject\n\t@BType\n\tprivate A b;\n\t@Inject\n\t@CType\n\tprivate A c;\n}\n```","source":"_posts/guice/Linked Bindings.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice 绑定\n---\n\n## 单绑定\n```java\npublic class TestBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(BindingA.class);\n\t\t\t}\n\t\t});\n\t\tBindingA a = injector.getInstance(BindingA.class);\n\t\ta.print();\n\t}\n}\n\nclass BindingA {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n```\n输出结果为\n```xml\nA\n```\n我们可以将`BindingA`绑定到Guice里, 当我们getInstance时会直接获得该实例\n\n> 注意如果单邦定时, BindingA必须为class, 如果为接口的话会产生No implementation for testGuice.BindingA was bound.异常\n\n> 参考@ImplementedBy or @ProvidedBy\n\n## 链式绑定\n```java\npublic class TestBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(BindingA.class).to(BindingB.class);\n\t\t\t\tbind(BindingB.class).to(BindingC.class);\n\t\t\t}\n\t\t});\n\n\t\tBindingC c = injector.getInstance(BindingC.class);\n\t\tc.print();\n\t\tBindingB b = injector.getInstance(BindingB.class);\n\t\tb.print();\n\t\tBindingA a = injector.getInstance(BindingA.class);\n\t\ta.print();\n\t}\n}\n\nclass BindingA {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass BindingB extends BindingA {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass BindingC extends BindingB {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"c\");\n\t}\n}\n```\n这段代码的最后调用结果都是\n```java\nc\nc\nc\n```\n这就是Guice的Linked Bindings, 当binding形成一条链之后,会以最终的绑定为最终绑定\n\n> 注意绑定关系必须是继承关系\n\n## 命名绑定\n这种特性是为了,当某个接口有多种实现时,我们可以通过`@Named`指定我们具体使用哪种实现\n```java\npublic class TestNamedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).annotatedWith(Names.named(\"BType\")).to(B.class);\n\t\t\t\tbind(A.class).annotatedWith(Names.named(\"CType\")).to(C.class);\n\t\t\t}\n\t\t});\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.printB();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\n\nclass Print {\n\tpublic void printB() {\n\t\tb.print();\n\t}\n\tpublic void printC() {\n\t\tc.print();\n\t}\n\t@Inject\n\t@Named(\"BType\")\n\tprivate A b;\n\t@Inject\n\t@Named(\"CType\")\n\tprivate A c;\n}\n```\n输出结果为\n```xml\nB\nC\nB\n```\n我们还可以使用`BindingAnnotation`来实现相同的功能\n```java\npublic class TestNamedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).annotatedWith(BType.class).to(B.class);\n\t\t\t\tbind(A.class).annotatedWith(CType.class).to(C.class);\n\t\t\t}\n\t\t});\n\t\tPrint print = injector.getInstance(Print.class);\n\t\tprint.printB();\n\t\tprint.printC();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\n\n@BindingAnnotation\n@Target({ FIELD, PARAMETER, METHOD }) @Retention(RUNTIME)\n@interface BType {}\n\n@BindingAnnotation\n@Target({ FIELD, PARAMETER, METHOD }) @Retention(RUNTIME)\n@interface CType {}\n\nclass Print {\n\tpublic void printB() {\n\t\tb.print();\n\t}\n\tpublic void printC() {\n\t\tc.print();\n\t}\n\t@Inject\n\t@BType\n\tprivate A b;\n\t@Inject\n\t@CType\n\tprivate A c;\n}\n```","slug":"guice/Linked Bindings","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrf0040vjs687rq49w4"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice 多模块分开绑定","_content":"我们可以在不同的模块里绑定实现不同的绑定\n```java\npublic class TestMultipleModules {\n\tpublic static void main(String[] args) {\n\t\tAbstractModule module1 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t};\n\n\t\tAbstractModule module2 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(B.class).to(C.class);\n\t\t\t}\n\t\t};\n\t\tInjector injector = Guice.createInjector(module1, module2);\n\t\tA a = injector.getInstance(A.class);\n\t\tB b = injector.getInstance(B.class);\n\t\ta.print();\n\t\tb.print();\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass B extends A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C extends B {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\nclass Print {\n\t@Inject\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n结果为\n```xml\nC\nC\n```\n> module1和module2里对A只能进行相同的绑定,也就是说即使在不同的module里也不能即A绑定到B又绑定到C","source":"_posts/guice/Multiple Modules.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice 多模块分开绑定\n---\n我们可以在不同的模块里绑定实现不同的绑定\n```java\npublic class TestMultipleModules {\n\tpublic static void main(String[] args) {\n\t\tAbstractModule module1 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t};\n\n\t\tAbstractModule module2 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(B.class).to(C.class);\n\t\t\t}\n\t\t};\n\t\tInjector injector = Guice.createInjector(module1, module2);\n\t\tA a = injector.getInstance(A.class);\n\t\tB b = injector.getInstance(B.class);\n\t\ta.print();\n\t\tb.print();\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass B extends A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\nclass C extends B {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"C\");\n\t}\n}\nclass Print {\n\t@Inject\n\tprivate A a;\n\n\tpublic void print() {\n\t\ta.print();\n\t}\n}\n```\n结果为\n```xml\nC\nC\n```\n> module1和module2里对A只能进行相同的绑定,也就是说即使在不同的module里也不能即A绑定到B又绑定到C","slug":"guice/Multiple Modules","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrh0043vjs6r35g69h9"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice Provides绑定方式","_content":"我们可以使用`Provides`注解替代`configure()`实现的绑定.\n```java\npublic class TestProvidesMethods {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t}\n\n\t\t\t@Provides\n\t\t\tpublic A provideA() {\n\t\t\t\tB b = new B();\n\t\t\t\treturn b;\n\t\t\t}\n\t\t});\n\t\tA print = injector.getInstance(A.class);\n\t\tprint.print();\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass B extends A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n```\n我们在module实现里添加了`@Provides`注释, 当我们在测试代码里要获取某种类型的对象的时候, Guice会根据返回某种类型的方法调用.\n\n> `@Provides`注释下的名字可以是任意的. 但是我们还是建议采用provideXXX的形式\n\n需要注意的是, 返回的类型必须是唯一的, 如果我们添加下面的代码\n```java\nclass C implementsA {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"c\");\n\t}\n}\n\n@Provides\npublic A provideC() {\n\tC b = new C();\n\treturn b;\n}\n```\nguice会产生异常\n```java\nException in thread \"main\" com.google.inject.CreationException: Unable to create injector, see the following errors:\n\n1) A binding to guice.A was already configured at guice.ABCModule.provideA().\n```\n\n还有一点需要注意的是,如果`@Provides`已经使用过某种类型,那么在`config()`方法里就不能再次使用\n```java\n@Override\nprotected void configure() {\n\tbind(A.class).to(C.class);\n}\n```\n同样会产生异常\n```java\nException in thread \"main\" com.google.inject.CreationException: Unable to create injector, see the following errors:\n\n1) A binding to guice.A was already configured at guice.ABCModule.provideA().\n```\n\n如果我们的`provide`方法很复杂,我们可以将其抽取到一个类里\n```java\npublic class TestLinkedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tA print = injector.getInstance(A.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass BProvider implements Provider<A> {\n\n\t@Override\n\tpublic A get() {\n\t\treturn new B();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).toProvider(BProvider.class);\n\t}\n}\n```\n","source":"_posts/guice/Provides Methods.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice Provides绑定方式\n---\n我们可以使用`Provides`注解替代`configure()`实现的绑定.\n```java\npublic class TestProvidesMethods {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t}\n\n\t\t\t@Provides\n\t\t\tpublic A provideA() {\n\t\t\t\tB b = new B();\n\t\t\t\treturn b;\n\t\t\t}\n\t\t});\n\t\tA print = injector.getInstance(A.class);\n\t\tprint.print();\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\nclass B extends A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n```\n我们在module实现里添加了`@Provides`注释, 当我们在测试代码里要获取某种类型的对象的时候, Guice会根据返回某种类型的方法调用.\n\n> `@Provides`注释下的名字可以是任意的. 但是我们还是建议采用provideXXX的形式\n\n需要注意的是, 返回的类型必须是唯一的, 如果我们添加下面的代码\n```java\nclass C implementsA {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"c\");\n\t}\n}\n\n@Provides\npublic A provideC() {\n\tC b = new C();\n\treturn b;\n}\n```\nguice会产生异常\n```java\nException in thread \"main\" com.google.inject.CreationException: Unable to create injector, see the following errors:\n\n1) A binding to guice.A was already configured at guice.ABCModule.provideA().\n```\n\n还有一点需要注意的是,如果`@Provides`已经使用过某种类型,那么在`config()`方法里就不能再次使用\n```java\n@Override\nprotected void configure() {\n\tbind(A.class).to(C.class);\n}\n```\n同样会产生异常\n```java\nException in thread \"main\" com.google.inject.CreationException: Unable to create injector, see the following errors:\n\n1) A binding to guice.A was already configured at guice.ABCModule.provideA().\n```\n\n如果我们的`provide`方法很复杂,我们可以将其抽取到一个类里\n```java\npublic class TestLinkedBindings {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new ABCModule());\n\t\tA print = injector.getInstance(A.class);\n\t\tprint.print();\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n\nclass BProvider implements Provider<A> {\n\n\t@Override\n\tpublic A get() {\n\t\treturn new B();\n\t}\n}\n\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).toProvider(BProvider.class);\n\t}\n}\n```\n","slug":"guice/Provides Methods","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrj0045vjs6w4hesldz"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice Scopes","_content":"默认的,Guice每次在`getInstance()`的时候都会返回一个新的对象.\n```java\npublic class TestScopes {\n\tpublic static void main(String[] args) {\n\t\tAbstractModule module1 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class);\n\t\t\t}\n\t\t};\n\t\tInjector injector = Guice.createInjector(module1);\n\t\tA a = injector.getInstance(A.class);\n\t\tA b = injector.getInstance(A.class);\n\t\tSystem.out.println(a.equals(b));\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n```\n输出结果为false, 但是我们可以使用Singleton注解采用单例方式创建全局唯一的对象\n```java\npublic class TestSingleton {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t});\n\t\tA b1 = injector.getInstance(A.class);\n\t\tA b2 = injector.getInstance(A.class);\n\t\tSystem.out.println(b1 == b2);\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\n@Singleton\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n```\n输出结果为\n```xml\ntrue\n```\n我们使用`Singleton`注解可以得到一个全局唯一的B实例, 每次注解B实例时, 都是同一个实例.\n\n另外,我们还可以在绑定的时候进行设置\n```java\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).to(B.class).in(Singleton.class);\n\t}\n}\n```\n\n\n","source":"_posts/guice/Scopes.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice Scopes\n---\n默认的,Guice每次在`getInstance()`的时候都会返回一个新的对象.\n```java\npublic class TestScopes {\n\tpublic static void main(String[] args) {\n\t\tAbstractModule module1 = new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class);\n\t\t\t}\n\t\t};\n\t\tInjector injector = Guice.createInjector(module1);\n\t\tA a = injector.getInstance(A.class);\n\t\tA b = injector.getInstance(A.class);\n\t\tSystem.out.println(a.equals(b));\n\t}\n}\nclass A {\n\tpublic void print() {\n\t\tSystem.out.println(\"A\");\n\t}\n}\n```\n输出结果为false, 但是我们可以使用Singleton注解采用单例方式创建全局唯一的对象\n```java\npublic class TestSingleton {\n\tpublic static void main(String[] args) {\n\t\tInjector injector = Guice.createInjector(new AbstractModule() {\n\t\t\t@Override\n\t\t\tprotected void configure() {\n\t\t\t\tbind(A.class).to(B.class);\n\t\t\t}\n\t\t});\n\t\tA b1 = injector.getInstance(A.class);\n\t\tA b2 = injector.getInstance(A.class);\n\t\tSystem.out.println(b1 == b2);\n\t}\n}\n\ninterface A {\n\tvoid print();\n}\n\n@Singleton\nclass B implements A {\n\t@Override\n\tpublic void print() {\n\t\tSystem.out.println(\"B\");\n\t}\n}\n```\n输出结果为\n```xml\ntrue\n```\n我们使用`Singleton`注解可以得到一个全局唯一的B实例, 每次注解B实例时, 都是同一个实例.\n\n另外,我们还可以在绑定的时候进行设置\n```java\nclass ABCModule extends AbstractModule {\n\t@Override\n\tprotected void configure() {\n\t\tbind(A.class).to(B.class).in(Singleton.class);\n\t}\n}\n```\n\n\n","slug":"guice/Scopes","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrk0047vjs63zm5tuqt"},{"date":"2015-12-07T16:00:00.000Z","title":"Guice 初探","_content":"Google Guice 是一个轻量级的依赖注入框架\n\n在Guice的依赖注入中我们使用如下API进行注入\n* `Binder`\n* `Injector`\n* `Module`\n* `Guice`\n直接看例子\n```java\npublic class CarModule implements Module {\n\n\t@Override\n\tpublic void configure(Binder binder) {\n\t\tbinder.bind(Car.class).to(Benci.class);\n\t}\n}\n\npublic interface Car {\n\tpublic void run();\n}\n\npublic class Benci implements Car {\n\t@Override\n\tpublic void run() {\n\t\tSystem.out.println(\"Benci Run\");\n\t}\n}\n```\n测试代码\n```java\nInjector injector = Guice.createInjector(new CarModule());\nCar benci = injector.getInstance(Car.class);\nbenci.run();\n```\n\n## ImplementedBy\n```java\npublic class LunYu implements Book {\n\t@Override\n\tpublic String content() {\n\t\treturn \"Lunyu\";\n\t}\n}\n\n@ImplementedBy(LunYu.class)\npublic interface Book {\n\n\tpublic String content();\n}\n\npublic class ReadBook {\n\n\tpublic void readLunyu() {\n\t\tSystem.out.println(book.content());\n\t}\n\n\t@Inject\n\tprivate Book book;\n}\n```\n测试代码\n```java\nInjector intjector = Guice.createInjector();\nBook lunyu = intjector.getInstance(Book.class);\nSystem.out.println(lunyu.content());\n```\n\n## Inject\n```java\npublic class Man implements People {\n\t@Override\n\tpublic String name() {\n\t\treturn \"Tom\";\n\t}\n}\n\npublic interface People {\n\n\tpublic String name();\n}\n\npublic class PeopleModule implements Module {\n\t@Override\n\tpublic void configure(Binder binder) {\n\t\tbinder.bind(People.class).to(Man.class);\n\t}\n}\n\npublic class PrintName {\n\n\tpublic void print() {\n\t\tSystem.out.println(man.name());\n\t}\n\n\t@Inject\n\tprivate People man;\n}\n```\n测试代码\n```java\nInjector intjector = Guice.createInjector(new PeopleModule());\nPrintName pn = intjector.getInstance(PrintName.class);\npn.print();\n```\n","source":"_posts/guice/guice初探.md","raw":"category: guice\ndate: 2015-12-08\ntitle: Guice 初探\n---\nGoogle Guice 是一个轻量级的依赖注入框架\n\n在Guice的依赖注入中我们使用如下API进行注入\n* `Binder`\n* `Injector`\n* `Module`\n* `Guice`\n直接看例子\n```java\npublic class CarModule implements Module {\n\n\t@Override\n\tpublic void configure(Binder binder) {\n\t\tbinder.bind(Car.class).to(Benci.class);\n\t}\n}\n\npublic interface Car {\n\tpublic void run();\n}\n\npublic class Benci implements Car {\n\t@Override\n\tpublic void run() {\n\t\tSystem.out.println(\"Benci Run\");\n\t}\n}\n```\n测试代码\n```java\nInjector injector = Guice.createInjector(new CarModule());\nCar benci = injector.getInstance(Car.class);\nbenci.run();\n```\n\n## ImplementedBy\n```java\npublic class LunYu implements Book {\n\t@Override\n\tpublic String content() {\n\t\treturn \"Lunyu\";\n\t}\n}\n\n@ImplementedBy(LunYu.class)\npublic interface Book {\n\n\tpublic String content();\n}\n\npublic class ReadBook {\n\n\tpublic void readLunyu() {\n\t\tSystem.out.println(book.content());\n\t}\n\n\t@Inject\n\tprivate Book book;\n}\n```\n测试代码\n```java\nInjector intjector = Guice.createInjector();\nBook lunyu = intjector.getInstance(Book.class);\nSystem.out.println(lunyu.content());\n```\n\n## Inject\n```java\npublic class Man implements People {\n\t@Override\n\tpublic String name() {\n\t\treturn \"Tom\";\n\t}\n}\n\npublic interface People {\n\n\tpublic String name();\n}\n\npublic class PeopleModule implements Module {\n\t@Override\n\tpublic void configure(Binder binder) {\n\t\tbinder.bind(People.class).to(Man.class);\n\t}\n}\n\npublic class PrintName {\n\n\tpublic void print() {\n\t\tSystem.out.println(man.name());\n\t}\n\n\t@Inject\n\tprivate People man;\n}\n```\n测试代码\n```java\nInjector intjector = Guice.createInjector(new PeopleModule());\nPrintName pn = intjector.getInstance(PrintName.class);\npn.print();\n```\n","slug":"guice/guice初探","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrm004avjs67l9w0cfk"},{"date":"2015-12-08T16:00:00.000Z","title":"Mybatis Guice 初探","_content":"参考文档[mybatis-guice](http://mybatis.org/guice/index.html)\n\nmybatis-guice需要依赖\n```xml\n<dependency>\n    <groupId>com.google.inject</groupId>\n    <artifactId>guice</artifactId>\n    <version>4.0</version>\n</dependency>\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis-guice</artifactId>\n    <version>3.7</version>\n</dependency>\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis</artifactId>\n    <version>3.2.2</version>\n</dependency>\n<dependency>\n    <groupId>com.google.inject.extensions</groupId>\n    <artifactId>guice-multibindings</artifactId>\n    <version>4.0</version>\n</dependency>\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.37</version>\n</dependency>\n</dependencies>\n```\n表结构\n```sql\nCREATE TABLE `user` (\n  `userId` varchar(100) DEFAULT NULL,\n  `name` varchar(100) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n我们首先定义使用到的model类和mapper类\n```java\nclass User {\n    public String userId;\n    public String name;\n}\n\ninterface UserMapper {\n    @Select(\"SELECT * FROM user WHERE userId = #{userId}\")\n    User getUser(@Param(\"userId\") String userId);\n}\n```\n然后我们实现Guice对Mybatis的注解管理\n```java\nclass MySqlManager {\n    private static final Injector injector;\n    static {\n        injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule());\n    }\n    private MySqlManager() {\n    }\n\n    public static <T> T getInstance(Class<T> var1) {\n        return injector.getInstance(var1);\n    }\n\n    private static class MysqlModule extends MyBatisModule {\n\n        @Override\n        protected void initialize() {\n            bindDataSourceProviderType(PooledDataSourceProvider.class);\n            bindTransactionFactoryType(JdbcTransactionFactory.class);\n            Names.bindProperties(binder(), createUnpooledProperties());\n\n            addMapperClass();\n        }\n\n        // 添加映射类\n        private void addMapperClass() {\n            addMapperClass(UserMapper.class);\n        }\n\n        private Properties createUnpooledProperties() {\n            Properties myBatisProperties = new Properties();\n            myBatisProperties.setProperty(\"mybatis.environment.id\", \"test\");\n            myBatisProperties.setProperty(\"JDBC.schema\", \"test\");\n//\t\t\tmyBatisProperties.setProperty(\"JDBC.url\", \"localhost\");\n//\t\t\tmyBatisProperties.setProperty(\"JDBC.driver\", \"\");\n            myBatisProperties.setProperty(\"JDBC.username\", \"root\");\n            myBatisProperties.setProperty(\"JDBC.password\", \"root\");\n            myBatisProperties.setProperty(\"JDBC.loginTimeout\", \"10\");\n            myBatisProperties.setProperty(\"JDBC.autoCommit\", \"false\");\n            myBatisProperties.setProperty(\"derby.create\", \"true\");\n            return myBatisProperties;\n        }\n    }\n}\n```\n然后我们写一个测试类\n```java\npublic class GettingStarted {\n\n    public static void main(String[] args) {\n        UserMapper user = MySqlManager.getInstance(UserMapper.class);\n        User user1 = user.getUser(\"1\");\n        System.out.println(user1.name);\n\t\t\n\t\tUserMapper userMapper = new UserMapper();\n\t\tinjector.injectMembers(userMapper);\n\t\tSystem.out.println(userMapper.name);\n    }\n}\n```\n\n`MyBatisModule`还为我们提供了下述功能的接口\n* 添加自己的拦截器 : `addInterceptorClass(MySqlInterceptor.class);`\n* 添加自己的类型转换器 : `handleType()`\n* 添加别名 : `addSimpleAlias(User.class);`或者`addAlias(\"AUser\").to(User.class);`\n\n## 开启事务\n我们在`FooServiceMapperImpl`中还能定义开启事务\n```java\n// 开启事务\n@Transactional(\n        executorType = ExecutorType.BATCH,\n        isolation = Isolation.READ_UNCOMMITTED,\n//\t\trethrowExceptionsAs = MyDaoException.class,\n        exceptionMessage = \"Something went wrong\"\n)\npublic User getUser(String userId) {\n    return this.userMapper.getUser(userId);\n}\n```\n\n\n## 定义自己的连接池\n```java\nprivate void addPooledProperties(Binder binder) {\n    // 连接池并发访问数据的连接数, 默认为10\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumActiveConnections\")).to(10);\n    // 在被强制返回之前，池中连接被检查的时间\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumCheckoutTime\")).to(20000);\n    // 连接池里空闲连接数, 默认为5\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumIdleConnections\")).to(5);\n    // 由于数据库会检查连接达到8小时(默认值)闲置会单方面断开连接, 而客户端如果继续使用已经断开的连接,则会产生异常.\n    // mybatis里内带了ping机制, 设置该值为true的话, 就开启了ping机制\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingEnabled\")).to(false);\n    // 设置空闲连接ping时间间隔, 如果超时就进行ping,查看连接是否有效\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingConnectionsNotUsedFor\")).to(3600000);\n    // 执行ping时执行的语句\n\t//\tbinder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingQuery\")).to(\"\");\n    // 这是一个低层设置，如果获取连接花费的相当长的时间，它会给连接池打印日志并重新尝试获取一个连接的机会（避免在误配置的情况下一直安静的失败），默认值：20000 毫秒（即 20 秒）。\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.timeToWait\")).to(0);\n}\n\nprivate void addC3P0Properties(Binder binder) {\n    // 当连接池中的的连接耗尽的时候c3p0一次同时获取的连接数，但是池中最大数不会超过maxPoolSize\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireIncrement\")).to(1);\n    // 从数据库请求连接失败之后,尝试的次数\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireRetryAttempts\")).to(1);\n    // 连接池耗尽, 连续获得俩个连接直接的间隔时间. 单位ms\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireRetryDelay\")).to(1000);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.automaticTestTable\")).to(\"test\");\n    // 如果为true，则当连接获取失败时自动关闭数据源\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.breakAfterAcquireFailure\")).to(false);\n    // 连接池所有连接耗尽时,应用程序获得新的连接的等待时间. 为0则无限等待直至有其他连接释放或者创建新的连接，\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.checkoutTimeout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.connectionCustomizerClassName\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.connectionTesterClassName\")).to(1);\n    // 检查所有连接池中的空闲连接的时间间隔, 单位秒\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.idleConnectionTestPeriod\")).to(900);\n    // 连接池初始化时创建的连接数,default : 3\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.initialPoolSize\")).to(3);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxAdministrativeTaskTime\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxConnectionAge\")).to(1);\n    // 池中连接最大空闲时长,如果超时则断开这个连接. 单位是秒\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxIdleTime\")).to(600);\n\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxIdleTimeExcessConnections\")).to(1);\n    // 接池中拥有的最大连接数，如果获得新连接时会使连接总数超过这个值则不会再获取新连接，而是等待其他连接释放\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxPoolSize\")).to(15);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxStatements\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxStatementsPerConnection\")).to(1);\n    // 连接池保持的最小连接数\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.minPoolSize\")).to(3);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.preferredTestQuery\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.propertyCycle\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.testConnectionOnCheckin\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.testConnectionOnCheckout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.unreturnedConnectionTimeout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.usesTraditionalReflectiveProxies\")).to(1);\n}\n```\n\n我们还可以采用配置文件的方式设置\n```java\nimport org.mybatis.guice.XMLMyBatisModule;\nimport org.mybatis.guice.datasource.helper.JdbcHelper;\n\nimport com.google.inject.Guice;\nimport com.google.inject.Injector;\n\npublic class MybatisManager {\n    private static Injector injector;\n    static {\n        injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule());\n    }\n    private MybatisManager() {\n    }\n\n    public static <T> T getInstance(Class<T> var1) {\n        return injector.getInstance(var1);\n    }\n\n\tprivate static class MysqlModule extends XMLMyBatisModule {\n\n\t\t@Override\n\t\tprotected void initialize() {\n            setClassPathResource(\"configuration.xml\");\n\t\t}\n\t}\n}\n```","source":"_posts/guice/mybatis-guice.md","raw":"category: guice\ndate: 2015-12-09\ntitle: Mybatis Guice 初探\n---\n参考文档[mybatis-guice](http://mybatis.org/guice/index.html)\n\nmybatis-guice需要依赖\n```xml\n<dependency>\n    <groupId>com.google.inject</groupId>\n    <artifactId>guice</artifactId>\n    <version>4.0</version>\n</dependency>\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis-guice</artifactId>\n    <version>3.7</version>\n</dependency>\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis</artifactId>\n    <version>3.2.2</version>\n</dependency>\n<dependency>\n    <groupId>com.google.inject.extensions</groupId>\n    <artifactId>guice-multibindings</artifactId>\n    <version>4.0</version>\n</dependency>\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.37</version>\n</dependency>\n</dependencies>\n```\n表结构\n```sql\nCREATE TABLE `user` (\n  `userId` varchar(100) DEFAULT NULL,\n  `name` varchar(100) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n我们首先定义使用到的model类和mapper类\n```java\nclass User {\n    public String userId;\n    public String name;\n}\n\ninterface UserMapper {\n    @Select(\"SELECT * FROM user WHERE userId = #{userId}\")\n    User getUser(@Param(\"userId\") String userId);\n}\n```\n然后我们实现Guice对Mybatis的注解管理\n```java\nclass MySqlManager {\n    private static final Injector injector;\n    static {\n        injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule());\n    }\n    private MySqlManager() {\n    }\n\n    public static <T> T getInstance(Class<T> var1) {\n        return injector.getInstance(var1);\n    }\n\n    private static class MysqlModule extends MyBatisModule {\n\n        @Override\n        protected void initialize() {\n            bindDataSourceProviderType(PooledDataSourceProvider.class);\n            bindTransactionFactoryType(JdbcTransactionFactory.class);\n            Names.bindProperties(binder(), createUnpooledProperties());\n\n            addMapperClass();\n        }\n\n        // 添加映射类\n        private void addMapperClass() {\n            addMapperClass(UserMapper.class);\n        }\n\n        private Properties createUnpooledProperties() {\n            Properties myBatisProperties = new Properties();\n            myBatisProperties.setProperty(\"mybatis.environment.id\", \"test\");\n            myBatisProperties.setProperty(\"JDBC.schema\", \"test\");\n//\t\t\tmyBatisProperties.setProperty(\"JDBC.url\", \"localhost\");\n//\t\t\tmyBatisProperties.setProperty(\"JDBC.driver\", \"\");\n            myBatisProperties.setProperty(\"JDBC.username\", \"root\");\n            myBatisProperties.setProperty(\"JDBC.password\", \"root\");\n            myBatisProperties.setProperty(\"JDBC.loginTimeout\", \"10\");\n            myBatisProperties.setProperty(\"JDBC.autoCommit\", \"false\");\n            myBatisProperties.setProperty(\"derby.create\", \"true\");\n            return myBatisProperties;\n        }\n    }\n}\n```\n然后我们写一个测试类\n```java\npublic class GettingStarted {\n\n    public static void main(String[] args) {\n        UserMapper user = MySqlManager.getInstance(UserMapper.class);\n        User user1 = user.getUser(\"1\");\n        System.out.println(user1.name);\n\t\t\n\t\tUserMapper userMapper = new UserMapper();\n\t\tinjector.injectMembers(userMapper);\n\t\tSystem.out.println(userMapper.name);\n    }\n}\n```\n\n`MyBatisModule`还为我们提供了下述功能的接口\n* 添加自己的拦截器 : `addInterceptorClass(MySqlInterceptor.class);`\n* 添加自己的类型转换器 : `handleType()`\n* 添加别名 : `addSimpleAlias(User.class);`或者`addAlias(\"AUser\").to(User.class);`\n\n## 开启事务\n我们在`FooServiceMapperImpl`中还能定义开启事务\n```java\n// 开启事务\n@Transactional(\n        executorType = ExecutorType.BATCH,\n        isolation = Isolation.READ_UNCOMMITTED,\n//\t\trethrowExceptionsAs = MyDaoException.class,\n        exceptionMessage = \"Something went wrong\"\n)\npublic User getUser(String userId) {\n    return this.userMapper.getUser(userId);\n}\n```\n\n\n## 定义自己的连接池\n```java\nprivate void addPooledProperties(Binder binder) {\n    // 连接池并发访问数据的连接数, 默认为10\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumActiveConnections\")).to(10);\n    // 在被强制返回之前，池中连接被检查的时间\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumCheckoutTime\")).to(20000);\n    // 连接池里空闲连接数, 默认为5\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.maximumIdleConnections\")).to(5);\n    // 由于数据库会检查连接达到8小时(默认值)闲置会单方面断开连接, 而客户端如果继续使用已经断开的连接,则会产生异常.\n    // mybatis里内带了ping机制, 设置该值为true的话, 就开启了ping机制\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingEnabled\")).to(false);\n    // 设置空闲连接ping时间间隔, 如果超时就进行ping,查看连接是否有效\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingConnectionsNotUsedFor\")).to(3600000);\n    // 执行ping时执行的语句\n\t//\tbinder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.pingQuery\")).to(\"\");\n    // 这是一个低层设置，如果获取连接花费的相当长的时间，它会给连接池打印日志并重新尝试获取一个连接的机会（避免在误配置的情况下一直安静的失败），默认值：20000 毫秒（即 20 秒）。\n    binder.bindConstant().annotatedWith(Names.named(\"mybatis.pooled.timeToWait\")).to(0);\n}\n\nprivate void addC3P0Properties(Binder binder) {\n    // 当连接池中的的连接耗尽的时候c3p0一次同时获取的连接数，但是池中最大数不会超过maxPoolSize\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireIncrement\")).to(1);\n    // 从数据库请求连接失败之后,尝试的次数\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireRetryAttempts\")).to(1);\n    // 连接池耗尽, 连续获得俩个连接直接的间隔时间. 单位ms\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.acquireRetryDelay\")).to(1000);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.automaticTestTable\")).to(\"test\");\n    // 如果为true，则当连接获取失败时自动关闭数据源\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.breakAfterAcquireFailure\")).to(false);\n    // 连接池所有连接耗尽时,应用程序获得新的连接的等待时间. 为0则无限等待直至有其他连接释放或者创建新的连接，\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.checkoutTimeout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.connectionCustomizerClassName\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.connectionTesterClassName\")).to(1);\n    // 检查所有连接池中的空闲连接的时间间隔, 单位秒\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.idleConnectionTestPeriod\")).to(900);\n    // 连接池初始化时创建的连接数,default : 3\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.initialPoolSize\")).to(3);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxAdministrativeTaskTime\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxConnectionAge\")).to(1);\n    // 池中连接最大空闲时长,如果超时则断开这个连接. 单位是秒\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxIdleTime\")).to(600);\n\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxIdleTimeExcessConnections\")).to(1);\n    // 接池中拥有的最大连接数，如果获得新连接时会使连接总数超过这个值则不会再获取新连接，而是等待其他连接释放\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxPoolSize\")).to(15);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxStatements\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.maxStatementsPerConnection\")).to(1);\n    // 连接池保持的最小连接数\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.minPoolSize\")).to(3);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.preferredTestQuery\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.propertyCycle\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.testConnectionOnCheckin\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.testConnectionOnCheckout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.unreturnedConnectionTimeout\")).to(1);\n    binder.bindConstant().annotatedWith(Names.named(\"c3p0.usesTraditionalReflectiveProxies\")).to(1);\n}\n```\n\n我们还可以采用配置文件的方式设置\n```java\nimport org.mybatis.guice.XMLMyBatisModule;\nimport org.mybatis.guice.datasource.helper.JdbcHelper;\n\nimport com.google.inject.Guice;\nimport com.google.inject.Injector;\n\npublic class MybatisManager {\n    private static Injector injector;\n    static {\n        injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule());\n    }\n    private MybatisManager() {\n    }\n\n    public static <T> T getInstance(Class<T> var1) {\n        return injector.getInstance(var1);\n    }\n\n\tprivate static class MysqlModule extends XMLMyBatisModule {\n\n\t\t@Override\n\t\tprotected void initialize() {\n            setClassPathResource(\"configuration.xml\");\n\t\t}\n\t}\n}\n```","slug":"guice/mybatis-guice","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihro004cvjs6p3mcsz18"},{"date":"2015-12-27T16:00:00.000Z","title":"01_HelloWorld","_content":"```java\nimport org.openjdk.jmh.annotations.Benchmark;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\npublic class JMHSample_01_HelloWorld {\n\n    /*\n     * 这是我们的第一个基准函数\n     *\n     * JMH通过如下流程工作: 用户通过@Benchmark注解基准函数, 然后JMH在执行基准测试时会自动生成一些代码.\n     * @Benchmark注解的详细信息可以参考其Javadoc,但是我们可以简单地将其想象成有效负载测试.\n     *\n     * 我们可以在同一个类中定义多个benchmark函数, 函数名都无所谓, 但是我们应该尽可能的起一个有意义的名字.\n     *\n     * 需要注意的是, 如果函数没有执行完的话, JMH也不会停止运行. 如果函数中抛出异常, 那JMH同样的会停止运行, 执行下一个benchmark\n     *\n     * 尽管我们实例中并没有测试任何功能, 但是这个例子却能展示出当你进行基准测试时, 基础设施的基准线.\n     */\n\n\t@Benchmark\n\tpublic void wellHelloThere() {\n\t\t// 我们故意将该函数留空\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_01_HelloWorld.class.getSimpleName())\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n\n执行结果为\n```java\n# JMH 1.11.2 (released 60 days ago)\n# Warmup: 20 iterations, 1 s each\n# Measurement: 20 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_01_HelloWorld.wellHelloThere\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 3385522466.026 ops/s\n# Warmup Iteration   2: 3522171101.974 ops/s\n# Warmup Iteration   3: 3565836983.445 ops/s\n# Warmup Iteration   4: 3515408341.483 ops/s\n# Warmup Iteration   5: 3588745518.898 ops/s\n# Warmup Iteration   6: 3565087523.829 ops/s\n# Warmup Iteration   7: 3562771873.632 ops/s\n# Warmup Iteration   8: 3583632296.413 ops/s\n# Warmup Iteration   9: 3565611310.891 ops/s\n# Warmup Iteration  10: 3590948927.976 ops/s\n# Warmup Iteration  11: 3576434147.340 ops/s\n# Warmup Iteration  12: 3588304463.970 ops/s\n# Warmup Iteration  13: 3581233142.118 ops/s\n# Warmup Iteration  14: 3575921198.480 ops/s\n# Warmup Iteration  15: 3581761922.835 ops/s\n# Warmup Iteration  16: 3589445022.964 ops/s\n# Warmup Iteration  17: 3566869657.337 ops/s\n# Warmup Iteration  18: 3537779750.878 ops/s\n# Warmup Iteration  19: 3568040140.557 ops/s\n# Warmup Iteration  20: 3590220221.972 ops/s\nIteration   1: 3583340988.084 ops/s\nIteration   2: 3582273415.857 ops/s\nIteration   3: 3581430663.273 ops/s\nIteration   4: 3573066377.669 ops/s\nIteration   5: 3578876607.022 ops/s\nIteration   6: 3581448410.242 ops/s\nIteration   7: 3566004905.951 ops/s\nIteration   8: 3585318369.276 ops/s\nIteration   9: 3559148782.715 ops/s\nIteration  10: 3545919918.740 ops/s\nIteration  11: 3594271895.253 ops/s\nIteration  12: 3570179893.808 ops/s\nIteration  13: 3566673424.322 ops/s\nIteration  14: 3568946183.344 ops/s\nIteration  15: 3554498386.309 ops/s\nIteration  16: 3586741606.233 ops/s\nIteration  17: 3583433388.045 ops/s\nIteration  18: 3583027708.144 ops/s\nIteration  19: 3569799683.683 ops/s\nIteration  20: 3581887656.086 ops/s\n\n\nResult \"wellHelloThere\":\n  3574814413.203 ±(99.9%) 10497360.400 ops/s [Average]\n  (min, avg, max) = (3545919918.740, 3574814413.203, 3594271895.253), stdev = 12088775.847\n  CI (99.9%): [3564317052.803, 3585311773.603] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:40\n\nBenchmark                                    Mode  Cnt           Score          Error  Units\nJMH.JMHSample_01_HelloWorld.wellHelloThere  thrpt   20  3574814413.203 ± 10497360.400  ops/s\n```\n上面的输出依次为\n1. JMH执行版本\n2. 执行20次热身, 每次执行1秒\n3. 测试20次, 每次执行1秒\n4. 每次执行的超时时间, 默认是10分钟\n5. 执行线程, 我们设置的是1个线程, 且测试是同步执行的\n6. 基准模式是每秒执行的吞吐量\n7. 下面的执行结果是, 热身执行了20次, 每次执行的吞吐量大概为35亿次\n","source":"_posts/jmh/JMHSample_01_HelloWorld.md","raw":"category: JMH\ndate: 2015-12-28\ntitle: 01_HelloWorld\n---\n```java\nimport org.openjdk.jmh.annotations.Benchmark;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\npublic class JMHSample_01_HelloWorld {\n\n    /*\n     * 这是我们的第一个基准函数\n     *\n     * JMH通过如下流程工作: 用户通过@Benchmark注解基准函数, 然后JMH在执行基准测试时会自动生成一些代码.\n     * @Benchmark注解的详细信息可以参考其Javadoc,但是我们可以简单地将其想象成有效负载测试.\n     *\n     * 我们可以在同一个类中定义多个benchmark函数, 函数名都无所谓, 但是我们应该尽可能的起一个有意义的名字.\n     *\n     * 需要注意的是, 如果函数没有执行完的话, JMH也不会停止运行. 如果函数中抛出异常, 那JMH同样的会停止运行, 执行下一个benchmark\n     *\n     * 尽管我们实例中并没有测试任何功能, 但是这个例子却能展示出当你进行基准测试时, 基础设施的基准线.\n     */\n\n\t@Benchmark\n\tpublic void wellHelloThere() {\n\t\t// 我们故意将该函数留空\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_01_HelloWorld.class.getSimpleName())\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n\n执行结果为\n```java\n# JMH 1.11.2 (released 60 days ago)\n# Warmup: 20 iterations, 1 s each\n# Measurement: 20 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_01_HelloWorld.wellHelloThere\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 3385522466.026 ops/s\n# Warmup Iteration   2: 3522171101.974 ops/s\n# Warmup Iteration   3: 3565836983.445 ops/s\n# Warmup Iteration   4: 3515408341.483 ops/s\n# Warmup Iteration   5: 3588745518.898 ops/s\n# Warmup Iteration   6: 3565087523.829 ops/s\n# Warmup Iteration   7: 3562771873.632 ops/s\n# Warmup Iteration   8: 3583632296.413 ops/s\n# Warmup Iteration   9: 3565611310.891 ops/s\n# Warmup Iteration  10: 3590948927.976 ops/s\n# Warmup Iteration  11: 3576434147.340 ops/s\n# Warmup Iteration  12: 3588304463.970 ops/s\n# Warmup Iteration  13: 3581233142.118 ops/s\n# Warmup Iteration  14: 3575921198.480 ops/s\n# Warmup Iteration  15: 3581761922.835 ops/s\n# Warmup Iteration  16: 3589445022.964 ops/s\n# Warmup Iteration  17: 3566869657.337 ops/s\n# Warmup Iteration  18: 3537779750.878 ops/s\n# Warmup Iteration  19: 3568040140.557 ops/s\n# Warmup Iteration  20: 3590220221.972 ops/s\nIteration   1: 3583340988.084 ops/s\nIteration   2: 3582273415.857 ops/s\nIteration   3: 3581430663.273 ops/s\nIteration   4: 3573066377.669 ops/s\nIteration   5: 3578876607.022 ops/s\nIteration   6: 3581448410.242 ops/s\nIteration   7: 3566004905.951 ops/s\nIteration   8: 3585318369.276 ops/s\nIteration   9: 3559148782.715 ops/s\nIteration  10: 3545919918.740 ops/s\nIteration  11: 3594271895.253 ops/s\nIteration  12: 3570179893.808 ops/s\nIteration  13: 3566673424.322 ops/s\nIteration  14: 3568946183.344 ops/s\nIteration  15: 3554498386.309 ops/s\nIteration  16: 3586741606.233 ops/s\nIteration  17: 3583433388.045 ops/s\nIteration  18: 3583027708.144 ops/s\nIteration  19: 3569799683.683 ops/s\nIteration  20: 3581887656.086 ops/s\n\n\nResult \"wellHelloThere\":\n  3574814413.203 ±(99.9%) 10497360.400 ops/s [Average]\n  (min, avg, max) = (3545919918.740, 3574814413.203, 3594271895.253), stdev = 12088775.847\n  CI (99.9%): [3564317052.803, 3585311773.603] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:40\n\nBenchmark                                    Mode  Cnt           Score          Error  Units\nJMH.JMHSample_01_HelloWorld.wellHelloThere  thrpt   20  3574814413.203 ± 10497360.400  ops/s\n```\n上面的输出依次为\n1. JMH执行版本\n2. 执行20次热身, 每次执行1秒\n3. 测试20次, 每次执行1秒\n4. 每次执行的超时时间, 默认是10分钟\n5. 执行线程, 我们设置的是1个线程, 且测试是同步执行的\n6. 基准模式是每秒执行的吞吐量\n7. 下面的执行结果是, 热身执行了20次, 每次执行的吞吐量大概为35亿次\n","slug":"jmh/JMHSample_01_HelloWorld","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrq004fvjs6h10g45zp"},{"date":"2015-12-27T16:00:00.000Z","title":"02_BenchmarkModes","_content":"当benchmark编译过程中, JMH会为此生成大量的额外代码. JMH可以在多种不同的模式下进行基准测试.\n\n## 吞吐量\n```java\npublic class JMHSample_02_BenchmarkModes {\n\t/*\n     * Mode.Throughput, 统计一段时间内可持续调用基准测试方法的次数.\n     */\n\t@Benchmark\n\t@BenchmarkMode(Mode.Throughput)\n\t@OutputTimeUnit(TimeUnit.SECONDS)\n\tpublic void measureThroughput() throws InterruptedException {\n\t\tTimeUnit.MILLISECONDS.sleep(100);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n结果为\n```java\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: 10.007 ops/s\n# Warmup Iteration   2: 10.006 ops/s\n# Warmup Iteration   3: 10.004 ops/s\nIteration   1: 9.987 ops/s\nIteration   2: 10.005 ops/s\nIteration   3: 10.002 ops/s\nIteration   4: 9.999 ops/s\n\n\nResult \"measureThroughput\":\n  9.999 ±(99.9%) 0.051 ops/s [Average]\n  (min, avg, max) = (9.987, 9.999, 10.005), stdev = 0.008\n  CI (99.9%): [9.947, 10.050] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                           Mode  Cnt  Score   Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureThroughput  thrpt    4  9.999 ± 0.051  ops/s\n```\n从上面的结果中我们可以看到\n* Benchmark：执行的基准测试为`JMH.JMHSample_02_BenchmarkModes.measureThroughput`\n* Mode：执行模式为thrpt, 即Throughput\n* Cnt：执行次数为4\n* Score： 平均得分为9.999\n* Error：差值为0.051\n* Units：执行单元为ops/s\n\n## 平均执行时间\n```java\n/*\n * Mode.AverageTime 测试每个操作的平均执行时间.\n */\n@Benchmark\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureAvgTime() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果为\n```java\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: 99925.584 us/op\n# Warmup Iteration   2: 99961.273 us/op\n# Warmup Iteration   3: 100001.479 us/op\nIteration   1: 99958.320 us/op\nIteration   2: 99991.971 us/op\nIteration   3: 99951.680 us/op\nIteration   4: 100001.128 us/op\n\n\nResult \"measureAvgTime\":\n  99975.775 ±(99.9%) 157.859 us/op [Average]\n  (min, avg, max) = (99951.680, 99975.775, 100001.128), stdev = 24.429\n  CI (99.9%): [99817.916, 100133.634] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                       Mode  Cnt      Score     Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureAvgTime  avgt    4  99975.775 ± 157.859  us/op\n```\n在这个测试中我们要注意的是`us`和`MICROSECONDS`都是同一个含义, 都是微秒. 每个操作的平均值为100000微妙左右,也就是100毫秒左右,而我们的操作是sleep 100毫秒,和我们的预期结果相近\n\n## 采样\n```java\n/*\n * Mode.SampleTime 会对执行时间进行采样.\n *\n * JMH还会对采样自动调节频率, 如果方法足够长的话, 我们会得到所有的采样\n */\n@Benchmark\n@BenchmarkMode(Mode.SampleTime)\n@OutputTimeUnit(TimeUnit.MILLISECONDS)\npublic void measureSamples() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 4 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Sampling time\n# Benchmark: JMH.JMHSample_02_BenchmarkModes.measureSamples\n\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\n# Warmup Iteration   2: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\n# Warmup Iteration   3: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   1: n = 11, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   2: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   3: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   4: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\n\n\nResult \"measureSamples\":\n  99.886 ±(99.9%) 0.088 ms/op [Average]\n  (min, avg, max) = (99.222, 99.886, 100.008), stdev = 0.159\n  CI (99.9%): [99.798, 99.975] (assumes normal distribution)\n  Samples, N = 41\n        mean =     99.886 ±(99.9%) 0.088 ms/op\n         min =     99.222 ms/op\n  p( 0.0000) =     99.222 ms/op\n  p(50.0000) =     99.877 ms/op\n  p(90.0000) =    100.008 ms/op\n  p(95.0000) =    100.008 ms/op\n  p(99.0000) =    100.008 ms/op\n  p(99.9000) =    100.008 ms/op\n  p(99.9900) =    100.008 ms/op\n  p(99.9990) =    100.008 ms/op\n  p(99.9999) =    100.008 ms/op\n         max =    100.008 ms/op\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                         Mode  Cnt   Score   Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureSamples  sample   41  99.886 ± 0.088  ms/op\n```\n\n## 单次执行\n```java\n/*\n * Mode.SingleShotTime 测试单个方法的调用时间. 我们只会调用一次基准方法. 这个模式非常适用于你不想要持续执行基准测试\n * 的冷启动测试\n */\n@Benchmark\n@BenchmarkMode(Mode.SingleShotTime)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureSingleShot() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, single-shot each\n# Measurement: 4 iterations, single-shot each\n# Timeout: 10 min per iteration\n# Threads: 1 thread\n# Benchmark mode: Single shot invocation time\n# Benchmark: JMH.JMHSample_02_BenchmarkModes.measureSingleShot\n\n# Run progress: 0.00% complete, ETA 00:00:00\n# Fork: 1 of 1\n# Warmup Iteration   1: 99620.910 us/op\n# Warmup Iteration   2: 99072.153 us/op\n# Warmup Iteration   3: 99502.285 us/op\nIteration   1: 99269.561 us/op\nIteration   2: 99170.555 us/op\nIteration   3: 99598.574 us/op\nIteration   4: 99304.877 us/op\n\n\nResult \"measureSingleShot\":\n  99335.892 ±(99.9%) 1189.778 us/op [Average]\n  (min, avg, max) = (99170.555, 99335.892, 99598.574), stdev = 184.119\n  CI (99.9%): [98146.114, 100525.670] (assumes normal distribution)\n  Samples, N = 4\n        mean =  99335.892 ±(99.9%) 1189.778 us/op\n         min =  99170.555 us/op\n  p( 0.0000) =  99170.555 us/op\n  p(50.0000) =  99287.219 us/op\n  p(90.0000) =  99598.574 us/op\n  p(95.0000) =  99598.574 us/op\n  p(99.0000) =  99598.574 us/op\n  p(99.9000) =  99598.574 us/op\n  p(99.9900) =  99598.574 us/op\n  p(99.9990) =  99598.574 us/op\n  p(99.9999) =  99598.574 us/op\n         max =  99598.574 us/op\n\n\n# Run complete. Total time: 00:00:01\n\nBenchmark                                          Mode  Cnt      Score      Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureSingleShot    ss    4  99335.892 ± 1189.778  us/op\n```\n\n## 组合模式\n我们还可以将以上模式组合起来\n```java\n@Benchmark\n@BenchmarkMode({Mode.Throughput, Mode.AverageTime, Mode.SampleTime, Mode.SingleShotTime})\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureMultiple() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n```\n\n## 全部依次执行\n\n```java\n@Benchmark\n@BenchmarkMode(Mode.All)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureAll() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n```\n","source":"_posts/jmh/JMHSample_02_BenchmarkModes.md","raw":"category: JMH\ndate: 2015-12-28\ntitle: 02_BenchmarkModes\n---\n当benchmark编译过程中, JMH会为此生成大量的额外代码. JMH可以在多种不同的模式下进行基准测试.\n\n## 吞吐量\n```java\npublic class JMHSample_02_BenchmarkModes {\n\t/*\n     * Mode.Throughput, 统计一段时间内可持续调用基准测试方法的次数.\n     */\n\t@Benchmark\n\t@BenchmarkMode(Mode.Throughput)\n\t@OutputTimeUnit(TimeUnit.SECONDS)\n\tpublic void measureThroughput() throws InterruptedException {\n\t\tTimeUnit.MILLISECONDS.sleep(100);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n结果为\n```java\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: 10.007 ops/s\n# Warmup Iteration   2: 10.006 ops/s\n# Warmup Iteration   3: 10.004 ops/s\nIteration   1: 9.987 ops/s\nIteration   2: 10.005 ops/s\nIteration   3: 10.002 ops/s\nIteration   4: 9.999 ops/s\n\n\nResult \"measureThroughput\":\n  9.999 ±(99.9%) 0.051 ops/s [Average]\n  (min, avg, max) = (9.987, 9.999, 10.005), stdev = 0.008\n  CI (99.9%): [9.947, 10.050] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                           Mode  Cnt  Score   Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureThroughput  thrpt    4  9.999 ± 0.051  ops/s\n```\n从上面的结果中我们可以看到\n* Benchmark：执行的基准测试为`JMH.JMHSample_02_BenchmarkModes.measureThroughput`\n* Mode：执行模式为thrpt, 即Throughput\n* Cnt：执行次数为4\n* Score： 平均得分为9.999\n* Error：差值为0.051\n* Units：执行单元为ops/s\n\n## 平均执行时间\n```java\n/*\n * Mode.AverageTime 测试每个操作的平均执行时间.\n */\n@Benchmark\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureAvgTime() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果为\n```java\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: 99925.584 us/op\n# Warmup Iteration   2: 99961.273 us/op\n# Warmup Iteration   3: 100001.479 us/op\nIteration   1: 99958.320 us/op\nIteration   2: 99991.971 us/op\nIteration   3: 99951.680 us/op\nIteration   4: 100001.128 us/op\n\n\nResult \"measureAvgTime\":\n  99975.775 ±(99.9%) 157.859 us/op [Average]\n  (min, avg, max) = (99951.680, 99975.775, 100001.128), stdev = 24.429\n  CI (99.9%): [99817.916, 100133.634] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                       Mode  Cnt      Score     Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureAvgTime  avgt    4  99975.775 ± 157.859  us/op\n```\n在这个测试中我们要注意的是`us`和`MICROSECONDS`都是同一个含义, 都是微秒. 每个操作的平均值为100000微妙左右,也就是100毫秒左右,而我们的操作是sleep 100毫秒,和我们的预期结果相近\n\n## 采样\n```java\n/*\n * Mode.SampleTime 会对执行时间进行采样.\n *\n * JMH还会对采样自动调节频率, 如果方法足够长的话, 我们会得到所有的采样\n */\n@Benchmark\n@BenchmarkMode(Mode.SampleTime)\n@OutputTimeUnit(TimeUnit.MILLISECONDS)\npublic void measureSamples() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 4 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Sampling time\n# Benchmark: JMH.JMHSample_02_BenchmarkModes.measureSamples\n\n# Run progress: 0.00% complete, ETA 00:00:07\n# Fork: 1 of 1\n# Warmup Iteration   1: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\n# Warmup Iteration   2: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\n# Warmup Iteration   3: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   1: n = 11, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   2: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 100, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   3: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\nIteration   4: n = 10, mean = 100 ms/op, p{0.00, 0.50, 0.90, 0.95, 0.99, 0.999, 0.9999, 1.00} = 99, 100, 100, 100, 100, 100, 100, 100 ms/op\n\n\nResult \"measureSamples\":\n  99.886 ±(99.9%) 0.088 ms/op [Average]\n  (min, avg, max) = (99.222, 99.886, 100.008), stdev = 0.159\n  CI (99.9%): [99.798, 99.975] (assumes normal distribution)\n  Samples, N = 41\n        mean =     99.886 ±(99.9%) 0.088 ms/op\n         min =     99.222 ms/op\n  p( 0.0000) =     99.222 ms/op\n  p(50.0000) =     99.877 ms/op\n  p(90.0000) =    100.008 ms/op\n  p(95.0000) =    100.008 ms/op\n  p(99.0000) =    100.008 ms/op\n  p(99.9000) =    100.008 ms/op\n  p(99.9900) =    100.008 ms/op\n  p(99.9990) =    100.008 ms/op\n  p(99.9999) =    100.008 ms/op\n         max =    100.008 ms/op\n\n\n# Run complete. Total time: 00:00:07\n\nBenchmark                                         Mode  Cnt   Score   Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureSamples  sample   41  99.886 ± 0.088  ms/op\n```\n\n## 单次执行\n```java\n/*\n * Mode.SingleShotTime 测试单个方法的调用时间. 我们只会调用一次基准方法. 这个模式非常适用于你不想要持续执行基准测试\n * 的冷启动测试\n */\n@Benchmark\n@BenchmarkMode(Mode.SingleShotTime)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureSingleShot() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n\npublic static void main(String[] args) throws RunnerException {\n\tOptions opt = new OptionsBuilder()\n\t\t\t.include(JMHSample_02_BenchmarkModes.class.getSimpleName())\n\t\t\t.warmupIterations(3)\t// 热身3次\n\t\t\t.measurementIterations(4)\t// 执行4次\n\t\t\t.forks(1)\n\t\t\t.build();\n\n\tnew Runner(opt).run();\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, single-shot each\n# Measurement: 4 iterations, single-shot each\n# Timeout: 10 min per iteration\n# Threads: 1 thread\n# Benchmark mode: Single shot invocation time\n# Benchmark: JMH.JMHSample_02_BenchmarkModes.measureSingleShot\n\n# Run progress: 0.00% complete, ETA 00:00:00\n# Fork: 1 of 1\n# Warmup Iteration   1: 99620.910 us/op\n# Warmup Iteration   2: 99072.153 us/op\n# Warmup Iteration   3: 99502.285 us/op\nIteration   1: 99269.561 us/op\nIteration   2: 99170.555 us/op\nIteration   3: 99598.574 us/op\nIteration   4: 99304.877 us/op\n\n\nResult \"measureSingleShot\":\n  99335.892 ±(99.9%) 1189.778 us/op [Average]\n  (min, avg, max) = (99170.555, 99335.892, 99598.574), stdev = 184.119\n  CI (99.9%): [98146.114, 100525.670] (assumes normal distribution)\n  Samples, N = 4\n        mean =  99335.892 ±(99.9%) 1189.778 us/op\n         min =  99170.555 us/op\n  p( 0.0000) =  99170.555 us/op\n  p(50.0000) =  99287.219 us/op\n  p(90.0000) =  99598.574 us/op\n  p(95.0000) =  99598.574 us/op\n  p(99.0000) =  99598.574 us/op\n  p(99.9000) =  99598.574 us/op\n  p(99.9900) =  99598.574 us/op\n  p(99.9990) =  99598.574 us/op\n  p(99.9999) =  99598.574 us/op\n         max =  99598.574 us/op\n\n\n# Run complete. Total time: 00:00:01\n\nBenchmark                                          Mode  Cnt      Score      Error  Units\nJMH.JMHSample_02_BenchmarkModes.measureSingleShot    ss    4  99335.892 ± 1189.778  us/op\n```\n\n## 组合模式\n我们还可以将以上模式组合起来\n```java\n@Benchmark\n@BenchmarkMode({Mode.Throughput, Mode.AverageTime, Mode.SampleTime, Mode.SingleShotTime})\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureMultiple() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n```\n\n## 全部依次执行\n\n```java\n@Benchmark\n@BenchmarkMode(Mode.All)\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic void measureAll() throws InterruptedException {\n\tTimeUnit.MILLISECONDS.sleep(100);\n}\n```\n","slug":"jmh/JMHSample_02_BenchmarkModes","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrs004hvjs6huebg8i9"},{"date":"2015-12-31T16:00:00.000Z","title":"03_States","_content":"在很多种情况下, 在benchmark运行的过程中, 你可能需要维持一些状态, 但是JMH被设计成经常并发的执行benchmark, 因此JMH提供了一些用于保存状态的对象.\n\n我们可以使用`@State`赋予其一个生命周期. 如下例所示, \n```java\nimport org.openjdk.jmh.annotations.Benchmark;\nimport org.openjdk.jmh.annotations.Scope;\nimport org.openjdk.jmh.annotations.State;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\npublic class JMHSample_03_States {\n\n\n    @State(Scope.Benchmark)\n    public static class BenchmarkState {\n        volatile double x = Math.PI;\n    }\n\n    @State(Scope.Thread)\n    public static class ThreadState {\n        volatile double x = Math.PI;\n    }\n\n    /*\n     * Benchmark函数可以引用哪些状态对象, 这些状态对象的值由JMH负责注入. Benchmark函数可以没有状态对象,\n     * 也可以有一个或者多个状态对象引用. 我们可以很轻松的构建一个多线程的Benchmark.\n     */\n\n    @Benchmark\n    public void measureUnshared(ThreadState state) {\n        // 所有的Benchmark线程都会调用这个方法,但是由于`ThreadState`作用在了Scope.Thread, 因此每个线程都会有一个自己的本地\n        // 状态数据拷贝, 线程间的状态数据并不会进行共享\n        state.x++;\n    }\n\n    @Benchmark\n    public void measureShared(BenchmarkState state) {\n        // 所有的benchmark都会调用这个方法, 由于BenchmarkState是作用于Scope.Benchmark, 因此所有的线程都会共享同一个\n        // BenchmarkState实例\n        state.x++;\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(JMHSample_03_States.class.getSimpleName())\n                .warmupIterations(5)\n                .measurementIterations(5)\n                .threads(4)\n                .forks(1)\n                .build();\n\n        new Runner(opt).run();\n    }\n\n}\n\n```\n有一点非常重要的是state由对其进行访问的benchmark线程实例化.","source":"_posts/jmh/JMHSample_03_States.md","raw":"category: JMH\ndate: 2016-01-01\ntitle: 03_States \n---\n在很多种情况下, 在benchmark运行的过程中, 你可能需要维持一些状态, 但是JMH被设计成经常并发的执行benchmark, 因此JMH提供了一些用于保存状态的对象.\n\n我们可以使用`@State`赋予其一个生命周期. 如下例所示, \n```java\nimport org.openjdk.jmh.annotations.Benchmark;\nimport org.openjdk.jmh.annotations.Scope;\nimport org.openjdk.jmh.annotations.State;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\npublic class JMHSample_03_States {\n\n\n    @State(Scope.Benchmark)\n    public static class BenchmarkState {\n        volatile double x = Math.PI;\n    }\n\n    @State(Scope.Thread)\n    public static class ThreadState {\n        volatile double x = Math.PI;\n    }\n\n    /*\n     * Benchmark函数可以引用哪些状态对象, 这些状态对象的值由JMH负责注入. Benchmark函数可以没有状态对象,\n     * 也可以有一个或者多个状态对象引用. 我们可以很轻松的构建一个多线程的Benchmark.\n     */\n\n    @Benchmark\n    public void measureUnshared(ThreadState state) {\n        // 所有的Benchmark线程都会调用这个方法,但是由于`ThreadState`作用在了Scope.Thread, 因此每个线程都会有一个自己的本地\n        // 状态数据拷贝, 线程间的状态数据并不会进行共享\n        state.x++;\n    }\n\n    @Benchmark\n    public void measureShared(BenchmarkState state) {\n        // 所有的benchmark都会调用这个方法, 由于BenchmarkState是作用于Scope.Benchmark, 因此所有的线程都会共享同一个\n        // BenchmarkState实例\n        state.x++;\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(JMHSample_03_States.class.getSimpleName())\n                .warmupIterations(5)\n                .measurementIterations(5)\n                .threads(4)\n                .forks(1)\n                .build();\n\n        new Runner(opt).run();\n    }\n\n}\n\n```\n有一点非常重要的是state由对其进行访问的benchmark线程实例化.","slug":"jmh/JMHSample_03_States","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihrx004kvjs6xx93ay5x"},{"date":"2015-12-31T16:00:00.000Z","title":"04_DefaultState","_content":"```java\n/*\n * 幸运的是, 在大多数情况下我们只需要一个状态对象, 因此我们可以将@State注解到Benchmark类的自身, 然后\n * 让所有的benchmark函数都可以对其进行访问\n */\n\n@State(Scope.Thread)\npublic class JMHSample_04_DefaultState {\n\n    double x = Math.PI;\n\n    @Benchmark\n    public void measure() {\n        x++;\n    }\n\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(JMHSample_04_DefaultState.class.getSimpleName())\n                .warmupIterations(5)\n                .measurementIterations(5)\n                .forks(1)\n                .build();\n\n        new Runner(opt).run();\n    }\n\n}\n```","source":"_posts/jmh/JMHSample_04_DefaultState.md","raw":"category: JMH\ndate: 2016-01-01\ntitle: 04_DefaultState \n---\n```java\n/*\n * 幸运的是, 在大多数情况下我们只需要一个状态对象, 因此我们可以将@State注解到Benchmark类的自身, 然后\n * 让所有的benchmark函数都可以对其进行访问\n */\n\n@State(Scope.Thread)\npublic class JMHSample_04_DefaultState {\n\n    double x = Math.PI;\n\n    @Benchmark\n    public void measure() {\n        x++;\n    }\n\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(JMHSample_04_DefaultState.class.getSimpleName())\n                .warmupIterations(5)\n                .measurementIterations(5)\n                .forks(1)\n                .build();\n\n        new Runner(opt).run();\n    }\n\n}\n```","slug":"jmh/JMHSample_04_DefaultState","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihs0004mvjs6fwmeuodl"},{"date":"2016-01-03T16:00:00.000Z","title":"05_StateFixtures","_content":"```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\n@State(Scope.Thread)\npublic class JMHSample_05_StateFixtures {\n\n\tdouble x;\n\n    /*\n     * 由于@State对象会存在于整个benchmark的生命周期之中, 因此JMH提供了一些在生命周期中的某个阶段执行一些特殊的函数.\n     * 这些函数称为Fixture methods, 注意这些函数只在@State对象中有用, 如果用于非@State对象则会编译失败.\n     * 这些函数和JUnit中的@Before等等很像\n     *\n     * 还有一点需要说明的是这些对象只会由调用了含有@State对象的benchmark函数的线程执行调用. 这意味着这些函数是在\n     * thread-local上下文中执行, 你不必使用synchronization进行并发保护\n     */\n\n\t// 由于我们使用的是Scope.Thread, 因此每当线程第一次调用含有@State对象的基准函数时都会调用prepare()函数\n\t@Setup\n\tpublic void prepare() {\n\t\tx = Math.PI;\n\t}\n\n\t// 由于我们使用的是Scope.Thread, 因此每当线程调用完含有@State对象的基准函数时都会调用prepare()函数\n\t@TearDown\n\tpublic void check() {\n\t\tassert x > Math.PI : \"Nothing changed?\";\n\t}\n\n\t@Benchmark\n\tpublic void measureRight() {\n\t\tx++;\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\tdouble x = 0;\n\t\tx++;\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_05_StateFixtures.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.jvmArgs(\"-ea\")\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n执行结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_05_StateFixtures.measureRight\n\n# Run progress: 0.00% complete, ETA 00:00:20\n# Fork: 1 of 1\n# Warmup Iteration   1: 395892824.608 ops/s\n# Warmup Iteration   2: 390597753.910 ops/s\n# Warmup Iteration   3: 391909791.701 ops/s\n# Warmup Iteration   4: 390345655.260 ops/s\n# Warmup Iteration   5: 397800824.768 ops/s\nIteration   1: 399438984.759 ops/s\nIteration   2: 393471030.370 ops/s\nIteration   3: 397809527.925 ops/s\nIteration   4: 395613641.908 ops/s\nIteration   5: 393314885.110 ops/s\n\n\nResult \"measureRight\":\n  395929614.015 ±(99.9%) 10337928.122 ops/s [Average]\n  (min, avg, max) = (393314885.110, 395929614.015, 399438984.759), stdev = 2684727.104\n  CI (99.9%): [385591685.893, 406267542.136] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_05_StateFixtures.measureWrong\n\n# Run progress: 50.00% complete, ETA 00:00:11\n# Fork: 1 of 1\n# Warmup Iteration   1: 3066015172.981 ops/s\n# Warmup Iteration   2: 3143979330.555 ops/s\n# Warmup Iteration   3: 3078037603.045 ops/s\n# Warmup Iteration   4: 2944032954.636 ops/s\n# Warmup Iteration   5: 3062399303.457 ops/s\nIteration   1: 3020901214.195 ops/s\nIteration   2: 3117915404.622 ops/s\nIteration   3: 3186149965.554 ops/s\nIteration   4: 3204341135.065 ops/s\nIteration   5: <failure>\n\njava.lang.AssertionError: Nothing changed?\n\tat JMH.JMHSample_05_StateFixtures.check(JMHSample_05_StateFixtures.java:35)\n\tat JMH.generated.JMHSample_05_StateFixtures_measureWrong_jmhTest.measureWrong_Throughput(JMHSample_05_StateFixtures_measureWrong_jmhTest.java:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:430)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:412)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n\n\nResult \"measureWrong\":\n  3132326929.859 ±(99.9%) 536855433.895 ops/s [Average]\n  (min, avg, max) = (3020901214.195, 3132326929.859, 3204341135.065), stdev = 83078972.658\n  CI (99.9%): [2595471495.964, 3669182363.754] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:23\n\nBenchmark                                     Mode  Cnt           Score           Error  Units\nJMH.JMHSample_05_StateFixtures.measureRight  thrpt    5   395929614.015 ±  10337928.122  ops/s\nJMH.JMHSample_05_StateFixtures.measureWrong  thrpt    4  3132326929.859 ± 536855433.895  ops/s\n```\n我们可以看出当Thread执行完之后, check的时候就发生了异常\n","source":"_posts/jmh/JMHSample_05_StateFixtures.md","raw":"category: JMH\ndate: 2016-01-04\ntitle: 05_StateFixtures\n---\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\n@State(Scope.Thread)\npublic class JMHSample_05_StateFixtures {\n\n\tdouble x;\n\n    /*\n     * 由于@State对象会存在于整个benchmark的生命周期之中, 因此JMH提供了一些在生命周期中的某个阶段执行一些特殊的函数.\n     * 这些函数称为Fixture methods, 注意这些函数只在@State对象中有用, 如果用于非@State对象则会编译失败.\n     * 这些函数和JUnit中的@Before等等很像\n     *\n     * 还有一点需要说明的是这些对象只会由调用了含有@State对象的benchmark函数的线程执行调用. 这意味着这些函数是在\n     * thread-local上下文中执行, 你不必使用synchronization进行并发保护\n     */\n\n\t// 由于我们使用的是Scope.Thread, 因此每当线程第一次调用含有@State对象的基准函数时都会调用prepare()函数\n\t@Setup\n\tpublic void prepare() {\n\t\tx = Math.PI;\n\t}\n\n\t// 由于我们使用的是Scope.Thread, 因此每当线程调用完含有@State对象的基准函数时都会调用prepare()函数\n\t@TearDown\n\tpublic void check() {\n\t\tassert x > Math.PI : \"Nothing changed?\";\n\t}\n\n\t@Benchmark\n\tpublic void measureRight() {\n\t\tx++;\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\tdouble x = 0;\n\t\tx++;\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_05_StateFixtures.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.jvmArgs(\"-ea\")\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n执行结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_05_StateFixtures.measureRight\n\n# Run progress: 0.00% complete, ETA 00:00:20\n# Fork: 1 of 1\n# Warmup Iteration   1: 395892824.608 ops/s\n# Warmup Iteration   2: 390597753.910 ops/s\n# Warmup Iteration   3: 391909791.701 ops/s\n# Warmup Iteration   4: 390345655.260 ops/s\n# Warmup Iteration   5: 397800824.768 ops/s\nIteration   1: 399438984.759 ops/s\nIteration   2: 393471030.370 ops/s\nIteration   3: 397809527.925 ops/s\nIteration   4: 395613641.908 ops/s\nIteration   5: 393314885.110 ops/s\n\n\nResult \"measureRight\":\n  395929614.015 ±(99.9%) 10337928.122 ops/s [Average]\n  (min, avg, max) = (393314885.110, 395929614.015, 399438984.759), stdev = 2684727.104\n  CI (99.9%): [385591685.893, 406267542.136] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_05_StateFixtures.measureWrong\n\n# Run progress: 50.00% complete, ETA 00:00:11\n# Fork: 1 of 1\n# Warmup Iteration   1: 3066015172.981 ops/s\n# Warmup Iteration   2: 3143979330.555 ops/s\n# Warmup Iteration   3: 3078037603.045 ops/s\n# Warmup Iteration   4: 2944032954.636 ops/s\n# Warmup Iteration   5: 3062399303.457 ops/s\nIteration   1: 3020901214.195 ops/s\nIteration   2: 3117915404.622 ops/s\nIteration   3: 3186149965.554 ops/s\nIteration   4: 3204341135.065 ops/s\nIteration   5: <failure>\n\njava.lang.AssertionError: Nothing changed?\n\tat JMH.JMHSample_05_StateFixtures.check(JMHSample_05_StateFixtures.java:35)\n\tat JMH.generated.JMHSample_05_StateFixtures_measureWrong_jmhTest.measureWrong_Throughput(JMHSample_05_StateFixtures_measureWrong_jmhTest.java:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:430)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:412)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n\n\nResult \"measureWrong\":\n  3132326929.859 ±(99.9%) 536855433.895 ops/s [Average]\n  (min, avg, max) = (3020901214.195, 3132326929.859, 3204341135.065), stdev = 83078972.658\n  CI (99.9%): [2595471495.964, 3669182363.754] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:23\n\nBenchmark                                     Mode  Cnt           Score           Error  Units\nJMH.JMHSample_05_StateFixtures.measureRight  thrpt    5   395929614.015 ±  10337928.122  ops/s\nJMH.JMHSample_05_StateFixtures.measureWrong  thrpt    4  3132326929.859 ± 536855433.895  ops/s\n```\n我们可以看出当Thread执行完之后, check的时候就发生了异常\n","slug":"jmh/JMHSample_05_StateFixtures","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihs1004ovjs6cskryrrg"},{"date":"2016-01-03T16:00:00.000Z","title":"06_FixtureLevel","_content":"在演示这个示例之前我们先说一下`@State`里Fixture methods的运行级别含义\n* Level.Trial: 整个benchmark, 其含义是iteration的序列集合\n* Level.Iteration: benchmark里单个iteration,　包含统计内调用方法的集合\n* Level.Invocation:　单个benchmark方法的调用\n\n```java\n@State(Scope.Thread)\npublic class JMHSample_06_FixtureLevel {\n\n\tdouble x;\n\n    /* Fixture methods有三种不同的运行级别:\n     *\n     * Level.Trial: 在整个benchmark之前或者之后运行\n     * Level.Iteration: 在每个benchmark iteration 之前或者之后运行\n     * Level.Invocation: 在每个 benchmark method 调用之前或者之后运行\n     *\n     * fixture methods 所消耗的事件并不会统计在最终结果中, 因此我们可以在这些方法中做一些耗时操作\n     */\n\n\t@TearDown(Level.Iteration)\n\tpublic void check() {\n\t\tassert x > Math.PI : \"Nothing changed?\";\n\t}\n\n\t@Benchmark\n\tpublic void measureRight() {\n\t\tx++;\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\tdouble x = 0;\n\t\tx++;\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_06_FixtureLevel.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\n\t\t\t\t.measurementIterations(3)\n\t\t\t\t.forks(1)\n\t\t\t\t.jvmArgs(\"-ea\")\n\t\t\t\t.shouldFailOnError(false) // switch to \"true\" to fail the complete run\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n我们观察到的结果是\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_06_FixtureLevel.measureRight\n\n# Run progress: 0.00% complete, ETA 00:00:12\n# Fork: 1 of 1\n# Warmup Iteration   1: 399616586.177 ops/s\n# Warmup Iteration   2: 399871057.355 ops/s\n# Warmup Iteration   3: 400062522.871 ops/s\nIteration   1: 399026547.186 ops/s\nIteration   2: 400226493.878 ops/s\nIteration   3: 398754925.120 ops/s\n\n\nResult \"measureRight\":\n  399335988.728 ±(99.9%) 14286060.402 ops/s [Average]\n  (min, avg, max) = (398754925.120, 399335988.728, 400226493.878), stdev = 783067.177\n  CI (99.9%): [385049928.326, 413622049.130] (assumes normal distribution)\n\n\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_06_FixtureLevel.measureWrong\n\n# Run progress: 50.00% complete, ETA 00:00:06\n# Fork: 1 of 1\n# Warmup Iteration   1: <failure>\n\njava.lang.AssertionError: Nothing changed?\n\tat JMH.JMHSample_06_FixtureLevel.check(JMHSample_06_FixtureLevel.java:28)\n\tat JMH.generated.JMHSample_06_FixtureLevel_measureWrong_jmhTest.measureWrong_Throughput(JMHSample_06_FixtureLevel_measureWrong_jmhTest.java:80)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:430)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:412)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n# Run complete. Total time: 00:00:08\n\nBenchmark                                    Mode  Cnt          Score          Error  Units\nJMH.JMHSample_06_FixtureLevel.measureRight  thrpt    3  399335988.728 ± 14286060.402  ops/s\n```\n从结果中我们可以看到在测试measureWrong时，刚执行完一个iteration就产生了异常\n","source":"_posts/jmh/JMHSample_06_FixtureLevel.md","raw":"category: JMH\ndate: 2016-01-04\ntitle: 06_FixtureLevel\n---\n在演示这个示例之前我们先说一下`@State`里Fixture methods的运行级别含义\n* Level.Trial: 整个benchmark, 其含义是iteration的序列集合\n* Level.Iteration: benchmark里单个iteration,　包含统计内调用方法的集合\n* Level.Invocation:　单个benchmark方法的调用\n\n```java\n@State(Scope.Thread)\npublic class JMHSample_06_FixtureLevel {\n\n\tdouble x;\n\n    /* Fixture methods有三种不同的运行级别:\n     *\n     * Level.Trial: 在整个benchmark之前或者之后运行\n     * Level.Iteration: 在每个benchmark iteration 之前或者之后运行\n     * Level.Invocation: 在每个 benchmark method 调用之前或者之后运行\n     *\n     * fixture methods 所消耗的事件并不会统计在最终结果中, 因此我们可以在这些方法中做一些耗时操作\n     */\n\n\t@TearDown(Level.Iteration)\n\tpublic void check() {\n\t\tassert x > Math.PI : \"Nothing changed?\";\n\t}\n\n\t@Benchmark\n\tpublic void measureRight() {\n\t\tx++;\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\tdouble x = 0;\n\t\tx++;\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_06_FixtureLevel.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\n\t\t\t\t.measurementIterations(3)\n\t\t\t\t.forks(1)\n\t\t\t\t.jvmArgs(\"-ea\")\n\t\t\t\t.shouldFailOnError(false) // switch to \"true\" to fail the complete run\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n```\n我们观察到的结果是\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_06_FixtureLevel.measureRight\n\n# Run progress: 0.00% complete, ETA 00:00:12\n# Fork: 1 of 1\n# Warmup Iteration   1: 399616586.177 ops/s\n# Warmup Iteration   2: 399871057.355 ops/s\n# Warmup Iteration   3: 400062522.871 ops/s\nIteration   1: 399026547.186 ops/s\nIteration   2: 400226493.878 ops/s\nIteration   3: 398754925.120 ops/s\n\n\nResult \"measureRight\":\n  399335988.728 ±(99.9%) 14286060.402 ops/s [Average]\n  (min, avg, max) = (398754925.120, 399335988.728, 400226493.878), stdev = 783067.177\n  CI (99.9%): [385049928.326, 413622049.130] (assumes normal distribution)\n\n\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: JMH.JMHSample_06_FixtureLevel.measureWrong\n\n# Run progress: 50.00% complete, ETA 00:00:06\n# Fork: 1 of 1\n# Warmup Iteration   1: <failure>\n\njava.lang.AssertionError: Nothing changed?\n\tat JMH.JMHSample_06_FixtureLevel.check(JMHSample_06_FixtureLevel.java:28)\n\tat JMH.generated.JMHSample_06_FixtureLevel_measureWrong_jmhTest.measureWrong_Throughput(JMHSample_06_FixtureLevel_measureWrong_jmhTest.java:80)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:430)\n\tat org.openjdk.jmh.runner.BenchmarkHandler$BenchmarkTask.call(BenchmarkHandler.java:412)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n# Run complete. Total time: 00:00:08\n\nBenchmark                                    Mode  Cnt          Score          Error  Units\nJMH.JMHSample_06_FixtureLevel.measureRight  thrpt    3  399335988.728 ± 14286060.402  ops/s\n```\n从结果中我们可以看到在测试measureWrong时，刚执行完一个iteration就产生了异常\n","slug":"jmh/JMHSample_06_FixtureLevel","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihs4004rvjs65ccoxem1"},{"date":"2016-01-03T16:00:00.000Z","title":"07_FixtureLevelInvocation","_content":"Fixtures含有不同的运行等级. Level.Invocation通常可以帮我们在基准测试方法之前执行一些特殊的操作, 这些操作并不会被统计在测量结果中. 但是需要注意的是生成的时间戳和同步代码块会对测量的结果产生偏移\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.*;\n\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic class JMHSample_07_FixtureLevelInvocation {\n    /*\n     * 我们在整个benchmark过程中保持同一个NormalState对象, 然后分别在benchmark刚开始启动和\n     * benchmark结束时创建和销毁ExecutorService对象\n     */\n\t@State(Scope.Benchmark)\n\tpublic static class NormalState {\n\t\tExecutorService service;\n\n\t\t// 在整个benchmark开始进行初始化\n\t\t@Setup(Level.Trial)\n\t\tpublic void up() {\n\t\t\tservice = Executors.newCachedThreadPool();\n\t\t}\n\n\t\t// 在整个benchmark结束后, 将ExecutorService关闭掉\n\t\t@TearDown(Level.Trial)\n\t\tpublic void down() {\n\t\t\tservice.shutdown();\n\t\t}\n\n\t}\n\n\tpublic static class LaggingState extends NormalState {\n\t\tpublic static final int SLEEP_TIME = Integer.getInteger(\"sleepTime\", 10);\n\n\t\t// 在benchmark过程中, 没执行一次benchmark方法调用, 都会首先执行一下这个方法\n\t\t@Setup(Level.Invocation)\n\t\tpublic void lag() throws InterruptedException {\n\t\t\tTimeUnit.MILLISECONDS.sleep(SLEEP_TIME);\n\t\t}\n\t}\n\n\t@Benchmark\n\t@BenchmarkMode(Mode.AverageTime)\n\tpublic double measureHot(NormalState e, final Scratch s) throws ExecutionException, InterruptedException {\n\t\treturn e.service.submit(new Task(s)).get();\n\t}\n\n\t@Benchmark\n\t@BenchmarkMode(Mode.AverageTime)\n\tpublic double measureCold(LaggingState e, final Scratch s) throws ExecutionException, InterruptedException {\n\t\treturn e.service.submit(new Task(s)).get();\n\t}\n\n\t@State(Scope.Thread)\n\tpublic static class Scratch {\n\t\tprivate double p;\n\t\tpublic double doWork() {\n\t\t\tp = Math.log(p);\n\t\t\treturn p;\n\t\t}\n\t}\n\n\tpublic static class Task implements Callable<Double> {\n\t\tprivate Scratch s;\n\n\t\tpublic Task(Scratch s) {\n\t\t\tthis.s = s;\n\t\t}\n\n\t\t@Override\n\t\tpublic Double call() {\n\t\t\treturn s.doWork();\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_07_FixtureLevelInvocation.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\n\t\t\t\t.measurementIterations(3)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_07_FixtureLevelInvocation.measureCold\n\n# Run progress: 0.00% complete, ETA 00:00:12\n# Fork: 1 of 1\n# Warmup Iteration   1: 110.941 us/op\n# Warmup Iteration   2: 91.016 us/op\n# Warmup Iteration   3: 94.717 us/op\nIteration   1: 87.367 us/op\nIteration   2: 70.264 us/op\nIteration   3: 74.239 us/op\n\n\nResult \"measureCold\":\n  77.290 ±(99.9%) 163.284 us/op [Average]\n  (min, avg, max) = (70.264, 77.290, 87.367), stdev = 8.950\n  CI (99.9%): [≈ 0, 240.574] (assumes normal distribution)\n\n\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_07_FixtureLevelInvocation.measureHot\n\n# Run progress: 50.00% complete, ETA 00:00:06\n# Fork: 1 of 1\n# Warmup Iteration   1: 5.642 us/op\n# Warmup Iteration   2: 5.384 us/op\n# Warmup Iteration   3: 5.234 us/op\nIteration   1: 5.187 us/op\nIteration   2: 5.178 us/op\nIteration   3: 5.536 us/op\n\n\nResult \"measureHot\":\n  5.300 ±(99.9%) 3.723 us/op [Average]\n  (min, avg, max) = (5.178, 5.300, 5.536), stdev = 0.204\n  CI (99.9%): [1.578, 9.023] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:13\n\nBenchmark                                            Mode  Cnt   Score     Error  Units\nJMH.JMHSample_07_FixtureLevelInvocation.measureCold  avgt    3  77.290 ± 163.284  us/op\nJMH.JMHSample_07_FixtureLevelInvocation.measureHot   avgt    3   5.300 ±   3.723  us/op\n```\n","source":"_posts/jmh/JMHSample_07_FixtureLevelInvocation.md","raw":"category: JMH\ndate: 2016-01-04\ntitle: 07_FixtureLevelInvocation\n---\nFixtures含有不同的运行等级. Level.Invocation通常可以帮我们在基准测试方法之前执行一些特殊的操作, 这些操作并不会被统计在测量结果中. 但是需要注意的是生成的时间戳和同步代码块会对测量的结果产生偏移\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.*;\n\n@OutputTimeUnit(TimeUnit.MICROSECONDS)\npublic class JMHSample_07_FixtureLevelInvocation {\n    /*\n     * 我们在整个benchmark过程中保持同一个NormalState对象, 然后分别在benchmark刚开始启动和\n     * benchmark结束时创建和销毁ExecutorService对象\n     */\n\t@State(Scope.Benchmark)\n\tpublic static class NormalState {\n\t\tExecutorService service;\n\n\t\t// 在整个benchmark开始进行初始化\n\t\t@Setup(Level.Trial)\n\t\tpublic void up() {\n\t\t\tservice = Executors.newCachedThreadPool();\n\t\t}\n\n\t\t// 在整个benchmark结束后, 将ExecutorService关闭掉\n\t\t@TearDown(Level.Trial)\n\t\tpublic void down() {\n\t\t\tservice.shutdown();\n\t\t}\n\n\t}\n\n\tpublic static class LaggingState extends NormalState {\n\t\tpublic static final int SLEEP_TIME = Integer.getInteger(\"sleepTime\", 10);\n\n\t\t// 在benchmark过程中, 没执行一次benchmark方法调用, 都会首先执行一下这个方法\n\t\t@Setup(Level.Invocation)\n\t\tpublic void lag() throws InterruptedException {\n\t\t\tTimeUnit.MILLISECONDS.sleep(SLEEP_TIME);\n\t\t}\n\t}\n\n\t@Benchmark\n\t@BenchmarkMode(Mode.AverageTime)\n\tpublic double measureHot(NormalState e, final Scratch s) throws ExecutionException, InterruptedException {\n\t\treturn e.service.submit(new Task(s)).get();\n\t}\n\n\t@Benchmark\n\t@BenchmarkMode(Mode.AverageTime)\n\tpublic double measureCold(LaggingState e, final Scratch s) throws ExecutionException, InterruptedException {\n\t\treturn e.service.submit(new Task(s)).get();\n\t}\n\n\t@State(Scope.Thread)\n\tpublic static class Scratch {\n\t\tprivate double p;\n\t\tpublic double doWork() {\n\t\t\tp = Math.log(p);\n\t\t\treturn p;\n\t\t}\n\t}\n\n\tpublic static class Task implements Callable<Double> {\n\t\tprivate Scratch s;\n\n\t\tpublic Task(Scratch s) {\n\t\t\tthis.s = s;\n\t\t}\n\n\t\t@Override\n\t\tpublic Double call() {\n\t\t\treturn s.doWork();\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_07_FixtureLevelInvocation.class.getSimpleName())\n\t\t\t\t.warmupIterations(3)\n\t\t\t\t.measurementIterations(3)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n执行结果\n```java\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_07_FixtureLevelInvocation.measureCold\n\n# Run progress: 0.00% complete, ETA 00:00:12\n# Fork: 1 of 1\n# Warmup Iteration   1: 110.941 us/op\n# Warmup Iteration   2: 91.016 us/op\n# Warmup Iteration   3: 94.717 us/op\nIteration   1: 87.367 us/op\nIteration   2: 70.264 us/op\nIteration   3: 74.239 us/op\n\n\nResult \"measureCold\":\n  77.290 ±(99.9%) 163.284 us/op [Average]\n  (min, avg, max) = (70.264, 77.290, 87.367), stdev = 8.950\n  CI (99.9%): [≈ 0, 240.574] (assumes normal distribution)\n\n\n# Warmup: 3 iterations, 1 s each\n# Measurement: 3 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_07_FixtureLevelInvocation.measureHot\n\n# Run progress: 50.00% complete, ETA 00:00:06\n# Fork: 1 of 1\n# Warmup Iteration   1: 5.642 us/op\n# Warmup Iteration   2: 5.384 us/op\n# Warmup Iteration   3: 5.234 us/op\nIteration   1: 5.187 us/op\nIteration   2: 5.178 us/op\nIteration   3: 5.536 us/op\n\n\nResult \"measureHot\":\n  5.300 ±(99.9%) 3.723 us/op [Average]\n  (min, avg, max) = (5.178, 5.300, 5.536), stdev = 0.204\n  CI (99.9%): [1.578, 9.023] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:13\n\nBenchmark                                            Mode  Cnt   Score     Error  Units\nJMH.JMHSample_07_FixtureLevelInvocation.measureCold  avgt    3  77.290 ± 163.284  us/op\nJMH.JMHSample_07_FixtureLevelInvocation.measureHot   avgt    3   5.300 ±   3.723  us/op\n```\n","slug":"jmh/JMHSample_07_FixtureLevelInvocation","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihs9004tvjs6qa82b7rs"},{"date":"2016-01-04T16:00:00.000Z","title":"08_DeadCode","_content":"下面的benchmark中有许多Dead-Code Elimination, 编译器能够发现那些冗余计算并且消除他们. 但是如果被消除的部分是我们的基准测试部分, 则会引发问题.幸运的的是, JMH提供了一些基础服务来解决这些问题:带有返回结果的基准测试会强制JMH不进行Dead-Code Elimination\n```java\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\npublic class JMHSample_08_DeadCode {\n\n\tprivate double x = Math.PI;\n\n\t@Benchmark\n\tpublic void baseline() {\n\t\t// 什么都不做，我们将其作为这次基准测试的基准线\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\t// 从结果中我们会观察出, 这个基准测试会进行优化\n\t\tMath.log(x);\n\t}\n\n\t@Benchmark\n\tpublic double measureRight() {\n\t\t// This is correct: the result is being used.\n\t\treturn Math.log(x);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_08_DeadCode.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n\n```\n运行结果为\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_08_DeadCode.measureWrong\n\n# Run progress: 66.67% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 0.281 ns/op\n# Warmup Iteration   2: 0.281 ns/op\n# Warmup Iteration   3: 0.278 ns/op\n# Warmup Iteration   4: 0.280 ns/op\n# Warmup Iteration   5: 0.278 ns/op\nIteration   1: 0.278 ns/op\nIteration   2: 0.278 ns/op\nIteration   3: 0.278 ns/op\nIteration   4: 0.277 ns/op\nIteration   5: 0.278 ns/op\n\n\nResult \"measureWrong\":\n  0.278 ±(99.9%) 0.002 ns/op [Average]\n  (min, avg, max) = (0.277, 0.278, 0.278), stdev = 0.001\n  CI (99.9%): [0.276, 0.280] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:31\n\nBenchmark                               Mode  Cnt   Score   Error  Units\nJMH.JMHSample_08_DeadCode.baseline      avgt    5   0.279 ± 0.004  ns/op\nJMH.JMHSample_08_DeadCode.measureRight  avgt    5  21.067 ± 0.288  ns/op\nJMH.JMHSample_08_DeadCode.measureWrong  avgt    5   0.278 ± 0.002  ns/op\n```\n我们可以看到baseline和measureWrong的测试结果是相近的\n","source":"_posts/jmh/JMHSample_08_DeadCode.md","raw":"category: JMH\ndate: 2016-01-05\ntitle: 08_DeadCode  \n---\n下面的benchmark中有许多Dead-Code Elimination, 编译器能够发现那些冗余计算并且消除他们. 但是如果被消除的部分是我们的基准测试部分, 则会引发问题.幸运的的是, JMH提供了一些基础服务来解决这些问题:带有返回结果的基准测试会强制JMH不进行Dead-Code Elimination\n```java\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\npublic class JMHSample_08_DeadCode {\n\n\tprivate double x = Math.PI;\n\n\t@Benchmark\n\tpublic void baseline() {\n\t\t// 什么都不做，我们将其作为这次基准测试的基准线\n\t}\n\n\t@Benchmark\n\tpublic void measureWrong() {\n\t\t// 从结果中我们会观察出, 这个基准测试会进行优化\n\t\tMath.log(x);\n\t}\n\n\t@Benchmark\n\tpublic double measureRight() {\n\t\t// This is correct: the result is being used.\n\t\treturn Math.log(x);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_08_DeadCode.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n\n}\n\n```\n运行结果为\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_08_DeadCode.measureWrong\n\n# Run progress: 66.67% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 0.281 ns/op\n# Warmup Iteration   2: 0.281 ns/op\n# Warmup Iteration   3: 0.278 ns/op\n# Warmup Iteration   4: 0.280 ns/op\n# Warmup Iteration   5: 0.278 ns/op\nIteration   1: 0.278 ns/op\nIteration   2: 0.278 ns/op\nIteration   3: 0.278 ns/op\nIteration   4: 0.277 ns/op\nIteration   5: 0.278 ns/op\n\n\nResult \"measureWrong\":\n  0.278 ±(99.9%) 0.002 ns/op [Average]\n  (min, avg, max) = (0.277, 0.278, 0.278), stdev = 0.001\n  CI (99.9%): [0.276, 0.280] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:31\n\nBenchmark                               Mode  Cnt   Score   Error  Units\nJMH.JMHSample_08_DeadCode.baseline      avgt    5   0.279 ± 0.004  ns/op\nJMH.JMHSample_08_DeadCode.measureRight  avgt    5  21.067 ± 0.288  ns/op\nJMH.JMHSample_08_DeadCode.measureWrong  avgt    5   0.278 ± 0.002  ns/op\n```\n我们可以看到baseline和measureWrong的测试结果是相近的\n","slug":"jmh/JMHSample_08_DeadCode","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsd004wvjs69ksnegap"},{"date":"2016-01-04T16:00:00.000Z","title":"09_Blackholes","_content":"\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.infra.Blackhole;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.TimeUnit;\n\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\n@State(Scope.Thread)\npublic class JMHSample_09_Blackholes {\n\n    /*\n     * 如果你的benchmark想要返回多个结果, 你可以参考以下俩种方式:\n     */\n\n\tdouble x1 = Math.PI;\n\tdouble x2 = Math.PI * 2;\n\n\t// 基准线, 执行Math.log所产生的消耗\n\t@Benchmark\n\tpublic double baseline() {\n\t\treturn Math.log(x1);\n\t}\n\n\t// 下面这个基准测试, Math.log(x1)会被优化掉, 只有 Math.log(x2)会进行计算\n\t@Benchmark\n\tpublic double measureWrong() {\n\t\tMath.log(x1);\n\t\treturn Math.log(x2);\n\t}\n\n\t// 返回多个选项A方案: 将多个计算结果进行合并. 这种方案是可接受, 它们并不会对结果产生太大的偏移\n\t@Benchmark\n\tpublic double measureRight_1() {\n\t\treturn Math.log(x1) + Math.log(x2);\n\t}\n\n\t// 返回多个选项A方案: 显式的使用Blackhole对每个计算进行操作()\n\t@Benchmark\n\tpublic void measureRight_2(Blackhole bh) {\n\t\tbh.consume(Math.log(x1));\n\t\tbh.consume(Math.log(x2));\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_09_Blackholes.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n计算结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.baseline\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 21.217 ns/op\n# Warmup Iteration   2: 20.386 ns/op\n# Warmup Iteration   3: 20.780 ns/op\n# Warmup Iteration   4: 20.764 ns/op\n# Warmup Iteration   5: 20.795 ns/op\nIteration   1: 20.748 ns/op\nIteration   2: 21.183 ns/op\nIteration   3: 20.868 ns/op\nIteration   4: 20.828 ns/op\nIteration   5: 20.835 ns/op\n\n\nResult \"baseline\":\n  20.892 ±(99.9%) 0.648 ns/op [Average]\n  (min, avg, max) = (20.748, 20.892, 21.183), stdev = 0.168\n  CI (99.9%): [20.245, 21.540] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureRight_1\n\n# Run progress: 25.00% complete, ETA 00:00:31\n# Fork: 1 of 1\n# Warmup Iteration   1: 39.457 ns/op\n# Warmup Iteration   2: 38.186 ns/op\n# Warmup Iteration   3: 38.109 ns/op\n# Warmup Iteration   4: 38.053 ns/op\n# Warmup Iteration   5: 38.107 ns/op\nIteration   1: 38.232 ns/op\nIteration   2: 38.069 ns/op\nIteration   3: 38.040 ns/op\nIteration   4: 38.070 ns/op\nIteration   5: 38.101 ns/op\n\n\nResult \"measureRight_1\":\n  38.102 ±(99.9%) 0.292 ns/op [Average]\n  (min, avg, max) = (38.040, 38.102, 38.232), stdev = 0.076\n  CI (99.9%): [37.811, 38.394] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureRight_2\n\n# Run progress: 50.00% complete, ETA 00:00:21\n# Fork: 1 of 1\n# Warmup Iteration   1: 41.007 ns/op\n# Warmup Iteration   2: 40.831 ns/op\n# Warmup Iteration   3: 40.163 ns/op\n# Warmup Iteration   4: 40.266 ns/op\n# Warmup Iteration   5: 40.146 ns/op\nIteration   1: 40.281 ns/op\nIteration   2: 40.250 ns/op\nIteration   3: 40.336 ns/op\nIteration   4: 40.207 ns/op\nIteration   5: 40.336 ns/op\n\n\nResult \"measureRight_2\":\n  40.282 ±(99.9%) 0.215 ns/op [Average]\n  (min, avg, max) = (40.207, 40.282, 40.336), stdev = 0.056\n  CI (99.9%): [40.067, 40.497] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureWrong\n\n# Run progress: 75.00% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 20.723 ns/op\n# Warmup Iteration   2: 20.512 ns/op\n# Warmup Iteration   3: 20.907 ns/op\n# Warmup Iteration   4: 20.870 ns/op\n# Warmup Iteration   5: 20.921 ns/op\nIteration   1: 20.886 ns/op\nIteration   2: 20.900 ns/op\nIteration   3: 20.908 ns/op\nIteration   4: 20.880 ns/op\nIteration   5: 20.820 ns/op\n\n\nResult \"measureWrong\":\n  20.879 ±(99.9%) 0.133 ns/op [Average]\n  (min, avg, max) = (20.820, 20.879, 20.908), stdev = 0.035\n  CI (99.9%): [20.746, 21.012] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:42\n\nBenchmark                                   Mode  Cnt   Score   Error  Units\nJMH.JMHSample_09_Blackholes.baseline        avgt    5  20.892 ± 0.648  ns/op\nJMH.JMHSample_09_Blackholes.measureRight_1  avgt    5  38.102 ± 0.292  ns/op\nJMH.JMHSample_09_Blackholes.measureRight_2  avgt    5  40.282 ± 0.215  ns/op\nJMH.JMHSample_09_Blackholes.measureWrong    avgt    5  20.879 ± 0.133  ns/op\n```\n根据我们观察的结果来看measureWrong和baseline确实是经过了优化, measureRight_1和measureRight_2的结果也是相近的\n","source":"_posts/jmh/JMHSample_09_Blackholes.md","raw":"category: JMH\ndate: 2016-01-05\ntitle: 09_Blackholes\n---\n\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.infra.Blackhole;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.TimeUnit;\n\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\n@State(Scope.Thread)\npublic class JMHSample_09_Blackholes {\n\n    /*\n     * 如果你的benchmark想要返回多个结果, 你可以参考以下俩种方式:\n     */\n\n\tdouble x1 = Math.PI;\n\tdouble x2 = Math.PI * 2;\n\n\t// 基准线, 执行Math.log所产生的消耗\n\t@Benchmark\n\tpublic double baseline() {\n\t\treturn Math.log(x1);\n\t}\n\n\t// 下面这个基准测试, Math.log(x1)会被优化掉, 只有 Math.log(x2)会进行计算\n\t@Benchmark\n\tpublic double measureWrong() {\n\t\tMath.log(x1);\n\t\treturn Math.log(x2);\n\t}\n\n\t// 返回多个选项A方案: 将多个计算结果进行合并. 这种方案是可接受, 它们并不会对结果产生太大的偏移\n\t@Benchmark\n\tpublic double measureRight_1() {\n\t\treturn Math.log(x1) + Math.log(x2);\n\t}\n\n\t// 返回多个选项A方案: 显式的使用Blackhole对每个计算进行操作()\n\t@Benchmark\n\tpublic void measureRight_2(Blackhole bh) {\n\t\tbh.consume(Math.log(x1));\n\t\tbh.consume(Math.log(x2));\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_09_Blackholes.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n计算结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.baseline\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 21.217 ns/op\n# Warmup Iteration   2: 20.386 ns/op\n# Warmup Iteration   3: 20.780 ns/op\n# Warmup Iteration   4: 20.764 ns/op\n# Warmup Iteration   5: 20.795 ns/op\nIteration   1: 20.748 ns/op\nIteration   2: 21.183 ns/op\nIteration   3: 20.868 ns/op\nIteration   4: 20.828 ns/op\nIteration   5: 20.835 ns/op\n\n\nResult \"baseline\":\n  20.892 ±(99.9%) 0.648 ns/op [Average]\n  (min, avg, max) = (20.748, 20.892, 21.183), stdev = 0.168\n  CI (99.9%): [20.245, 21.540] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureRight_1\n\n# Run progress: 25.00% complete, ETA 00:00:31\n# Fork: 1 of 1\n# Warmup Iteration   1: 39.457 ns/op\n# Warmup Iteration   2: 38.186 ns/op\n# Warmup Iteration   3: 38.109 ns/op\n# Warmup Iteration   4: 38.053 ns/op\n# Warmup Iteration   5: 38.107 ns/op\nIteration   1: 38.232 ns/op\nIteration   2: 38.069 ns/op\nIteration   3: 38.040 ns/op\nIteration   4: 38.070 ns/op\nIteration   5: 38.101 ns/op\n\n\nResult \"measureRight_1\":\n  38.102 ±(99.9%) 0.292 ns/op [Average]\n  (min, avg, max) = (38.040, 38.102, 38.232), stdev = 0.076\n  CI (99.9%): [37.811, 38.394] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureRight_2\n\n# Run progress: 50.00% complete, ETA 00:00:21\n# Fork: 1 of 1\n# Warmup Iteration   1: 41.007 ns/op\n# Warmup Iteration   2: 40.831 ns/op\n# Warmup Iteration   3: 40.163 ns/op\n# Warmup Iteration   4: 40.266 ns/op\n# Warmup Iteration   5: 40.146 ns/op\nIteration   1: 40.281 ns/op\nIteration   2: 40.250 ns/op\nIteration   3: 40.336 ns/op\nIteration   4: 40.207 ns/op\nIteration   5: 40.336 ns/op\n\n\nResult \"measureRight_2\":\n  40.282 ±(99.9%) 0.215 ns/op [Average]\n  (min, avg, max) = (40.207, 40.282, 40.336), stdev = 0.056\n  CI (99.9%): [40.067, 40.497] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_09_Blackholes.measureWrong\n\n# Run progress: 75.00% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 20.723 ns/op\n# Warmup Iteration   2: 20.512 ns/op\n# Warmup Iteration   3: 20.907 ns/op\n# Warmup Iteration   4: 20.870 ns/op\n# Warmup Iteration   5: 20.921 ns/op\nIteration   1: 20.886 ns/op\nIteration   2: 20.900 ns/op\nIteration   3: 20.908 ns/op\nIteration   4: 20.880 ns/op\nIteration   5: 20.820 ns/op\n\n\nResult \"measureWrong\":\n  20.879 ±(99.9%) 0.133 ns/op [Average]\n  (min, avg, max) = (20.820, 20.879, 20.908), stdev = 0.035\n  CI (99.9%): [20.746, 21.012] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:42\n\nBenchmark                                   Mode  Cnt   Score   Error  Units\nJMH.JMHSample_09_Blackholes.baseline        avgt    5  20.892 ± 0.648  ns/op\nJMH.JMHSample_09_Blackholes.measureRight_1  avgt    5  38.102 ± 0.292  ns/op\nJMH.JMHSample_09_Blackholes.measureRight_2  avgt    5  40.282 ± 0.215  ns/op\nJMH.JMHSample_09_Blackholes.measureWrong    avgt    5  20.879 ± 0.133  ns/op\n```\n根据我们观察的结果来看measureWrong和baseline确实是经过了优化, measureRight_1和measureRight_2的结果也是相近的\n","slug":"jmh/JMHSample_09_Blackholes","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsg004yvjs6pfu1naph"},{"date":"2016-01-04T16:00:00.000Z","title":"10_ConstantFold","_content":"```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.TimeUnit;\n\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\npublic class JMHSample_10_ConstantFold {\n\n    /*\n     * dead-code elimination另一种方式是常量展开.\n     *\n     * 如果JVM意识到基准测试的结果总是相同的, 那么JVM就会对其进行优化.\n     *\n     * 避免常量展开的一种方式是在@State对象中使用非final成员, 在进行基准测试计算中,使用这些非final成员进行计算\n     */\n\n\tprivate double x = Math.PI;\n\n\tprivate final double wrongX = Math.PI;\n\n\t@Benchmark\n\tpublic double baseline() {\n\t\t// simply return the value, this is a baseline\n\t\treturn Math.PI;\n\t}\n\n\t@Benchmark\n\tpublic double measureWrong_1() {\n\t\t// 这个基准会进行优化, 因为JVM会预料到这个代码产生的结果总是相同的\n\t\treturn Math.log(Math.PI);\n\t}\n\n\t@Benchmark\n\tpublic double measureWrong_2() {\n\t\t// 这个基准会进行优化, 因为JVM会预料到这个代码产生的结果总是相同的\n\t\treturn Math.log(wrongX);\n\t}\n\n\t@Benchmark\n\tpublic double measureRight() {\n\t\t// 因为x是一个变量, 因此每次执行基准测试产生的结果可能都是不相同的\n\t\treturn Math.log(x);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_10_ConstantFold.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n执行结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.baseline\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.483 ns/op\n# Warmup Iteration   2: 3.215 ns/op\n# Warmup Iteration   3: 2.551 ns/op\n# Warmup Iteration   4: 2.561 ns/op\n# Warmup Iteration   5: 2.551 ns/op\nIteration   1: 2.569 ns/op\nIteration   2: 2.610 ns/op\nIteration   3: 2.578 ns/op\nIteration   4: 2.570 ns/op\nIteration   5: 2.540 ns/op\n\n\nResult \"baseline\":\n  2.573 ±(99.9%) 0.097 ns/op [Average]\n  (min, avg, max) = (2.540, 2.573, 2.610), stdev = 0.025\n  CI (99.9%): [2.476, 2.671] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureRight\n\n# Run progress: 25.00% complete, ETA 00:00:31\n# Fork: 1 of 1\n# Warmup Iteration   1: 21.162 ns/op\n# Warmup Iteration   2: 21.094 ns/op\n# Warmup Iteration   3: 20.798 ns/op\n# Warmup Iteration   4: 21.164 ns/op\n# Warmup Iteration   5: 20.823 ns/op\nIteration   1: 20.857 ns/op\nIteration   2: 20.809 ns/op\nIteration   3: 21.032 ns/op\nIteration   4: 20.807 ns/op\nIteration   5: 21.207 ns/op\n\n\nResult \"measureRight\":\n  20.942 ±(99.9%) 0.671 ns/op [Average]\n  (min, avg, max) = (20.807, 20.942, 21.207), stdev = 0.174\n  CI (99.9%): [20.271, 21.614] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureWrong_1\n\n# Run progress: 50.00% complete, ETA 00:00:21\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.213 ns/op\n# Warmup Iteration   2: 3.204 ns/op\n# Warmup Iteration   3: 2.527 ns/op\n# Warmup Iteration   4: 2.511 ns/op\n# Warmup Iteration   5: 2.518 ns/op\nIteration   1: 2.514 ns/op\nIteration   2: 2.513 ns/op\nIteration   3: 2.517 ns/op\nIteration   4: 2.513 ns/op\nIteration   5: 2.518 ns/op\n\n\nResult \"measureWrong_1\":\n  2.515 ±(99.9%) 0.010 ns/op [Average]\n  (min, avg, max) = (2.513, 2.515, 2.518), stdev = 0.003\n  CI (99.9%): [2.505, 2.525] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureWrong_2\n\n# Run progress: 75.00% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.215 ns/op\n# Warmup Iteration   2: 3.201 ns/op\n# Warmup Iteration   3: 2.537 ns/op\n# Warmup Iteration   4: 2.548 ns/op\n# Warmup Iteration   5: 2.542 ns/op\nIteration   1: 2.532 ns/op\nIteration   2: 2.533 ns/op\nIteration   3: 2.533 ns/op\nIteration   4: 2.531 ns/op\nIteration   5: 2.532 ns/op\n\n\nResult \"measureWrong_2\":\n  2.532 ±(99.9%) 0.004 ns/op [Average]\n  (min, avg, max) = (2.531, 2.532, 2.533), stdev = 0.001\n  CI (99.9%): [2.528, 2.537] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:41\n\nBenchmark                                     Mode  Cnt   Score   Error  Units\nJMH.JMHSample_10_ConstantFold.baseline        avgt    5   2.573 ± 0.097  ns/op\nJMH.JMHSample_10_ConstantFold.measureRight    avgt    5  20.942 ± 0.671  ns/op\nJMH.JMHSample_10_ConstantFold.measureWrong_1  avgt    5   2.515 ± 0.010  ns/op\nJMH.JMHSample_10_ConstantFold.measureWrong_2  avgt    5   2.532 ± 0.004  ns/op\n```\n我们看到measureWrong_1和measureWrong_2都进行了常量展开, 只有measureRight才每次都进行了计算\n","source":"_posts/jmh/JMHSample_10_ConstantFold.md","raw":"category: JMH\ndate: 2016-01-05\ntitle: 10_ConstantFold\n---\n```java\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.runner.Runner;\nimport org.openjdk.jmh.runner.RunnerException;\nimport org.openjdk.jmh.runner.options.Options;\nimport org.openjdk.jmh.runner.options.OptionsBuilder;\n\nimport java.util.concurrent.TimeUnit;\n\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\npublic class JMHSample_10_ConstantFold {\n\n    /*\n     * dead-code elimination另一种方式是常量展开.\n     *\n     * 如果JVM意识到基准测试的结果总是相同的, 那么JVM就会对其进行优化.\n     *\n     * 避免常量展开的一种方式是在@State对象中使用非final成员, 在进行基准测试计算中,使用这些非final成员进行计算\n     */\n\n\tprivate double x = Math.PI;\n\n\tprivate final double wrongX = Math.PI;\n\n\t@Benchmark\n\tpublic double baseline() {\n\t\t// simply return the value, this is a baseline\n\t\treturn Math.PI;\n\t}\n\n\t@Benchmark\n\tpublic double measureWrong_1() {\n\t\t// 这个基准会进行优化, 因为JVM会预料到这个代码产生的结果总是相同的\n\t\treturn Math.log(Math.PI);\n\t}\n\n\t@Benchmark\n\tpublic double measureWrong_2() {\n\t\t// 这个基准会进行优化, 因为JVM会预料到这个代码产生的结果总是相同的\n\t\treturn Math.log(wrongX);\n\t}\n\n\t@Benchmark\n\tpublic double measureRight() {\n\t\t// 因为x是一个变量, 因此每次执行基准测试产生的结果可能都是不相同的\n\t\treturn Math.log(x);\n\t}\n\n\tpublic static void main(String[] args) throws RunnerException {\n\t\tOptions opt = new OptionsBuilder()\n\t\t\t\t.include(JMHSample_10_ConstantFold.class.getSimpleName())\n\t\t\t\t.warmupIterations(5)\n\t\t\t\t.measurementIterations(5)\n\t\t\t\t.forks(1)\n\t\t\t\t.build();\n\n\t\tnew Runner(opt).run();\n\t}\n}\n```\n执行结果\n```java\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.baseline\n\n# Run progress: 0.00% complete, ETA 00:00:40\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.483 ns/op\n# Warmup Iteration   2: 3.215 ns/op\n# Warmup Iteration   3: 2.551 ns/op\n# Warmup Iteration   4: 2.561 ns/op\n# Warmup Iteration   5: 2.551 ns/op\nIteration   1: 2.569 ns/op\nIteration   2: 2.610 ns/op\nIteration   3: 2.578 ns/op\nIteration   4: 2.570 ns/op\nIteration   5: 2.540 ns/op\n\n\nResult \"baseline\":\n  2.573 ±(99.9%) 0.097 ns/op [Average]\n  (min, avg, max) = (2.540, 2.573, 2.610), stdev = 0.025\n  CI (99.9%): [2.476, 2.671] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureRight\n\n# Run progress: 25.00% complete, ETA 00:00:31\n# Fork: 1 of 1\n# Warmup Iteration   1: 21.162 ns/op\n# Warmup Iteration   2: 21.094 ns/op\n# Warmup Iteration   3: 20.798 ns/op\n# Warmup Iteration   4: 21.164 ns/op\n# Warmup Iteration   5: 20.823 ns/op\nIteration   1: 20.857 ns/op\nIteration   2: 20.809 ns/op\nIteration   3: 21.032 ns/op\nIteration   4: 20.807 ns/op\nIteration   5: 21.207 ns/op\n\n\nResult \"measureRight\":\n  20.942 ±(99.9%) 0.671 ns/op [Average]\n  (min, avg, max) = (20.807, 20.942, 21.207), stdev = 0.174\n  CI (99.9%): [20.271, 21.614] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureWrong_1\n\n# Run progress: 50.00% complete, ETA 00:00:21\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.213 ns/op\n# Warmup Iteration   2: 3.204 ns/op\n# Warmup Iteration   3: 2.527 ns/op\n# Warmup Iteration   4: 2.511 ns/op\n# Warmup Iteration   5: 2.518 ns/op\nIteration   1: 2.514 ns/op\nIteration   2: 2.513 ns/op\nIteration   3: 2.517 ns/op\nIteration   4: 2.513 ns/op\nIteration   5: 2.518 ns/op\n\n\nResult \"measureWrong_1\":\n  2.515 ±(99.9%) 0.010 ns/op [Average]\n  (min, avg, max) = (2.513, 2.515, 2.518), stdev = 0.003\n  CI (99.9%): [2.505, 2.525] (assumes normal distribution)\n\n\n# Warmup: 5 iterations, 1 s each\n# Measurement: 5 iterations, 1 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Average time, time/op\n# Benchmark: JMH.JMHSample_10_ConstantFold.measureWrong_2\n\n# Run progress: 75.00% complete, ETA 00:00:10\n# Fork: 1 of 1\n# Warmup Iteration   1: 3.215 ns/op\n# Warmup Iteration   2: 3.201 ns/op\n# Warmup Iteration   3: 2.537 ns/op\n# Warmup Iteration   4: 2.548 ns/op\n# Warmup Iteration   5: 2.542 ns/op\nIteration   1: 2.532 ns/op\nIteration   2: 2.533 ns/op\nIteration   3: 2.533 ns/op\nIteration   4: 2.531 ns/op\nIteration   5: 2.532 ns/op\n\n\nResult \"measureWrong_2\":\n  2.532 ±(99.9%) 0.004 ns/op [Average]\n  (min, avg, max) = (2.531, 2.532, 2.533), stdev = 0.001\n  CI (99.9%): [2.528, 2.537] (assumes normal distribution)\n\n\n# Run complete. Total time: 00:00:41\n\nBenchmark                                     Mode  Cnt   Score   Error  Units\nJMH.JMHSample_10_ConstantFold.baseline        avgt    5   2.573 ± 0.097  ns/op\nJMH.JMHSample_10_ConstantFold.measureRight    avgt    5  20.942 ± 0.671  ns/op\nJMH.JMHSample_10_ConstantFold.measureWrong_1  avgt    5   2.515 ± 0.010  ns/op\nJMH.JMHSample_10_ConstantFold.measureWrong_2  avgt    5   2.532 ± 0.004  ns/op\n```\n我们看到measureWrong_1和measureWrong_2都进行了常量展开, 只有measureRight才每次都进行了计算\n","slug":"jmh/JMHSample_10_ConstantFold","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsi0050vjs6al28woo4"},{"date":"2015-12-27T16:00:00.000Z","title":"JMH 环境搭建","_content":"JMH是一个用于java或者其他JVM语言的, 提供构建,运行,分析多种基准的工具.\n我们通过使用引入依赖的方式,在我们的项目中添加基准测试\n```xml\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-generator-annprocess</artifactId>\n    <version>1.11.2</version>\n</dependency>\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-core</artifactId>\n    <version>1.11.2</version>\n</dependency>\n```\n\n但是, JMH的官方推荐使用方式是,使用MAVEN构建一个基于要测试项目的一个独立的项目.\n\n我们使用archetype生成基准测试项目\n```java\nmvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jmh -DarchetypeArtifactId=jmh-java-benchmark-archetype -DgroupId=wang.ming15.jmh -DartifactId=test -Dversion=1.0\n```\n执行完该命令后会生成一个新的项目,里面会有一个测试文件\n```java\npackage wang.ming15.jmh;\n\nimport org.openjdk.jmh.annotations.Benchmark;\n\npublic class MyBenchmark {\n\n    @Benchmark\n    public void testMethod() {\n        // This is a demo/sample template for building your JMH benchmarks. Edit as needed.\n        // Put your benchmark code here.\n    }\n\n}\n```\n\n然后我们依赖要测试的项目就可以在新的项目中写基准测试到代码了\n","source":"_posts/jmh/JMH初探.md","raw":"category: JMH\ndate: 2015-12-28\ntitle: JMH 环境搭建\n---\nJMH是一个用于java或者其他JVM语言的, 提供构建,运行,分析多种基准的工具.\n我们通过使用引入依赖的方式,在我们的项目中添加基准测试\n```xml\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-generator-annprocess</artifactId>\n    <version>1.11.2</version>\n</dependency>\n<dependency>\n    <groupId>org.openjdk.jmh</groupId>\n    <artifactId>jmh-core</artifactId>\n    <version>1.11.2</version>\n</dependency>\n```\n\n但是, JMH的官方推荐使用方式是,使用MAVEN构建一个基于要测试项目的一个独立的项目.\n\n我们使用archetype生成基准测试项目\n```java\nmvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jmh -DarchetypeArtifactId=jmh-java-benchmark-archetype -DgroupId=wang.ming15.jmh -DartifactId=test -Dversion=1.0\n```\n执行完该命令后会生成一个新的项目,里面会有一个测试文件\n```java\npackage wang.ming15.jmh;\n\nimport org.openjdk.jmh.annotations.Benchmark;\n\npublic class MyBenchmark {\n\n    @Benchmark\n    public void testMethod() {\n        // This is a demo/sample template for building your JMH benchmarks. Edit as needed.\n        // Put your benchmark code here.\n    }\n\n}\n```\n\n然后我们依赖要测试的项目就可以在新的项目中写基准测试到代码了\n","slug":"jmh/JMH初探","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsk0052vjs658eggeem"},{"date":"2016-05-14T16:00:00.000Z","title":"CRaSH 安装启动","_content":"CRaSH 的全名是 Common Reusable SHell . 网上对其介绍是: 基于 Java 发布提供与 JVM 进行交互的 SHELL 环境. 作为入门, 这篇文章介绍一下, 作为单独程序的使用.\n\n我在mac上使用brew安装上里CRaSH, 大家可以根据自己的环境自行安装.\n\n我启动了一个SpringBoot HTTP服务, 然后使用CRaSH连接到这个服务上.\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\n@EnableAutoConfiguration\npublic class HTTPServer {\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    String home() {\n        return \"Hello World!\";\n    }\n\n    public static void main(String[] args) throws Exception {\n        SpringApplication.run(HTTPServer.class, args);\n    }\n}\n```\n然后在命令行找到这个进程id\n```bash\n➜  ~ jps -l\n467\n488 org.jetbrains.idea.maven.server.RemoteMavenServer\n696 com.intellij.rt.execution.application.AppMain\n697 org.jetbrains.jps.cmdline.Launcher\n845 sun.tools.jps.Jps\n➜  ~ crash.sh 696\n\n   _____     ________                 _______    ____ ____\n .'     `.  |        `.             .'       `. |    |    | 1.3.0\n|    |    | |    |    |  .-------.  |    |    | |    |    |\n|    |____| |    `   .' |   _|    |  .    '~_ ` |         |\n|    |    | |    .   `.  .~'      | | `~_    `| |         |\n|    |    | |    |    | |    |    | |    |    | |    |    |\n `._____.'  |____|____| `.________|  `._____.'  |____|____|\n\nFollow and support the project on http://www.crashub.org\nWelcome to localhost + !\nIt is Sun May 15 10:44:03 CST 2016 now\n%\n```\n\n最后出现`%`说明我们已经连接到SpringBoot服务所在的虚拟机里了. 同样的在SpringBoot服务的日志里也有输出\n```bash\n2016-05-15 10:44:00.005  INFO 696 --- [Attach Listener] org.crsh.standalone.Agent                : CRaSH agent loaded\n2016-05-15 10:44:00.007  INFO 696 --- [Attach Listener] org.crsh.standalone.Agent                : Spawned CRaSH thread 23 for further processing\n2016-05-15 10:44:00.097  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property vfs.refresh_period=1 from properties\n2016-05-15 10:44:00.203  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.port=2000 from properties\n2016-05-15 10:44:00.203  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.auth_timeout=600000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.idle_timeout=600000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.default_encoding=UTF-8 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth=simple from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property telnet.port=5000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property mail.debug=false from properties\n2016-05-15 10:44:00.205  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth.simple.username=admin from properties\n2016-05-15 10:44:00.205  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth.simple.password=admin from properties\n2016-05-15 10:44:02.111  INFO 696 --- [       Thread-6] net.wimpi.telnetd.net.PortListener       : Listening to Port 5,000 with a connectivity queue size of 5.\n2016-05-15 10:44:02.700  INFO 696 --- [       Thread-3] org.crsh.standalone.Agent                : Callback back remote on port 50656\n```\n\n当我们在启动时, 还可以指定一些参数设置\n* `--cmd` : 这个选项用于指定, 我们要执行的命令所在的目录. 如果不指定的话, 会默认地从当前classpath下的`/crash/commands/`进行查找\n* `--conf` : 用于指定配置文件所在的目录, 可以指定多个目录\n* `--property` : `--cmd`可选参数, 可以覆盖配置文件中的配置, 示例`crash.sh --property crash.telnet.port=3000`\n\n下面我们看一下在CRaSH中都可以使用哪些命令\n```bash\n% help\nTry one of these commands with the -h or --help switch:\n\nNAME      DESCRIPTION\nclock\ncron      manages the cron plugin\ndashboard a monitoring dashboard\ndate      show the current time\negrep     search file(s) for lines that match a pattern\nenv       display the term env\nfilter    a filter for a stream of map\nhello\njava      various java language commands\njdbc      JDBC connection\njmx       Java Management Extensions\njndi      Java Naming and Directory Interface\njpa       Java persistance API\njul       java.util.logging commands\njvm       JVM informations\nless      opposite of more\nmail      interact with emails\nman       format and display the on-line manual pages\nshell     shell related command\nsleep     sleep for some time\nsort      sort a map\nsystem    vm system properties commands\nthread    JVM thread commands\nhelp      provides basic help\nrepl      list the repl or change the current repl\n```\nCRaSH为我们提供了非常多的命令, 对于命令的具体用法, 大家可以使用`jvm --help`这样的用法具体看一下. CRaSH还提供了pipline, 我们可以使用`|`管道符使用多个命令.\n\n\n具体的命令这篇文章就不再多介绍了, 下面我们看一下如何将CRaSH内嵌到Spring里. 为了简单, 我并没有直接使用CRaSH官网里介绍的那样, 使用xml配置Spring\n```java\nimport org.crsh.spring.SpringBootstrap;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\npublic class Main {\n\n    public static void main(String[] args) throws InterruptedException {\n        SpringBootstrap springBootstrap = new SpringBootstrap();\n        Properties properties = new Properties();\n        properties.setProperty(\"crash.vfs.refresh_period\", \"1\");\n        properties.setProperty(\"crash.ssh.port\", \"2000\");\n        properties.setProperty(\"crash.ssh.idle_timeout\", \"3000000\");\n        properties.setProperty(\"crash.telnet.port\", \"5000\");\n        properties.setProperty(\"crash.ssh.auth_timeout\", \"300000\");\n        properties.setProperty(\"crash.auth\", \"simple\");\n        properties.setProperty(\"crash.auth.simple.username\", \"admin\");\n        properties.setProperty(\"crash.auth.simple.password\", \"admin\");\n        springBootstrap.setConfig(properties);\n\n        TimeUnit.DAYS.sleep(1);\n    }\n}\n```\n然后启动一个客户端\n```bash\n➜  ~ telnet localhost 5000\nTrying ::1...\nConnected to localhost.\nEscape character is '^]'.\n\n   _____     ________                 _______    ____ ____\n .'     `.  |        `.             .'       `. |    |    | 1.3.0\n|    |    | |    |    |  .-------.  |    |    | |    |    |\n|    |____| |    `   .' |   _|    |  .    '~_ ` |         |\n|    |    | |    .   `.  .~'      | | `~_    `| |         |\n|    |    | |    |    | |    |    | |    |    | |    |    |\n `._____.'  |____|____| `.________|  `._____.'  |____|____|\n\nFollow and support the project on http://www.crashub.org\nWelcome to localhost + !\nIt is Sun May 15 11:29:56 CST 2016 now\n\n%\n```\n通过telnet, 我们也成功连接进来了.\n\n这个需要添加的CRaSH的maven依赖有\n```xml\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.shell -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.shell</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.cli -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.cli</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.packaging -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.packaging</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.embed.spring -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.embed.spring</artifactId>\n    <version>1.3.2</version>\n</dependency>\n```\n","source":"_posts/jvm/CRaSH 命令行.md","raw":"category: JVM\ndate: 2016-05-15\ntitle: CRaSH 安装启动\n---\nCRaSH 的全名是 Common Reusable SHell . 网上对其介绍是: 基于 Java 发布提供与 JVM 进行交互的 SHELL 环境. 作为入门, 这篇文章介绍一下, 作为单独程序的使用.\n\n我在mac上使用brew安装上里CRaSH, 大家可以根据自己的环境自行安装.\n\n我启动了一个SpringBoot HTTP服务, 然后使用CRaSH连接到这个服务上.\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\n@EnableAutoConfiguration\npublic class HTTPServer {\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    String home() {\n        return \"Hello World!\";\n    }\n\n    public static void main(String[] args) throws Exception {\n        SpringApplication.run(HTTPServer.class, args);\n    }\n}\n```\n然后在命令行找到这个进程id\n```bash\n➜  ~ jps -l\n467\n488 org.jetbrains.idea.maven.server.RemoteMavenServer\n696 com.intellij.rt.execution.application.AppMain\n697 org.jetbrains.jps.cmdline.Launcher\n845 sun.tools.jps.Jps\n➜  ~ crash.sh 696\n\n   _____     ________                 _______    ____ ____\n .'     `.  |        `.             .'       `. |    |    | 1.3.0\n|    |    | |    |    |  .-------.  |    |    | |    |    |\n|    |____| |    `   .' |   _|    |  .    '~_ ` |         |\n|    |    | |    .   `.  .~'      | | `~_    `| |         |\n|    |    | |    |    | |    |    | |    |    | |    |    |\n `._____.'  |____|____| `.________|  `._____.'  |____|____|\n\nFollow and support the project on http://www.crashub.org\nWelcome to localhost + !\nIt is Sun May 15 10:44:03 CST 2016 now\n%\n```\n\n最后出现`%`说明我们已经连接到SpringBoot服务所在的虚拟机里了. 同样的在SpringBoot服务的日志里也有输出\n```bash\n2016-05-15 10:44:00.005  INFO 696 --- [Attach Listener] org.crsh.standalone.Agent                : CRaSH agent loaded\n2016-05-15 10:44:00.007  INFO 696 --- [Attach Listener] org.crsh.standalone.Agent                : Spawned CRaSH thread 23 for further processing\n2016-05-15 10:44:00.097  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property vfs.refresh_period=1 from properties\n2016-05-15 10:44:00.203  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.port=2000 from properties\n2016-05-15 10:44:00.203  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.auth_timeout=600000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.idle_timeout=600000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property ssh.default_encoding=UTF-8 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth=simple from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property telnet.port=5000 from properties\n2016-05-15 10:44:00.204  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property mail.debug=false from properties\n2016-05-15 10:44:00.205  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth.simple.username=admin from properties\n2016-05-15 10:44:00.205  INFO 696 --- [       Thread-3] org.crsh.standalone.Bootstrap            : Configuring property auth.simple.password=admin from properties\n2016-05-15 10:44:02.111  INFO 696 --- [       Thread-6] net.wimpi.telnetd.net.PortListener       : Listening to Port 5,000 with a connectivity queue size of 5.\n2016-05-15 10:44:02.700  INFO 696 --- [       Thread-3] org.crsh.standalone.Agent                : Callback back remote on port 50656\n```\n\n当我们在启动时, 还可以指定一些参数设置\n* `--cmd` : 这个选项用于指定, 我们要执行的命令所在的目录. 如果不指定的话, 会默认地从当前classpath下的`/crash/commands/`进行查找\n* `--conf` : 用于指定配置文件所在的目录, 可以指定多个目录\n* `--property` : `--cmd`可选参数, 可以覆盖配置文件中的配置, 示例`crash.sh --property crash.telnet.port=3000`\n\n下面我们看一下在CRaSH中都可以使用哪些命令\n```bash\n% help\nTry one of these commands with the -h or --help switch:\n\nNAME      DESCRIPTION\nclock\ncron      manages the cron plugin\ndashboard a monitoring dashboard\ndate      show the current time\negrep     search file(s) for lines that match a pattern\nenv       display the term env\nfilter    a filter for a stream of map\nhello\njava      various java language commands\njdbc      JDBC connection\njmx       Java Management Extensions\njndi      Java Naming and Directory Interface\njpa       Java persistance API\njul       java.util.logging commands\njvm       JVM informations\nless      opposite of more\nmail      interact with emails\nman       format and display the on-line manual pages\nshell     shell related command\nsleep     sleep for some time\nsort      sort a map\nsystem    vm system properties commands\nthread    JVM thread commands\nhelp      provides basic help\nrepl      list the repl or change the current repl\n```\nCRaSH为我们提供了非常多的命令, 对于命令的具体用法, 大家可以使用`jvm --help`这样的用法具体看一下. CRaSH还提供了pipline, 我们可以使用`|`管道符使用多个命令.\n\n\n具体的命令这篇文章就不再多介绍了, 下面我们看一下如何将CRaSH内嵌到Spring里. 为了简单, 我并没有直接使用CRaSH官网里介绍的那样, 使用xml配置Spring\n```java\nimport org.crsh.spring.SpringBootstrap;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\npublic class Main {\n\n    public static void main(String[] args) throws InterruptedException {\n        SpringBootstrap springBootstrap = new SpringBootstrap();\n        Properties properties = new Properties();\n        properties.setProperty(\"crash.vfs.refresh_period\", \"1\");\n        properties.setProperty(\"crash.ssh.port\", \"2000\");\n        properties.setProperty(\"crash.ssh.idle_timeout\", \"3000000\");\n        properties.setProperty(\"crash.telnet.port\", \"5000\");\n        properties.setProperty(\"crash.ssh.auth_timeout\", \"300000\");\n        properties.setProperty(\"crash.auth\", \"simple\");\n        properties.setProperty(\"crash.auth.simple.username\", \"admin\");\n        properties.setProperty(\"crash.auth.simple.password\", \"admin\");\n        springBootstrap.setConfig(properties);\n\n        TimeUnit.DAYS.sleep(1);\n    }\n}\n```\n然后启动一个客户端\n```bash\n➜  ~ telnet localhost 5000\nTrying ::1...\nConnected to localhost.\nEscape character is '^]'.\n\n   _____     ________                 _______    ____ ____\n .'     `.  |        `.             .'       `. |    |    | 1.3.0\n|    |    | |    |    |  .-------.  |    |    | |    |    |\n|    |____| |    `   .' |   _|    |  .    '~_ ` |         |\n|    |    | |    .   `.  .~'      | | `~_    `| |         |\n|    |    | |    |    | |    |    | |    |    | |    |    |\n `._____.'  |____|____| `.________|  `._____.'  |____|____|\n\nFollow and support the project on http://www.crashub.org\nWelcome to localhost + !\nIt is Sun May 15 11:29:56 CST 2016 now\n\n%\n```\n通过telnet, 我们也成功连接进来了.\n\n这个需要添加的CRaSH的maven依赖有\n```xml\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.shell -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.shell</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.cli -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.cli</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.packaging -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.packaging</artifactId>\n    <version>1.3.2</version>\n</dependency>\n\n<!-- http://mvnrepository.com/artifact/org.crashub/crash.embed.spring -->\n<dependency>\n    <groupId>org.crashub</groupId>\n    <artifactId>crash.embed.spring</artifactId>\n    <version>1.3.2</version>\n</dependency>\n```\n","slug":"jvm/CRaSH 命令行","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsm0054vjs6d8wc39kq"},{"date":"2014-10-01T16:00:00.000Z","title":"jps","_content":"虚拟机进程状况工具\n\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID).\n\n对于本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令显示主类的功能才能区分.\n\n命令格式:\n```java\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n\njps工具主要选项\n* `-q`: 只输出LVMID,省略主类的名称\n* `-m`: 输出虚拟机进程启动时传递给主类main()函数的参数\n* `-l`: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* `-v`: 输出虚拟机进程启动时JVM参数.\n","source":"_posts/jvm/JPS.md","raw":"category: JVM\ndate: 2014-10-02\ntitle: jps\n---\n虚拟机进程状况工具\n\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID).\n\n对于本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令显示主类的功能才能区分.\n\n命令格式:\n```java\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n\njps工具主要选项\n* `-q`: 只输出LVMID,省略主类的名称\n* `-m`: 输出虚拟机进程启动时传递给主类main()函数的参数\n* `-l`: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* `-v`: 输出虚拟机进程启动时JVM参数.\n","slug":"jvm/JPS","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsp0056vjs68bjnep5l"},{"date":"2014-08-31T16:00:00.000Z","title":"JVM内存参数","_content":"## 内存分配\n### Xmx\n这个参数设置可用的最大堆内存, 如果我们不使用这个参数,在Mac平台上,默认分配的堆内存为1431M.\n```java\npublic class Test {\n\tpublic static void main(String[] main) {\n\t\tlong maxMemory = Runtime.getRuntime().maxMemory();\n\n\t\tSystem.out.println(maxMemory / 1000 / 1000 + \"M\");\n\t}\n}\n```\n当我们使用上`-Xmx1m`的时候,我们手动地将堆内存设置为1m, 通过刚才的程序输出,确实是最大的内存为1m.  在这个例子中我们还要注意到, 在JVM分配内存时候, 1M = 1000KBM, 而不是1024KBM\n\n### Xss\n这个参数用来分配线程最大的栈空间, 这个参数决定了方法调用的最大的次数. 如果我们不使用这个参数,在mac平台上大概能进行16000个方法调用. 这个参数可设置的最小值为160k. 当我们设置上160k的时候, 程序能调用818次的方法调用\n```java\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf();\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\tpublic static void invokeSelf() {\n\t\tcount++;\n\t\tinvokeSelf();\n\t}\n}\n```\n我们知道在java的方法调用就是在栈帧不断地在java栈中出栈入栈, 因此栈帧的大小也影响着方法的调用次数.  栈帧是由局部变量表,操作数栈,和帧数据几个部分组成.\n\n\n下面我们测试一下将上例的递归函数加入一个参数,看看调用次数\n```java\n\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf(count);\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tpublic static void invokeSelf(long times) {\n\t\tcount++;\n\t\tinvokeSelf(times);\n\t}\n}\n```\n\n这次的调用次数成了682次,说明局部变量表确实是在影响方法调用的次数.\n```java\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf(count);\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tpublic static void invokeSelf(long times) {\n\t\tcount++;\n\t\tint newCount = (int)count;\n\t\tinvokeSelf(times);\n\t}\n}\n```\n这次我添加了一个中间过程,调用次数变成了629\n\n\n本想这个次数是针对一个线程的设置还是个共享值, 但是在多线程的情况下,明显的出现了难以预料的结果,他的调用次数有了明显的提升\n```java\npublic class Test {\n\n    private static long count = 0;\n    public static void main(String[] main) {\n\n        Runnable runnable = () -> {\n            try {\n                invokeSelf(count);\n            } catch (Throwable e) {\n                System.out.println(\"invoke : \" + count);\n    //            e.printStackTrace();\n            }\n\n        };\n\n        Runnable runnable2 = () -> {\n            try {\n                invokeSelf2(count);\n            } catch (Throwable e) {\n                System.out.println(\"invoke : \" + count);\n                //            e.printStackTrace();\n            }\n\n        };\n\n        Thread t = new Thread(runnable);\n        Thread t2 = new Thread(runnable2);\n        t.start();\n        t2.start();\n    }\n\n    public static void invokeSelf(long times) {\n        count++;\n        int newCount = (int)count;\n        invokeSelf(times);\n    }\n\n    public static void invokeSelf2(long times) {\n        count++;\n        int newCount = (int)count;\n        invokeSelf2(times);\n    }\n\n}\n```\n这个很奇怪,\n结果为\n```java\ninvoke : 1083\ninvoke : 1083\n```\n或者\n```java\ninvoke : 650\ninvoke : 1300\n```\n要不然次数是一样的,要不然次数是个倍数的关系\n\n### SurvivorRatio\n`-XX:SurvivorRatio=6`:新生代中Eden区和Survivor区的容量比值(默认为8)\n\n### PretenureSizeThreshold\n`-XX:PretenureSizeThreshold`:直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n\n### MaxTenuringThreshold\n`-XX:MaxTenuringThreshold`:晋升到老年代的对象年龄,每个对象在坚持过一次MinorGC之后,年龄就+1,当超过这个参数值时就进入老年代\n\n### UseAdaptiveSizePolicy\n`-XX:UseAdaptiveSizePolicy`:动态调整java堆中各个区域的大小及进入老年代的年龄\n> 吞吐量垃圾回收器利用了一种叫做自适应大小的特性，自适应大小是基于对象的分配和存活率来自动改变eden空间和survivor空间大小，目的是优化对象的岁数分布。自适应大小的企图是提供易用性，容易优化JVM，以致于提供可靠的吞吐量\n\n### HandlePromotionFailure\n`-XX:HandlePromotionFailure`:是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n\n### UseTLAB\n`-XX:UseTLAB`:优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n\n### NewRatio\n`-XX:NewRatio=n`:老年代与新生代比例(默认是2).\n\n### MaxHeapFreeRatio\n`-XX:MaxHeapFreeRatio`:当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n\n### MinHeapFreeRatio\n`-XX:MinHeapFreeRatio`:当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n\n### MaxPermSize\n`-XX:MaxPermSize`:永久代的最大值\n\n### ms\n`-XX:ms`:初始堆大小\n\n### mn\n`-XX:`:设置年轻代大小.整个JVM内存大小=年轻代大小+年老代大小+持久代大小.(Xms必须大于Xmn)\n\n### NewSize\n`-XX:NewSize=2m`:新生代默认大小(单位是字节)\n\n### MaxNewSize\n`-XX:MaxNewSize=size`:新生代最大值(单位字节)\n\n### ThreadStackSize\n`-XX:ThreadStackSize=512`:线程堆栈大小(单位Kbytes,0使用默认大小)\n\n\n## 垃圾收集器\n### ExplicitGCInvokesConcurrent\n`-XX:`:当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n\n### UseSerialGC\n`-XX:`:打开此开关后使用Serial+SerialOld的收集器组合进行内存回收.\n\n### UseParNewGC\n`-XX:`:虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+SeialOld的收集器组合进行垃圾收集\n\n### UseConcMarkSweepGc\n`-XX:`:打开次开关后使用`ParNew+CMS+SerialOld`收集器组合进行垃圾收集.如果CMS收集器出现`ConcurrentModeFailure`,则`SeialOld`收集器将作为后备收集器.\n\n### UseParallelGC\n`-XX:`:虚拟机运行在Server模式下的默认值,打开此开关后,使用ParallelScavenge+SerialOld的收集器组合进行内存回收\n\n### UseParaelOldGC\n`-XX:`:打开此开关后,使用ParallelScavenge+ParallelOld的收集器组合进行内存回收\n\n### ParallelGCThreads\n`-XX:`:设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n\n### CMSInitiatingOccupancyFraction\n`-XX:`:设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n\n### UseCMSCompactAtFullCollection\n`-XX:`:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n\n### CMSFullGCBeforeCompaction\n`-XX:`:设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n\n### UseParallelOldGC\n`-XX:-UseParallelOldGC`:所有的集合使用并行垃圾收集器.能够自动化地设置这个选项-XX:+UseParallelGC\n\n###　ConcGCThreads\n`-XX:ConcGCThreads=n`:`concurrentgarbagecollectors`使用的线程数.(默认值与JVM所在平台有关).\n\n### UseG1GC\n`-XX:+UseG1GC`:使用`GarbageFirst(G1)`收集器\n\n## 设置GC\n\n### DisableExplicitGC\n`-XDisableExplicitGC` 忽略来自System.gc()方法触发的垃圾收集\n\n### GCTimeRatio\n`-XX:`:GC时间占总时间的比率.仅在使用ParallelScavenge收集器时生效\n\n### MaxGCPauseMillis\n`-XX:`:设置GC最大停顿时间.仅在使用ParallelScavenge收集器时生效\n\n### ScavengeBeforeFullGC\n`-XX:`:在FullGC发生之前触发一次MinorGC\n\n### UseGCOverheadLimit\n`-XX:`:禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n\n### InitiatingHeapOccupancyPercent\n`-XX:InitiatingHeapOccupancyPercent=n`:设置触发标记周期的Java堆占用率阈值.默认占用率是整个Java堆的45%.\n\n### G1HeapRegionSize\n`-XX:G1HeapRegionSize=n`:设置的G1区域的大小.值是2的幂,范围是1MB到32MB之间.目标是根据最小的Java堆大小划分出约2048个区域.\n\n### G1ReservePercent\n`-XX:G1ReservePercent=n`:设置作为空闲空间的预留内存百分比,以降低目标空间溢出的风险.默认值是10%.增加或减少百分比时,请确保对总的Java堆调整相同的量.JavaHotSpotVMbuild23中没有此设置.\n","source":"_posts/jvm/JVM 内存参数.md","raw":"category: JVM\ndate: 2014-09-01\ntitle: JVM内存参数\n---\n## 内存分配\n### Xmx\n这个参数设置可用的最大堆内存, 如果我们不使用这个参数,在Mac平台上,默认分配的堆内存为1431M.\n```java\npublic class Test {\n\tpublic static void main(String[] main) {\n\t\tlong maxMemory = Runtime.getRuntime().maxMemory();\n\n\t\tSystem.out.println(maxMemory / 1000 / 1000 + \"M\");\n\t}\n}\n```\n当我们使用上`-Xmx1m`的时候,我们手动地将堆内存设置为1m, 通过刚才的程序输出,确实是最大的内存为1m.  在这个例子中我们还要注意到, 在JVM分配内存时候, 1M = 1000KBM, 而不是1024KBM\n\n### Xss\n这个参数用来分配线程最大的栈空间, 这个参数决定了方法调用的最大的次数. 如果我们不使用这个参数,在mac平台上大概能进行16000个方法调用. 这个参数可设置的最小值为160k. 当我们设置上160k的时候, 程序能调用818次的方法调用\n```java\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf();\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\tpublic static void invokeSelf() {\n\t\tcount++;\n\t\tinvokeSelf();\n\t}\n}\n```\n我们知道在java的方法调用就是在栈帧不断地在java栈中出栈入栈, 因此栈帧的大小也影响着方法的调用次数.  栈帧是由局部变量表,操作数栈,和帧数据几个部分组成.\n\n\n下面我们测试一下将上例的递归函数加入一个参数,看看调用次数\n```java\n\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf(count);\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tpublic static void invokeSelf(long times) {\n\t\tcount++;\n\t\tinvokeSelf(times);\n\t}\n}\n```\n\n这次的调用次数成了682次,说明局部变量表确实是在影响方法调用的次数.\n```java\npublic class Test {\n\tprivate static long count = 0;\n\tpublic static void main(String[] main) {\n\t\ttry {\n\t\t\tinvokeSelf(count);\n\t\t} catch (Throwable e) {\n\t\t\tSystem.out.println(\"invoke:\" + count);\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tpublic static void invokeSelf(long times) {\n\t\tcount++;\n\t\tint newCount = (int)count;\n\t\tinvokeSelf(times);\n\t}\n}\n```\n这次我添加了一个中间过程,调用次数变成了629\n\n\n本想这个次数是针对一个线程的设置还是个共享值, 但是在多线程的情况下,明显的出现了难以预料的结果,他的调用次数有了明显的提升\n```java\npublic class Test {\n\n    private static long count = 0;\n    public static void main(String[] main) {\n\n        Runnable runnable = () -> {\n            try {\n                invokeSelf(count);\n            } catch (Throwable e) {\n                System.out.println(\"invoke : \" + count);\n    //            e.printStackTrace();\n            }\n\n        };\n\n        Runnable runnable2 = () -> {\n            try {\n                invokeSelf2(count);\n            } catch (Throwable e) {\n                System.out.println(\"invoke : \" + count);\n                //            e.printStackTrace();\n            }\n\n        };\n\n        Thread t = new Thread(runnable);\n        Thread t2 = new Thread(runnable2);\n        t.start();\n        t2.start();\n    }\n\n    public static void invokeSelf(long times) {\n        count++;\n        int newCount = (int)count;\n        invokeSelf(times);\n    }\n\n    public static void invokeSelf2(long times) {\n        count++;\n        int newCount = (int)count;\n        invokeSelf2(times);\n    }\n\n}\n```\n这个很奇怪,\n结果为\n```java\ninvoke : 1083\ninvoke : 1083\n```\n或者\n```java\ninvoke : 650\ninvoke : 1300\n```\n要不然次数是一样的,要不然次数是个倍数的关系\n\n### SurvivorRatio\n`-XX:SurvivorRatio=6`:新生代中Eden区和Survivor区的容量比值(默认为8)\n\n### PretenureSizeThreshold\n`-XX:PretenureSizeThreshold`:直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n\n### MaxTenuringThreshold\n`-XX:MaxTenuringThreshold`:晋升到老年代的对象年龄,每个对象在坚持过一次MinorGC之后,年龄就+1,当超过这个参数值时就进入老年代\n\n### UseAdaptiveSizePolicy\n`-XX:UseAdaptiveSizePolicy`:动态调整java堆中各个区域的大小及进入老年代的年龄\n> 吞吐量垃圾回收器利用了一种叫做自适应大小的特性，自适应大小是基于对象的分配和存活率来自动改变eden空间和survivor空间大小，目的是优化对象的岁数分布。自适应大小的企图是提供易用性，容易优化JVM，以致于提供可靠的吞吐量\n\n### HandlePromotionFailure\n`-XX:HandlePromotionFailure`:是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n\n### UseTLAB\n`-XX:UseTLAB`:优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n\n### NewRatio\n`-XX:NewRatio=n`:老年代与新生代比例(默认是2).\n\n### MaxHeapFreeRatio\n`-XX:MaxHeapFreeRatio`:当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n\n### MinHeapFreeRatio\n`-XX:MinHeapFreeRatio`:当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n\n### MaxPermSize\n`-XX:MaxPermSize`:永久代的最大值\n\n### ms\n`-XX:ms`:初始堆大小\n\n### mn\n`-XX:`:设置年轻代大小.整个JVM内存大小=年轻代大小+年老代大小+持久代大小.(Xms必须大于Xmn)\n\n### NewSize\n`-XX:NewSize=2m`:新生代默认大小(单位是字节)\n\n### MaxNewSize\n`-XX:MaxNewSize=size`:新生代最大值(单位字节)\n\n### ThreadStackSize\n`-XX:ThreadStackSize=512`:线程堆栈大小(单位Kbytes,0使用默认大小)\n\n\n## 垃圾收集器\n### ExplicitGCInvokesConcurrent\n`-XX:`:当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n\n### UseSerialGC\n`-XX:`:打开此开关后使用Serial+SerialOld的收集器组合进行内存回收.\n\n### UseParNewGC\n`-XX:`:虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+SeialOld的收集器组合进行垃圾收集\n\n### UseConcMarkSweepGc\n`-XX:`:打开次开关后使用`ParNew+CMS+SerialOld`收集器组合进行垃圾收集.如果CMS收集器出现`ConcurrentModeFailure`,则`SeialOld`收集器将作为后备收集器.\n\n### UseParallelGC\n`-XX:`:虚拟机运行在Server模式下的默认值,打开此开关后,使用ParallelScavenge+SerialOld的收集器组合进行内存回收\n\n### UseParaelOldGC\n`-XX:`:打开此开关后,使用ParallelScavenge+ParallelOld的收集器组合进行内存回收\n\n### ParallelGCThreads\n`-XX:`:设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n\n### CMSInitiatingOccupancyFraction\n`-XX:`:设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n\n### UseCMSCompactAtFullCollection\n`-XX:`:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n\n### CMSFullGCBeforeCompaction\n`-XX:`:设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n\n### UseParallelOldGC\n`-XX:-UseParallelOldGC`:所有的集合使用并行垃圾收集器.能够自动化地设置这个选项-XX:+UseParallelGC\n\n###　ConcGCThreads\n`-XX:ConcGCThreads=n`:`concurrentgarbagecollectors`使用的线程数.(默认值与JVM所在平台有关).\n\n### UseG1GC\n`-XX:+UseG1GC`:使用`GarbageFirst(G1)`收集器\n\n## 设置GC\n\n### DisableExplicitGC\n`-XDisableExplicitGC` 忽略来自System.gc()方法触发的垃圾收集\n\n### GCTimeRatio\n`-XX:`:GC时间占总时间的比率.仅在使用ParallelScavenge收集器时生效\n\n### MaxGCPauseMillis\n`-XX:`:设置GC最大停顿时间.仅在使用ParallelScavenge收集器时生效\n\n### ScavengeBeforeFullGC\n`-XX:`:在FullGC发生之前触发一次MinorGC\n\n### UseGCOverheadLimit\n`-XX:`:禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n\n### InitiatingHeapOccupancyPercent\n`-XX:InitiatingHeapOccupancyPercent=n`:设置触发标记周期的Java堆占用率阈值.默认占用率是整个Java堆的45%.\n\n### G1HeapRegionSize\n`-XX:G1HeapRegionSize=n`:设置的G1区域的大小.值是2的幂,范围是1MB到32MB之间.目标是根据最小的Java堆大小划分出约2048个区域.\n\n### G1ReservePercent\n`-XX:G1ReservePercent=n`:设置作为空闲空间的预留内存百分比,以降低目标空间溢出的风险.默认值是10%.增加或减少百分比时,请确保对总的Java堆调整相同的量.JavaHotSpotVMbuild23中没有此设置.\n","slug":"jvm/JVM 内存参数","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsr0059vjs6mw3tg6tb"},{"date":"2014-09-01T16:00:00.000Z","title":"JVM 堆内存","_content":"## java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上分配也不是那么绝对了\n\n简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象. Java 的堆是一个运行时数据区 , 对象被存储在堆中 . 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放. 因此， 在堆里分配存储有很大的灵活性 . 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 .\n\n## 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n## 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 . 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 . 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n## 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n永久代的垃圾回收主要是回收俩部分内容:\n* 废弃常量: 回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n2. 加载该类的ClassLoader已经被回收.<br.>\n3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n## 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n## 静态存储\n\n静态存储里存放程序运行时一直存在的数据 . 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 . 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 .\n","source":"_posts/jvm/JVM 堆内存.md","raw":"category: JVM\ndate: 2014-09-02\ntitle: JVM 堆内存\n---\n## java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上分配也不是那么绝对了\n\n简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象. Java 的堆是一个运行时数据区 , 对象被存储在堆中 . 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放. 因此， 在堆里分配存储有很大的灵活性 . 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 .\n\n## 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n## 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 . 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 . 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n## 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n永久代的垃圾回收主要是回收俩部分内容:\n* 废弃常量: 回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n2. 加载该类的ClassLoader已经被回收.<br.>\n3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n## 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n## 静态存储\n\n静态存储里存放程序运行时一直存在的数据 . 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 . 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 .\n","slug":"jvm/JVM 堆内存","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihst005bvjs6l9z4xez6"},{"date":"2014-09-02T16:00:00.000Z","title":"JVM栈","_content":"JVM栈和常用的数据结构很相似,都是一种先进后出的数据结构. JVM栈是每个线程私有的内存空间.线程的基本行为就是方法调用, 而方法调用就是通过JVM栈传递的.每当我们创建一个线程对象的的时候, 都会创建一个JVM栈. 它的生命周期与线程相同.\n\nJVM栈是由JVM栈帧组成的, 每次方法调用都会有一个JVM栈帧进入JVM栈,也称入栈, 当方法执行完(不管是return还是异常),栈帧都会被弹出JVM栈,也称出栈. 栈帧包含如下结构:\n* PC寄存器\n* 本地方法栈\n* 局部变量表\n* 操作数栈\n* 动态连接\n* 方法出口\n\n在java虚拟机中.对这个区域规定了俩种异常情况:\n1. 如果请求的栈深度大于虚拟机所允许的深度,抛出`StackOverflowError`\n2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出`OutOfMemoryError`异常\n\n## PC寄存器\n每当我们创建一个线程的时候, 都会JVM都会附带着创建一个本线程私有的PC寄存器和虚拟机栈. PC寄存器用于存放当前线程执行的字节码指令(线程当前方法)地址. 字节码解释器通过修改寄存器里的值使线程完成下一个指令的执行. 分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个寄存器完成. 在一个单CPU的环境中, 一个多线程的程序通过轮流切换线程完成多线程运行. 那么在切换线程的时候, 被切换的线程对应的寄存器里的值被保存了下来, 当线程再切换回来的时候,线程得以继续运行.\n\n> PC寄存器是唯一一个在java虚拟机规范中没有规定任何`OutOfMemoryError`情况的区域.\n\n## 本地方法栈\n* 用来支持native方法\n\n## 局部变量表\n局部变量表存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中. 其有如下特点\n\n* 其长度在编译器决定\n* 一个局部变量称为一个Slot.每个Slot只可以保存一个`boolean, byte, char, short, int, float, reference,returnAddress`类型的数据.`long`或者`double`需要俩个Slot保存.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n\n局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n```\n运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n\n运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n## 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n","source":"_posts/jvm/JVM 栈.md","raw":"category: JVM\ndate: 2014-09-03\ntitle: JVM栈\n---\nJVM栈和常用的数据结构很相似,都是一种先进后出的数据结构. JVM栈是每个线程私有的内存空间.线程的基本行为就是方法调用, 而方法调用就是通过JVM栈传递的.每当我们创建一个线程对象的的时候, 都会创建一个JVM栈. 它的生命周期与线程相同.\n\nJVM栈是由JVM栈帧组成的, 每次方法调用都会有一个JVM栈帧进入JVM栈,也称入栈, 当方法执行完(不管是return还是异常),栈帧都会被弹出JVM栈,也称出栈. 栈帧包含如下结构:\n* PC寄存器\n* 本地方法栈\n* 局部变量表\n* 操作数栈\n* 动态连接\n* 方法出口\n\n在java虚拟机中.对这个区域规定了俩种异常情况:\n1. 如果请求的栈深度大于虚拟机所允许的深度,抛出`StackOverflowError`\n2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出`OutOfMemoryError`异常\n\n## PC寄存器\n每当我们创建一个线程的时候, 都会JVM都会附带着创建一个本线程私有的PC寄存器和虚拟机栈. PC寄存器用于存放当前线程执行的字节码指令(线程当前方法)地址. 字节码解释器通过修改寄存器里的值使线程完成下一个指令的执行. 分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个寄存器完成. 在一个单CPU的环境中, 一个多线程的程序通过轮流切换线程完成多线程运行. 那么在切换线程的时候, 被切换的线程对应的寄存器里的值被保存了下来, 当线程再切换回来的时候,线程得以继续运行.\n\n> PC寄存器是唯一一个在java虚拟机规范中没有规定任何`OutOfMemoryError`情况的区域.\n\n## 本地方法栈\n* 用来支持native方法\n\n## 局部变量表\n局部变量表存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中. 其有如下特点\n\n* 其长度在编译器决定\n* 一个局部变量称为一个Slot.每个Slot只可以保存一个`boolean, byte, char, short, int, float, reference,returnAddress`类型的数据.`long`或者`double`需要俩个Slot保存.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n\n局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n```\n运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n\n运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n## 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n","slug":"jvm/JVM 栈","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsv005dvjs6elzlcf0m"},{"date":"2014-09-03T16:00:00.000Z","title":"JVM方法调用","_content":"## 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n## 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n## 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n## 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n## 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n","source":"_posts/jvm/JVM方法调用.md","raw":"category: JVM\ndate: 2014-09-04\ntitle: JVM方法调用\n---\n## 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n## 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n## 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n## 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n## 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n","slug":"jvm/JVM方法调用","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihsx005gvjs6d12fom9n"},{"date":"2016-05-04T16:00:00.000Z","title":"Java 引用类型","_content":"在java中引用分为四个级别\n* 强引用 : 不会被回收\n* 软引用 : 内存不足时回收\n* 弱引用 : 发现就回收\n* 虚引用 : 用于跟踪对象回收\n\n\n## 强引用\nJVM在GC的时候并不会释放强引用的堆实例, 因此当堆内GC后仍然不能获得足够的空间, 就会发生OOM\n```java\nString str = new String(\"Hi\");\n```\n上面的例子中, 在栈中分配的`str`指向了堆中分配的String实例, 那么`str`引用就是这个实例的强引用.\n> 保存在数组和集合中以及Map中的引用都都算是强引用.\n\n## 软引用\nJVM在GC时不一定会释放软引用所引用的对象实例, 那什么时候会进行释放呢? 只有当JVM发现堆内存不足时, 才会在GC时将软引用的堆内存释放掉\n```java\nimport java.lang.ref.Reference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        SoftReference<User> softReference = new SoftReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + ref);\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n    }\n}\n\nclass User {\n    public String name;\n}\n```\n我们指定虚拟机参数`-Xmx10M -Xms10M -XX:PrintGC`, 运行一下这个程序的结果为:\n```bash\n[GC (Allocation Failure)  2048K->836K(9728K), 0.0023890 secs]\nBefore GC :  testRef.User@404b9385\n[GC (System.gc())  1145K->844K(9728K), 0.0013400 secs]\n[Full GC (System.gc())  844K->750K(9728K), 0.0085260 secs]\nAfter GC : testRef.User@404b9385\n[GC (Allocation Failure)  788K->782K(9728K), 0.0003760 secs]\n[GC (Allocation Failure)  782K->782K(9728K), 0.0002590 secs]\n[Full GC (Allocation Failure)  782K->750K(9728K), 0.0043290 secs]\n[GC (Allocation Failure)  750K->750K(9728K), 0.0004580 secs]\n[Full GC (Allocation Failure)  750K->692K(9728K), 0.0079430 secs]\nChanged : java.lang.ref.SoftReference@19366529\nAlocate : null\n```\n我们在构建`SoftReference`实例对象时, 除了添加一个测试对象外, 还添加里一个`ReferenceQueue`实例对象, 当对象的可达状态发生改变时, `SoftReference`就会移动到`ReferenceQueue`队列里. 从最后的Poll  这个输出里我们可以看到, 已经看不到这个对象了.\n\n## 弱引用\n弱引用是一种比软饮用更加弱的引用, JVM在GC时只要发现弱引用, 都会对其引用的实例进行回收\n```java\nimport java.lang.ref.Reference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\nimport java.lang.ref.WeakReference;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        WeakReference<User> softReference = new WeakReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + ref);\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n\n    }\n}\n\nclass User {}\n```\n我们指定虚拟机参数`-Xmx10M -Xms10M -XX:+PrintGC`, 运行一下这个程序的结果为:\n```bash\n[GC (Allocation Failure)  2048K->800K(9728K), 0.0031060 secs]\nBefore GC :  null\nChanged : java.lang.ref.WeakReference@175fdc70[GC (System.gc())  1084K->824K(9728K), 0.0011480 secs]\n[Full GC (System.gc())  824K->748K(9728K), 0.0088060 secs]\n\nAfter GC : null\n[GC (Allocation Failure)  807K->812K(9728K), 0.0010100 secs]\n[GC (Allocation Failure)  812K->844K(9728K), 0.0004150 secs]\n[Full GC (Allocation Failure)  844K->748K(9728K), 0.0090930 secs]\n[GC (Allocation Failure)  748K->748K(9728K), 0.0003230 secs]\n[Full GC (Allocation Failure)  748K->690K(9728K), 0.0082600 secs]\nAlocate : null\n```\n\n## 虚引用\n\n虚引用是所有引用类型中最弱的一个, 一个被虚引用持有的对象跟没有被持有的效果基本上是一样的. 当我们从虚引用中get时, 总会获得一个空, 那既然如此还为什么要设计出一个这样的引用呢? 因为虚引用必须跟一个引用队列, 我们可以将一些资源性的东西放到虚引用中执行和记录.\n```java\nimport java.lang.ref.*;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        PhantomReference<User> softReference = new PhantomReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + System.currentTimeMillis());\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + System.currentTimeMillis() + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n\n    }\n}\n\nclass User {}\n```\n我们指定虚拟机参数`-Xmx30M -Xms30M -XX:+PrintGC`, 运行一下这个程序的结果为:\n```bash\nBefore GC : 1462461362835 null\n[GC (System.gc())  2806K->904K(29696K), 0.0033390 secs]\n[Full GC (System.gc())  904K->779K(29696K), 0.0095950 secs]\nChanged : 1462461362850\nAfter GC : null\nAlocate : null\n```\n","source":"_posts/jvm/Java 引用类型.md","raw":"category: JVM\ndate: 2016-05-05\ntitle: Java 引用类型\n---\n在java中引用分为四个级别\n* 强引用 : 不会被回收\n* 软引用 : 内存不足时回收\n* 弱引用 : 发现就回收\n* 虚引用 : 用于跟踪对象回收\n\n\n## 强引用\nJVM在GC的时候并不会释放强引用的堆实例, 因此当堆内GC后仍然不能获得足够的空间, 就会发生OOM\n```java\nString str = new String(\"Hi\");\n```\n上面的例子中, 在栈中分配的`str`指向了堆中分配的String实例, 那么`str`引用就是这个实例的强引用.\n> 保存在数组和集合中以及Map中的引用都都算是强引用.\n\n## 软引用\nJVM在GC时不一定会释放软引用所引用的对象实例, 那什么时候会进行释放呢? 只有当JVM发现堆内存不足时, 才会在GC时将软引用的堆内存释放掉\n```java\nimport java.lang.ref.Reference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        SoftReference<User> softReference = new SoftReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + ref);\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n    }\n}\n\nclass User {\n    public String name;\n}\n```\n我们指定虚拟机参数`-Xmx10M -Xms10M -XX:PrintGC`, 运行一下这个程序的结果为:\n```bash\n[GC (Allocation Failure)  2048K->836K(9728K), 0.0023890 secs]\nBefore GC :  testRef.User@404b9385\n[GC (System.gc())  1145K->844K(9728K), 0.0013400 secs]\n[Full GC (System.gc())  844K->750K(9728K), 0.0085260 secs]\nAfter GC : testRef.User@404b9385\n[GC (Allocation Failure)  788K->782K(9728K), 0.0003760 secs]\n[GC (Allocation Failure)  782K->782K(9728K), 0.0002590 secs]\n[Full GC (Allocation Failure)  782K->750K(9728K), 0.0043290 secs]\n[GC (Allocation Failure)  750K->750K(9728K), 0.0004580 secs]\n[Full GC (Allocation Failure)  750K->692K(9728K), 0.0079430 secs]\nChanged : java.lang.ref.SoftReference@19366529\nAlocate : null\n```\n我们在构建`SoftReference`实例对象时, 除了添加一个测试对象外, 还添加里一个`ReferenceQueue`实例对象, 当对象的可达状态发生改变时, `SoftReference`就会移动到`ReferenceQueue`队列里. 从最后的Poll  这个输出里我们可以看到, 已经看不到这个对象了.\n\n## 弱引用\n弱引用是一种比软饮用更加弱的引用, JVM在GC时只要发现弱引用, 都会对其引用的实例进行回收\n```java\nimport java.lang.ref.Reference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\nimport java.lang.ref.WeakReference;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        WeakReference<User> softReference = new WeakReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + ref);\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n\n    }\n}\n\nclass User {}\n```\n我们指定虚拟机参数`-Xmx10M -Xms10M -XX:+PrintGC`, 运行一下这个程序的结果为:\n```bash\n[GC (Allocation Failure)  2048K->800K(9728K), 0.0031060 secs]\nBefore GC :  null\nChanged : java.lang.ref.WeakReference@175fdc70[GC (System.gc())  1084K->824K(9728K), 0.0011480 secs]\n[Full GC (System.gc())  824K->748K(9728K), 0.0088060 secs]\n\nAfter GC : null\n[GC (Allocation Failure)  807K->812K(9728K), 0.0010100 secs]\n[GC (Allocation Failure)  812K->844K(9728K), 0.0004150 secs]\n[Full GC (Allocation Failure)  844K->748K(9728K), 0.0090930 secs]\n[GC (Allocation Failure)  748K->748K(9728K), 0.0003230 secs]\n[Full GC (Allocation Failure)  748K->690K(9728K), 0.0082600 secs]\nAlocate : null\n```\n\n## 虚引用\n\n虚引用是所有引用类型中最弱的一个, 一个被虚引用持有的对象跟没有被持有的效果基本上是一样的. 当我们从虚引用中get时, 总会获得一个空, 那既然如此还为什么要设计出一个这样的引用呢? 因为虚引用必须跟一个引用队列, 我们可以将一些资源性的东西放到虚引用中执行和记录.\n```java\nimport java.lang.ref.*;\n\npublic class TestSoft {\n\n    public static void main(String[] args) throws InterruptedException {\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<>();\n        User user = new User();\n        PhantomReference<User> softReference = new PhantomReference<>(user, referenceQueue);\n        user = null;\n\n        Thread t = new Thread(() -> {\n            while (true) {\n                Reference<? extends User> ref = referenceQueue.poll();\n                if (ref != null) {\n                    System.out.println(\"Changed : \" + System.currentTimeMillis());\n                    break;\n                }\n            }\n        });\n\n        t.setDaemon(true);\n        t.start();\n\n        System.out.println(\"Before GC : \" + System.currentTimeMillis() + \" \" + softReference.get());\n\n        System.gc();\n        System.out.println(\"After GC : \" + softReference.get());\n\n        byte[] array = new byte[1024 * 920 * 7];\n        System.out.println(\"Alocate : \" + softReference.get());\n\n    }\n}\n\nclass User {}\n```\n我们指定虚拟机参数`-Xmx30M -Xms30M -XX:+PrintGC`, 运行一下这个程序的结果为:\n```bash\nBefore GC : 1462461362835 null\n[GC (System.gc())  2806K->904K(29696K), 0.0033390 secs]\n[Full GC (System.gc())  904K->779K(29696K), 0.0095950 secs]\nChanged : 1462461362850\nAfter GC : null\nAlocate : null\n```\n","slug":"jvm/Java 引用类型","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iht0005ivjs6nxrvmoj8"},{"date":"2014-10-03T16:00:00.000Z","title":"Jinfo","_content":"jinfo的作用是实时查看和调整虚拟机的各项参数.\n```java\njinfo [ option ] pid\n```\noption可以为如下值\n* `-flag <name>`         to print the value of the named VM flag\n* `-flag [+|-]<name>`    to enable or disable the named VM flag\n* `-flag <name>=<value>` to set the named VM flag to the given value\n* `-flags`               to print VM flags\n* `-sysprops`            to print Java system properties\n* `<no option>`          to print both of the above\n```bash\ntest jinfo 2028\nAttaching to process ID 2028, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.5-b02\nJava System Properties:\n\njava.runtime.name = Java(TM) SE Runtime Environment\njava.vm.version = 25.5-b02\nsun.boot.library.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib\ngopherProxySet = false\njava.vendor.url = http://java.oracle.com/\njava.vm.vendor = Oracle Corporation\npath.separator = :\nfile.encoding.pkg = sun.io\njava.vm.name = Java HotSpot(TM) 64-Bit Server VM\nidea.launcher.port = 7532\nsun.os.patch.level = unknown\nsun.java.launcher = SUN_STANDARD\nuser.country = CN\njava.vm.specification.name = Java Virtual Machine Specification\nPID = 2028\njava.runtime.version = 1.8.0_05-b13\njava.awt.graphicsenv = sun.awt.CGraphicsEnvironment\nos.arch = x86_64\njava.endorsed.dirs = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/endorsed\norg.jboss.logging.provider = slf4j\nline.separator =\n\njava.io.tmpdir = /var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/\njava.vm.specification.vendor = Oracle Corporation\nos.name = Mac OS X\nsun.jnu.encoding = UTF-8\nspring.beaninfo.ignore = true\njava.specification.name = Java Platform API Specification\njava.class.version = 52.0\nsun.management.compiler = HotSpot 64-Bit Tiered Compilers\nos.version = 10.10.5\nuser.timezone = Asia/Harbin\ncatalina.useNaming = false\njava.awt.printerjob = sun.lwawt.macosx.CPrinterJob\nfile.encoding = UTF-8\njava.specification.version = 1.8\ncatalina.home = /private/var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/tomcat.3734431332202362357.8080\njava.vm.specification.version = 1.8\nsun.arch.data.model = 64\nsun.java.command = com.intellij.rt.execution.application.AppMain HTTPServer\njava.home = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre\nuser.language = zh\njava.specification.vendor = Oracle Corporation\nawt.toolkit = sun.lwawt.macosx.LWCToolkit\njava.vm.info = mixed mode\njava.version = 1.8.0_05\njava.awt.headless = true\njava.vendor = Oracle Corporation\ncatalina.base = /private/var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/tomcat.3734431332202362357.8080\nfile.separator = /\njava.vendor.url.bug = http://bugreport.sun.com/bugreport/\nsun.io.unicode.encoding = UnicodeBig\nsun.cpu.endian = little\nsun.cpu.isalist =\n\nVM Flags:\nNon-default VM flags: -XX:InitialHeapSize=100663296 -XX:MaxHeapSize=1610612736 -XX:MaxNewSize=536870912 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=1572864 -XX:OldSize=99090432 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC\n```\n","source":"_posts/jvm/Jinfo.md","raw":"category: JVM\ndate: 2014-10-04\ntitle: Jinfo\n---\njinfo的作用是实时查看和调整虚拟机的各项参数.\n```java\njinfo [ option ] pid\n```\noption可以为如下值\n* `-flag <name>`         to print the value of the named VM flag\n* `-flag [+|-]<name>`    to enable or disable the named VM flag\n* `-flag <name>=<value>` to set the named VM flag to the given value\n* `-flags`               to print VM flags\n* `-sysprops`            to print Java system properties\n* `<no option>`          to print both of the above\n```bash\ntest jinfo 2028\nAttaching to process ID 2028, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.5-b02\nJava System Properties:\n\njava.runtime.name = Java(TM) SE Runtime Environment\njava.vm.version = 25.5-b02\nsun.boot.library.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib\ngopherProxySet = false\njava.vendor.url = http://java.oracle.com/\njava.vm.vendor = Oracle Corporation\npath.separator = :\nfile.encoding.pkg = sun.io\njava.vm.name = Java HotSpot(TM) 64-Bit Server VM\nidea.launcher.port = 7532\nsun.os.patch.level = unknown\nsun.java.launcher = SUN_STANDARD\nuser.country = CN\njava.vm.specification.name = Java Virtual Machine Specification\nPID = 2028\njava.runtime.version = 1.8.0_05-b13\njava.awt.graphicsenv = sun.awt.CGraphicsEnvironment\nos.arch = x86_64\njava.endorsed.dirs = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/endorsed\norg.jboss.logging.provider = slf4j\nline.separator =\n\njava.io.tmpdir = /var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/\njava.vm.specification.vendor = Oracle Corporation\nos.name = Mac OS X\nsun.jnu.encoding = UTF-8\nspring.beaninfo.ignore = true\njava.specification.name = Java Platform API Specification\njava.class.version = 52.0\nsun.management.compiler = HotSpot 64-Bit Tiered Compilers\nos.version = 10.10.5\nuser.timezone = Asia/Harbin\ncatalina.useNaming = false\njava.awt.printerjob = sun.lwawt.macosx.CPrinterJob\nfile.encoding = UTF-8\njava.specification.version = 1.8\ncatalina.home = /private/var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/tomcat.3734431332202362357.8080\njava.vm.specification.version = 1.8\nsun.arch.data.model = 64\nsun.java.command = com.intellij.rt.execution.application.AppMain HTTPServer\njava.home = /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre\nuser.language = zh\njava.specification.vendor = Oracle Corporation\nawt.toolkit = sun.lwawt.macosx.LWCToolkit\njava.vm.info = mixed mode\njava.version = 1.8.0_05\njava.awt.headless = true\njava.vendor = Oracle Corporation\ncatalina.base = /private/var/folders/54/dy3_8pkj1ld2_q6r8rvvr1n80000gn/T/tomcat.3734431332202362357.8080\nfile.separator = /\njava.vendor.url.bug = http://bugreport.sun.com/bugreport/\nsun.io.unicode.encoding = UnicodeBig\nsun.cpu.endian = little\nsun.cpu.isalist =\n\nVM Flags:\nNon-default VM flags: -XX:InitialHeapSize=100663296 -XX:MaxHeapSize=1610612736 -XX:MaxNewSize=536870912 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=1572864 -XX:OldSize=99090432 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC\n```\n","slug":"jvm/Jinfo","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iht3005lvjs6elf1btxp"},{"date":"2014-09-30T16:00:00.000Z","title":"Jmap","_content":"java内存映射工具,用于生成堆转储快照.\n\n如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n* `-XX:+HeapDumpOnOutOfMemoryError`: 可以让虚拟机在OOM异常自动生成dump文件,通过\n* `-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]`: 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n```bash\njmap [ option ] vmid\n```\n\njmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n获取当前进程的堆快照\n```bash\n➜ test jmap -dump:live,format=b,file=2028dump 2028\nDumping heap to /Users/wangming/Desktop/test/2028dump ...\nHeap dump file created\n```\n\n获取当前进程的对象统计信息, 下面统计出了数量大于10000个对象的类\n```bash\n➜ test jmap -histo 2028 | awk '{if($2> 10000) print $1 \"  \" $2 \"  \"  $3 \"  \" $4 }'\n1:  36397  6363208  [C\n3:  35324  847776  java.lang.String\n7:  10522  336704  java.util.concurrent.ConcurrentHashMap$Node\nTotal  207899  14900384\n```\n","source":"_posts/jvm/Jmap.md","raw":"category: JVM\ndate: 2014-10-01\ntitle: Jmap\n---\njava内存映射工具,用于生成堆转储快照.\n\n如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n* `-XX:+HeapDumpOnOutOfMemoryError`: 可以让虚拟机在OOM异常自动生成dump文件,通过\n* `-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]`: 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n```bash\njmap [ option ] vmid\n```\n\njmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n获取当前进程的堆快照\n```bash\n➜ test jmap -dump:live,format=b,file=2028dump 2028\nDumping heap to /Users/wangming/Desktop/test/2028dump ...\nHeap dump file created\n```\n\n获取当前进程的对象统计信息, 下面统计出了数量大于10000个对象的类\n```bash\n➜ test jmap -histo 2028 | awk '{if($2> 10000) print $1 \"  \" $2 \"  \"  $3 \"  \" $4 }'\n1:  36397  6363208  [C\n3:  35324  847776  java.lang.String\n7:  10522  336704  java.util.concurrent.ConcurrentHashMap$Node\nTotal  207899  14900384\n```\n","slug":"jvm/Jmap","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iht5005nvjs698olpeyn"},{"date":"2014-09-09T16:00:00.000Z","title":"class文件格式","_content":"\n## ClassFile 结构\n```java\nu4              magic;\nu2              minor_version;\nu2              major_version;\nu2              constant_pool_count;\ncp_info         constant_pool[constant_pool_count - 1];\nu2              access_flags;\nu2              this_class;\nu2              super_class;\nu2              interfaces_count;\nu2              interfaces[interfaces_count];\nu2              fields_count;\nfield_info      fields[fields_count];\nu2              methods_count;\nmethod_info     methods[methods_count];\nu2              attributes_count;\nattribute_info  attributes[attributes_count];\n```\n\n### magic\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为`0xCAFEBABY`,不会改变\n\n### 版本号\n* minor_version副版本号\n* major_version主版本号\n二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool(常量池)\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.\n\n常量池主要存放俩大类常量:\n* 字面量 : 文本字符串,被声明为final的常量值\n* 符号引用. 符号引用则包括了下列三种常量:\n\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|CONSTANT_Utf8_info              |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\naccess_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上`ACC_INTERFACE`意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 `ACC_ABSTRACT`,则不能再设置`ACC_FINAL,ACC_SUPER,ACC_ENUM`.\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n#### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n> 对于max_locals有如下说明：对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\nExceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n> number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个xception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n\n#### LineNumberTable属性\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,并且在断点时,无法按照源码设置断点.\n\n#### LocalVariableTable 属性\n用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n#### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\nSourceFile属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n\n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\nConstantValue属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\nInnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\ninner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引. 分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\ninner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n","source":"_posts/jvm/class文件格式.md","raw":"category: JVM\ndate: 2014-09-10\ntitle: class文件格式\n---\n\n## ClassFile 结构\n```java\nu4              magic;\nu2              minor_version;\nu2              major_version;\nu2              constant_pool_count;\ncp_info         constant_pool[constant_pool_count - 1];\nu2              access_flags;\nu2              this_class;\nu2              super_class;\nu2              interfaces_count;\nu2              interfaces[interfaces_count];\nu2              fields_count;\nfield_info      fields[fields_count];\nu2              methods_count;\nmethod_info     methods[methods_count];\nu2              attributes_count;\nattribute_info  attributes[attributes_count];\n```\n\n### magic\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为`0xCAFEBABY`,不会改变\n\n### 版本号\n* minor_version副版本号\n* major_version主版本号\n二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool(常量池)\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.\n\n常量池主要存放俩大类常量:\n* 字面量 : 文本字符串,被声明为final的常量值\n* 符号引用. 符号引用则包括了下列三种常量:\n\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|CONSTANT_Utf8_info              |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\naccess_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上`ACC_INTERFACE`意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 `ACC_ABSTRACT`,则不能再设置`ACC_FINAL,ACC_SUPER,ACC_ENUM`.\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n#### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n> 对于max_locals有如下说明：对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\nExceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n> number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个xception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n\n#### LineNumberTable属性\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,并且在断点时,无法按照源码设置断点.\n\n#### LocalVariableTable 属性\n用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n#### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\nSourceFile属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n\n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\nConstantValue属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\nInnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\ninner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引. 分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\ninner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n","slug":"jvm/class文件格式","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8iht8005pvjs6j1k78mli"},{"date":"2014-10-05T16:00:00.000Z","title":"hprof","_content":"这个是java agent工具, 用它可以监控应用程序在运行时的CPU信息和堆信息. 我们来看一下它的官网文档是怎么说的\n```bash\n➜  test java -agentlib:hprof=help\n\n     HPROF: Heap and CPU Profiling Agent (JVMTI Demonstration Code)\n\nhprof usage: java -agentlib:hprof=[help]|[<option>=<value>, ...]\n\nOption Name and Value  Description                    Default\n---------------------  -----------                    -------\nheap=dump|sites|all    heap profiling                 all\ncpu=samples|times|old  CPU usage                      off\nmonitor=y|n            monitor contention             n\nformat=a|b             text(txt) or binary output     a\nfile=<file>            write data to file             java.hprof[{.txt}]\nnet=<host>:<port>      send data over a socket        off\ndepth=<size>           stack trace depth              4\ninterval=<ms>          sample interval in ms          10\ncutoff=<value>         output cutoff point            0.0001\nlineno=y|n             line number in traces?         y\nthread=y|n             thread in traces?              n\ndoe=y|n                dump on exit?                  y\nmsa=y|n                Solaris micro state accounting n\nforce=y|n              force output to <file>         y\nverbose=y|n            print messages about dumps     y\n\nObsolete Options\n----------------\ngc_okay=y|n\n```\n示例:\n\n每20毫秒统计一次CPU信息(栈深度为3):\n```bash\njava -agentlib:hprof=cpu=samples,interval=20,depth=3 classname\n```\nGet heap usage information based on the allocation sites:\n```bash\njava -agentlib:hprof=heap=sites classname\n```\n\n注意:\n* `format=b`不能和`monitor=y`一起使用\n* `format=b`不能和`cpu=old|times`一起使用\n* `-Xrunhprof`接口可以继续使用, 例如`java -Xrunhprof:[help]|[<option>=<value>, ...]`.这个等同于`java -agentlib:hprof=[help]|[<option>=<value>, ...]`\n\n我们看一个很简单的统计函数运行时间的示例\n```bash\njava -agentlib:hprof=cpu=times,interval=10 Test\n```\n","source":"_posts/jvm/hprof.md","raw":"category: JVM\ndate: 2014-10-06\ntitle: hprof\n---\n这个是java agent工具, 用它可以监控应用程序在运行时的CPU信息和堆信息. 我们来看一下它的官网文档是怎么说的\n```bash\n➜  test java -agentlib:hprof=help\n\n     HPROF: Heap and CPU Profiling Agent (JVMTI Demonstration Code)\n\nhprof usage: java -agentlib:hprof=[help]|[<option>=<value>, ...]\n\nOption Name and Value  Description                    Default\n---------------------  -----------                    -------\nheap=dump|sites|all    heap profiling                 all\ncpu=samples|times|old  CPU usage                      off\nmonitor=y|n            monitor contention             n\nformat=a|b             text(txt) or binary output     a\nfile=<file>            write data to file             java.hprof[{.txt}]\nnet=<host>:<port>      send data over a socket        off\ndepth=<size>           stack trace depth              4\ninterval=<ms>          sample interval in ms          10\ncutoff=<value>         output cutoff point            0.0001\nlineno=y|n             line number in traces?         y\nthread=y|n             thread in traces?              n\ndoe=y|n                dump on exit?                  y\nmsa=y|n                Solaris micro state accounting n\nforce=y|n              force output to <file>         y\nverbose=y|n            print messages about dumps     y\n\nObsolete Options\n----------------\ngc_okay=y|n\n```\n示例:\n\n每20毫秒统计一次CPU信息(栈深度为3):\n```bash\njava -agentlib:hprof=cpu=samples,interval=20,depth=3 classname\n```\nGet heap usage information based on the allocation sites:\n```bash\njava -agentlib:hprof=heap=sites classname\n```\n\n注意:\n* `format=b`不能和`monitor=y`一起使用\n* `format=b`不能和`cpu=old|times`一起使用\n* `-Xrunhprof`接口可以继续使用, 例如`java -Xrunhprof:[help]|[<option>=<value>, ...]`.这个等同于`java -agentlib:hprof=[help]|[<option>=<value>, ...]`\n\n我们看一个很简单的统计函数运行时间的示例\n```bash\njava -agentlib:hprof=cpu=times,interval=10 Test\n```\n","slug":"jvm/hprof","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtb005rvjs6jbph5y4v"},{"date":"2015-11-23T16:00:00.000Z","title":"Instrumentation Agentmain","_content":"\n在 Java SE 5 中premain 所作的 Instrumentation 也仅限与 main 函数执行前，这样的方式存在一定的局限性。Java SE 6 针对这种状况做出了改进，开发者可以在 main 函数开始执行以后，再启动自己的 Instrumentation 程序。在 Java SE 6 的 Instrumentation 当中，有一个跟 premain“并驾齐驱”的“agentmain”方法，可以在 main 函数开始运行之后再运行。\n\n首先我们还是需要修改MANIFEST.MF文件, 在其中添加\n```java\nManifest-Version: 1.0\nAgent-Class: AgentMain\nCan-Redefine-Classes: true\n```\n\n然后我们写一个代理类\n```java\nimport javax.xml.transform.Transformer;\nimport java.lang.instrument.Instrumentation;\nimport java.lang.instrument.UnmodifiableClassException;\n\npublic class AgentMain {\n\n    public static void agentmain(String agentArgs, Instrumentation inst)\n            throws ClassNotFoundException, UnmodifiableClassException,\n            InterruptedException {\n        for (Class clazz : inst.getAllLoadedClasses()) {\n            System.out.println(\"Loaded Class : \" + clazz.getName());\n        }\n        Printer.printTime();\n    }\n}\n\nclass Printer {\n\n    public static void printTime() {\n        System.out.println(\"now is \" + new Date());\n    }\n}\n```\n然后写一个启动类\n```java\nimport com.sun.tools.attach.VirtualMachine;\n\nimport java.lang.management.ManagementFactory;\nimport java.util.concurrent.TimeUnit;\n\npublic class AgentLoader {\n\n    public static void main(String[] args) throws Exception {\n        String name = ManagementFactory.getRuntimeMXBean().getName();\n        String pid = name.split(\"@\")[0];\n        System.out.println(pid);\n        VirtualMachine vm = VirtualMachine.attach(pid);\n        for (int i = 0; i < 100; i++) {\n//            vm.loadAgent(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            vm.loadAgentPath(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            System.out.println(\"Load Agent Over!!!\");\n            TimeUnit.SECONDS.sleep(10);\n        }\n    }\n}\n```\n打包后, 执行命令\n```java\njava -cp .;./* AgentLoader\n```\n","source":"_posts/jvm/instrument agentmain.md","raw":"category: JVM\ndate: 2015-11-24\ntitle: Instrumentation Agentmain\n---\n\n在 Java SE 5 中premain 所作的 Instrumentation 也仅限与 main 函数执行前，这样的方式存在一定的局限性。Java SE 6 针对这种状况做出了改进，开发者可以在 main 函数开始执行以后，再启动自己的 Instrumentation 程序。在 Java SE 6 的 Instrumentation 当中，有一个跟 premain“并驾齐驱”的“agentmain”方法，可以在 main 函数开始运行之后再运行。\n\n首先我们还是需要修改MANIFEST.MF文件, 在其中添加\n```java\nManifest-Version: 1.0\nAgent-Class: AgentMain\nCan-Redefine-Classes: true\n```\n\n然后我们写一个代理类\n```java\nimport javax.xml.transform.Transformer;\nimport java.lang.instrument.Instrumentation;\nimport java.lang.instrument.UnmodifiableClassException;\n\npublic class AgentMain {\n\n    public static void agentmain(String agentArgs, Instrumentation inst)\n            throws ClassNotFoundException, UnmodifiableClassException,\n            InterruptedException {\n        for (Class clazz : inst.getAllLoadedClasses()) {\n            System.out.println(\"Loaded Class : \" + clazz.getName());\n        }\n        Printer.printTime();\n    }\n}\n\nclass Printer {\n\n    public static void printTime() {\n        System.out.println(\"now is \" + new Date());\n    }\n}\n```\n然后写一个启动类\n```java\nimport com.sun.tools.attach.VirtualMachine;\n\nimport java.lang.management.ManagementFactory;\nimport java.util.concurrent.TimeUnit;\n\npublic class AgentLoader {\n\n    public static void main(String[] args) throws Exception {\n        String name = ManagementFactory.getRuntimeMXBean().getName();\n        String pid = name.split(\"@\")[0];\n        System.out.println(pid);\n        VirtualMachine vm = VirtualMachine.attach(pid);\n        for (int i = 0; i < 100; i++) {\n//            vm.loadAgent(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            vm.loadAgentPath(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            System.out.println(\"Load Agent Over!!!\");\n            TimeUnit.SECONDS.sleep(10);\n        }\n    }\n}\n```\n打包后, 执行命令\n```java\njava -cp .;./* AgentLoader\n```\n","slug":"jvm/instrument agentmain","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtg005tvjs6cd64tdem"},{"date":"2015-11-23T16:00:00.000Z","title":"Instrumentation Premain","_content":"使用 Instrumentation，开发者可以构建一个独立于应用程序的代理程序（Agent），用来监测和协助运行在 JVM 上的程序，甚至能够替换和修改某些类的定义。\n\nInstrumentation提供了这样的功能：\n* 获取某个对象的大小\n* 热加载class文件\n* 获取JVM信息\n\n> 要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.另外一般内存的使用会被填充为8字节的倍数.\n\n\n## Premain\npremain函数是JavaSE5中实现instrument的方式.\n\n使用premain我们要自定义MANIFEST.MF文件, 定义Premain-Class\n```java\nManifest-Version: 1.0\nPremain-Class: wang.ming15.instrument.core.Premain\n```\n然后我们在maven文件中输出该文件\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n            </configuration>\n        </plugin>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-jar-plugin</artifactId>\n            <configuration>\n                <archive>\n                    <manifestFile>\n                        src/main/resources/META-INF/MANIFEST.MF\n                    </manifestFile>\n                    <manifest>\n                        <addClasspath>true</addClasspath>\n                        <classpathPrefix>lib/</classpathPrefix>\n                        <mainClass>\n                        </mainClass>\n                    </manifest>\n                </archive>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n\n### 获取对象大小\n首先我们要写一个代理文件出来(该文件放在`core-1.0-SNAPSHOT.jar`中)\n```java\npublic class Premain {\n\n\tprivate static Instrumentation instrumentation;\n\n\tpublic static void premain(String agentArgs, Instrumentation inst) {\n\t\tinstrumentation = inst;\n\t};\n\n\tpublic static Instrumentation getInstrumentation() {\n\t\treturn instrumentation;\n\t}\n}\n```\n然后在自己的应用程序中引用该文件(在`examples-1.0-SNAPSHOT.jar`中)\n```java\npublic class PrintObjectSize {\n\n\tpublic static void main(String[] args) {\n\t\tSystem.out.println(\"Hello world, App\");\n\n\t\tobjectSize();\n\t}\n\n\tpublic static void objectSize() {\n\t\tInstrumentation inst = Premain.getInstrumentation();\n\t\tString str = \"123456789\";\n\t\tlong size = inst.getObjectSize(str);\n\t\tSystem.out.println(str + \" 对象大小: \" + size);\n\t}\n}\n```\n然后执行命令\n```java\njava -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.ming15.instrument.examples.PrintObjectSize\n```\n然后就会获得对象的大小\n```java\nHello world, App\n123456789 对象大小: 24\n```\n\n### 加载jar包\n我们在Premain类中增加一个动态向系统cp加载jar的功能\n```java\npublic static void appendJarToSystemClassLoader(String path) {\n\tJarFile jarFile = null;\n\ttry {\n\t\tjarFile = new JarFile(path);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\tinstrumentation.appendToSystemClassLoaderSearch(jarFile);\n\n}\n\npublic static void appendJarToBootstrapClassLoader(Instrumentation inst, String path) {\n\tJarFile jarFile = null;\n\ttry {\n\t\tjarFile = new JarFile(path);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\tinst.appendToBootstrapClassLoaderSearch(jarFile);\n\n}\n```\n然后我们写一个测试类\n```java\npublic class TestJarLoader {\n\n\tpublic static void main(String[] args) {\n\t\tfor (int i = 0; i < 120; i++) {\n\t\t\tPremain.appendJarToSystemClassLoader(args[0]);\n\t\t\tPrint.print();\n\n\t\t\tStream.of(Premain.getInstrumentation().getAllLoadedClasses())\n\t\t\t\t\t.filter(clazz -> clazz.getName().contains(\"Print\"))\n\t\t\t\t\t.forEach(aClass -> System.out.println(aClass.getName() + \"  \" + aClass.getMethods().length));\n\n\t\t\ttry {\n\t\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n}\n```\n然后执行命令\n```java\njava -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.ming15.instrument.examples.TestJarLoader D:/workspace/idea/instrument/trunk/print/target/print-1.0-SNAPSHOT.jar\n```\n结果输出为\n```java\nNow Time is Thu Dec 31 10:50:39 CST 2015\n\nwang.ming15.instrument.print.Print  11\njava.io.PrintStream  44\nNow Time is Thu Dec 31 10:50:44 CST 2015\n\nwang.ming15.instrument.print.Print  11\njava.io.PrintStream  44\n```\n\n### 热加载\n* `redefineClasses()`使用新的字节码全部替换原先存在的Class字节码. (它并不会触发初始化操作, 也不会抛出初始化时的异常. 因此一些静态属性并不会被重新赋值)\n* `retransformClasses()` 修改原先存在的Class字节码.\n\n> 对于已经在栈帧中的字节码, 他们会继续执行下去, 但是当方法再次调用的时候,则会使用刚刚加载完成的新的字节码. 在重新加载类的时候, 该类已经实例化出的对象同时也不会受到影响.\n\n该方法的操作过程是一个基于操作集合的, 也就是说在redefine的时候, 可能有A B俩个类都进行, 而且A依赖于B, 那么在redefine的时候这俩个操作是同时完成的, 类似于原子操作.\n\nredefine 操作可以改变修改如下字节码\n* 方法体\n* 常量池\n* 属性\n但是redefine过程不能产生如下影响\n* 对方法进行增加,删除,重命名的操作\n* 对属性进行增加,删除,重命名的操作\n* 不能修改方法签名以及修改继承关系.\n\n在redefine过程中,一旦抛出异常, 那么此过程执已经redefine成功的class也会被会滚成原来的.\n\n想使用这个功能我们需要在MANIFEST.MF文件中增加这样一行`Can-Redefine-Classes: true`, 然后我们在Premain中增加一个load方法, 用于重新加载某个文件夹下所有的文件\n```java\nimport org.apache.log4j.Logger;\n\nimport java.io.*;\nimport java.lang.instrument.ClassDefinition;\nimport java.lang.instrument.Instrumentation;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipFile;\nimport java.util.zip.ZipInputStream;\n\n/**\n * 实现服务器局部代码热加载功能\n *      目前只支持方法体代码热更以及对属性值的改变\n *      但是不能修改类的继承结构, 不能修改方法签名, 不能增加删除方法以及属性成员\n *\n *  使用方法\n *      java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* MainServerStart\n *      只需要将该项目打包出来然后参照上面的例子进行代理处理就好了, 然后正常启动游戏服就好\n *\n */\npublic class Premain {\n    private static final Logger logger = Logger.getLogger(Premain.class);\n\n    private static Instrumentation instrumentation;\n    public static void premain(String agentArgs, Instrumentation inst) {\n        instrumentation = inst;\n    }\n\n\tprivate static int classSize = 0;\n\n    /**\n     * 遍历某个目录加载所有的class文件\n     * @param directionPath\n     */\n    public static void loadFromDirection(String directionPath) {\n        loadFromDirection(new File(directionPath), \"\");\n    }\n\n    private static void loadFromDirection(File dir, String parantName) {\n        try {\n            for (File file : dir.listFiles()) {\n                if (file.isFile() && !file.getName().endsWith(\".class\")) {\n                    continue;\n                }\n                if (file.isDirectory()) {\n                    String fileName = file.getName();\n                    if (parantName != null && !parantName.equals(\"\")) {\n                        fileName = parantName + \".\" + fileName;\n                    }\n                    loadFromDirection(file, fileName);\n                    continue;\n                }\n                try(InputStream input = new FileInputStream(file);) {\n                    String fileName = file.getPath();\n                    String className = findClassName(fileName);\n                    if (parantName != null && !parantName.equals(\"\")) {\n                        className = parantName + \".\" + className;\n                    }\n                    redefineClassesFromBytes(input, className, null);\n                } catch (final Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        } catch (final Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 从jar包或者ZIP里加载所有的class文件\n     * @param jarPath\n     */\n    public static void loadFromZipFile(String jarPath, String prfixName) {\n\t\tClass[] allLoadClasses = instrumentation.getAllLoadedClasses();\n\t\tMap<String, Class> allLoadClassesMap = new HashMap<>(classSize);\n\t\tfor (Class loadedClass : allLoadClasses) {\n\t\t\tif (loadedClass.getName().startsWith(prfixName)) {\n\t\t\t\tallLoadClassesMap.put(loadedClass.getName(), loadedClass);\n\t\t\t}\n\t\t}\n\t\t// 加载的类我们不会主动去卸载它, 因此, 我们记录下来上次更新时的类的数量, 下次就根据这个数量直接分配, 避免动态扩容\n\t\tclassSize = allLoadClassesMap.size();\n\n\t\ttry(InputStream in = new BufferedInputStream(new FileInputStream(new File(jarPath)));\n            ZipInputStream zin = new ZipInputStream(in);) {\n            ZipEntry ze;\n            while ((ze = zin.getNextEntry()) != null) {\n                if (ze.isDirectory()) {\n                    // TODO 检查是否还有其他操作要做\n                } else {\n                    long size = ze.getSize();\n                    if (size > 0) {\n                        String fileName = ze.getName();\n                        if (!fileName.endsWith(\".class\")) {\n                            continue;\n                        }\n                        ZipFile zf = new ZipFile(jarPath);\n                        InputStream input = zf.getInputStream(ze);\n                        if (input == null) {\n                            logger.error(\"Code Reload cant find file : \" + fileName);\n                            continue;\n                        }\n                        redefineClassesFromBytes(input, fileName, allLoadClassesMap);\n                        input.close();\n                        zf.close();\n                    }\n                }\n            }\n        } catch (final Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static String findClassName(String fileName) {\n        int idx = fileName.lastIndexOf(\"\\\\\");\n        fileName = fileName.substring(idx + 1);\n        fileName = fileName.split(\"\\\\.class\")[0];\n        return fileName;\n    }\n\n    /* 使用instrumentation将读取的class byte数组加载进虚拟机\n     */\n    private static void redefineClassesFromBytes(InputStream input, String fileName, Map<String, Class> allLoadClassesMap) {\n        try {\n        \tString className = getClassName(fileName);\n            logger.info(\"Start Hot Reload Class : \" + fileName + \"  (\" + className + \")\");\n\t        byte[] bytes = new byte[input.available()];\n    \t    input.read(bytes);\n\t\t\tClass loadedClass = allLoadClassesMap.get(className);\n\t\t\tif (loadedClass != null) {\n\t\t\t\tinstrumentation.redefineClasses(new ClassDefinition(loadedClass, bytes));\n\t\t\t}\n        } catch (final Exception e) {\n            logger.error(\"Code Reload Failed : \" + fileName, e);\n        } catch (Error error) {\n\t\t\tlogger.error(\"Code Reload Failed : \" + fileName, error);\n\t\t}\n    }\n\n    private static String getClassName(String fileName) {\n        fileName = fileName.split(\"\\\\.class\")[0];\n        fileName = fileName.replace(\"\\\\\\\\\", \".\");\n        fileName = fileName.replace(\"/\", \".\");\n        return fileName;\n    }\n```\n然后我们写一个测试类\n```java\nimport java.util.concurrent.TimeUnit;\n\npublic class TestReload {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n        fromDirection();\n    }\n\n    public static void fromJar() throws InterruptedException{\n        for (int i = 0; i < 300; i++) {\n            Premain.loadFromJarFile(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            TestReload.printTime();\n            new TestReload().printNewTime();\n            TimeUnit.SECONDS.sleep(5);\n        }\n    }\n\n    public static void fromDirection() throws InterruptedException {\n        for (int i = 0; i < 300; i++) {\n            Premain.loadFromDirection(\"D:\\\\ming\\\\test\\\\target\\\\classes\");\n            TestReload.printTime();\n            new TestReload().printNewTime();\n            TimeUnit.SECONDS.sleep(5);\n        }\n    }\n\n    public static void printTime() {\n        System.out.println(2);\n    }\n\n    public void printNewTime() {\n        System.out.println(2);\n        System.out.println(id);\n    }\n\n    public int id = 2;\n}\n```\n我们不断地修改printTime()和printNewTime()以及Id的值, 最后成功输出\n```java\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n```\n\n> 在上面的实现中我分别实现了从目录和jar包对class文件进行热加载\n\n下面我们测试一下,如果增加了属性和方法成员, 看看有什么变化(下面只列出了TestReload.java的新增以及修改部分)\n```java\npublic class TestReload {\n\n\t...\n\n        public void printNewTime() {\n        System.out.println(id);\n        printName();\n    }\n\n    public int id = 2;\n\n    public String name = \"abc\";\n\n    public void printName() {\n        System.out.println(name);\n    }\n}\n```\n当我们再次重新加载的时候就会抛出异常\n```xml\nD:\\ming\\test\\target>java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* TestReload\n1\n1\n2\n2\n2\n2\njava.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields)\n\tat sun.instrument.InstrumentationImpl.redefineClasses0(Native Method)\n\tat sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source)\n\tat Premain.redefineClassesFromBytes(Premain.java:44)\n\tat Premain.loadFromDirection(Premain.java:24)\n\tat TestReload.fromDirection(TestReload.java:19)\n\tat TestReload.main(TestReload.java:6)\n2\njava.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields)\n\tat sun.instrument.InstrumentationImpl.redefineClasses0(Native Method)\n\tat sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source)\n\tat Premain.redefineClassesFromBytes(Premain.java:44)\n\tat Premain.loadFromDirection(Premain.java:24)\n\tat TestReload.fromDirection(TestReload.java:19)\n\tat TestReload.main(TestReload.java:6)\n2\n```\n","source":"_posts/jvm/instrument premain.md","raw":"category: JVM\ndate: 2015-11-24\ntitle: Instrumentation Premain\n---\n使用 Instrumentation，开发者可以构建一个独立于应用程序的代理程序（Agent），用来监测和协助运行在 JVM 上的程序，甚至能够替换和修改某些类的定义。\n\nInstrumentation提供了这样的功能：\n* 获取某个对象的大小\n* 热加载class文件\n* 获取JVM信息\n\n> 要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.另外一般内存的使用会被填充为8字节的倍数.\n\n\n## Premain\npremain函数是JavaSE5中实现instrument的方式.\n\n使用premain我们要自定义MANIFEST.MF文件, 定义Premain-Class\n```java\nManifest-Version: 1.0\nPremain-Class: wang.ming15.instrument.core.Premain\n```\n然后我们在maven文件中输出该文件\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n            </configuration>\n        </plugin>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-jar-plugin</artifactId>\n            <configuration>\n                <archive>\n                    <manifestFile>\n                        src/main/resources/META-INF/MANIFEST.MF\n                    </manifestFile>\n                    <manifest>\n                        <addClasspath>true</addClasspath>\n                        <classpathPrefix>lib/</classpathPrefix>\n                        <mainClass>\n                        </mainClass>\n                    </manifest>\n                </archive>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n\n### 获取对象大小\n首先我们要写一个代理文件出来(该文件放在`core-1.0-SNAPSHOT.jar`中)\n```java\npublic class Premain {\n\n\tprivate static Instrumentation instrumentation;\n\n\tpublic static void premain(String agentArgs, Instrumentation inst) {\n\t\tinstrumentation = inst;\n\t};\n\n\tpublic static Instrumentation getInstrumentation() {\n\t\treturn instrumentation;\n\t}\n}\n```\n然后在自己的应用程序中引用该文件(在`examples-1.0-SNAPSHOT.jar`中)\n```java\npublic class PrintObjectSize {\n\n\tpublic static void main(String[] args) {\n\t\tSystem.out.println(\"Hello world, App\");\n\n\t\tobjectSize();\n\t}\n\n\tpublic static void objectSize() {\n\t\tInstrumentation inst = Premain.getInstrumentation();\n\t\tString str = \"123456789\";\n\t\tlong size = inst.getObjectSize(str);\n\t\tSystem.out.println(str + \" 对象大小: \" + size);\n\t}\n}\n```\n然后执行命令\n```java\njava -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.ming15.instrument.examples.PrintObjectSize\n```\n然后就会获得对象的大小\n```java\nHello world, App\n123456789 对象大小: 24\n```\n\n### 加载jar包\n我们在Premain类中增加一个动态向系统cp加载jar的功能\n```java\npublic static void appendJarToSystemClassLoader(String path) {\n\tJarFile jarFile = null;\n\ttry {\n\t\tjarFile = new JarFile(path);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\tinstrumentation.appendToSystemClassLoaderSearch(jarFile);\n\n}\n\npublic static void appendJarToBootstrapClassLoader(Instrumentation inst, String path) {\n\tJarFile jarFile = null;\n\ttry {\n\t\tjarFile = new JarFile(path);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\tinst.appendToBootstrapClassLoaderSearch(jarFile);\n\n}\n```\n然后我们写一个测试类\n```java\npublic class TestJarLoader {\n\n\tpublic static void main(String[] args) {\n\t\tfor (int i = 0; i < 120; i++) {\n\t\t\tPremain.appendJarToSystemClassLoader(args[0]);\n\t\t\tPrint.print();\n\n\t\t\tStream.of(Premain.getInstrumentation().getAllLoadedClasses())\n\t\t\t\t\t.filter(clazz -> clazz.getName().contains(\"Print\"))\n\t\t\t\t\t.forEach(aClass -> System.out.println(aClass.getName() + \"  \" + aClass.getMethods().length));\n\n\t\t\ttry {\n\t\t\t\tTimeUnit.SECONDS.sleep(5);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n}\n```\n然后执行命令\n```java\njava -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.ming15.instrument.examples.TestJarLoader D:/workspace/idea/instrument/trunk/print/target/print-1.0-SNAPSHOT.jar\n```\n结果输出为\n```java\nNow Time is Thu Dec 31 10:50:39 CST 2015\n\nwang.ming15.instrument.print.Print  11\njava.io.PrintStream  44\nNow Time is Thu Dec 31 10:50:44 CST 2015\n\nwang.ming15.instrument.print.Print  11\njava.io.PrintStream  44\n```\n\n### 热加载\n* `redefineClasses()`使用新的字节码全部替换原先存在的Class字节码. (它并不会触发初始化操作, 也不会抛出初始化时的异常. 因此一些静态属性并不会被重新赋值)\n* `retransformClasses()` 修改原先存在的Class字节码.\n\n> 对于已经在栈帧中的字节码, 他们会继续执行下去, 但是当方法再次调用的时候,则会使用刚刚加载完成的新的字节码. 在重新加载类的时候, 该类已经实例化出的对象同时也不会受到影响.\n\n该方法的操作过程是一个基于操作集合的, 也就是说在redefine的时候, 可能有A B俩个类都进行, 而且A依赖于B, 那么在redefine的时候这俩个操作是同时完成的, 类似于原子操作.\n\nredefine 操作可以改变修改如下字节码\n* 方法体\n* 常量池\n* 属性\n但是redefine过程不能产生如下影响\n* 对方法进行增加,删除,重命名的操作\n* 对属性进行增加,删除,重命名的操作\n* 不能修改方法签名以及修改继承关系.\n\n在redefine过程中,一旦抛出异常, 那么此过程执已经redefine成功的class也会被会滚成原来的.\n\n想使用这个功能我们需要在MANIFEST.MF文件中增加这样一行`Can-Redefine-Classes: true`, 然后我们在Premain中增加一个load方法, 用于重新加载某个文件夹下所有的文件\n```java\nimport org.apache.log4j.Logger;\n\nimport java.io.*;\nimport java.lang.instrument.ClassDefinition;\nimport java.lang.instrument.Instrumentation;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipFile;\nimport java.util.zip.ZipInputStream;\n\n/**\n * 实现服务器局部代码热加载功能\n *      目前只支持方法体代码热更以及对属性值的改变\n *      但是不能修改类的继承结构, 不能修改方法签名, 不能增加删除方法以及属性成员\n *\n *  使用方法\n *      java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* MainServerStart\n *      只需要将该项目打包出来然后参照上面的例子进行代理处理就好了, 然后正常启动游戏服就好\n *\n */\npublic class Premain {\n    private static final Logger logger = Logger.getLogger(Premain.class);\n\n    private static Instrumentation instrumentation;\n    public static void premain(String agentArgs, Instrumentation inst) {\n        instrumentation = inst;\n    }\n\n\tprivate static int classSize = 0;\n\n    /**\n     * 遍历某个目录加载所有的class文件\n     * @param directionPath\n     */\n    public static void loadFromDirection(String directionPath) {\n        loadFromDirection(new File(directionPath), \"\");\n    }\n\n    private static void loadFromDirection(File dir, String parantName) {\n        try {\n            for (File file : dir.listFiles()) {\n                if (file.isFile() && !file.getName().endsWith(\".class\")) {\n                    continue;\n                }\n                if (file.isDirectory()) {\n                    String fileName = file.getName();\n                    if (parantName != null && !parantName.equals(\"\")) {\n                        fileName = parantName + \".\" + fileName;\n                    }\n                    loadFromDirection(file, fileName);\n                    continue;\n                }\n                try(InputStream input = new FileInputStream(file);) {\n                    String fileName = file.getPath();\n                    String className = findClassName(fileName);\n                    if (parantName != null && !parantName.equals(\"\")) {\n                        className = parantName + \".\" + className;\n                    }\n                    redefineClassesFromBytes(input, className, null);\n                } catch (final Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        } catch (final Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 从jar包或者ZIP里加载所有的class文件\n     * @param jarPath\n     */\n    public static void loadFromZipFile(String jarPath, String prfixName) {\n\t\tClass[] allLoadClasses = instrumentation.getAllLoadedClasses();\n\t\tMap<String, Class> allLoadClassesMap = new HashMap<>(classSize);\n\t\tfor (Class loadedClass : allLoadClasses) {\n\t\t\tif (loadedClass.getName().startsWith(prfixName)) {\n\t\t\t\tallLoadClassesMap.put(loadedClass.getName(), loadedClass);\n\t\t\t}\n\t\t}\n\t\t// 加载的类我们不会主动去卸载它, 因此, 我们记录下来上次更新时的类的数量, 下次就根据这个数量直接分配, 避免动态扩容\n\t\tclassSize = allLoadClassesMap.size();\n\n\t\ttry(InputStream in = new BufferedInputStream(new FileInputStream(new File(jarPath)));\n            ZipInputStream zin = new ZipInputStream(in);) {\n            ZipEntry ze;\n            while ((ze = zin.getNextEntry()) != null) {\n                if (ze.isDirectory()) {\n                    // TODO 检查是否还有其他操作要做\n                } else {\n                    long size = ze.getSize();\n                    if (size > 0) {\n                        String fileName = ze.getName();\n                        if (!fileName.endsWith(\".class\")) {\n                            continue;\n                        }\n                        ZipFile zf = new ZipFile(jarPath);\n                        InputStream input = zf.getInputStream(ze);\n                        if (input == null) {\n                            logger.error(\"Code Reload cant find file : \" + fileName);\n                            continue;\n                        }\n                        redefineClassesFromBytes(input, fileName, allLoadClassesMap);\n                        input.close();\n                        zf.close();\n                    }\n                }\n            }\n        } catch (final Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static String findClassName(String fileName) {\n        int idx = fileName.lastIndexOf(\"\\\\\");\n        fileName = fileName.substring(idx + 1);\n        fileName = fileName.split(\"\\\\.class\")[0];\n        return fileName;\n    }\n\n    /* 使用instrumentation将读取的class byte数组加载进虚拟机\n     */\n    private static void redefineClassesFromBytes(InputStream input, String fileName, Map<String, Class> allLoadClassesMap) {\n        try {\n        \tString className = getClassName(fileName);\n            logger.info(\"Start Hot Reload Class : \" + fileName + \"  (\" + className + \")\");\n\t        byte[] bytes = new byte[input.available()];\n    \t    input.read(bytes);\n\t\t\tClass loadedClass = allLoadClassesMap.get(className);\n\t\t\tif (loadedClass != null) {\n\t\t\t\tinstrumentation.redefineClasses(new ClassDefinition(loadedClass, bytes));\n\t\t\t}\n        } catch (final Exception e) {\n            logger.error(\"Code Reload Failed : \" + fileName, e);\n        } catch (Error error) {\n\t\t\tlogger.error(\"Code Reload Failed : \" + fileName, error);\n\t\t}\n    }\n\n    private static String getClassName(String fileName) {\n        fileName = fileName.split(\"\\\\.class\")[0];\n        fileName = fileName.replace(\"\\\\\\\\\", \".\");\n        fileName = fileName.replace(\"/\", \".\");\n        return fileName;\n    }\n```\n然后我们写一个测试类\n```java\nimport java.util.concurrent.TimeUnit;\n\npublic class TestReload {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n        fromDirection();\n    }\n\n    public static void fromJar() throws InterruptedException{\n        for (int i = 0; i < 300; i++) {\n            Premain.loadFromJarFile(\"D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar\");\n            TestReload.printTime();\n            new TestReload().printNewTime();\n            TimeUnit.SECONDS.sleep(5);\n        }\n    }\n\n    public static void fromDirection() throws InterruptedException {\n        for (int i = 0; i < 300; i++) {\n            Premain.loadFromDirection(\"D:\\\\ming\\\\test\\\\target\\\\classes\");\n            TestReload.printTime();\n            new TestReload().printNewTime();\n            TimeUnit.SECONDS.sleep(5);\n        }\n    }\n\n    public static void printTime() {\n        System.out.println(2);\n    }\n\n    public void printNewTime() {\n        System.out.println(2);\n        System.out.println(id);\n    }\n\n    public int id = 2;\n}\n```\n我们不断地修改printTime()和printNewTime()以及Id的值, 最后成功输出\n```java\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n```\n\n> 在上面的实现中我分别实现了从目录和jar包对class文件进行热加载\n\n下面我们测试一下,如果增加了属性和方法成员, 看看有什么变化(下面只列出了TestReload.java的新增以及修改部分)\n```java\npublic class TestReload {\n\n\t...\n\n        public void printNewTime() {\n        System.out.println(id);\n        printName();\n    }\n\n    public int id = 2;\n\n    public String name = \"abc\";\n\n    public void printName() {\n        System.out.println(name);\n    }\n}\n```\n当我们再次重新加载的时候就会抛出异常\n```xml\nD:\\ming\\test\\target>java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* TestReload\n1\n1\n2\n2\n2\n2\njava.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields)\n\tat sun.instrument.InstrumentationImpl.redefineClasses0(Native Method)\n\tat sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source)\n\tat Premain.redefineClassesFromBytes(Premain.java:44)\n\tat Premain.loadFromDirection(Premain.java:24)\n\tat TestReload.fromDirection(TestReload.java:19)\n\tat TestReload.main(TestReload.java:6)\n2\njava.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields)\n\tat sun.instrument.InstrumentationImpl.redefineClasses0(Native Method)\n\tat sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source)\n\tat Premain.redefineClassesFromBytes(Premain.java:44)\n\tat Premain.loadFromDirection(Premain.java:24)\n\tat TestReload.fromDirection(TestReload.java:19)\n\tat TestReload.main(TestReload.java:6)\n2\n```\n","slug":"jvm/instrument premain","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtl005vvjs6uq2b0tkc"},{"date":"2014-10-09T16:00:00.000Z","title":"javap","_content":"javap是JDK自带的反汇编器，可以查看java编译器为我们生成的字节码\n```bash\nD:\\>javap\n用法: javap <options> <classes>\n其中, 可能的选项包括:\n  -version                 版本信息\n  -v  -verbose             输出附加信息\n  -l                       输出行号和本地变量表\n  -public                  仅显示公共类和成员\n  -protected               显示受保护的/公共类和成员\n  -package                 显示程序包/受保护的/公共类和成员 (默认)\n  -p  -private             显示所有类和成员\n  -c                       对代码进行反汇编\n  -s                       输出内部类型签名\n  -sysinfo                 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列)\n  -constants               显示最终常量\n  -classpath <path>        指定查找用户类文件的位置\n  -cp <path>               指定查找用户类文件的位置\n  -bootclasspath <path>    覆盖引导类文件的位置\n```","source":"_posts/jvm/javap.md","raw":"category: JVM\ndate: 2014-10-10\ntitle: javap\n---\njavap是JDK自带的反汇编器，可以查看java编译器为我们生成的字节码\n```bash\nD:\\>javap\n用法: javap <options> <classes>\n其中, 可能的选项包括:\n  -version                 版本信息\n  -v  -verbose             输出附加信息\n  -l                       输出行号和本地变量表\n  -public                  仅显示公共类和成员\n  -protected               显示受保护的/公共类和成员\n  -package                 显示程序包/受保护的/公共类和成员 (默认)\n  -p  -private             显示所有类和成员\n  -c                       对代码进行反汇编\n  -s                       输出内部类型签名\n  -sysinfo                 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列)\n  -constants               显示最终常量\n  -classpath <path>        指定查找用户类文件的位置\n  -cp <path>               指定查找用户类文件的位置\n  -bootclasspath <path>    覆盖引导类文件的位置\n```","slug":"jvm/javap","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtn005xvjs6armah9vr"},{"date":"2014-10-03T16:00:00.000Z","title":"jcmd","_content":"jcmd是在JDK7 中新添加的一款工具(内嵌了对jps, jmap等功能支持, 而且Oracle官网也推荐使用jcmd替代jmap)\n```bash\n➜  test jcmd 2028 help\n2028:\nThe following commands are available:\nJFR.stop\nJFR.start\nJFR.dump\nJFR.check\nVM.native_memory\nVM.check_commercial_features\nVM.unlock_commercial_features\nManagementAgent.stop\nManagementAgent.start_local\nManagementAgent.start\nThread.print\nGC.class_stats\nGC.class_histogram\nGC.heap_dump\nGC.run_finalization\nGC.run\nVM.uptime\nVM.flags\nVM.system_properties\nVM.command_line\nVM.version\nhelp\n```\n上面罗列了对2028号进程所支持的所有的jcmd操作.\n\n下面我们看一下2028进程的线程信息\n```bash\n➜  test jcmd 2028 Thread.print\n2028:\n2016-05-29 18:35:12\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.5-b02 mixed mode):\n\n\"DestroyJavaVM\" #22 prio=5 os_prio=31 tid=0x00007febd3cfe800 nid=0xf03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"http-nio-8080-Acceptor-0\" #20 daemon prio=5 os_prio=31 tid=0x00007febd3354000 nid=0x5d03 runnable [0x000000012a739000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)\n\tat sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241)\n\t- locked <0x0000000760b89690> (a java.lang.Object)\n\tat org.apache.tomcat.util.net.NioEndpoint$Acceptor.run(NioEndpoint.java:682)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"http-nio-8080-ClientPoller-1\" #19 daemon prio=5 os_prio=31 tid=0x00007febd3353800 nid=0x5b03 runnable [0x000000012a1b4000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b89bb0> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b89bc0> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b89b60> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1034)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"http-nio-8080-ClientPoller-0\" #18 daemon prio=5 os_prio=31 tid=0x00007febd33f2800 nid=0x5903 runnable [0x0000000129e7e000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b8a298> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b8a2a8> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b8a248> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1034)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"NioBlockingSelector.BlockPoller-1\" #17 daemon prio=5 os_prio=31 tid=0x00007febd585d000 nid=0x5703 runnable [0x0000000128733000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b8a948> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b8a958> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b8a8f8> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioBlockingSelector$BlockPoller.run(NioBlockingSelector.java:342)\n\n\"container-0\" #16 prio=5 os_prio=31 tid=0x00007febd34ac000 nid=0x5503 waiting on condition [0x0000000129d7b000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.catalina.core.StandardServer.await(StandardServer.java:425)\n\tat org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer$1.run(TomcatEmbeddedServletContainer.java:140)\n\n\"ContainerBackgroundProcessor[StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]]\" #15 daemon prio=5 os_prio=31 tid=0x00007febd34b3000 nid=0x5303 waiting on condition [0x000000012815f000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1344)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"Attach Listener\" #12 daemon prio=9 os_prio=31 tid=0x00007febd4a6e800 nid=0x4f03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Monitor Ctrl-Break\" #9 daemon prio=5 os_prio=31 tid=0x00007febd48a2000 nid=0x4b03 runnable [0x0000000127e69000]\n   java.lang.Thread.State: RUNNABLE\n\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\n\tat com.intellij.rt.execution.application.AppMain$1.run(AppMain.java:90)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"Service Thread\" #8 daemon prio=9 os_prio=31 tid=0x00007febd303a800 nid=0x4703 runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C1 CompilerThread2\" #7 daemon prio=9 os_prio=31 tid=0x00007febd303a000 nid=0x4503 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread1\" #6 daemon prio=9 os_prio=31 tid=0x00007febd4810000 nid=0x4303 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread0\" #5 daemon prio=9 os_prio=31 tid=0x00007febd3021000 nid=0x4103 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Signal Dispatcher\" #4 daemon prio=9 os_prio=31 tid=0x00007febd3020800 nid=0x3c0f runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Finalizer\" #3 daemon prio=8 os_prio=31 tid=0x00007febd3009800 nid=0x2f03 in Object.wait() [0x0000000125c53000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:142)\n\t- locked <0x000000076005b248> (a java.lang.ref.ReferenceQueue$Lock)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:158)\n\tat java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)\n\n\"Reference Handler\" #2 daemon prio=10 os_prio=31 tid=0x00007febd4033800 nid=0x2d03 in Object.wait() [0x0000000125b50000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Object.wait(Object.java:502)\n\tat java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157)\n\t- locked <0x0000000760057ca0> (a java.lang.ref.Reference$Lock)\n\n\"VM Thread\" os_prio=31 tid=0x00007febd382e800 nid=0x2b03 runnable\n\n\"GC task thread#0 (ParallelGC)\" os_prio=31 tid=0x00007febd4012800 nid=0x2203 runnable\n\n\"GC task thread#1 (ParallelGC)\" os_prio=31 tid=0x00007febd3806800 nid=0x2403 runnable\n\n\"GC task thread#2 (ParallelGC)\" os_prio=31 tid=0x00007febd3807000 nid=0x2603 runnable\n\n\"GC task thread#3 (ParallelGC)\" os_prio=31 tid=0x00007febd3808000 nid=0x2803 runnable\n\n\"VM Periodic Task Thread\" os_prio=31 tid=0x00007febd4813000 nid=0x4903 waiting on condition\n\nJNI global references: 238\n\n➜  test\n```\n","source":"_posts/jvm/jcmd.md","raw":"category: JVM\ndate: 2014-10-04\ntitle: jcmd\n---\njcmd是在JDK7 中新添加的一款工具(内嵌了对jps, jmap等功能支持, 而且Oracle官网也推荐使用jcmd替代jmap)\n```bash\n➜  test jcmd 2028 help\n2028:\nThe following commands are available:\nJFR.stop\nJFR.start\nJFR.dump\nJFR.check\nVM.native_memory\nVM.check_commercial_features\nVM.unlock_commercial_features\nManagementAgent.stop\nManagementAgent.start_local\nManagementAgent.start\nThread.print\nGC.class_stats\nGC.class_histogram\nGC.heap_dump\nGC.run_finalization\nGC.run\nVM.uptime\nVM.flags\nVM.system_properties\nVM.command_line\nVM.version\nhelp\n```\n上面罗列了对2028号进程所支持的所有的jcmd操作.\n\n下面我们看一下2028进程的线程信息\n```bash\n➜  test jcmd 2028 Thread.print\n2028:\n2016-05-29 18:35:12\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.5-b02 mixed mode):\n\n\"DestroyJavaVM\" #22 prio=5 os_prio=31 tid=0x00007febd3cfe800 nid=0xf03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"http-nio-8080-Acceptor-0\" #20 daemon prio=5 os_prio=31 tid=0x00007febd3354000 nid=0x5d03 runnable [0x000000012a739000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)\n\tat sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241)\n\t- locked <0x0000000760b89690> (a java.lang.Object)\n\tat org.apache.tomcat.util.net.NioEndpoint$Acceptor.run(NioEndpoint.java:682)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"http-nio-8080-ClientPoller-1\" #19 daemon prio=5 os_prio=31 tid=0x00007febd3353800 nid=0x5b03 runnable [0x000000012a1b4000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b89bb0> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b89bc0> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b89b60> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1034)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"http-nio-8080-ClientPoller-0\" #18 daemon prio=5 os_prio=31 tid=0x00007febd33f2800 nid=0x5903 runnable [0x0000000129e7e000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b8a298> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b8a2a8> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b8a248> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1034)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"NioBlockingSelector.BlockPoller-1\" #17 daemon prio=5 os_prio=31 tid=0x00007febd585d000 nid=0x5703 runnable [0x0000000128733000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\n\tat sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:202)\n\tat sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x0000000760b8a948> (a sun.nio.ch.Util$2)\n\t- locked <0x0000000760b8a958> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x0000000760b8a8f8> (a sun.nio.ch.KQueueSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat org.apache.tomcat.util.net.NioBlockingSelector$BlockPoller.run(NioBlockingSelector.java:342)\n\n\"container-0\" #16 prio=5 os_prio=31 tid=0x00007febd34ac000 nid=0x5503 waiting on condition [0x0000000129d7b000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.catalina.core.StandardServer.await(StandardServer.java:425)\n\tat org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer$1.run(TomcatEmbeddedServletContainer.java:140)\n\n\"ContainerBackgroundProcessor[StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]]\" #15 daemon prio=5 os_prio=31 tid=0x00007febd34b3000 nid=0x5303 waiting on condition [0x000000012815f000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1344)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"Attach Listener\" #12 daemon prio=9 os_prio=31 tid=0x00007febd4a6e800 nid=0x4f03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Monitor Ctrl-Break\" #9 daemon prio=5 os_prio=31 tid=0x00007febd48a2000 nid=0x4b03 runnable [0x0000000127e69000]\n   java.lang.Thread.State: RUNNABLE\n\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\n\tat com.intellij.rt.execution.application.AppMain$1.run(AppMain.java:90)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"Service Thread\" #8 daemon prio=9 os_prio=31 tid=0x00007febd303a800 nid=0x4703 runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C1 CompilerThread2\" #7 daemon prio=9 os_prio=31 tid=0x00007febd303a000 nid=0x4503 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread1\" #6 daemon prio=9 os_prio=31 tid=0x00007febd4810000 nid=0x4303 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread0\" #5 daemon prio=9 os_prio=31 tid=0x00007febd3021000 nid=0x4103 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Signal Dispatcher\" #4 daemon prio=9 os_prio=31 tid=0x00007febd3020800 nid=0x3c0f runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Finalizer\" #3 daemon prio=8 os_prio=31 tid=0x00007febd3009800 nid=0x2f03 in Object.wait() [0x0000000125c53000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:142)\n\t- locked <0x000000076005b248> (a java.lang.ref.ReferenceQueue$Lock)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:158)\n\tat java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)\n\n\"Reference Handler\" #2 daemon prio=10 os_prio=31 tid=0x00007febd4033800 nid=0x2d03 in Object.wait() [0x0000000125b50000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Object.wait(Object.java:502)\n\tat java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157)\n\t- locked <0x0000000760057ca0> (a java.lang.ref.Reference$Lock)\n\n\"VM Thread\" os_prio=31 tid=0x00007febd382e800 nid=0x2b03 runnable\n\n\"GC task thread#0 (ParallelGC)\" os_prio=31 tid=0x00007febd4012800 nid=0x2203 runnable\n\n\"GC task thread#1 (ParallelGC)\" os_prio=31 tid=0x00007febd3806800 nid=0x2403 runnable\n\n\"GC task thread#2 (ParallelGC)\" os_prio=31 tid=0x00007febd3807000 nid=0x2603 runnable\n\n\"GC task thread#3 (ParallelGC)\" os_prio=31 tid=0x00007febd3808000 nid=0x2803 runnable\n\n\"VM Periodic Task Thread\" os_prio=31 tid=0x00007febd4813000 nid=0x4903 waiting on condition\n\nJNI global references: 238\n\n➜  test\n```\n","slug":"jvm/jcmd","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtq005zvjs61gpb9yww"},{"date":"2014-10-05T16:00:00.000Z","title":"jhat","_content":"jhat是一款jdk自带的堆快照分析工具\n```bash\n➜  test jhat 2028dump\nReading from 2028dump...\nDump file created Sun May 29 18:10:00 CST 2016\nSnapshot read, resolving...\nResolving 205627 objects...\nChasing references, expect 41 dots.........................................\nEliminating duplicate references.........................................\nSnapshot resolved.\nStarted HTTP server on port 7000\nServer is ready.\n```\n我们在浏览器里直接浏览\n```bash\nhttp://localhost:7000\n```\n打开之后我们会看到满满的JDK对我们爱的死去活来了(lol), 在最下面JDK还为我们提供了OQL查询的支持\n","source":"_posts/jvm/jhat.md","raw":"category: JVM\ndate: 2014-10-06\ntitle: jhat\n---\njhat是一款jdk自带的堆快照分析工具\n```bash\n➜  test jhat 2028dump\nReading from 2028dump...\nDump file created Sun May 29 18:10:00 CST 2016\nSnapshot read, resolving...\nResolving 205627 objects...\nChasing references, expect 41 dots.........................................\nEliminating duplicate references.........................................\nSnapshot resolved.\nStarted HTTP server on port 7000\nServer is ready.\n```\n我们在浏览器里直接浏览\n```bash\nhttp://localhost:7000\n```\n打开之后我们会看到满满的JDK对我们爱的死去活来了(lol), 在最下面JDK还为我们提供了OQL查询的支持\n","slug":"jvm/jhat","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtu0061vjs6xta51ri5"},{"date":"2014-10-04T16:00:00.000Z","title":"jstack","_content":"java堆栈跟踪工具. `jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\njstack命令格式\n```java\njstack [ option ] vmid\n```\noption值：\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n当对线程堆栈分析时，首先查找`BLOCKED`, 找到锁住的线程。\n\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```java\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n第一行数据分析\n```java\nnioEventLoopGroup-2461-1 表示的是进程名字\n#4955\nprio=10\nos_prio=0\nnid: 线程ID的16进制表示(可以通过`top -H`查看pid)\ntid:\nrunnable\n[0x00007fd7374bc000]`\n```\n\n线程堆栈信息\n```java\njava.lang.Thread.State 线程状态\nlocked` 锁住的资源,分别锁住了  <0x00000000e673cf38>, <0x00000000e673cd30>, <0x00000000e673cc58>\n```\n\njava.lang.Thread.State 线程状态\n* `Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.\n> 此时线程状态一般都是 `Blocked`:如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n> 如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.  此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\n> 每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列. 此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`;\n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n","source":"_posts/jvm/jstack.md","raw":"category: JVM\ndate: 2014-10-05\ntitle: jstack\n---\njava堆栈跟踪工具. `jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\njstack命令格式\n```java\njstack [ option ] vmid\n```\noption值：\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n当对线程堆栈分析时，首先查找`BLOCKED`, 找到锁住的线程。\n\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```java\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n第一行数据分析\n```java\nnioEventLoopGroup-2461-1 表示的是进程名字\n#4955\nprio=10\nos_prio=0\nnid: 线程ID的16进制表示(可以通过`top -H`查看pid)\ntid:\nrunnable\n[0x00007fd7374bc000]`\n```\n\n线程堆栈信息\n```java\njava.lang.Thread.State 线程状态\nlocked` 锁住的资源,分别锁住了  <0x00000000e673cf38>, <0x00000000e673cd30>, <0x00000000e673cc58>\n```\n\njava.lang.Thread.State 线程状态\n* `Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.\n> 此时线程状态一般都是 `Blocked`:如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n> 如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.  此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\n> 每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列. 此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`;\n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n","slug":"jvm/jstack","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihtx0063vjs6um0itsua"},{"date":"2014-10-02T16:00:00.000Z","title":"jstat","_content":"虚拟机统计信息监视工具\n\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,垃圾收集,JIT编译等运行数据.\n\njstat命令格式\n```java\njstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程虚拟机进程,那么VMID的格式应该是:\n```java\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n\noption参数代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况, 可选值有:\n* `-class`: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* `-gc`: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* `-gccapacity`: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* `-gcutil`: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* `-gccause`: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* `-gcnew`:监视新生代GC的状况.\n* `-gcnewcapacity`: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* `-gcold`: 监视老年代GC的状况.\n* `-gcoldcapacity`: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* `-gcpermcapacity`: 输出永久代使用到呃最大和最小空间\n* `-compiler`: 输出JIT编译器编译过的方法,耗时等信息\n* `-printcompilation`: 输出已经被JIT编译的方法.\n\n其他参数\n* `-t`: 在输出信息前添加一个时间, 表示程序运行的时间\n* `-h`: 表示输出多少行后,输出一个表头信息\n* `interval`: 统计数据的周期, 单位是毫秒\n* `count`: 统计的次数\n\n我们才有Spring Boot Web开启一个Http服务\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\n@EnableAutoConfiguration\npublic class HTTPServer {\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    String home() {\n        return \"Hello World!\";\n    }\n\n    public static void main(String[] args) throws Exception {\n        SpringApplication.run(HTTPServer.class, args);\n    }\n}\n```\n然后使用jstat看一下这个进程的运行\n```bash\n➜  test jstat -gc  -t  2028 5000 5\nTimestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n          200.8 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          205.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          210.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          215.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          220.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n```\n* `Timestamp` 程序运行的时间\n* `S0C` survive0的大小(单位KB)\n* `S1C` survive1的大小(单位KB)\n* `S0U` survive0使用的大小(单位KB)\n* `S1U` survive1使用的大小(单位KB)\n* `EC` eden区大小(单位KB)\n* `EU` eden区使用的大小(单位KB)\n* `OC` 老年代大小(单位KB)\n* `OU` 老年代使用的大小(单位KB)\n* `MC` 元数据区大小(单位KB)\n* `MU` 元数据区使用大小(单位KB)\n* `CCSC`\n* `CCSU`\n* `YGC` 新生代GC次数\n* `YGCT` 新生代GC耗时\n* `FGC` FullGC次数\n* `FGCT` FullGC耗时\n* `GCT` GC总耗时\n","source":"_posts/jvm/jstat.md","raw":"category: JVM\ndate: 2014-10-03\ntitle: jstat\n---\n虚拟机统计信息监视工具\n\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,垃圾收集,JIT编译等运行数据.\n\njstat命令格式\n```java\njstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程虚拟机进程,那么VMID的格式应该是:\n```java\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n\noption参数代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况, 可选值有:\n* `-class`: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* `-gc`: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* `-gccapacity`: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* `-gcutil`: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* `-gccause`: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* `-gcnew`:监视新生代GC的状况.\n* `-gcnewcapacity`: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* `-gcold`: 监视老年代GC的状况.\n* `-gcoldcapacity`: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* `-gcpermcapacity`: 输出永久代使用到呃最大和最小空间\n* `-compiler`: 输出JIT编译器编译过的方法,耗时等信息\n* `-printcompilation`: 输出已经被JIT编译的方法.\n\n其他参数\n* `-t`: 在输出信息前添加一个时间, 表示程序运行的时间\n* `-h`: 表示输出多少行后,输出一个表头信息\n* `interval`: 统计数据的周期, 单位是毫秒\n* `count`: 统计的次数\n\n我们才有Spring Boot Web开启一个Http服务\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\n@EnableAutoConfiguration\npublic class HTTPServer {\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    String home() {\n        return \"Hello World!\";\n    }\n\n    public static void main(String[] args) throws Exception {\n        SpringApplication.run(HTTPServer.class, args);\n    }\n}\n```\n然后使用jstat看一下这个进程的运行\n```bash\n➜  test jstat -gc  -t  2028 5000 5\nTimestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n          200.8 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          205.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          210.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          215.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n          220.9 4608.0 4096.0  0.0   3152.8 39936.0   8518.2   17920.0    13639.7   27520.0 27031.4 3456.0 3372.0     23    0.078   2      0.149    0.227\n```\n* `Timestamp` 程序运行的时间\n* `S0C` survive0的大小(单位KB)\n* `S1C` survive1的大小(单位KB)\n* `S0U` survive0使用的大小(单位KB)\n* `S1U` survive1使用的大小(单位KB)\n* `EC` eden区大小(单位KB)\n* `EU` eden区使用的大小(单位KB)\n* `OC` 老年代大小(单位KB)\n* `OU` 老年代使用的大小(单位KB)\n* `MC` 元数据区大小(单位KB)\n* `MU` 元数据区使用大小(单位KB)\n* `CCSC`\n* `CCSU`\n* `YGC` 新生代GC次数\n* `YGCT` 新生代GC耗时\n* `FGC` FullGC次数\n* `FGCT` FullGC耗时\n* `GCT` GC总耗时\n","slug":"jvm/jstat","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihu10065vjs6f0dw7dy6"},{"date":"2016-01-28T16:00:00.000Z","title":"使用Classloader加载类","_content":"\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n> 判断俩个类相等可以通过下面方法: `Class`对象的`equals()`方法, `isAssignbleFrom()`方法, `isInstance()`方法的返回结果, 也包括使用`instanceof`关键字做对象所属关系判断等. 不同的类加载器对`instanceof`关键字运算结果的影响\n\n\n## 双亲委派模型\n\n![ClassLoader的体系架构](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/ClassLoader%E7%9A%84%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png)\n从JVM来角度讲, 只存在俩种不同的类加载器:\n* 启动类加载器: 使用C++语言实践,是虚拟机自身的一部分. \n* 其他类加载器: 这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n系统提供的类加载器\n* 启动类加载器 : 这个类加载器负责将`<JAVA_HOME>\\lib`目录中的,或者`-Xbootclasspath`参数所指定的路径中的,并且是虚拟机识别的(仅按照文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法被java程序直接使用.\n* 扩展类加载器 : 这个类加载器由`sun.misc.Launcher$ExtClassLoader`实现,负责加载`<JAVA_HOME>\\lib\\ext`目录中的,或者被`java.ext.dirs`系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n* 应用程序加载器 : 这个类加载器由`sun.misc.Launcher$AppClassLoader`来实现. 由于类加载器是`ClassLoader`中`getSystemClassLoader()`方法的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n\n类加载器收到类加载请求,它不会自己去尝试加载这个类,而把这个请求委派给父类加载器去完成,每一个层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n```java\n protected Class<?> loadClass(String name, boolean resolve)\n        throws ClassNotFoundException\n    {\n        synchronized (getClassLoadingLock(name)) {\n            // 第一步检查被加载的类是否已经被加载进入了虚拟机\n            Class<?> c = findLoadedClass(name);\n            if (c == null) {\n\t\t\t\t// 如果没有被加载进虚拟机中则进行加载\n                long t0 = System.nanoTime();\n                try {\n\t\t\t\t\t// 优先从父类加载器中进行加载, 所有的类加请求最终都应该传送到顶层的启动类加载器中\n                    if (parent != null) {\n                        c = parent.loadClass(name, false);\n                    } else {\n\t\t\t\t\t// \n                        c = findBootstrapClassOrNull(name);\n                    }\n                } catch (ClassNotFoundException e) {\n                    // ClassNotFoundException thrown if class not found\n                    // from the non-null parent class loader\n                }\n\t\t\t\t\n                if (c == null) {\n                    // 父类加载器找不到则调用自己的findClass(name)找到类然后进行加载\n                    long t1 = System.nanoTime();\n                    c = findClass(name);\n\n                    // this is the defining class loader; record the stats\n                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);\n                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);\n                    sun.misc.PerfCounter.getFindClasses().increment();\n                }\n            }\n            if (resolve) {\n                resolveClass(c);\n            }\n            return c;\n        }\n    }\n```\n\n> 使用双亲委派模型来组织类加载之间的关系, 可以确保我们自己JVM的安全. 因为当我们自己写一个 `java.lang.Object`, 这个类虽然能够被正常编译, 但是它永远不会被加载器虚拟机中, 因为这个类会在启动类加载器中完成了加载.\n\n在刚才的`loadClass()`方法中我们看到最终我们自己实现类加载的逻辑是在`findClass()`中进行的, 这是为了向前兼容,JDK1.2之后添加的方法.JDK1.2之后已不提倡用户再去覆盖`loadClass()`方法,而在`loadClass()`方法的逻辑里如果父类加载失败,则会调用自己的`findClass()`方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的.\n\n> 为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过`java.lang.Thread`类的`setContextClassLoaser()`方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n上面所说只完成了类加载的动作, 但是如果我们想要实现热更代码的这种功能的话,就不能单纯依赖重写`findClass(name)`了，而是要重写`loadClass(String name)`了，这是因为在`ClassLoader`中的`loadClass(String name)`方法当发现已经加载过的类就不会再重新加载了\n```java\nimport java.io.File;\nimport java.lang.reflect.Field;\nimport java.net.URL;\nimport java.net.URLClassLoader;\nimport java.util.Random;\n\nimport static org.objectweb.asm.Opcodes.*;\n\npublic class TestClassLoader {\n\n\tpublic static void main(String[] arg) throws Exception {\n\n\t\tURL url = new File(\".\").toURL();\n\t\tfor (int i = 0; i< 5; i++) {\n\t\t\tMyClassLoader myLoader = new MyClassLoader(new URL[]{url});\n\t\t\tClass<?> obj = myLoader.loadClass(\"Mesurable\");\n\t\t\tfor (Field field : obj.getFields()) {\n\t\t\t\tSystem.out.println(field.getName());\n\t\t\t}\n\t\t}\n\t}\n}\n\nclass MyClassLoader extends URLClassLoader {\n\n\tpublic MyClassLoader(URL[] urls) {\n\t\tsuper(urls);\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\tClass<?> loadClass = null;\n\t\tif (name.contains(\"java.lang.Object\")) {\n\t\t\t// 因为我们的父类是java.lang.Object, 因此我们要调用父类加载器进行加载\n\t\t\tloadClass = super.loadClass(name);\n\t\t} else {\n\t\t\tloadClass = findLoadedClass(name);\n\t\t\tif (loadClass != null) {\n\t\t\t\treturn loadClass;\n\t\t\t}\n\t\t\tbyte[] bytes = generateClass();\n\t\t\tloadClass = defineClass(name, bytes, 0, bytes.length);\n\t\t}\n\t\treturn loadClass;\n\t}\n\n\tprivate byte[] generateClass() {\n\t\tClassWriter cw = new ClassWriter(0);\n\t\tcw.visit(V1_8,\t\t\t\t\t\t\t\t\t\t\t// 指定class文件版本号, 我们将其设置为java8\n\t\t\t\tACC_PUBLIC,\t// 设置接口的修饰符\n\t\t\t\t\"Mesurable\",\t\t\t\t\t\t\t\t// 我们设置classname, 需要在这里指定全限定名\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t\t// 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null\n\t\t\t\t\"java/lang/Object\",\t\t\t\t\t\t\t// 设置父类, 同时需要设定全限定名\n\t\t\t\tnull);\t\t\t// 设置接口, 同样需要设置全限定名\n\n\t\tcw.visitField(\n\t\t\t\tACC_PUBLIC,\t// 设置字段的修饰符\n\t\t\t\t\"LESS__\" + random.nextInt(100),\t\t\t\t\t\t\t\t\t\t// 设置字段名\n\t\t\t\t\"I\",\t\t\t\t\t\t\t\t\t\t// 设置字段类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnew Long(-1))\t\t\t\t\t\t\t// 设置字面量值.\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitEnd();\n\t\treturn cw.toByteArray();\n\t}\n\n\tprivate Random random = new Random();\n}\n\n```\n\n> `URLClassLoader`根据`URL`指定的路径从`JAR`文件或者目录里加载`class`文件或者其他资源文件. 如果`URL`以`/`结束,就表示到某个目录里进行加载. 否则就表示到某个`JAR`文件里进行加载. 线程里用于创建`URLClassLoader`实例的`AccessControlContext`会在加载类文件以及资源文件时使用到. `URLClassLoader`实例创建好之后会根据默认的授权权限依据指定的`URL`来进行加载类.\n\n\n从文件中加载class\n```java\nimport java.io.*;\nimport java.lang.reflect.Method;\nimport java.net.URL;\nimport java.net.URLClassLoader;\nimport java.util.concurrent.TimeUnit;\n\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\n\t\tfor (int i = 0; i< 5; i++) {\n\t\t\tMyClassLoader myLoader = new MyClassLoader(new URL[]{});\n\t\t\tClass<?> obj = myLoader.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\t\tfor (Method method : obj.getMethods()) {\n\t\t\t\tif (method.getName().equals(\"printTime\")) {\n\t\t\t\t\tmethod.invoke(null);\n\t\t\t\t\tTimeUnit.SECONDS.sleep(10);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic static void printTime() {\n\t\tSystem.out.println(123);\n\t}\n}\n\nclass MyClassLoader extends URLClassLoader {\n\n\tpublic MyClassLoader(URL[] urls) {\n\t\tsuper(urls);\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\tClass<?> loadClass = findLoadedClass(name);\n\t\tif (loadClass != null) {\n\t\t\treturn loadClass;\n\t\t}\n\t\ttry {\n\t\t\tbyte[] bytes = loadClassFromFile(name);\n\t\t\tint idx = name.lastIndexOf(\"\\\\\");\n\t\t\tname = name.substring(idx + 1);\n\t\t\tname = name.split(\"\\\\.class\")[0];\n\t\t\tloadClass = defineClass(name, bytes, 0, bytes.length);\n\t\t} catch (Exception e) {\n\t\t\tloadClass = super.loadClass(name);\n\t\t}\n\n\t\treturn loadClass;\n\t}\n\n\tprivate byte[] loadClassFromFile(String fileName) throws Exception {\n\t\tInputStream input = new FileInputStream(new File(fileName));\n\t\tbyte[] bytes = new byte[input.available()];\n\t\tinput.read(bytes);\n\t\treturn bytes;\n\t}\n}\n\n```\n\n同一个类加载器不同加载同一个类俩次, 例如我们利用上面的`MyClassLoader`进行加载\n```java\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\t\tMyClassLoader myLoader1 = new MyClassLoader(new URL[]{});\n\t\tClass<?> obj1 = myLoader1.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tMyClassLoader myLoader2 = new MyClassLoader(new URL[]{});\n\t\tClass<?> obj2 = myLoader2.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tSystem.out.println(obj1.equals(obj2));\n\t\tClass<?> obj3 = myLoader2.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tSystem.out.println(obj2.equals(obj3));\n\t}\n}\n```\n会产生异常\n```java\nfalse\nException in thread \"main\" java.lang.LinkageError: loader (instance of  MyClassLoader): attempted  duplicate class definition for name: \"Test\"\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:642)\n\tat MyClassLoader.loadClass(Test.java:37)\n\tat Test.main(Test.java:15)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\n```\n\n\n\n\n\n","source":"_posts/jvm/使用Classloader加载类.md","raw":"category: JVM\ndate: 2016-01-29\ntitle: 使用Classloader加载类\n---\n\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n> 判断俩个类相等可以通过下面方法: `Class`对象的`equals()`方法, `isAssignbleFrom()`方法, `isInstance()`方法的返回结果, 也包括使用`instanceof`关键字做对象所属关系判断等. 不同的类加载器对`instanceof`关键字运算结果的影响\n\n\n## 双亲委派模型\n\n![ClassLoader的体系架构](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/ClassLoader%E7%9A%84%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png)\n从JVM来角度讲, 只存在俩种不同的类加载器:\n* 启动类加载器: 使用C++语言实践,是虚拟机自身的一部分. \n* 其他类加载器: 这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n系统提供的类加载器\n* 启动类加载器 : 这个类加载器负责将`<JAVA_HOME>\\lib`目录中的,或者`-Xbootclasspath`参数所指定的路径中的,并且是虚拟机识别的(仅按照文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法被java程序直接使用.\n* 扩展类加载器 : 这个类加载器由`sun.misc.Launcher$ExtClassLoader`实现,负责加载`<JAVA_HOME>\\lib\\ext`目录中的,或者被`java.ext.dirs`系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n* 应用程序加载器 : 这个类加载器由`sun.misc.Launcher$AppClassLoader`来实现. 由于类加载器是`ClassLoader`中`getSystemClassLoader()`方法的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n\n类加载器收到类加载请求,它不会自己去尝试加载这个类,而把这个请求委派给父类加载器去完成,每一个层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n```java\n protected Class<?> loadClass(String name, boolean resolve)\n        throws ClassNotFoundException\n    {\n        synchronized (getClassLoadingLock(name)) {\n            // 第一步检查被加载的类是否已经被加载进入了虚拟机\n            Class<?> c = findLoadedClass(name);\n            if (c == null) {\n\t\t\t\t// 如果没有被加载进虚拟机中则进行加载\n                long t0 = System.nanoTime();\n                try {\n\t\t\t\t\t// 优先从父类加载器中进行加载, 所有的类加请求最终都应该传送到顶层的启动类加载器中\n                    if (parent != null) {\n                        c = parent.loadClass(name, false);\n                    } else {\n\t\t\t\t\t// \n                        c = findBootstrapClassOrNull(name);\n                    }\n                } catch (ClassNotFoundException e) {\n                    // ClassNotFoundException thrown if class not found\n                    // from the non-null parent class loader\n                }\n\t\t\t\t\n                if (c == null) {\n                    // 父类加载器找不到则调用自己的findClass(name)找到类然后进行加载\n                    long t1 = System.nanoTime();\n                    c = findClass(name);\n\n                    // this is the defining class loader; record the stats\n                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);\n                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);\n                    sun.misc.PerfCounter.getFindClasses().increment();\n                }\n            }\n            if (resolve) {\n                resolveClass(c);\n            }\n            return c;\n        }\n    }\n```\n\n> 使用双亲委派模型来组织类加载之间的关系, 可以确保我们自己JVM的安全. 因为当我们自己写一个 `java.lang.Object`, 这个类虽然能够被正常编译, 但是它永远不会被加载器虚拟机中, 因为这个类会在启动类加载器中完成了加载.\n\n在刚才的`loadClass()`方法中我们看到最终我们自己实现类加载的逻辑是在`findClass()`中进行的, 这是为了向前兼容,JDK1.2之后添加的方法.JDK1.2之后已不提倡用户再去覆盖`loadClass()`方法,而在`loadClass()`方法的逻辑里如果父类加载失败,则会调用自己的`findClass()`方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的.\n\n> 为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过`java.lang.Thread`类的`setContextClassLoaser()`方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n上面所说只完成了类加载的动作, 但是如果我们想要实现热更代码的这种功能的话,就不能单纯依赖重写`findClass(name)`了，而是要重写`loadClass(String name)`了，这是因为在`ClassLoader`中的`loadClass(String name)`方法当发现已经加载过的类就不会再重新加载了\n```java\nimport java.io.File;\nimport java.lang.reflect.Field;\nimport java.net.URL;\nimport java.net.URLClassLoader;\nimport java.util.Random;\n\nimport static org.objectweb.asm.Opcodes.*;\n\npublic class TestClassLoader {\n\n\tpublic static void main(String[] arg) throws Exception {\n\n\t\tURL url = new File(\".\").toURL();\n\t\tfor (int i = 0; i< 5; i++) {\n\t\t\tMyClassLoader myLoader = new MyClassLoader(new URL[]{url});\n\t\t\tClass<?> obj = myLoader.loadClass(\"Mesurable\");\n\t\t\tfor (Field field : obj.getFields()) {\n\t\t\t\tSystem.out.println(field.getName());\n\t\t\t}\n\t\t}\n\t}\n}\n\nclass MyClassLoader extends URLClassLoader {\n\n\tpublic MyClassLoader(URL[] urls) {\n\t\tsuper(urls);\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\tClass<?> loadClass = null;\n\t\tif (name.contains(\"java.lang.Object\")) {\n\t\t\t// 因为我们的父类是java.lang.Object, 因此我们要调用父类加载器进行加载\n\t\t\tloadClass = super.loadClass(name);\n\t\t} else {\n\t\t\tloadClass = findLoadedClass(name);\n\t\t\tif (loadClass != null) {\n\t\t\t\treturn loadClass;\n\t\t\t}\n\t\t\tbyte[] bytes = generateClass();\n\t\t\tloadClass = defineClass(name, bytes, 0, bytes.length);\n\t\t}\n\t\treturn loadClass;\n\t}\n\n\tprivate byte[] generateClass() {\n\t\tClassWriter cw = new ClassWriter(0);\n\t\tcw.visit(V1_8,\t\t\t\t\t\t\t\t\t\t\t// 指定class文件版本号, 我们将其设置为java8\n\t\t\t\tACC_PUBLIC,\t// 设置接口的修饰符\n\t\t\t\t\"Mesurable\",\t\t\t\t\t\t\t\t// 我们设置classname, 需要在这里指定全限定名\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t\t// 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null\n\t\t\t\t\"java/lang/Object\",\t\t\t\t\t\t\t// 设置父类, 同时需要设定全限定名\n\t\t\t\tnull);\t\t\t// 设置接口, 同样需要设置全限定名\n\n\t\tcw.visitField(\n\t\t\t\tACC_PUBLIC,\t// 设置字段的修饰符\n\t\t\t\t\"LESS__\" + random.nextInt(100),\t\t\t\t\t\t\t\t\t\t// 设置字段名\n\t\t\t\t\"I\",\t\t\t\t\t\t\t\t\t\t// 设置字段类型\n\t\t\t\tnull,\t\t\t\t\t\t\t\t\t\t// 设置泛型信息\n\t\t\t\tnew Long(-1))\t\t\t\t\t\t\t// 设置字面量值.\n\t\t\t\t.visitEnd();\n\n\t\tcw.visitEnd();\n\t\treturn cw.toByteArray();\n\t}\n\n\tprivate Random random = new Random();\n}\n\n```\n\n> `URLClassLoader`根据`URL`指定的路径从`JAR`文件或者目录里加载`class`文件或者其他资源文件. 如果`URL`以`/`结束,就表示到某个目录里进行加载. 否则就表示到某个`JAR`文件里进行加载. 线程里用于创建`URLClassLoader`实例的`AccessControlContext`会在加载类文件以及资源文件时使用到. `URLClassLoader`实例创建好之后会根据默认的授权权限依据指定的`URL`来进行加载类.\n\n\n从文件中加载class\n```java\nimport java.io.*;\nimport java.lang.reflect.Method;\nimport java.net.URL;\nimport java.net.URLClassLoader;\nimport java.util.concurrent.TimeUnit;\n\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\n\t\tfor (int i = 0; i< 5; i++) {\n\t\t\tMyClassLoader myLoader = new MyClassLoader(new URL[]{});\n\t\t\tClass<?> obj = myLoader.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\t\tfor (Method method : obj.getMethods()) {\n\t\t\t\tif (method.getName().equals(\"printTime\")) {\n\t\t\t\t\tmethod.invoke(null);\n\t\t\t\t\tTimeUnit.SECONDS.sleep(10);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic static void printTime() {\n\t\tSystem.out.println(123);\n\t}\n}\n\nclass MyClassLoader extends URLClassLoader {\n\n\tpublic MyClassLoader(URL[] urls) {\n\t\tsuper(urls);\n\t}\n\n\t@Override\n\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\tClass<?> loadClass = findLoadedClass(name);\n\t\tif (loadClass != null) {\n\t\t\treturn loadClass;\n\t\t}\n\t\ttry {\n\t\t\tbyte[] bytes = loadClassFromFile(name);\n\t\t\tint idx = name.lastIndexOf(\"\\\\\");\n\t\t\tname = name.substring(idx + 1);\n\t\t\tname = name.split(\"\\\\.class\")[0];\n\t\t\tloadClass = defineClass(name, bytes, 0, bytes.length);\n\t\t} catch (Exception e) {\n\t\t\tloadClass = super.loadClass(name);\n\t\t}\n\n\t\treturn loadClass;\n\t}\n\n\tprivate byte[] loadClassFromFile(String fileName) throws Exception {\n\t\tInputStream input = new FileInputStream(new File(fileName));\n\t\tbyte[] bytes = new byte[input.available()];\n\t\tinput.read(bytes);\n\t\treturn bytes;\n\t}\n}\n\n```\n\n同一个类加载器不同加载同一个类俩次, 例如我们利用上面的`MyClassLoader`进行加载\n```java\npublic class Test {\n\n\tpublic static void main(String[] arg) throws Exception {\n\t\tMyClassLoader myLoader1 = new MyClassLoader(new URL[]{});\n\t\tClass<?> obj1 = myLoader1.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tMyClassLoader myLoader2 = new MyClassLoader(new URL[]{});\n\t\tClass<?> obj2 = myLoader2.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tSystem.out.println(obj1.equals(obj2));\n\t\tClass<?> obj3 = myLoader2.loadClass(\"D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class\");\n\t\tSystem.out.println(obj2.equals(obj3));\n\t}\n}\n```\n会产生异常\n```java\nfalse\nException in thread \"main\" java.lang.LinkageError: loader (instance of  MyClassLoader): attempted  duplicate class definition for name: \"Test\"\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:642)\n\tat MyClassLoader.loadClass(Test.java:37)\n\tat Test.main(Test.java:15)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\n```\n\n\n\n\n\n","slug":"jvm/使用Classloader加载类","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihu50067vjs64h73ustr"},{"date":"2014-09-04T16:00:00.000Z","title":"内存分配","_content":"\n## 引用计数算法\n引用计数算法很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n\n### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n## 内存分配\n1. 新生代GC(`Minor GC`)：新生代GC, Java对象大多都朝生夕灭,所以`Minor GC`非常频繁,回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：老年代GC,出现了Major GC,经常会伴随至少一次的Minor GC. MajorGC的速度一般会比Minor GC慢10倍以上.\n\n### 新生代\n新生代分为Eden区和Survivor区(Eden有一个, Survivor有俩个, 参考复制算法).\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`, 将存活下来的对象移动到一个Survivor区中\n\n> 虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.\n\n示例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 * _1MB];\n\t    allocation2 = new byte[2 * _1MB];\n\t    allocation3 = new byte[2 * _1MB];\n\t    allocation4 = new byte[4 * _1MB];  // 出现一次Minor GC\n}\n```\n分析如下：\n\n1. 首先在堆中分配3个2MB大小和1个4MB大小的byte数组, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n2. `-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n3. 执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n4. 这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n5. 这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用)\n\n### 老年代\n大对象和长期存活的对象会进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组. 如果连续出现多个大对象, 会导致老年代频繁发生`Full GC`, 因此在写程序时应该避免频繁出现大对象.\n\n我们可以使用`-XX:PretenureSizeThreshold`参数令大于这个值的对象直接在老年代中分配. 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(新生代采用复制算法收集内存).\n\n\n示例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  * -XX:PretenureSizeThreshold=3145728\n  */\npublic static void testPretenureSizeThreshold() {\n\t　byte[] allocation;\n\t　allocation = new byte[4 * _1MB];  //直接分配在老年代中\n}\n```\n我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,`Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n大家可以分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行刚才示例. 例子中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n实例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n  * -XX:+PrintTenuringDistribution\n  */\n@SuppressWarnings(\"unused\")\npublic static void testTenuringThreshold() {\n\t byte[] allocation1, allocation2, allocation3;\n\t allocation1 = new byte[_1MB / 4];\n\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t allocation2 = new byte[4 * _1MB];\n\t allocation3 = new byte[4 * _1MB];\n\t allocation3 = null;\n\t allocation3 = new byte[4 * _1MB];\n}\n```\n\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n例如下例中设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n\n### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n","source":"_posts/jvm/内存分配.md","raw":"category: JVM\ndate: 2014-09-05\ntitle: 内存分配\n---\n\n## 引用计数算法\n引用计数算法很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n\n### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n## 内存分配\n1. 新生代GC(`Minor GC`)：新生代GC, Java对象大多都朝生夕灭,所以`Minor GC`非常频繁,回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：老年代GC,出现了Major GC,经常会伴随至少一次的Minor GC. MajorGC的速度一般会比Minor GC慢10倍以上.\n\n### 新生代\n新生代分为Eden区和Survivor区(Eden有一个, Survivor有俩个, 参考复制算法).\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`, 将存活下来的对象移动到一个Survivor区中\n\n> 虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.\n\n示例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 * _1MB];\n\t    allocation2 = new byte[2 * _1MB];\n\t    allocation3 = new byte[2 * _1MB];\n\t    allocation4 = new byte[4 * _1MB];  // 出现一次Minor GC\n}\n```\n分析如下：\n\n1. 首先在堆中分配3个2MB大小和1个4MB大小的byte数组, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n2. `-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n3. 执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n4. 这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n5. 这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用)\n\n### 老年代\n大对象和长期存活的对象会进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组. 如果连续出现多个大对象, 会导致老年代频繁发生`Full GC`, 因此在写程序时应该避免频繁出现大对象.\n\n我们可以使用`-XX:PretenureSizeThreshold`参数令大于这个值的对象直接在老年代中分配. 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(新生代采用复制算法收集内存).\n\n\n示例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  * -XX:PretenureSizeThreshold=3145728\n  */\npublic static void testPretenureSizeThreshold() {\n\t　byte[] allocation;\n\t　allocation = new byte[4 * _1MB];  //直接分配在老年代中\n}\n```\n我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,`Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n大家可以分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行刚才示例. 例子中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n实例代码\n```java\nprivate static final int _1MB = 1024 * 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n  * -XX:+PrintTenuringDistribution\n  */\n@SuppressWarnings(\"unused\")\npublic static void testTenuringThreshold() {\n\t byte[] allocation1, allocation2, allocation3;\n\t allocation1 = new byte[_1MB / 4];\n\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t allocation2 = new byte[4 * _1MB];\n\t allocation3 = new byte[4 * _1MB];\n\t allocation3 = null;\n\t allocation3 = new byte[4 * _1MB];\n}\n```\n\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n例如下例中设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n\n### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n","slug":"jvm/内存分配","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihu90069vjs6cotlymnx"},{"date":"2014-09-05T16:00:00.000Z","title":"内存溢出","_content":"\n### java堆溢出\n溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n执行代码\n```java\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n1. 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位出泄漏代码的位置.\n2. 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n\n### 虚拟机栈和本地方法栈溢出\n溢出代码\n```java\n/**\n  * -Xoss 设置本地放发栈 但是此参数无效\n  * -Xss 虚拟机栈 设置此参数\n  * @param args\n  */\n\npublic class JavaVMStackSOF {\n\n\tprivate int stackLength = 1;\n\n\tpublic void stackLeak() {\n\t\tstackLength ++;\n\t\tstackLeak();\n\t}\n\n\n\tpublic static void main(String[] args) {\n\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\ttry {\n\t\t\toom.stackLeak();\n\t\t} catch(Throwable e) {\n\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\tthrow e;\n\t\t}\n\t}\n}\n\npublic class JavaVMStackOOM {\n\tprivate void dontStop() {\n\t\twhile(true) {\n\n\t\t}\n\t}\n\n\tpublic void stackLeakByThread() {\n\t\twhile(true) {\n\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tdontStop();\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\tom.stackLeakByThread();\n\t}\n}\n```\n以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆和减少栈容量来换取更多的线程.\n\n### 运行时常量池溢出\n\n溢出代码\n```java\n/**\n * 运行时常量溢出\n * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n * @author mingwang\n *\n */\npublic class RuntimeConstantPoolOOM {\n\n\tpublic static void main(String[] args) {\n\t\tList<String> list = new ArrayList<>();\n\t\tint i = 0;\n\t\twhile(true) {\n\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t}\n\t}\n}\n```\n如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String对象包含的字符串添加到常量池中,并返回次String对象音乐.\n\n### 方法区溢出\n\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n执行代码\n```java\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.本例中使用的是CGLib, 还可以使用ASM等框架进行测试.方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n\n\n### 本地内存直接溢出\n溢出代码\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:unsafe.allocateMemory(_1MB);\n","source":"_posts/jvm/内存溢出.md","raw":"category: JVM\ndate: 2014-09-06\ntitle: 内存溢出\n---\n\n### java堆溢出\n溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n执行代码\n```java\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n1. 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位出泄漏代码的位置.\n2. 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n\n### 虚拟机栈和本地方法栈溢出\n溢出代码\n```java\n/**\n  * -Xoss 设置本地放发栈 但是此参数无效\n  * -Xss 虚拟机栈 设置此参数\n  * @param args\n  */\n\npublic class JavaVMStackSOF {\n\n\tprivate int stackLength = 1;\n\n\tpublic void stackLeak() {\n\t\tstackLength ++;\n\t\tstackLeak();\n\t}\n\n\n\tpublic static void main(String[] args) {\n\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\ttry {\n\t\t\toom.stackLeak();\n\t\t} catch(Throwable e) {\n\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\tthrow e;\n\t\t}\n\t}\n}\n\npublic class JavaVMStackOOM {\n\tprivate void dontStop() {\n\t\twhile(true) {\n\n\t\t}\n\t}\n\n\tpublic void stackLeakByThread() {\n\t\twhile(true) {\n\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tdontStop();\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\tom.stackLeakByThread();\n\t}\n}\n```\n以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆和减少栈容量来换取更多的线程.\n\n### 运行时常量池溢出\n\n溢出代码\n```java\n/**\n * 运行时常量溢出\n * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n * @author mingwang\n *\n */\npublic class RuntimeConstantPoolOOM {\n\n\tpublic static void main(String[] args) {\n\t\tList<String> list = new ArrayList<>();\n\t\tint i = 0;\n\t\twhile(true) {\n\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t}\n\t}\n}\n```\n如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String对象包含的字符串添加到常量池中,并返回次String对象音乐.\n\n### 方法区溢出\n\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n执行代码\n```java\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.本例中使用的是CGLib, 还可以使用ASM等框架进行测试.方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n\n\n### 本地内存直接溢出\n溢出代码\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:unsafe.allocateMemory(_1MB);\n","slug":"jvm/内存溢出","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihuc006bvjs6jbvwt4gi"},{"date":"2014-09-06T16:00:00.000Z","title":"垃圾收集算法及垃圾回收器","_content":"## 垃圾回收算法\n\n### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n算法伪代码\n\nNEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n\nmark算法\n```java\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n\nsweep算法\n```java\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n\n### 复制算法\n\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n![复制算法a](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n\n> 商业虚拟机都采用这种算法来收集新生代. 由于大多数的新生代对象都是朝生夕死, 因此按照1:1 的比例分配新生代内存代价就有点高了. 因此现在的做法一般是将新生代分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n### 标记-整理算法\n由于新生代的对象是朝生夕死的，因此复制算法每次复制的对象都不会太多, 但是老年代都是一些大对象, 如果在老年代仍然采用复制算法的话, 效率会变低, 因此提出了标记-整理算法. 标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n### 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n\n### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n作为单线程收集器, 它不仅仅只会使用一个CPU或一条收集线程完成GC,更重要的是在它进行GC时, 其他的工作线程也必须暂停工作, 直到它收集结束. 这在多线程的应用中是难以接受的. 但是桌面应用程序会将虚拟机设置为Client模式, 这种模式下单线程收集一百兆左右的新生代内存时间完全可以控制在一百毫秒以内, 这种停顿只要是不发生的太频繁, 用户是完全可以接受的. 而且对于 限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.\n\n### ParNew收集器\n\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样.\n\n> 需要指出的是, ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n注意，从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n### Parallel Scavege收集器\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n> 注意ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程,而不必先进行Minor GC\n\n### Serial Old收集器\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n### Parallel old收集器\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n### CMS收集器\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n","source":"_posts/jvm/垃圾收集算法及垃圾回收器.md","raw":"category: JVM\ndate: 2014-09-07\ntitle: 垃圾收集算法及垃圾回收器\n---\n## 垃圾回收算法\n\n### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n算法伪代码\n\nNEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n\nmark算法\n```java\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n\nsweep算法\n```java\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n\n### 复制算法\n\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n![复制算法a](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n\n> 商业虚拟机都采用这种算法来收集新生代. 由于大多数的新生代对象都是朝生夕死, 因此按照1:1 的比例分配新生代内存代价就有点高了. 因此现在的做法一般是将新生代分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n### 标记-整理算法\n由于新生代的对象是朝生夕死的，因此复制算法每次复制的对象都不会太多, 但是老年代都是一些大对象, 如果在老年代仍然采用复制算法的话, 效率会变低, 因此提出了标记-整理算法. 标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/ming15/blog-website/images/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n### 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n\n### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n作为单线程收集器, 它不仅仅只会使用一个CPU或一条收集线程完成GC,更重要的是在它进行GC时, 其他的工作线程也必须暂停工作, 直到它收集结束. 这在多线程的应用中是难以接受的. 但是桌面应用程序会将虚拟机设置为Client模式, 这种模式下单线程收集一百兆左右的新生代内存时间完全可以控制在一百毫秒以内, 这种停顿只要是不发生的太频繁, 用户是完全可以接受的. 而且对于 限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.\n\n### ParNew收集器\n\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样.\n\n> 需要指出的是, ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n注意，从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n### Parallel Scavege收集器\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n> 注意ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程,而不必先进行Minor GC\n\n### Serial Old收集器\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n### Parallel old收集器\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n### CMS收集器\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n","slug":"jvm/垃圾收集算法及垃圾回收器","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihuh006dvjs625qm6unn"},{"date":"2014-09-07T16:00:00.000Z","title":"字节码指令","_content":"## 字节码指令\n\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```java\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```java\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```java\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```java\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```java\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```java\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```java\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```java\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```java\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```java\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```java\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```java\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```java\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```java\n  1.  iinc\n```\n* 比较之类\n```java\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```java\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```java\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```java\n  1.  new\n```\n* 创建数组的指令\n```java\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```java\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```java\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```java\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```java\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```java\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```java\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n 控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n\n*   条件分支指令\n```java\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```java\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```java\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```java\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```java\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```java\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","source":"_posts/jvm/字节码指令.md","raw":"category: JVM\ndate: 2014-09-08\ntitle: 字节码指令\n---\n## 字节码指令\n\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```java\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```java\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```java\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```java\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```java\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```java\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```java\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```java\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```java\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```java\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```java\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```java\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```java\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```java\n  1.  iinc\n```\n* 比较之类\n```java\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```java\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```java\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```java\n  1.  new\n```\n* 创建数组的指令\n```java\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```java\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```java\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```java\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```java\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```java\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```java\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n 控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n\n*   条件分支指令\n```java\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```java\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```java\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```java\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```java\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```java\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","slug":"jvm/字节码指令","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihul006fvjs6mbfs548c"},{"date":"2014-12-05T16:00:00.000Z","title":"栈上分配","_content":"栈上分配是虚拟机提供的一项优化技术,这项技术将java对象分配在jvm栈上而不是在堆上进行分配.\n\n那么什么对象会在jvm栈上进行分配呢?答案是线程私有的对象. 我们使用逃逸分析来判断一个对象是否是线程私有的, 一般评判的标准是对象是非能够逃出方法体. 例如下面的对象tomorrow就逃逸出了方法体.\n```java\npublic class TestStackObject {\n\n    private LocalDate tomorrow;\n\n    public static void main(String s) {\n\n    }\n\n    private void initTomorrow() {\n        tomorrow = LocalDate.now().plusDays(1);\n    }\n\n}\n```\n而下面的对象tomorrow就没有逃逸出方法体\n```java\npublic class TestStackObject {\n\n    public static void main(String[] s) {\n        TestStackObject testStackObject = new TestStackObject();\n        testStackObject.printTomorrow();\n    }\n\n    private void printTomorrow() {\n        LocalDate tomorrow = LocalDate.now().plusDays(1);\n        System.out.println(tomorrow.atStartOfDay().toString());\n    }\n\n}\n\n```\n\n接下来我们利用程序来验证一下tomorrow对象是否是真的分配在了栈上\n```java\npublic class TestStackObject {\n\n\tpublic static void main(String[] s) {\n\t\tfor (int i = 0; i < 1024 * 10; i++) {\n\t\t\tnewNow(i);\n\t\t}\n\t}\n\n\tprivate static void newNow(int i) {\n\t\tbyte[] obj = new byte[1024];\n\t}\n}\n```\n运行这个程序的时候我们添加上下面的虚拟机参数\n```java\n-Xmx20m -Xms20m -XX:+PrintGC\n```\n结果我们看到了大量的Full GC日志, 说明这些对象直接分配在了老年代, 而引发的GC\n```java\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0052440 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0047600 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0063610 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0076120 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0071990 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0085370 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0050040 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0046870 secs]\n```\n\n但是如果我们添加下面的虚拟机参数的话\n```java\n-XX:+DoEscapeAnalysis -XX:-UseTLAB -XX:+EliminateAllocations\n```\n会发生什么呢\n\n* DoEscapeAnalysis : 开启逃逸分析\n* UseTLAB :\n* EliminateAllocations : 开启标量替换\n","source":"_posts/jvm/栈上分配.md","raw":"category: JVM\ndate: 2014-12-06\ntitle: 栈上分配\n---\n栈上分配是虚拟机提供的一项优化技术,这项技术将java对象分配在jvm栈上而不是在堆上进行分配.\n\n那么什么对象会在jvm栈上进行分配呢?答案是线程私有的对象. 我们使用逃逸分析来判断一个对象是否是线程私有的, 一般评判的标准是对象是非能够逃出方法体. 例如下面的对象tomorrow就逃逸出了方法体.\n```java\npublic class TestStackObject {\n\n    private LocalDate tomorrow;\n\n    public static void main(String s) {\n\n    }\n\n    private void initTomorrow() {\n        tomorrow = LocalDate.now().plusDays(1);\n    }\n\n}\n```\n而下面的对象tomorrow就没有逃逸出方法体\n```java\npublic class TestStackObject {\n\n    public static void main(String[] s) {\n        TestStackObject testStackObject = new TestStackObject();\n        testStackObject.printTomorrow();\n    }\n\n    private void printTomorrow() {\n        LocalDate tomorrow = LocalDate.now().plusDays(1);\n        System.out.println(tomorrow.atStartOfDay().toString());\n    }\n\n}\n\n```\n\n接下来我们利用程序来验证一下tomorrow对象是否是真的分配在了栈上\n```java\npublic class TestStackObject {\n\n\tpublic static void main(String[] s) {\n\t\tfor (int i = 0; i < 1024 * 10; i++) {\n\t\t\tnewNow(i);\n\t\t}\n\t}\n\n\tprivate static void newNow(int i) {\n\t\tbyte[] obj = new byte[1024];\n\t}\n}\n```\n运行这个程序的时候我们添加上下面的虚拟机参数\n```java\n-Xmx20m -Xms20m -XX:+PrintGC\n```\n结果我们看到了大量的Full GC日志, 说明这些对象直接分配在了老年代, 而引发的GC\n```java\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0052440 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0047600 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0063610 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0076120 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0071990 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0085370 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0050040 secs]\n[Full GC (Ergonomics)  977K->465K(1536K), 0.0046870 secs]\n```\n\n但是如果我们添加下面的虚拟机参数的话\n```java\n-XX:+DoEscapeAnalysis -XX:-UseTLAB -XX:+EliminateAllocations\n```\n会发生什么呢\n\n* DoEscapeAnalysis : 开启逃逸分析\n* UseTLAB :\n* EliminateAllocations : 开启标量替换\n","slug":"jvm/栈上分配","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihuo006hvjs6mr9c9dba"},{"date":"2014-09-08T16:00:00.000Z","title":"类加载机制","_content":"## 类加载机制\n\n### 生命周期\n类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n\n1. 加载\n2. 验证\n3. 准备\n4. 解析\n5. 初始化\n6. 使用\n7. 卸载\n\n> 特殊说明\n> 2.验证, 3.准备, 4.解析 又称为连接阶段\n> 1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n\n\n### 加载:\n加载的过程其实就是将class文件字节码加载进虚拟机的方法区中(方法区中数据格式由虚拟机定义),然后在堆中实例化对其实例化一个`java.lang.Class`对象,然后程序使用该对象访问存储在方法区里的类型数据.\n\n虚拟机通过下面三个阶段完成一个类的加载过程\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java堆中生成一个代表这个类的`java.class.Class`对象.\n\n类的加载过程必须完成以上三个过程但是这三个阶段并没有具体说明从哪里获取以及如何获取类的字节码,我们可以使用系统提供的类加载器或者自定义类加载器完成读取二进制流的动作.\n\n加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 验证:\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n#### 校验过程\n\n##### class文件格式验证\n保证输入的字节流能正确地解析并存储于方法区之内.确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  \n基于方法区的数据结构进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证\n基于方法区的数据结构,基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n符号引用的校验是确保解析动作能正常执行.最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析\n对`CONSTANT_Class_info`结构体进行解析\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析\n对`CONSTANT_Fieldref_info`结构体进行解析\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析\n对`CONSTANT_Methodref_info`结构体进行解析\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析\n对`CONSTANT_InterfaceMethodref_info`结构体进行解析\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n`<clinit>`方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n`<clinit>`方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n\n字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n\n#### 类初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n* 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n\n* 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n\n* 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n","source":"_posts/jvm/类加载.md","raw":"category: JVM\ndate: 2014-09-09\ntitle: 类加载机制\n---\n## 类加载机制\n\n### 生命周期\n类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n\n1. 加载\n2. 验证\n3. 准备\n4. 解析\n5. 初始化\n6. 使用\n7. 卸载\n\n> 特殊说明\n> 2.验证, 3.准备, 4.解析 又称为连接阶段\n> 1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n\n\n### 加载:\n加载的过程其实就是将class文件字节码加载进虚拟机的方法区中(方法区中数据格式由虚拟机定义),然后在堆中实例化对其实例化一个`java.lang.Class`对象,然后程序使用该对象访问存储在方法区里的类型数据.\n\n虚拟机通过下面三个阶段完成一个类的加载过程\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java堆中生成一个代表这个类的`java.class.Class`对象.\n\n类的加载过程必须完成以上三个过程但是这三个阶段并没有具体说明从哪里获取以及如何获取类的字节码,我们可以使用系统提供的类加载器或者自定义类加载器完成读取二进制流的动作.\n\n加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 验证:\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n#### 校验过程\n\n##### class文件格式验证\n保证输入的字节流能正确地解析并存储于方法区之内.确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  \n基于方法区的数据结构进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证\n基于方法区的数据结构,基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n符号引用的校验是确保解析动作能正常执行.最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析\n对`CONSTANT_Class_info`结构体进行解析\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析\n对`CONSTANT_Fieldref_info`结构体进行解析\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析\n对`CONSTANT_Methodref_info`结构体进行解析\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析\n对`CONSTANT_InterfaceMethodref_info`结构体进行解析\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n`<clinit>`方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n`<clinit>`方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n\n字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n\n#### 类初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n* 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n\n* 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n\n* 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n","slug":"jvm/类加载","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihur006jvjs6rx339y9c"},{"date":"2015-10-07T16:00:00.000Z","title":"AWK","_content":"# AWK\nawk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。\n\n语法\n```awk\nawk [-F  field-separator]  'commands'  input-file(s)\n```\n* -F: 域分隔符,由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。(我们指定:为分隔符`-F ':'`)\n* commands: 'PATTERN{COMMAND}'. PATTERN为模式(正在表达式),COMMAND为要执行的命令.\n\n```awk\nawk  -F ':'  'BEGIN {print \"start\"}  {print $1\"} END {print \"end\"}' ./txt\n```\n上面的例子是读取`txt`文件,然后使用`:`分割每一行数据,在开始处理的时候输出start，在处理过程中第一列数据，最后输出end。\n\n## 变量\n\n### 内置变量\n我们可以在AWK命令中直接使用以下内置变量\n```awk\nARGC               命令行参数个数\nARGV               命令行参数排列\nENVIRON            支持队列中系统环境变量的使用\nFILENAME           awk浏览的文件名\nFNR                浏览文件的记录数\nFS                 设置输入域分隔符，等价于命令行 -F选项\nNF                 浏览记录的域的个数\nNR                 已读的记录数\nOFS                输出域分隔符\nORS                输出记录分隔符\nRS                 控制记录分隔符\n```\n例如\n```awk\njps -l | awk '{print ARGC}'\n```\n\n### 自定义变量\n我们通过赋值的方式直接定义一个变量\n```awk\njps -l | awk 'BEGIN{size=0;} {size=1+size} {print $1} END{print size}'\n```\n上面我们定义了一个数值型的size变量.\n\n### 数组\n\n# 运算符\n* `= += -= *= /= %= ^= **=`\t赋值\n* `?:`\tC条件表达式\n* `||`\t逻辑或\n* `&&`\t逻辑与\n* `~ ~!`\t匹配正则表达式和不匹配正则表达式\n* `< <= > >= != ==`\t关系运算符\n* `空格`\t连接\n* `+ -`\t加，减\n* `* / &`\t乘，除与求余\n* `+ - !`\t一元加，减和逻辑非\n* `^ ***`\t求幂\n* `++ --`\t增加或减少，作为前缀或后缀\n* `$`\t字段引用\n* `in`\t数组成员\n\n\n# 流程控制\n## 条件语句\n下面输出了大于10000的java进程号\n```awk\njps -l | awk 'BEGIN{size=0} {if($1>10000) {size++;print $1}} END{print size}'\n```\n\n## 循环语句\nawk中的循环语句借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。\n\n# 字符串处理\n## sub函数\n匹配从左侧开始找到的第一个符合规则的字符串，然后使用替换字符串替换这些字符串\n```awk\njps -l | awk '{sub(/moon/, \"sun\")} {print $2}'\n```\n上面这个例子就使用sun这个字符串替换了$2中的moon字符串。\n\n我们还可以指定在哪列执行查找替换\n```awk\njps -l | awk '{sub(/moon/, \"sun\", $1)} {print $2}'\n```\n上面的例子中我们只在第一列进行查找替换\n\n## gsub函数\n与sub函数不同的是，这个执行的是全局替换\n```awk\njps -l | awk '{gsub(/moon/, \"sun\")} {print $2}'\n```\n\n## index函数\n返回子字符串第一次被匹配的位置，偏移量从位置1开始\n```awk\njps -l | awk '{print$2; $2=index($2, \"moon\")} {print $2}'\n```\n\n## length函数\n返回记录的字符数\n```awk\njps -l | awk '{print$2; $2=length($2)} {print $2}'\n```\n\n## substr函数\n返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串\n```awk\njps -l | awk '{print substr($2, 2, 10)} '\n```\n上面的例子将$2字符串从第二个字符还是截取，截取10个长度的字符串出来\n\n## toupper和tolower函数\n可用于字符串大小间的转换\n```awk\nawk '{print toupper($2)} '\n```\n\n## split函数\n可按给定的分隔符把字符串分割为一个数组\n```awk\njps -l | awk '{ split($2, array, \"/\"); print array[3]} '\n```\n上面的例子我们将$2这一列按照`/`进行分割,然后将分割出的数据存储到array数组里. 注意这里首先不需要转义\n\n\n# 正则表达式\n\n## \\\n将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配换行符。序列“\\\\”匹配“\\”，“\\(”匹配“(”。\n```awk\nawk '/\\\\/{print $0}' ./txt\n```\n过滤出带有`\\`的行\n\n## ^\n匹配输入字符串与最左侧开始的位置的字符串。\n```awk\nawk '/^\\\\n/{print $0}' ./txt\n```\n找到所有以`\\n`字符串开始的数据\n\n## $\n匹配输入字符串结尾的位置。\n```awk\nawk '/)。$/{print $0}' ./txt\n```\n过滤以`)。`结尾的行\n\n## *\n零次或多次匹配前面的字符或子表达式。例如，zo* 匹配“z”和“zoo”。* 等效于 {0,}。\n```awk\nawk '/反向引用*/{print $0}' ./txt\n```\n\n## +\n一次或多次匹配前面的字符或子表达式。例如，“zo+”与“zo”和“zoo”匹配，但与“z”不匹配。+ 等效于 {1,}。\n```awk\nawk '/反向引用+/{print $0}' ./txt\n```\n\n## ?\n零次或一次匹配前面的字符或子表达式。例如，“do(es)?”匹配“do”或“does”中的“do”。? 等效于 {0,1}。\n```awk\nawk '/反向引用?/{print $0}' ./txt\n```\n\n## {n}\nn 是非负整数。正好匹配 n 次。例如，“o{2}”与“Bob”中的“o”不匹配，但与“food”中的两个“o”匹配。\n```awk\n\n```\n\n## {n,}\nn 是非负整数。至少匹配 n 次。例如，“o{2,}”不匹配“Bob”中的“o”，而匹配“foooood”中的所有 o。“o{1,}”等效于“o+”。“o{0,}”等效于“o*”。\n```awk\n\n```\n\n## {n,m}\nM 和 n 是非负整数，其中 n <= m。匹配至少 n 次，至多 m 次。例如，“o{1,3}”匹配“fooooood”中的头三个 o。'o{0,1}' 等效于 'o?'。注意：您不能将空格插入逗号和数字之间。\n```awk\n\n```\n\n## .\n匹配除“\\n”之外的任何单个字符。若要匹配包括“\\n”在内的任意字符，请使用诸如“[\\s\\S]”之类的模式。\n```awk\n\n```\n\n## (pattern)\n匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果“匹配”集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用“\\(”或者“\\)”。\n```awk\n\n```\n\n## (?:pattern)\n匹配 pattern 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用“or”字符 (|) 组合模式部件的情况很有用。例如，'industr(?:y|ies) 是比 'industry|industries' 更经济的表达式。\n```awk\n\n```\n\n## (?=pattern)\n执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 pattern 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?=95|98|NT|2000)' 匹配“Windows 2000”中的“Windows”，但不匹配“Windows 3.1”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```awk\n\n```\n\n## (?!pattern)\n执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 pattern 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?!95|98|NT|2000)' 匹配“Windows 3.1”中的 “Windows”，但不匹配“Windows 2000”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```awk\n\n```\n\n## x|y\n匹配 x 或 y。\n```awk\n awk '/换页符等|十六进制转义码必须正好是两位数长/ {print $0}' ./txt\n```\n\n## [xyz]\n匹配是否包含xyz中任意一个字符\n```awk\nawk '/[前面至少有]/ {print $0}' ./txt\n```\n\n## [^xyz]\n匹配不能包含xyz任意一个字符\n```awk\nawk '/[^前面至少有]/ {print $0}' ./txt\n```\n\n## [a-z]\n与`[xyz]`规则相同,只不过这个模式提供了一个范围模式.例如[a-c]实际为匹配[abc]\n```awk\nawk '/[a-b]/ {print $0}' ./txt\n```\n\n## [^a-z]\n反向范围字符。匹配不在指定的范围内的任何字符。例如，“[^a-z]”匹配任何不在“a”到“z”范围内的任何字符。\n```awk\nawk '/[^a-z]/ {print $0}' ./txt\n```\n需要注意的是'\\t'会被匹配出来\n\n## \\d\n数字字符匹配。等效于 [0-9]。\n```awk\nawk '/\\d/ {print $0}' ./txt\n```\n\n## \\D\n非数字字符匹配。等效于 [^0-9]。\n```awk\nawk '/\\D/ {print $0}' ./txt\n```\n\n## \\n\n换行符匹配。等效于 \\x0a 和 \\cJ。\n```awk\nawk '/\\n/ {print $0}' ./txt\n```\n\n## \\r\n匹配一个回车符。等效于 \\x0d 和 \\cM。\n```awk\n awk '/\\t/ {print $0}' ./txt\n```\n\n## \\s\n匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\n```awk\nawk '/\\s/ {print $0}' ./txt\n```\n\n## \\S\n匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\n```awk\nawk '/\\S/ {print $0}' ./txt\n```\n\n## \\w\n匹配任何字类字符，包括下划线。与“[A-Za-z0-9_]”等效。\n```awk\nawk '/\\w/ {print $0}' ./txt\n```\n\n## \\W\n与任何非单词字符匹配。与“[^A-Za-z0-9_]”等效。\n```awk\nawk '/\\W/ {print $0}' ./txt\n```\n","source":"_posts/linux/2015-10-12-AWK.md","raw":"category: linux\ndate: 2015-10-08\ntitle: AWK\n---\n# AWK\nawk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。\n\n语法\n```awk\nawk [-F  field-separator]  'commands'  input-file(s)\n```\n* -F: 域分隔符,由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。(我们指定:为分隔符`-F ':'`)\n* commands: 'PATTERN{COMMAND}'. PATTERN为模式(正在表达式),COMMAND为要执行的命令.\n\n```awk\nawk  -F ':'  'BEGIN {print \"start\"}  {print $1\"} END {print \"end\"}' ./txt\n```\n上面的例子是读取`txt`文件,然后使用`:`分割每一行数据,在开始处理的时候输出start，在处理过程中第一列数据，最后输出end。\n\n## 变量\n\n### 内置变量\n我们可以在AWK命令中直接使用以下内置变量\n```awk\nARGC               命令行参数个数\nARGV               命令行参数排列\nENVIRON            支持队列中系统环境变量的使用\nFILENAME           awk浏览的文件名\nFNR                浏览文件的记录数\nFS                 设置输入域分隔符，等价于命令行 -F选项\nNF                 浏览记录的域的个数\nNR                 已读的记录数\nOFS                输出域分隔符\nORS                输出记录分隔符\nRS                 控制记录分隔符\n```\n例如\n```awk\njps -l | awk '{print ARGC}'\n```\n\n### 自定义变量\n我们通过赋值的方式直接定义一个变量\n```awk\njps -l | awk 'BEGIN{size=0;} {size=1+size} {print $1} END{print size}'\n```\n上面我们定义了一个数值型的size变量.\n\n### 数组\n\n# 运算符\n* `= += -= *= /= %= ^= **=`\t赋值\n* `?:`\tC条件表达式\n* `||`\t逻辑或\n* `&&`\t逻辑与\n* `~ ~!`\t匹配正则表达式和不匹配正则表达式\n* `< <= > >= != ==`\t关系运算符\n* `空格`\t连接\n* `+ -`\t加，减\n* `* / &`\t乘，除与求余\n* `+ - !`\t一元加，减和逻辑非\n* `^ ***`\t求幂\n* `++ --`\t增加或减少，作为前缀或后缀\n* `$`\t字段引用\n* `in`\t数组成员\n\n\n# 流程控制\n## 条件语句\n下面输出了大于10000的java进程号\n```awk\njps -l | awk 'BEGIN{size=0} {if($1>10000) {size++;print $1}} END{print size}'\n```\n\n## 循环语句\nawk中的循环语句借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。\n\n# 字符串处理\n## sub函数\n匹配从左侧开始找到的第一个符合规则的字符串，然后使用替换字符串替换这些字符串\n```awk\njps -l | awk '{sub(/moon/, \"sun\")} {print $2}'\n```\n上面这个例子就使用sun这个字符串替换了$2中的moon字符串。\n\n我们还可以指定在哪列执行查找替换\n```awk\njps -l | awk '{sub(/moon/, \"sun\", $1)} {print $2}'\n```\n上面的例子中我们只在第一列进行查找替换\n\n## gsub函数\n与sub函数不同的是，这个执行的是全局替换\n```awk\njps -l | awk '{gsub(/moon/, \"sun\")} {print $2}'\n```\n\n## index函数\n返回子字符串第一次被匹配的位置，偏移量从位置1开始\n```awk\njps -l | awk '{print$2; $2=index($2, \"moon\")} {print $2}'\n```\n\n## length函数\n返回记录的字符数\n```awk\njps -l | awk '{print$2; $2=length($2)} {print $2}'\n```\n\n## substr函数\n返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串\n```awk\njps -l | awk '{print substr($2, 2, 10)} '\n```\n上面的例子将$2字符串从第二个字符还是截取，截取10个长度的字符串出来\n\n## toupper和tolower函数\n可用于字符串大小间的转换\n```awk\nawk '{print toupper($2)} '\n```\n\n## split函数\n可按给定的分隔符把字符串分割为一个数组\n```awk\njps -l | awk '{ split($2, array, \"/\"); print array[3]} '\n```\n上面的例子我们将$2这一列按照`/`进行分割,然后将分割出的数据存储到array数组里. 注意这里首先不需要转义\n\n\n# 正则表达式\n\n## \\\n将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配换行符。序列“\\\\”匹配“\\”，“\\(”匹配“(”。\n```awk\nawk '/\\\\/{print $0}' ./txt\n```\n过滤出带有`\\`的行\n\n## ^\n匹配输入字符串与最左侧开始的位置的字符串。\n```awk\nawk '/^\\\\n/{print $0}' ./txt\n```\n找到所有以`\\n`字符串开始的数据\n\n## $\n匹配输入字符串结尾的位置。\n```awk\nawk '/)。$/{print $0}' ./txt\n```\n过滤以`)。`结尾的行\n\n## *\n零次或多次匹配前面的字符或子表达式。例如，zo* 匹配“z”和“zoo”。* 等效于 {0,}。\n```awk\nawk '/反向引用*/{print $0}' ./txt\n```\n\n## +\n一次或多次匹配前面的字符或子表达式。例如，“zo+”与“zo”和“zoo”匹配，但与“z”不匹配。+ 等效于 {1,}。\n```awk\nawk '/反向引用+/{print $0}' ./txt\n```\n\n## ?\n零次或一次匹配前面的字符或子表达式。例如，“do(es)?”匹配“do”或“does”中的“do”。? 等效于 {0,1}。\n```awk\nawk '/反向引用?/{print $0}' ./txt\n```\n\n## {n}\nn 是非负整数。正好匹配 n 次。例如，“o{2}”与“Bob”中的“o”不匹配，但与“food”中的两个“o”匹配。\n```awk\n\n```\n\n## {n,}\nn 是非负整数。至少匹配 n 次。例如，“o{2,}”不匹配“Bob”中的“o”，而匹配“foooood”中的所有 o。“o{1,}”等效于“o+”。“o{0,}”等效于“o*”。\n```awk\n\n```\n\n## {n,m}\nM 和 n 是非负整数，其中 n <= m。匹配至少 n 次，至多 m 次。例如，“o{1,3}”匹配“fooooood”中的头三个 o。'o{0,1}' 等效于 'o?'。注意：您不能将空格插入逗号和数字之间。\n```awk\n\n```\n\n## .\n匹配除“\\n”之外的任何单个字符。若要匹配包括“\\n”在内的任意字符，请使用诸如“[\\s\\S]”之类的模式。\n```awk\n\n```\n\n## (pattern)\n匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果“匹配”集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用“\\(”或者“\\)”。\n```awk\n\n```\n\n## (?:pattern)\n匹配 pattern 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用“or”字符 (|) 组合模式部件的情况很有用。例如，'industr(?:y|ies) 是比 'industry|industries' 更经济的表达式。\n```awk\n\n```\n\n## (?=pattern)\n执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 pattern 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?=95|98|NT|2000)' 匹配“Windows 2000”中的“Windows”，但不匹配“Windows 3.1”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```awk\n\n```\n\n## (?!pattern)\n执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 pattern 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?!95|98|NT|2000)' 匹配“Windows 3.1”中的 “Windows”，但不匹配“Windows 2000”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```awk\n\n```\n\n## x|y\n匹配 x 或 y。\n```awk\n awk '/换页符等|十六进制转义码必须正好是两位数长/ {print $0}' ./txt\n```\n\n## [xyz]\n匹配是否包含xyz中任意一个字符\n```awk\nawk '/[前面至少有]/ {print $0}' ./txt\n```\n\n## [^xyz]\n匹配不能包含xyz任意一个字符\n```awk\nawk '/[^前面至少有]/ {print $0}' ./txt\n```\n\n## [a-z]\n与`[xyz]`规则相同,只不过这个模式提供了一个范围模式.例如[a-c]实际为匹配[abc]\n```awk\nawk '/[a-b]/ {print $0}' ./txt\n```\n\n## [^a-z]\n反向范围字符。匹配不在指定的范围内的任何字符。例如，“[^a-z]”匹配任何不在“a”到“z”范围内的任何字符。\n```awk\nawk '/[^a-z]/ {print $0}' ./txt\n```\n需要注意的是'\\t'会被匹配出来\n\n## \\d\n数字字符匹配。等效于 [0-9]。\n```awk\nawk '/\\d/ {print $0}' ./txt\n```\n\n## \\D\n非数字字符匹配。等效于 [^0-9]。\n```awk\nawk '/\\D/ {print $0}' ./txt\n```\n\n## \\n\n换行符匹配。等效于 \\x0a 和 \\cJ。\n```awk\nawk '/\\n/ {print $0}' ./txt\n```\n\n## \\r\n匹配一个回车符。等效于 \\x0d 和 \\cM。\n```awk\n awk '/\\t/ {print $0}' ./txt\n```\n\n## \\s\n匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\n```awk\nawk '/\\s/ {print $0}' ./txt\n```\n\n## \\S\n匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\n```awk\nawk '/\\S/ {print $0}' ./txt\n```\n\n## \\w\n匹配任何字类字符，包括下划线。与“[A-Za-z0-9_]”等效。\n```awk\nawk '/\\w/ {print $0}' ./txt\n```\n\n## \\W\n与任何非单词字符匹配。与“[^A-Za-z0-9_]”等效。\n```awk\nawk '/\\W/ {print $0}' ./txt\n```\n","slug":"linux/2015-10-12-AWK","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihuv006lvjs6uv82xdb5"},{"date":"2015-10-14T16:00:00.000Z","title":"Linux常用命令","_content":"## gzip\n将文件或者文件夹压缩成后缀为`.gz`的文件\n\n* `-a` 　使用ASCII文字模式.\n* `-c` 　把压缩后的文件输出到标准输出设备,不去更动原始文件.\n* `-d` 　解开压缩文件.\n* `-f` 　强行压缩文件.不理会文件名称或硬连接是否存在以及该文件是否为符号连接.\n* `-l` 　列出压缩文件的相关信息.\n* `-L` 　显示版本与版权信息.\n* `-n` 　压缩文件时,不保存原来的文件名称及时间戳记.\n* `-N` 　压缩文件时,保存原来的文件名称及时间戳记.\n* `-q` 　不显示警告信息.\n* `-r` 　递归处理,将指定目录下的所有文件及子目录一并处理.\n* `-S` 　更改压缩字尾字符串.\n* `-t` 　测试压缩文件是否正确无误.\n* `-v` 　显示指令执行过程.\n* `-num` 用指定的数字num调整压缩的速度,-1或--fast表示最快压缩方法（低压缩比）,-9或--best表示最慢压缩方法（高压缩比）.系统缺省值为6.\n\n常用命令\n* `gzip *`  把test6目录下的每个文件压缩成.gz文件\n* `gzip -dv *` 把例1中每个压缩的文件解压,并列出详细的信息\n* `gzip -l *` 详细显示例1中每个压缩的文件的信息,并不解压\n* `gzip -r log.tar` 压缩一个tar备份文件,此时压缩文件的扩展名为.tar.gz\n* `gzip -rv test6` 递归的压缩目录\n* `gzip -dr test6` 递归地解压目录\n\n## tar\ntar可用于建立,还原,查看,管理文件,也可方 便的追加新文件到备份文件中,或仅更新部分的备份文件,以及解压,删除指定的文件\n\n将tar.gz提取到新目录里：\n```shell\ntar zxvf package.tar.gz -C new_dir\n```\n将small目录压缩到small.tar.gz里\n```shell\ntar -czf small.tar.gz small \n```\n压缩为zip, 且忽略指定目录\n```shell\ntar -zcvf  web.zip --exclude=\"restful\" web/\n```\n> --exclude=\"restful\"  一定要放在压缩文件和被压缩文件夹之间\n\n## sort\nsort将文件的每一行作为一个单位,相互比较,比较原则是从首字符向后,依次按ASCII码值进行比较,最后将他们按升序输出.\n\n命令参数\n* `-u` 在输出行中去除重复行.\n* `-r` sort默认的排序方式是升序,加-r改成降序\n* `-o` 将排序结果输出到原文件,而使用重定向是不可以的.\n* `-n` sort命令默认是按照字符排序的,如果遇到数字的字符, 可能会出现1大于10的情况, 所以我们可以设定`-n`选项, 将其按照数字排序\n* `-t` 设定间隔符. 设置间隔符,就会将每一行分割成一个数组,我们可以使用-k参数指定按照某列排序\n* `-k` -t指定了间隔符之后,可以用-k指定基于某列排序.\n* `-f` 会将小写字母都转换为大写字母来进行比较,亦即忽略大小写\n* `-c` 会检查文件是否已排好序,如果乱序,则输出第一个乱序的行的相关信息,最后返回1\n* `-C` 会检查文件是否已排好序,如果乱序,不输出内容,仅返回1\n* `-M` 会以月份来排序,比如JAN小于FEB等等\n* `-b` 会忽略每一行前面的所有空白部分,从第一个可见字符开始比较.\n\n## wc\n统计指定文件中的字节数,字数,行数,并将统计结果显示输出.该命令统计指定文件中的字节数,字数,行数.如果没有给出文件名,则从标准输入读取.wc同时也给出所指定文件的总统计数.\n\n* `-c` 统计字节数.\n* `-l` 统计行数.\n* `-m` 统计字符数.这个标志不能与 -c 标志一起使用.\n* `-w` 统计字数.一个字被定义为由空白,跳格或换行字符分隔的字符串.\n* `-L` 打印最长行的长度.\n\n## find\n\n`find pathname -options [-print -exec -ok ...]`\n\n命令参数；\n`pathname`: 要查找的路径.\n`-print`： find命令将匹配的文件输出到标准输出.\n`-exec`： 匹配到合适文件后执行的shell命令.相应命令的形式为`'command' { } ;`(注意{ }和；之间的空格).\n`-ok`： 和-exec的作用相同,但是在执行命令之前,都会给出提示确认是否真的执行.\n\noptions选项\n* `-name` 要查找的文件名(可以使用正则).\n* `-perm` 按照文件权限查找文件.\n* `-prune` 使用这一选项可以使find命令不在当前指定的目录中查找,如果同时使用-depth选项,那么-prune将被find命令忽略.\n* `-user` 按照文件属主来查找文件.\n* `-group` 按照文件所属的组来查找文件.\n* `-mtime -n +n` 按照文件的更改时间来查找文件, - n表示文件更改时间距现在n天以内,+ n表示文件更改时间距现在n天以前.\n* `-nogroup` 查找无有效所属组的文件,即该文件所属的组在/etc/groups中不存在.\n* `-nouser` 查找无有效属主的文件,即该文件的属主在/etc/passwd中不存在.\n* `-newer file1 ! file2` 查找更改时间比文件file1新但比文件file2旧的文件.\n* `-type` 查找某一类型的文件(例如: `-b`块设备文件. `-d`目录. `-c`字符设备文件. `-p`管道文件. `-l`符号链接文件. `-f`普通文件.)\n* `-size n [c]`：查找文件长度为n块的文件,带有c时表示文件长度以字节计.\n* `-depth`：在查找文件时,首先查找当前目录中的文件,然后再在其子目录中查找.\n* `-mount`：在查找文件时不跨越文件系统mount点.\n* `-follow`：如果find命令遇到符号链接文件,就跟踪至链接所指向的文件.\n\n另外,下面三个的区别:\n* `-amin n`  查找系统中最后N分钟访问的文件\n* `-atime n` 查找系统中最后n*24小时访问的文件\n* `-cmin n`  查找系统中最后N分钟被改变文件状态的文件\n* `-ctime n` 查找系统中最后n*24小时被改变文件状态的文件\n* `-mmin n`  查找系统中最后N分钟被改变文件数据的文件\n* `-mtime n` 查找系统中最后n*24小时被改变文件数据的文件\n找出/home/user下所有空子目录：\n```shell\nfind /home/user -maxdepth 1 -type d -empty\n```\n获取test.txt文件中第50-60行内容：\n```shell\n< test.txt sed -n '50,60p'\n```\n将所有文件名中含有”txt”的文件移入/home/user目录：\n```shell\nfind -iname \"*txt*\" -exec mv -v {} /home/user \\;\n```\n\n## grep\n一种强大的文本搜索工具,它能使用正则表达式搜索文本,并把匹 配的行打印出来\n\n用法: `grep [选项]... PATTERN [FILE]...`. 在每个 FILE 或是标准输入中查找 PATTERN.默认的 PATTERN 是一个基本正则表达式(缩写为 BRE).\n```shell\ngrep -i 'hello world' menu.h main.c\n```\n\n主要参数：\n* `－c`：只输出匹配行的计数.\n* `－I`：不区分大小写(只适用于单字符).\n* `－h`：查询多文件时不显示文件名.\n* `－l`：查询多文件时只输出包含匹配字符的文件名.\n* `－n`：显示匹配行及行号.\n* `－s`：不显示不存在或无匹配文本的错误信息.\n* `－v`：显示不包含匹配文本的所有行.\n\npattern正则表达式主要参数：\n* `\\`： 忽略正则表达式中特殊字符的原有含义.\n* `^`：匹配正则表达式的开始行.\n* `$`: 匹配正则表达式的结束行.\n* `\\<`：从匹配正则表达 式的行开始.\n* `\\>`：到匹配正则表达式的行结束.\n* `[ ]`：单个字符,如[A]即A符合要求 .\n* `[ - ]`：范围,如[A-Z],即A,B,C一直到Z都符合要求 .\n* `.`：所有的单个字符.\n* `*` ：有字符,长度可以为0.\n\n正则表达式选择与解释:\n* `-E`     PATTERN 是一个可扩展的正则表达式(缩写为 ERE)\n* `-F`     PATTERN 是一组由断行符分隔的定长字符串.\n* `-G`     PATTERN 是一个基本正则表达式(缩写为 BRE)\n* `-e`     用 PATTERN 来进行匹配操作\n* `-f`     从 FILE 中取得 PATTERN\n* `-i`     忽略大小写\n* `-w`     强制 PATTERN 仅完全匹配字词\n* `-x`     强制 PATTERN 仅完全匹配一行\n* `-z`     一个 0 字节的数据行,但不是空行\n\n输出控制:\n* `-m` : 只获得前m个匹配结果\n* `-b` : 在输出的内容中打印byte offset\n* `-n` : 输出行号\n* `  ` : 每一行都输出, 不再行上进行缓存\n* `-H` : 输出文件名\n* `-h` : 不输出文件名\n* `-o` : 仅仅输出一行中符合 PATTERN模式 匹配要求的部分\n* `-a` : 等同于 --binary-files=text\n* `-I` : 等同于 --binary-files=without-match\n* `-d` : 处理目录方式; `read', `recurse', or `skip'\n* `-D` : 处理 devices, FIFOs and sockets的方式: `read' or `skip'\n* `-R` : equivalent to --directories=recurse\n>    --include=FILE_PATTERN  仅对符合FILE_PATTERN模式的文件进行搜索\n>     --exclude=FILE_PATTERN  跳过符合FILE_PATTERN的文件和目录\n>     --exclude-from=FILE   跳过符合FILE中file pattern所有的文件\n>     --exclude-dir=PATTERN  符合PATTERN模式的目录将被跳过.\n* `-L` :  只输出匹配失败的文件名\n* `-l` : 只输出匹配成功的文件名\n* `-c` : 只输出每个文件匹配成功的行数\n* `-Z` : 在文件名后输出0 byte\n\nContext control:\n* -B, --before-context=NUM  显示匹配字符串前n行的数据\n* -A, --after-context=NUM   显示匹配字符串后n行的数据\n* -C, --context=NUM         print NUM lines of output context\n* -NUM                      和 --context=NUM 一样\n\n当前目录下有多个文件我们想要同时对所有文件进行搜索的话, 我们可以使用\n```shell\ngrep \"刷新\" *\n```\n如果我们只想对今天的文件进行搜索的话, 可以使用\n```shell\ngrep \"刷新\" *2016-02-02*\n```\n如果我们的目录下有多个目录, 要搜索的文件都在当前的子目录里的话, 可以使用\n```shell\ngrep --directories=recurse \"刷新\" *\n```\n递归grep所有目录：\n```shell\ngrep -r \"some_text\" /path/to/dir\n```\n\n## cat,more,less\n* cat是一次性显示整个文件的内容,还可以将多个文件连接起来显示,它常与重定向符号配合使用,适用于文件内容少的情况；\n* more比cat强大,提供分页显示的功能\n* less比more更强大,提供翻页,跳转,查找等命令.\n\n## source\n1. 当shell脚本具有可执行权限时,用sh filename与./filename执行脚本是没有区别得../filename是因为当前目录没有在PATH中,所有\".\"是用来表示当前目录的.\n2. sh filename 重新建立一个子shell,在子shell中执行脚本里面的语句,该子shell继承父shell的环境变量,但子shell新建的,改变的变量不会被带回父shell,除非使用export.\n3. source filename：这个命令其实只是简单地读取脚本里面的语句依次在当前shell里面执行,没有建立新的子shell.那么脚本里面所有新建,改变变量的语句都会保存在当前shell里面.\n\n## wget\n用wget抓取完整的网站目录结构,存放到本地目录中：\n```shell\nwget -r --no-parent --reject \"index.html*\" http://hostname/ -P /home/user/dirs\n```\n用wget命令执行ftp下载：\n```shell\nwget -m ftp:\n//username:password@hostname\n```\n\n## mkdir\n一次创建多个目录：\n```shell\nmkdir -p /home/user/{test,test1,test2}\n```\n\n## ps\n列出包括子进程的进程树：\n```shell\nps axwef\n```\n\n## dd\n测试硬盘写入速度：\n```shell\ndd if=/dev/zero of=/tmp/output.img bs=8k count=256k; rm -rf /tmp/output.img\n```\n\n测试硬盘读取速度：\n```shell\nhdparm -Tt /dev/sda\n```\n\n## xmllint\n检查xml格式：\n```shell\nxmllint --noout file.xml\n```\n\n## curl\n使用curl获取HTTP头信息：\n```shell\ncurl -I http://www.example.com\n```\n指定header\n```shell\ncurl --header \"Auth: none\" http://www.example.com\n```\nPOST请求\n```shell\ncurl -d \"user=test&time=now\" http://www.example.com\n```\n\n## touch\n修改文件或目录的时间戳(YYMMDDhhmm)：\n```shell\ntouch -t 0712250000 file\n```\n\n## cp\n快速备份一个文件：\n```shell\ncp some_file_name{,.bkp}\n```\n\n## watch\n重复运行文件,显示其输出（缺省是2秒一次）：\n```shell\nwatch ps -ef\n```\n\n## lsof\n列出前10个最大的文件：\n```shell\nlsof / | awk '{ if($7 > 1048576) print $7/1048576 \"MB \"$9 }' | sort -n -u | tail\n```\n\n## free\n显示剩余内存(MB)：\n```shell\nfree -m | grep cache | awk '/[0-9]/{ print $4\" MB\" }'\n```\n\n## paste\n将文件按行并列显示：\n```shell\npaste test.txt test1.txt\n```\n\n## pv\nshell里的进度条：\n```shell\npv data.log\n```\n\n## scp\n文件复制：本机->远程服务器：\n```xml\nscp /home/shaoxiaohu/test1.txt shaoxiaohu@172.16.18.1:/home/test2.txt  \n```\n> 其中，test1为源文件，test2为目标文件，shaoxiaohu@172.16.18.1为远程服务器的用户名和ip地址。\n\n文件复制：远程服务器->本机\n```xml\nscp shaoxiaohu@172.16.18.2:/home/test2.txt /home/shaoxiaohu/test1.txt  \n```\n> 其中，haoxiaohu@172.16.18.2为远程服务器的用户名和ip地址， test2为源文件，test1为目标路径\n\n文件夹复制, 在scp命令后加`-r`参数即可。\n\n端口号, 如果端口号有更改，需在scp 后输入：`-P` 端口号 （注意是大写，ssh的命令中 `-p`是小写）。\n","source":"_posts/linux/Linux常用命令.md","raw":"category: linux\ndate: 2015-10-15\ntitle: Linux常用命令\n---\n## gzip\n将文件或者文件夹压缩成后缀为`.gz`的文件\n\n* `-a` 　使用ASCII文字模式.\n* `-c` 　把压缩后的文件输出到标准输出设备,不去更动原始文件.\n* `-d` 　解开压缩文件.\n* `-f` 　强行压缩文件.不理会文件名称或硬连接是否存在以及该文件是否为符号连接.\n* `-l` 　列出压缩文件的相关信息.\n* `-L` 　显示版本与版权信息.\n* `-n` 　压缩文件时,不保存原来的文件名称及时间戳记.\n* `-N` 　压缩文件时,保存原来的文件名称及时间戳记.\n* `-q` 　不显示警告信息.\n* `-r` 　递归处理,将指定目录下的所有文件及子目录一并处理.\n* `-S` 　更改压缩字尾字符串.\n* `-t` 　测试压缩文件是否正确无误.\n* `-v` 　显示指令执行过程.\n* `-num` 用指定的数字num调整压缩的速度,-1或--fast表示最快压缩方法（低压缩比）,-9或--best表示最慢压缩方法（高压缩比）.系统缺省值为6.\n\n常用命令\n* `gzip *`  把test6目录下的每个文件压缩成.gz文件\n* `gzip -dv *` 把例1中每个压缩的文件解压,并列出详细的信息\n* `gzip -l *` 详细显示例1中每个压缩的文件的信息,并不解压\n* `gzip -r log.tar` 压缩一个tar备份文件,此时压缩文件的扩展名为.tar.gz\n* `gzip -rv test6` 递归的压缩目录\n* `gzip -dr test6` 递归地解压目录\n\n## tar\ntar可用于建立,还原,查看,管理文件,也可方 便的追加新文件到备份文件中,或仅更新部分的备份文件,以及解压,删除指定的文件\n\n将tar.gz提取到新目录里：\n```shell\ntar zxvf package.tar.gz -C new_dir\n```\n将small目录压缩到small.tar.gz里\n```shell\ntar -czf small.tar.gz small \n```\n压缩为zip, 且忽略指定目录\n```shell\ntar -zcvf  web.zip --exclude=\"restful\" web/\n```\n> --exclude=\"restful\"  一定要放在压缩文件和被压缩文件夹之间\n\n## sort\nsort将文件的每一行作为一个单位,相互比较,比较原则是从首字符向后,依次按ASCII码值进行比较,最后将他们按升序输出.\n\n命令参数\n* `-u` 在输出行中去除重复行.\n* `-r` sort默认的排序方式是升序,加-r改成降序\n* `-o` 将排序结果输出到原文件,而使用重定向是不可以的.\n* `-n` sort命令默认是按照字符排序的,如果遇到数字的字符, 可能会出现1大于10的情况, 所以我们可以设定`-n`选项, 将其按照数字排序\n* `-t` 设定间隔符. 设置间隔符,就会将每一行分割成一个数组,我们可以使用-k参数指定按照某列排序\n* `-k` -t指定了间隔符之后,可以用-k指定基于某列排序.\n* `-f` 会将小写字母都转换为大写字母来进行比较,亦即忽略大小写\n* `-c` 会检查文件是否已排好序,如果乱序,则输出第一个乱序的行的相关信息,最后返回1\n* `-C` 会检查文件是否已排好序,如果乱序,不输出内容,仅返回1\n* `-M` 会以月份来排序,比如JAN小于FEB等等\n* `-b` 会忽略每一行前面的所有空白部分,从第一个可见字符开始比较.\n\n## wc\n统计指定文件中的字节数,字数,行数,并将统计结果显示输出.该命令统计指定文件中的字节数,字数,行数.如果没有给出文件名,则从标准输入读取.wc同时也给出所指定文件的总统计数.\n\n* `-c` 统计字节数.\n* `-l` 统计行数.\n* `-m` 统计字符数.这个标志不能与 -c 标志一起使用.\n* `-w` 统计字数.一个字被定义为由空白,跳格或换行字符分隔的字符串.\n* `-L` 打印最长行的长度.\n\n## find\n\n`find pathname -options [-print -exec -ok ...]`\n\n命令参数；\n`pathname`: 要查找的路径.\n`-print`： find命令将匹配的文件输出到标准输出.\n`-exec`： 匹配到合适文件后执行的shell命令.相应命令的形式为`'command' { } ;`(注意{ }和；之间的空格).\n`-ok`： 和-exec的作用相同,但是在执行命令之前,都会给出提示确认是否真的执行.\n\noptions选项\n* `-name` 要查找的文件名(可以使用正则).\n* `-perm` 按照文件权限查找文件.\n* `-prune` 使用这一选项可以使find命令不在当前指定的目录中查找,如果同时使用-depth选项,那么-prune将被find命令忽略.\n* `-user` 按照文件属主来查找文件.\n* `-group` 按照文件所属的组来查找文件.\n* `-mtime -n +n` 按照文件的更改时间来查找文件, - n表示文件更改时间距现在n天以内,+ n表示文件更改时间距现在n天以前.\n* `-nogroup` 查找无有效所属组的文件,即该文件所属的组在/etc/groups中不存在.\n* `-nouser` 查找无有效属主的文件,即该文件的属主在/etc/passwd中不存在.\n* `-newer file1 ! file2` 查找更改时间比文件file1新但比文件file2旧的文件.\n* `-type` 查找某一类型的文件(例如: `-b`块设备文件. `-d`目录. `-c`字符设备文件. `-p`管道文件. `-l`符号链接文件. `-f`普通文件.)\n* `-size n [c]`：查找文件长度为n块的文件,带有c时表示文件长度以字节计.\n* `-depth`：在查找文件时,首先查找当前目录中的文件,然后再在其子目录中查找.\n* `-mount`：在查找文件时不跨越文件系统mount点.\n* `-follow`：如果find命令遇到符号链接文件,就跟踪至链接所指向的文件.\n\n另外,下面三个的区别:\n* `-amin n`  查找系统中最后N分钟访问的文件\n* `-atime n` 查找系统中最后n*24小时访问的文件\n* `-cmin n`  查找系统中最后N分钟被改变文件状态的文件\n* `-ctime n` 查找系统中最后n*24小时被改变文件状态的文件\n* `-mmin n`  查找系统中最后N分钟被改变文件数据的文件\n* `-mtime n` 查找系统中最后n*24小时被改变文件数据的文件\n找出/home/user下所有空子目录：\n```shell\nfind /home/user -maxdepth 1 -type d -empty\n```\n获取test.txt文件中第50-60行内容：\n```shell\n< test.txt sed -n '50,60p'\n```\n将所有文件名中含有”txt”的文件移入/home/user目录：\n```shell\nfind -iname \"*txt*\" -exec mv -v {} /home/user \\;\n```\n\n## grep\n一种强大的文本搜索工具,它能使用正则表达式搜索文本,并把匹 配的行打印出来\n\n用法: `grep [选项]... PATTERN [FILE]...`. 在每个 FILE 或是标准输入中查找 PATTERN.默认的 PATTERN 是一个基本正则表达式(缩写为 BRE).\n```shell\ngrep -i 'hello world' menu.h main.c\n```\n\n主要参数：\n* `－c`：只输出匹配行的计数.\n* `－I`：不区分大小写(只适用于单字符).\n* `－h`：查询多文件时不显示文件名.\n* `－l`：查询多文件时只输出包含匹配字符的文件名.\n* `－n`：显示匹配行及行号.\n* `－s`：不显示不存在或无匹配文本的错误信息.\n* `－v`：显示不包含匹配文本的所有行.\n\npattern正则表达式主要参数：\n* `\\`： 忽略正则表达式中特殊字符的原有含义.\n* `^`：匹配正则表达式的开始行.\n* `$`: 匹配正则表达式的结束行.\n* `\\<`：从匹配正则表达 式的行开始.\n* `\\>`：到匹配正则表达式的行结束.\n* `[ ]`：单个字符,如[A]即A符合要求 .\n* `[ - ]`：范围,如[A-Z],即A,B,C一直到Z都符合要求 .\n* `.`：所有的单个字符.\n* `*` ：有字符,长度可以为0.\n\n正则表达式选择与解释:\n* `-E`     PATTERN 是一个可扩展的正则表达式(缩写为 ERE)\n* `-F`     PATTERN 是一组由断行符分隔的定长字符串.\n* `-G`     PATTERN 是一个基本正则表达式(缩写为 BRE)\n* `-e`     用 PATTERN 来进行匹配操作\n* `-f`     从 FILE 中取得 PATTERN\n* `-i`     忽略大小写\n* `-w`     强制 PATTERN 仅完全匹配字词\n* `-x`     强制 PATTERN 仅完全匹配一行\n* `-z`     一个 0 字节的数据行,但不是空行\n\n输出控制:\n* `-m` : 只获得前m个匹配结果\n* `-b` : 在输出的内容中打印byte offset\n* `-n` : 输出行号\n* `  ` : 每一行都输出, 不再行上进行缓存\n* `-H` : 输出文件名\n* `-h` : 不输出文件名\n* `-o` : 仅仅输出一行中符合 PATTERN模式 匹配要求的部分\n* `-a` : 等同于 --binary-files=text\n* `-I` : 等同于 --binary-files=without-match\n* `-d` : 处理目录方式; `read', `recurse', or `skip'\n* `-D` : 处理 devices, FIFOs and sockets的方式: `read' or `skip'\n* `-R` : equivalent to --directories=recurse\n>    --include=FILE_PATTERN  仅对符合FILE_PATTERN模式的文件进行搜索\n>     --exclude=FILE_PATTERN  跳过符合FILE_PATTERN的文件和目录\n>     --exclude-from=FILE   跳过符合FILE中file pattern所有的文件\n>     --exclude-dir=PATTERN  符合PATTERN模式的目录将被跳过.\n* `-L` :  只输出匹配失败的文件名\n* `-l` : 只输出匹配成功的文件名\n* `-c` : 只输出每个文件匹配成功的行数\n* `-Z` : 在文件名后输出0 byte\n\nContext control:\n* -B, --before-context=NUM  显示匹配字符串前n行的数据\n* -A, --after-context=NUM   显示匹配字符串后n行的数据\n* -C, --context=NUM         print NUM lines of output context\n* -NUM                      和 --context=NUM 一样\n\n当前目录下有多个文件我们想要同时对所有文件进行搜索的话, 我们可以使用\n```shell\ngrep \"刷新\" *\n```\n如果我们只想对今天的文件进行搜索的话, 可以使用\n```shell\ngrep \"刷新\" *2016-02-02*\n```\n如果我们的目录下有多个目录, 要搜索的文件都在当前的子目录里的话, 可以使用\n```shell\ngrep --directories=recurse \"刷新\" *\n```\n递归grep所有目录：\n```shell\ngrep -r \"some_text\" /path/to/dir\n```\n\n## cat,more,less\n* cat是一次性显示整个文件的内容,还可以将多个文件连接起来显示,它常与重定向符号配合使用,适用于文件内容少的情况；\n* more比cat强大,提供分页显示的功能\n* less比more更强大,提供翻页,跳转,查找等命令.\n\n## source\n1. 当shell脚本具有可执行权限时,用sh filename与./filename执行脚本是没有区别得../filename是因为当前目录没有在PATH中,所有\".\"是用来表示当前目录的.\n2. sh filename 重新建立一个子shell,在子shell中执行脚本里面的语句,该子shell继承父shell的环境变量,但子shell新建的,改变的变量不会被带回父shell,除非使用export.\n3. source filename：这个命令其实只是简单地读取脚本里面的语句依次在当前shell里面执行,没有建立新的子shell.那么脚本里面所有新建,改变变量的语句都会保存在当前shell里面.\n\n## wget\n用wget抓取完整的网站目录结构,存放到本地目录中：\n```shell\nwget -r --no-parent --reject \"index.html*\" http://hostname/ -P /home/user/dirs\n```\n用wget命令执行ftp下载：\n```shell\nwget -m ftp:\n//username:password@hostname\n```\n\n## mkdir\n一次创建多个目录：\n```shell\nmkdir -p /home/user/{test,test1,test2}\n```\n\n## ps\n列出包括子进程的进程树：\n```shell\nps axwef\n```\n\n## dd\n测试硬盘写入速度：\n```shell\ndd if=/dev/zero of=/tmp/output.img bs=8k count=256k; rm -rf /tmp/output.img\n```\n\n测试硬盘读取速度：\n```shell\nhdparm -Tt /dev/sda\n```\n\n## xmllint\n检查xml格式：\n```shell\nxmllint --noout file.xml\n```\n\n## curl\n使用curl获取HTTP头信息：\n```shell\ncurl -I http://www.example.com\n```\n指定header\n```shell\ncurl --header \"Auth: none\" http://www.example.com\n```\nPOST请求\n```shell\ncurl -d \"user=test&time=now\" http://www.example.com\n```\n\n## touch\n修改文件或目录的时间戳(YYMMDDhhmm)：\n```shell\ntouch -t 0712250000 file\n```\n\n## cp\n快速备份一个文件：\n```shell\ncp some_file_name{,.bkp}\n```\n\n## watch\n重复运行文件,显示其输出（缺省是2秒一次）：\n```shell\nwatch ps -ef\n```\n\n## lsof\n列出前10个最大的文件：\n```shell\nlsof / | awk '{ if($7 > 1048576) print $7/1048576 \"MB \"$9 }' | sort -n -u | tail\n```\n\n## free\n显示剩余内存(MB)：\n```shell\nfree -m | grep cache | awk '/[0-9]/{ print $4\" MB\" }'\n```\n\n## paste\n将文件按行并列显示：\n```shell\npaste test.txt test1.txt\n```\n\n## pv\nshell里的进度条：\n```shell\npv data.log\n```\n\n## scp\n文件复制：本机->远程服务器：\n```xml\nscp /home/shaoxiaohu/test1.txt shaoxiaohu@172.16.18.1:/home/test2.txt  \n```\n> 其中，test1为源文件，test2为目标文件，shaoxiaohu@172.16.18.1为远程服务器的用户名和ip地址。\n\n文件复制：远程服务器->本机\n```xml\nscp shaoxiaohu@172.16.18.2:/home/test2.txt /home/shaoxiaohu/test1.txt  \n```\n> 其中，haoxiaohu@172.16.18.2为远程服务器的用户名和ip地址， test2为源文件，test1为目标路径\n\n文件夹复制, 在scp命令后加`-r`参数即可。\n\n端口号, 如果端口号有更改，需在scp 后输入：`-P` 端口号 （注意是大写，ssh的命令中 `-p`是小写）。\n","slug":"linux/Linux常用命令","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihuy006nvjs6q8k2um22"},{"date":"2015-10-14T16:00:00.000Z","title":"Linux系统命令","_content":"### Vmstat\nvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。\n\n一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:\n```shell\n[root@cvs /]# vmstat 2 1\n=>\nprocs  -----------memory----------     ---swap--  -----io----  --system--   -----cpu-----\n r  b    swpd   free   buff  cache      si   so     bi    bo    in   cs     us sy id wa st\n 1  0  1339624 525012 464316 6796908    0    0      5    32     0    0      2  0 98  0  0\n```\n参数\n* -a：显示活跃和非活跃内存\n* -f：显示从系统启动至今的fork数量 。\n* -m：显示slabinfo\n* -n：只在开始时显示一次各字段名称。\n* -s：显示内存相关统计信息及多种系统活动数量。\n* delay：刷新时间间隔。如果不指定，只显示一条结果。\n* count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。\n* -d：显示磁盘相关统计信息。\n* -p：显示指定磁盘分区统计信息\n* -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）\n* -V：显示vmstat版本信息。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.gif)\n我们从上面那个图来解释各个参数\n> porcs\n* r：表示运行队列(分配到CPU进程数)\n* b：阻塞状态的进程数\n\n> memory\n* swpd：虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了\n* free：空闲的物理内存的大小\n* buff：作为buffer使用的内存数量（Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存）\n* cache：作为缓存使用的内存数量（ cache直接用来记忆我们打开的文件,给文件做缓冲）\n* inact：非活跃内存数\n* active： 活跃内存数\n\n> swap\n* si：从磁盘交换的内存量（每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了）\n* so：向磁盘交换的内存量（每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上）\n\n> io\n* bi：从阻塞设备接受到的块数据数量。\n* bo：向阻塞设备发送的块数据数量。\n\n> system\n* in：每秒CPU的中断次数，包括时间中断\n* cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目\n\n> cpu\n* us：用户CPU时间\n* sy：系统CPU时间\n* id：空闲 CPU时间\n* wa：等待IO CPU时间\n* st\n\n\n### pidstat\n监控锁竞争\n```shell\n[root@cvs /]# pidstat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月15日  _x86_64_        (8 CPU)\n\nPID    %usr %system  %guest    %CPU   CPU  Command\n```\n显式参数\n* PID : 被监控的任务的进程号\n* %usr :  当在用户层执行(应用程序)时这个任务的cpu使用率，和 nice 优先级无关。注意这个字段计算的cpu时间不包括在虚拟处理器中花去的时间。\n* %system :  这个任务在系统层使用时的cpu使用率。\n* %guest ：  任务花费在虚拟机上的cpu使用率（运行在虚拟处理器）。\n* %CPU ：  任务总的cpu使用率。在SMP环境(多处理器)中，如果在命令行中输入-I参数的话，cpu使用率会除以你的cpu数量。\n* CPU ： 正在运行这个任务的处理器编号。\n* Command ： 这个任务的命令名称。\n\n参数\n* -u: pidstat将显示各活动进程的cpu使用统计\n* -p: 我们可以查看特定进程的系统资源使用情况：\n* -r: pidstat将显示各活动进程的内存使用统计：\n* -d: 我们可以查看进程IO的统计信息\n\n-d:\n* kB_rd/s: 每秒进程从磁盘读取的数据量(以kB为单位)\n* kB_wr/s: 每秒进程向磁盘写的数据量(以kB为单位)\n* Command: 拉起进程对应的命令\n\n-r:\n* minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数\n* majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生\n* VSZ:      该进程使用的虚拟内存(以kB为单位)\n* RSS:      该进程使用的物理内存(以kB为单位)\n* %MEM:     该进程使用内存的百分比\n* Command:  拉起进程对应的命令\n\n\n### iostat\niostat用于输出CPU和磁盘I/O相关的统计信息.\n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n\n```shell\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`:\n* `%idle`: CPU空闲时间的百分比.\n\n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### uname\n* `-a` 　显示全部的信息。\n* `-m`　显示电脑类型。\n* `-n`　显示在网络上的主机名称。\n* `-r`　显示操作系统的发行编号。\n* `-s`　显示操作系统名称。\n* `-v` 　显示操作系统的版本。\n```xml\n[root@test game]# uname -a\nLinux test 2.6.32-431.el6.x86_64 #1 SMP Fri Nov 22 03:15:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n> 查看发行版本 `cat /etc/issue`\n\n### sar\n系统报告命令\n* `sar -q 1 5`    察看cpu的load状况，每1s钟统计1次，共统计5次\n* `sar -u 2 3`   察看cpu使用率，每2s统计1次，共统计3次\n* `sar -r`   察看当日内存占用情况(默认每10分钟统计一次)\n* `sar -b` 察看当日IO使用情况\n* `sar -n SOCK`   察看网络sock连接\n* `sar -n DEV` 察看网络流量\n\n\n### top  \n\n\n\n### df\n检查文件系统的磁盘空间占用情况\n* `-a` 显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统，如/proc文件系统。\n* `-k` 以k字节为单位显示。\n* `-i` 显示i节点信息，而不是磁盘块。\n* `-t` 显示各指定类型的文件系统的磁盘空间使用情况。\n* `-x` 列出不是某一指定类型文件系统的磁盘空间使用情况（与t选项相反）。\n* `-T` 显示文件系统类型。\n```shell\n文件系统                 1K-块      已用      可用 已用% 挂载点\n/dev/sda2             10079084   6660892   2906192  70% /\ntmpfs                  8141376         0   8141376   0% /dev/shm\n/dev/sda1             10079084    173308   9393776   2% /boot\n/dev/sda5            257592732 241557292   2950464  99% /opt\n```\n\n### du\n显示每个文件和目录的磁盘使用空间。\n* `-a或-all`  显示目录中个别文件的大小。   \n* `-b或-bytes`  显示目录或文件大小时，以byte为单位。   \n* `-c或--total`  除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。\n* `-k或--kilobytes`  以KB(1024bytes)为单位输出。\n* `-m或--megabytes`  以MB为单位输出。   \n* `-s或--summarize`  仅显示总计，只列出最后加总的值。\n* `-h或--human-readable`  以K，M，G为单位，提高信息的可读性。\n* `-x或--one-file-xystem`  以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。\n* `-L<符号链接>或--dereference<符号链接>` 显示选项中所指定符号链接的源文件大小。   \n* `-S或--separate-dirs`   显示个别目录的大小时，并不含其子目录的大小。\n* `-X<文件>或--exclude-from=<文件>`  在<文件>指定目录或文件。   \n* `--exclude=<目录或文件>`         略过指定的目录或文件。    \n* `-D或--dereference-args`   显示指定符号链接的源文件大小。   \n* `-H或--si`  与-h参数相同，但是K，M，G是以1000为换算单位。   \n* `-l或--count-links`   重复计算硬件链接的文件。  \n```shell\n# 对当前目前下所有文件按文件大小倒排序，大小相同按文件名字母倒排序\ndu -ak | sort -t$'\\t' -l1 -nr -k2 -r\n```\n","source":"_posts/linux/Linux系统命令.md","raw":"category: linux\ndate: 2015-10-15\ntitle: Linux系统命令\n---\n### Vmstat\nvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。\n\n一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:\n```shell\n[root@cvs /]# vmstat 2 1\n=>\nprocs  -----------memory----------     ---swap--  -----io----  --system--   -----cpu-----\n r  b    swpd   free   buff  cache      si   so     bi    bo    in   cs     us sy id wa st\n 1  0  1339624 525012 464316 6796908    0    0      5    32     0    0      2  0 98  0  0\n```\n参数\n* -a：显示活跃和非活跃内存\n* -f：显示从系统启动至今的fork数量 。\n* -m：显示slabinfo\n* -n：只在开始时显示一次各字段名称。\n* -s：显示内存相关统计信息及多种系统活动数量。\n* delay：刷新时间间隔。如果不指定，只显示一条结果。\n* count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。\n* -d：显示磁盘相关统计信息。\n* -p：显示指定磁盘分区统计信息\n* -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）\n* -V：显示vmstat版本信息。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.gif)\n我们从上面那个图来解释各个参数\n> porcs\n* r：表示运行队列(分配到CPU进程数)\n* b：阻塞状态的进程数\n\n> memory\n* swpd：虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了\n* free：空闲的物理内存的大小\n* buff：作为buffer使用的内存数量（Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存）\n* cache：作为缓存使用的内存数量（ cache直接用来记忆我们打开的文件,给文件做缓冲）\n* inact：非活跃内存数\n* active： 活跃内存数\n\n> swap\n* si：从磁盘交换的内存量（每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了）\n* so：向磁盘交换的内存量（每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上）\n\n> io\n* bi：从阻塞设备接受到的块数据数量。\n* bo：向阻塞设备发送的块数据数量。\n\n> system\n* in：每秒CPU的中断次数，包括时间中断\n* cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目\n\n> cpu\n* us：用户CPU时间\n* sy：系统CPU时间\n* id：空闲 CPU时间\n* wa：等待IO CPU时间\n* st\n\n\n### pidstat\n监控锁竞争\n```shell\n[root@cvs /]# pidstat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月15日  _x86_64_        (8 CPU)\n\nPID    %usr %system  %guest    %CPU   CPU  Command\n```\n显式参数\n* PID : 被监控的任务的进程号\n* %usr :  当在用户层执行(应用程序)时这个任务的cpu使用率，和 nice 优先级无关。注意这个字段计算的cpu时间不包括在虚拟处理器中花去的时间。\n* %system :  这个任务在系统层使用时的cpu使用率。\n* %guest ：  任务花费在虚拟机上的cpu使用率（运行在虚拟处理器）。\n* %CPU ：  任务总的cpu使用率。在SMP环境(多处理器)中，如果在命令行中输入-I参数的话，cpu使用率会除以你的cpu数量。\n* CPU ： 正在运行这个任务的处理器编号。\n* Command ： 这个任务的命令名称。\n\n参数\n* -u: pidstat将显示各活动进程的cpu使用统计\n* -p: 我们可以查看特定进程的系统资源使用情况：\n* -r: pidstat将显示各活动进程的内存使用统计：\n* -d: 我们可以查看进程IO的统计信息\n\n-d:\n* kB_rd/s: 每秒进程从磁盘读取的数据量(以kB为单位)\n* kB_wr/s: 每秒进程向磁盘写的数据量(以kB为单位)\n* Command: 拉起进程对应的命令\n\n-r:\n* minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数\n* majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生\n* VSZ:      该进程使用的虚拟内存(以kB为单位)\n* RSS:      该进程使用的物理内存(以kB为单位)\n* %MEM:     该进程使用内存的百分比\n* Command:  拉起进程对应的命令\n\n\n### iostat\niostat用于输出CPU和磁盘I/O相关的统计信息.\n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n\n```shell\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`:\n* `%idle`: CPU空闲时间的百分比.\n\n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### uname\n* `-a` 　显示全部的信息。\n* `-m`　显示电脑类型。\n* `-n`　显示在网络上的主机名称。\n* `-r`　显示操作系统的发行编号。\n* `-s`　显示操作系统名称。\n* `-v` 　显示操作系统的版本。\n```xml\n[root@test game]# uname -a\nLinux test 2.6.32-431.el6.x86_64 #1 SMP Fri Nov 22 03:15:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n> 查看发行版本 `cat /etc/issue`\n\n### sar\n系统报告命令\n* `sar -q 1 5`    察看cpu的load状况，每1s钟统计1次，共统计5次\n* `sar -u 2 3`   察看cpu使用率，每2s统计1次，共统计3次\n* `sar -r`   察看当日内存占用情况(默认每10分钟统计一次)\n* `sar -b` 察看当日IO使用情况\n* `sar -n SOCK`   察看网络sock连接\n* `sar -n DEV` 察看网络流量\n\n\n### top  \n\n\n\n### df\n检查文件系统的磁盘空间占用情况\n* `-a` 显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统，如/proc文件系统。\n* `-k` 以k字节为单位显示。\n* `-i` 显示i节点信息，而不是磁盘块。\n* `-t` 显示各指定类型的文件系统的磁盘空间使用情况。\n* `-x` 列出不是某一指定类型文件系统的磁盘空间使用情况（与t选项相反）。\n* `-T` 显示文件系统类型。\n```shell\n文件系统                 1K-块      已用      可用 已用% 挂载点\n/dev/sda2             10079084   6660892   2906192  70% /\ntmpfs                  8141376         0   8141376   0% /dev/shm\n/dev/sda1             10079084    173308   9393776   2% /boot\n/dev/sda5            257592732 241557292   2950464  99% /opt\n```\n\n### du\n显示每个文件和目录的磁盘使用空间。\n* `-a或-all`  显示目录中个别文件的大小。   \n* `-b或-bytes`  显示目录或文件大小时，以byte为单位。   \n* `-c或--total`  除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。\n* `-k或--kilobytes`  以KB(1024bytes)为单位输出。\n* `-m或--megabytes`  以MB为单位输出。   \n* `-s或--summarize`  仅显示总计，只列出最后加总的值。\n* `-h或--human-readable`  以K，M，G为单位，提高信息的可读性。\n* `-x或--one-file-xystem`  以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。\n* `-L<符号链接>或--dereference<符号链接>` 显示选项中所指定符号链接的源文件大小。   \n* `-S或--separate-dirs`   显示个别目录的大小时，并不含其子目录的大小。\n* `-X<文件>或--exclude-from=<文件>`  在<文件>指定目录或文件。   \n* `--exclude=<目录或文件>`         略过指定的目录或文件。    \n* `-D或--dereference-args`   显示指定符号链接的源文件大小。   \n* `-H或--si`  与-h参数相同，但是K，M，G是以1000为换算单位。   \n* `-l或--count-links`   重复计算硬件链接的文件。  \n```shell\n# 对当前目前下所有文件按文件大小倒排序，大小相同按文件名字母倒排序\ndu -ak | sort -t$'\\t' -l1 -nr -k2 -r\n```\n","slug":"linux/Linux系统命令","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihv1006qvjs6kefkzo7y"},{"date":"2015-10-14T16:00:00.000Z","title":"Linux系统文件","_content":"\n### /proc/cpuinfo\n```shell\n[root@cvs /]# cat /proc/cpuinfo\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 45\nmodel name      : Intel(R) Xeon(R) CPU E5-2603 0 @ 1.80GHz\nstepping        : 7\ncpu MHz         : 1800.009\ncache size      : 10240 KB\nphysical id     : 0\nsiblings        : 4\ncore id         : 0\ncpu cores       : 4\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce ...\nbogomips        : 3600.01\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 46 bits physical, 48 bits virtual\npower management:\n```\n* `processor`       : CPU号\n* `vendor_id`       : CPU制造商   \n* `cpu family`      : CPU产品系列代号\n* `model`           : CPU属于其系列中的哪一代的代号\n* `model name`      : CPU属于的名字及其编号、标称主频\n* `stepping`        : CPU属于制作更新版本\n* `cpu MHz`         : CPU的实际使用主频\n* `cache size`      : CPU二级缓存大小\n* `physical id`     : 单个CPU的标号\n* `siblings`        : 单个CPU逻辑物理核数\n* `core id`         : 当前物理核在其所处CPU中的编号，这个编号不一定连续\n* `cpu cores`       : 该逻辑核所处CPU的物理核数\n* `apicid`          : 用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续\n* `initial apicid`  :\n* `fpu`             : 是否具有浮点运算单元（Floating Point Unit）\n* `fpu_exception`   : 是否支持浮点计算异常\n* `cpuid level`     : 执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容\n* `wp`              : 表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）\n* `flags`           : 当前CPU支持的功能\n* `bogomips`        : 在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）\n* `clflush size`    : 每次刷新缓存的大小单位\n* `cache_alignment` : 缓存地址对齐单位\n* `address sizes`   : 可访问地址空间位数\n* `power management`: 对能源管理的支持，有以下几个可选支持功能\n\n### /proc/meminfo\n```shell\n[root@cvs /]# cat /proc/meminfo\nMemTotal:       16282756 kB\nMemFree:         2012664 kB\nBuffers:          491980 kB\nCached:          5477644 kB\nSwapCached:       110344 kB\nActive:          9224100 kB\nInactive:        4478716 kB\nActive(anon):    6410680 kB\nInactive(anon):  1322576 kB\nActive(file):    2813420 kB\nInactive(file):  3156140 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nSwapTotal:      10239992 kB\nSwapFree:        8921364 kB\nDirty:              1176 kB\nWriteback:             0 kB\nAnonPages:       7679964 kB\nMapped:            25344 kB\nShmem:                36 kB\nSlab:             328340 kB\nSReclaimable:     284284 kB\nSUnreclaim:        44056 kB\nKernelStack:        8504 kB\nPageTables:        27520 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:    18381368 kB\nCommitted_AS:   11103356 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:      307784 kB\nVmallocChunk:   34350792204 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:   6842368 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nDirectMap4k:        5056 kB\nDirectMap2M:     2045952 kB\nDirectMap1G:    14680064 kB\n```\n* `MemTotal`:\n* `MemFree`:空闲内存\n* `Buffers`:给文件的缓冲大小\n* `Cached`: 高速缓冲存储器(http://baike.baidu.com/view/496990.htm)使用的大小\n* `SwapCached`: 被高速缓冲存储用的交换空间大小\n* `Active`: 活跃使用中的高速缓冲存储器页面文件大小\n* `Inactive`: 不经常使用的高速缓冲存储器页面文件大小\n* `Active(anon)`:\n* `Inactive(anon)`:\n* `Active(file)`:\n* `Inactive(file)`:\n* `Unevictable`:\n* `Mlocked`:\n* `SwapTotal`:交换空间总大小\n* `SwapFree`: 空闲交换空间\n* `Dirty`:等待被写回到磁盘的大小\n* `Writeback`:正在被写回的大小\n* `AnonPages`:未映射的页的大小\n* `Mapped`: 设备和文件映射的大小\n* `Shmem`:\n* `Slab`: 内核数据结构缓存的大小，可减少申请和释放内存带来的消耗\n* `SReclaimable`: 可收回slab的大小\n* `SUnreclaim`: 不可收回的slab的大小23204+14164=37368\n* `KernelStack`:\n* `PageTables`: 管理内存分页的索引表的大小\n* `NFS_Unstable`: 不稳定页表的大小\n* `Bounce`: bounce:退回\n* `WritebackTmp`:\n* `CommitLimit`:\n* `Committed_AS`:\n* `VmallocTotal`: 虚拟内存大小\n* `VmallocUsed`:已经被使用的虚拟内存大小\n* `VmallocChunk`:\n* `HardwareCorrupted`:\n* `AnonHugePages`:\n* `HugePages_Total`:大页面的分配\n* `HugePages_Free`:\n* `HugePages_Rsvd`:\n* `HugePages_Surp`:\n* `Hugepagesize`:\n* `DirectMap4k`:\n* `DirectMap2M`:\n* `DirectMap1G`:\n\n### /proc/net/dev\n```shell\n[root@cvs /]# cat /proc/net/dev\nInter-|   Receive                                                |  Transmit\n face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed\n    lo:365528559149 865504543    0    0    0     0          0         0 365528559149 865504543    0    0    0     0       0          0\n   em1:542483270223 575346473    0    0    0    62          0   8267561 580200919340 586706511    0    0    0     0       0          0\n   em2:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em3:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em4:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n```\n\nInter                                                     \n* `face`:接口的名字\n\nReceive\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`:\n* `frame`:\n* `compressed`:\n* `multicast`:\n\nTransmit\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`:\n* `colls`:\n* `carrier`:\n* `compressed`:\n","source":"_posts/linux/linux系统文件.md","raw":"category: linux\ndate: 2015-10-15\ntitle: Linux系统文件\n---\n\n### /proc/cpuinfo\n```shell\n[root@cvs /]# cat /proc/cpuinfo\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 45\nmodel name      : Intel(R) Xeon(R) CPU E5-2603 0 @ 1.80GHz\nstepping        : 7\ncpu MHz         : 1800.009\ncache size      : 10240 KB\nphysical id     : 0\nsiblings        : 4\ncore id         : 0\ncpu cores       : 4\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce ...\nbogomips        : 3600.01\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 46 bits physical, 48 bits virtual\npower management:\n```\n* `processor`       : CPU号\n* `vendor_id`       : CPU制造商   \n* `cpu family`      : CPU产品系列代号\n* `model`           : CPU属于其系列中的哪一代的代号\n* `model name`      : CPU属于的名字及其编号、标称主频\n* `stepping`        : CPU属于制作更新版本\n* `cpu MHz`         : CPU的实际使用主频\n* `cache size`      : CPU二级缓存大小\n* `physical id`     : 单个CPU的标号\n* `siblings`        : 单个CPU逻辑物理核数\n* `core id`         : 当前物理核在其所处CPU中的编号，这个编号不一定连续\n* `cpu cores`       : 该逻辑核所处CPU的物理核数\n* `apicid`          : 用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续\n* `initial apicid`  :\n* `fpu`             : 是否具有浮点运算单元（Floating Point Unit）\n* `fpu_exception`   : 是否支持浮点计算异常\n* `cpuid level`     : 执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容\n* `wp`              : 表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）\n* `flags`           : 当前CPU支持的功能\n* `bogomips`        : 在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）\n* `clflush size`    : 每次刷新缓存的大小单位\n* `cache_alignment` : 缓存地址对齐单位\n* `address sizes`   : 可访问地址空间位数\n* `power management`: 对能源管理的支持，有以下几个可选支持功能\n\n### /proc/meminfo\n```shell\n[root@cvs /]# cat /proc/meminfo\nMemTotal:       16282756 kB\nMemFree:         2012664 kB\nBuffers:          491980 kB\nCached:          5477644 kB\nSwapCached:       110344 kB\nActive:          9224100 kB\nInactive:        4478716 kB\nActive(anon):    6410680 kB\nInactive(anon):  1322576 kB\nActive(file):    2813420 kB\nInactive(file):  3156140 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nSwapTotal:      10239992 kB\nSwapFree:        8921364 kB\nDirty:              1176 kB\nWriteback:             0 kB\nAnonPages:       7679964 kB\nMapped:            25344 kB\nShmem:                36 kB\nSlab:             328340 kB\nSReclaimable:     284284 kB\nSUnreclaim:        44056 kB\nKernelStack:        8504 kB\nPageTables:        27520 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:    18381368 kB\nCommitted_AS:   11103356 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:      307784 kB\nVmallocChunk:   34350792204 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:   6842368 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nDirectMap4k:        5056 kB\nDirectMap2M:     2045952 kB\nDirectMap1G:    14680064 kB\n```\n* `MemTotal`:\n* `MemFree`:空闲内存\n* `Buffers`:给文件的缓冲大小\n* `Cached`: 高速缓冲存储器(http://baike.baidu.com/view/496990.htm)使用的大小\n* `SwapCached`: 被高速缓冲存储用的交换空间大小\n* `Active`: 活跃使用中的高速缓冲存储器页面文件大小\n* `Inactive`: 不经常使用的高速缓冲存储器页面文件大小\n* `Active(anon)`:\n* `Inactive(anon)`:\n* `Active(file)`:\n* `Inactive(file)`:\n* `Unevictable`:\n* `Mlocked`:\n* `SwapTotal`:交换空间总大小\n* `SwapFree`: 空闲交换空间\n* `Dirty`:等待被写回到磁盘的大小\n* `Writeback`:正在被写回的大小\n* `AnonPages`:未映射的页的大小\n* `Mapped`: 设备和文件映射的大小\n* `Shmem`:\n* `Slab`: 内核数据结构缓存的大小，可减少申请和释放内存带来的消耗\n* `SReclaimable`: 可收回slab的大小\n* `SUnreclaim`: 不可收回的slab的大小23204+14164=37368\n* `KernelStack`:\n* `PageTables`: 管理内存分页的索引表的大小\n* `NFS_Unstable`: 不稳定页表的大小\n* `Bounce`: bounce:退回\n* `WritebackTmp`:\n* `CommitLimit`:\n* `Committed_AS`:\n* `VmallocTotal`: 虚拟内存大小\n* `VmallocUsed`:已经被使用的虚拟内存大小\n* `VmallocChunk`:\n* `HardwareCorrupted`:\n* `AnonHugePages`:\n* `HugePages_Total`:大页面的分配\n* `HugePages_Free`:\n* `HugePages_Rsvd`:\n* `HugePages_Surp`:\n* `Hugepagesize`:\n* `DirectMap4k`:\n* `DirectMap2M`:\n* `DirectMap1G`:\n\n### /proc/net/dev\n```shell\n[root@cvs /]# cat /proc/net/dev\nInter-|   Receive                                                |  Transmit\n face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed\n    lo:365528559149 865504543    0    0    0     0          0         0 365528559149 865504543    0    0    0     0       0          0\n   em1:542483270223 575346473    0    0    0    62          0   8267561 580200919340 586706511    0    0    0     0       0          0\n   em2:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em3:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em4:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n```\n\nInter                                                     \n* `face`:接口的名字\n\nReceive\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`:\n* `frame`:\n* `compressed`:\n* `multicast`:\n\nTransmit\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`:\n* `colls`:\n* `carrier`:\n* `compressed`:\n","slug":"linux/linux系统文件","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihv5006svjs6yipll2yi"},{"date":"2015-10-07T16:00:00.000Z","title":"Shell","_content":"每个shell脚本文件第一行都要指定使用哪个shell,我们默认使用`#!/bin/bash`\n\n# 变量\nbash变量分为\n* 局部变量: 脚本或命令中定义，仅在当前shell实例中有效\n* 环境变量: 所有的脚本和shell中都可以访问的变量\n* 预定义变量\n\n## 变量类型\n运行shell时，会同时存在三种变量：\n* 局部变量： 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。\n* 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。\n* shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行\n\n## 变量声明\n```shell\nv1=123\n```\n在上面的声明语法中我们需要注意以下几点\n* `=`左右不能用空格\n* 变量的默认类型是字符串\n* 该变量对当前以及子shell都有效\n\n将命令执行的结果作为值传送给一个变量可以使用\n```shell\ndirName=`date +%Y_%m_%d_%H_%M_%S`\n#或者\ndirName=$(date +%Y_%m_%d_%H_%M_%S)\n```\n\n\n### declare声明\nTODO\n\n## 变量引用\n我们通过使用`$`或者`${}`符号可以引用一个变量\n```shell\nv=1\necho $v\necho ${v}\n```\n\n> 需要注意的是, `$()`是用来做命令替换的(`\\`\\``也是用来做命令替换的), 而`${}`是用来做变量替换的(`$var`与`${var}`并没有啥不一样)\n\n## 只读变量\n`readonly` 命令可以将变量定义为只读变量\n```shell\nreadonly myUrl\n```\n\n## 删除变量\n```shell\nunset  myUrl\n```\n\n## 特殊变量\n* `$0`:\t当前脚本的文件名\n* `$n`:\t传递给脚本或函数的参数。(第一个参数是$1，第二个参数是$2)\n* `$#`:\t传递给脚本或函数的参数个数。\n* `$*`:\t传递给脚本或函数的所有参数。\n* `$@`:\t传递给脚本或函数的所有参数。被双引号(\" \")包含时，与 $* 稍有不同\n* `$?`:\t上个命令的退出状态，或函数的返回值。\n* `$$`:\t当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n## 数组\n\n### 数组定义\n一对括号表示是数组，数组元素用“空格”符号分割开。\n```shell\narray=(1 2 3 4 5)\n```\n\n### 数组长度\n```shell\n${#数组名[@或*]} : 可以得到数组长度\n${#array[@]}\n```\n\n### 索引数组成员\n`${数组名[下标]}` : 下标是从0开始 (下标是：*或者@ 得到整个数组内容)\n```shell\n${array[2]}\n```\n\n### 数组成员赋值\n`数组名[下标]`: 进行数组元素引用，如果下标不存在，自动添加新一个数组元素\n```shell\narray[1]=100\n```\n\n### 删除数组\n`unset 数组[下标]`：删除下标相应的元素，不带下标，则删掉整个数组。\n```shell\nunset array[1]\n```\n\n### 数组分片\n`${数组名[@或*]:起始位置:长度}`： 切片数组，返回一个用“空格”分割元素的字符串\n> 如果加上`()`，将得到切片数组\n\n```shell\nc=(${array[@]:1:4})\n```\n\n### 数组替换\n`${数组名[@或*]/查找字符/替换字符}`: 该操作不会改变原先数组内容\n```shell\n${array[@]/old/new}\n```\n\n# 运算符\n\n## 算术运算符\n我们可以使用`expr`, `let`, `(())`, `[]`等四种方式进行算术运算\n* `+`:\t加法\t`(($a + $b))`\n* `-\t`:\t减法`(($a - $b))`\n* `*`:\t乘法\t`(($a \\* $b))`\n* `/`:\t除法\t`(($b / $a))`\n* `%`:\t取余\t`(($b % $a))`\n* `=`:\t赋值\t`a=$b`\n* `==`:\t相等。用于比较两个数字，相同则返回 true。\t`[ $a == $b ]` 返回 false。\n* `!=`:\t不相等。用于比较两个数字，不相同则返回 true。\t`[ $a != $b ]` 返回 true。\n\n## 关系运算符\n关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n* `-eq`\t检测两个数是否相等，相等返回 true。\t`[ $a -eq $b ]` 返回 true。\n* `-ne`\t检测两个数是否相等，不相等返回 true。\t`[ $a -ne $b ]` 返回 true。\n* `-gt`\t检测左边的数是否大于右边的，如果是，则返回 true。\t`[ $a -gt $b ]` 返回 false。\n* `-lt`\t检测左边的数是否小于右边的，如果是，则返回 true。\t`[ $a -lt $b ]` 返回 true。\n* `-ge`\t检测左边的数是否大等于右边的，如果是，则返回 true。\t`[ $a -ge $b ]` 返回 false。\n* `-le`\t检测左边的数是否小于等于右边的，如果是，则返回 true。\t`[ $a -le $b ]` 返回 true。\n\n## 逻辑运算符\n* `!`\t非运算，表达式为 true 则返回 false，否则返回 true。\t`[ ! false ]` 返回 true。\n* `-o`\t或运算，有一个表达式为 true 则返回 true。\t`[ $a -lt 20 -o $b -gt 100 ]` 返回 true。\n* `-a`\t与运算，两个表达式都为 true 才返回 true。\t`[ $a -lt 20 -a $b -gt 100 ]` 返回 false。\n\n## 字符串运算符\n* `=`\t检测两个字符串是否相等，相等返回 true。\t`[ $a = $b ]` 返回 false。\n* `!=`\t检测两个字符串是否相等，不相等返回 true。\t`[ $a != $b ]` 返回 true。\n* `-z`\t检测字符串长度是否为0，为0返回 true。\t`[ -z $a `] 返回 false。\n* `-n`\t检测字符串长度是否为0，不为0返回 true。\t`[ -z $a `] 返回 true。\n* `str`\t检测字符串是否为空，不为空返回 true。\t`[ $a `] 返回 true。\n\n## 文件测试运算符\n* `-b` 文件是否是块设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-c` 文件是否是字符设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-d` 文件是否是目录，如果是，则返回 true。\t`[ -d $file `] 返回 false。\n* `-f` 文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。\t`[ -f $file `] 返回 true。\n* `-g` 文件是否设置了 SGID 位，如果是，则返回 true。\t`[ -g $file `] 返回 false。\n* `-k` 文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。\t`[ -k $file `] 返回 false。\n* `-p` 文件是否是具名管道，如果是，则返回 true。\t`[ -p $file `] 返回 false。\n* `-u` 文件是否设置了 SUID 位，如果是，则返回 true。\t`[ -u $file `] 返回 false。\n* `-r` 文件是否可读，如果是，则返回 true。\t`[ -r $file `] 返回 true。\n* `-w` 文件是否可写，如果是，则返回 true。\t`[ -w $file `] 返回 true。\n* `-x` 文件是否可执行，如果是，则返回 true。\t`[ -x $file `] 返回 true。\n* `-s` 文件是否为空（文件大小是否大于0），不为空返回 true。\t`[ -s $file `] 返回 true。\n* `-e` 文件（包括目录）是否存在，如果是，则返回 true。\t`[ -e $file `] 返回 true。\n\n# 流程控制\nshell流程控制包含：\n* if\n* while\n* until\n* case\n* for\n\n同样的shell也支持`break`和`continue`\n\n##  if else\n\n### if\n语法格式\n```shell\nif condition\nthen\n    command1\n    command2\n    ...\n    commandN\nfi\n```\n示例\n```shell\n#!/bin/bash\nv=123\nif [ -b $txt ];   \nthen\n        echo \"ok\";\nfi\n```\n我们一定要注意if前后的空格\n\n### if else\n```shell\nif condition\nthen\n    command1\n    command2\n    ...\n    commandN\nelse\n    command\nfi\n```\n\n### if else-if else\n```shell\nif condition1\nthen\n    command1\nelif condition2\n    command2\nelse\n    commandN\nfi\n```\n\n## case\n case语句为多选择语句\n```shell\ncase 值 in\n模式1)\n    command1\n    command2\n    ...\n    commandN\n    ;;\n模式2）\n    command1\n    command2\n    ...\n    commandN\n    ;;\nesac\n```\n示例\n```shell\n\n#!/bin/bash\n\nfor i in 1 2 3 4 5;\ndo\n        case $i in\n                1)  echo '你选择了 1'\n                ;;\n                2)  echo '你选择了 2'\n                ;;\n                3)  echo '你选择了 3'\n                ;;\n                4)  echo '你选择了 4'\n                ;;\n                *)  echo '你没有输入 1 到 4 之间的数字'\n                ;;\n                esac\ndone\n```\n\n## for\n```shell\nfor var in item1 item2 ... itemN\ndo\n    command1\n    command2\n    ...\n    commandN\ndone\n```\n示例\n```shell\n#!/bin/bash\n\nfor i in 1 2 3 4;\ndo\n        echo $i\ndone\n```\n\n## while\n```shell\nwhile condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nwhile(( $i<=5 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n## until\nuntil循环执行一系列命令直至条件为真时停止。\n```shell\nuntil condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nuntil(( $i>3 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n# 函数\n调用函数不需要加`()`\n```shell\nvi=123546789\nf() {\n\techo $vi\n}\nf\n```\n\n## 带参数的函数\n参数名是固定的`$n`, 如果参数大于10的话就需要`${10}`\n```shell\nf() {\necho $1\n}\nf 789\n```\n\n## 函数的返回值\n函数返回值在调用该函数后通过 `$?` 来获得\n```shell\nf() {\necho $1\n}\nf 789\necho $?\n```\n如果不写`return`, 则直接返回0\n```shell\nf() {\necho $1\nreturn 569\n}\nf 789\necho $?\n```\n\n## 在当前shell里执行一个文件里的命令：\n```shell\nsource /home/user/file.name\n```\n","source":"_posts/linux/shell.md","raw":"category: linux\ndate: 2015-10-08\ntitle: Shell\n---\n每个shell脚本文件第一行都要指定使用哪个shell,我们默认使用`#!/bin/bash`\n\n# 变量\nbash变量分为\n* 局部变量: 脚本或命令中定义，仅在当前shell实例中有效\n* 环境变量: 所有的脚本和shell中都可以访问的变量\n* 预定义变量\n\n## 变量类型\n运行shell时，会同时存在三种变量：\n* 局部变量： 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。\n* 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。\n* shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行\n\n## 变量声明\n```shell\nv1=123\n```\n在上面的声明语法中我们需要注意以下几点\n* `=`左右不能用空格\n* 变量的默认类型是字符串\n* 该变量对当前以及子shell都有效\n\n将命令执行的结果作为值传送给一个变量可以使用\n```shell\ndirName=`date +%Y_%m_%d_%H_%M_%S`\n#或者\ndirName=$(date +%Y_%m_%d_%H_%M_%S)\n```\n\n\n### declare声明\nTODO\n\n## 变量引用\n我们通过使用`$`或者`${}`符号可以引用一个变量\n```shell\nv=1\necho $v\necho ${v}\n```\n\n> 需要注意的是, `$()`是用来做命令替换的(`\\`\\``也是用来做命令替换的), 而`${}`是用来做变量替换的(`$var`与`${var}`并没有啥不一样)\n\n## 只读变量\n`readonly` 命令可以将变量定义为只读变量\n```shell\nreadonly myUrl\n```\n\n## 删除变量\n```shell\nunset  myUrl\n```\n\n## 特殊变量\n* `$0`:\t当前脚本的文件名\n* `$n`:\t传递给脚本或函数的参数。(第一个参数是$1，第二个参数是$2)\n* `$#`:\t传递给脚本或函数的参数个数。\n* `$*`:\t传递给脚本或函数的所有参数。\n* `$@`:\t传递给脚本或函数的所有参数。被双引号(\" \")包含时，与 $* 稍有不同\n* `$?`:\t上个命令的退出状态，或函数的返回值。\n* `$$`:\t当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n## 数组\n\n### 数组定义\n一对括号表示是数组，数组元素用“空格”符号分割开。\n```shell\narray=(1 2 3 4 5)\n```\n\n### 数组长度\n```shell\n${#数组名[@或*]} : 可以得到数组长度\n${#array[@]}\n```\n\n### 索引数组成员\n`${数组名[下标]}` : 下标是从0开始 (下标是：*或者@ 得到整个数组内容)\n```shell\n${array[2]}\n```\n\n### 数组成员赋值\n`数组名[下标]`: 进行数组元素引用，如果下标不存在，自动添加新一个数组元素\n```shell\narray[1]=100\n```\n\n### 删除数组\n`unset 数组[下标]`：删除下标相应的元素，不带下标，则删掉整个数组。\n```shell\nunset array[1]\n```\n\n### 数组分片\n`${数组名[@或*]:起始位置:长度}`： 切片数组，返回一个用“空格”分割元素的字符串\n> 如果加上`()`，将得到切片数组\n\n```shell\nc=(${array[@]:1:4})\n```\n\n### 数组替换\n`${数组名[@或*]/查找字符/替换字符}`: 该操作不会改变原先数组内容\n```shell\n${array[@]/old/new}\n```\n\n# 运算符\n\n## 算术运算符\n我们可以使用`expr`, `let`, `(())`, `[]`等四种方式进行算术运算\n* `+`:\t加法\t`(($a + $b))`\n* `-\t`:\t减法`(($a - $b))`\n* `*`:\t乘法\t`(($a \\* $b))`\n* `/`:\t除法\t`(($b / $a))`\n* `%`:\t取余\t`(($b % $a))`\n* `=`:\t赋值\t`a=$b`\n* `==`:\t相等。用于比较两个数字，相同则返回 true。\t`[ $a == $b ]` 返回 false。\n* `!=`:\t不相等。用于比较两个数字，不相同则返回 true。\t`[ $a != $b ]` 返回 true。\n\n## 关系运算符\n关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n* `-eq`\t检测两个数是否相等，相等返回 true。\t`[ $a -eq $b ]` 返回 true。\n* `-ne`\t检测两个数是否相等，不相等返回 true。\t`[ $a -ne $b ]` 返回 true。\n* `-gt`\t检测左边的数是否大于右边的，如果是，则返回 true。\t`[ $a -gt $b ]` 返回 false。\n* `-lt`\t检测左边的数是否小于右边的，如果是，则返回 true。\t`[ $a -lt $b ]` 返回 true。\n* `-ge`\t检测左边的数是否大等于右边的，如果是，则返回 true。\t`[ $a -ge $b ]` 返回 false。\n* `-le`\t检测左边的数是否小于等于右边的，如果是，则返回 true。\t`[ $a -le $b ]` 返回 true。\n\n## 逻辑运算符\n* `!`\t非运算，表达式为 true 则返回 false，否则返回 true。\t`[ ! false ]` 返回 true。\n* `-o`\t或运算，有一个表达式为 true 则返回 true。\t`[ $a -lt 20 -o $b -gt 100 ]` 返回 true。\n* `-a`\t与运算，两个表达式都为 true 才返回 true。\t`[ $a -lt 20 -a $b -gt 100 ]` 返回 false。\n\n## 字符串运算符\n* `=`\t检测两个字符串是否相等，相等返回 true。\t`[ $a = $b ]` 返回 false。\n* `!=`\t检测两个字符串是否相等，不相等返回 true。\t`[ $a != $b ]` 返回 true。\n* `-z`\t检测字符串长度是否为0，为0返回 true。\t`[ -z $a `] 返回 false。\n* `-n`\t检测字符串长度是否为0，不为0返回 true。\t`[ -z $a `] 返回 true。\n* `str`\t检测字符串是否为空，不为空返回 true。\t`[ $a `] 返回 true。\n\n## 文件测试运算符\n* `-b` 文件是否是块设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-c` 文件是否是字符设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-d` 文件是否是目录，如果是，则返回 true。\t`[ -d $file `] 返回 false。\n* `-f` 文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。\t`[ -f $file `] 返回 true。\n* `-g` 文件是否设置了 SGID 位，如果是，则返回 true。\t`[ -g $file `] 返回 false。\n* `-k` 文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。\t`[ -k $file `] 返回 false。\n* `-p` 文件是否是具名管道，如果是，则返回 true。\t`[ -p $file `] 返回 false。\n* `-u` 文件是否设置了 SUID 位，如果是，则返回 true。\t`[ -u $file `] 返回 false。\n* `-r` 文件是否可读，如果是，则返回 true。\t`[ -r $file `] 返回 true。\n* `-w` 文件是否可写，如果是，则返回 true。\t`[ -w $file `] 返回 true。\n* `-x` 文件是否可执行，如果是，则返回 true。\t`[ -x $file `] 返回 true。\n* `-s` 文件是否为空（文件大小是否大于0），不为空返回 true。\t`[ -s $file `] 返回 true。\n* `-e` 文件（包括目录）是否存在，如果是，则返回 true。\t`[ -e $file `] 返回 true。\n\n# 流程控制\nshell流程控制包含：\n* if\n* while\n* until\n* case\n* for\n\n同样的shell也支持`break`和`continue`\n\n##  if else\n\n### if\n语法格式\n```shell\nif condition\nthen\n    command1\n    command2\n    ...\n    commandN\nfi\n```\n示例\n```shell\n#!/bin/bash\nv=123\nif [ -b $txt ];   \nthen\n        echo \"ok\";\nfi\n```\n我们一定要注意if前后的空格\n\n### if else\n```shell\nif condition\nthen\n    command1\n    command2\n    ...\n    commandN\nelse\n    command\nfi\n```\n\n### if else-if else\n```shell\nif condition1\nthen\n    command1\nelif condition2\n    command2\nelse\n    commandN\nfi\n```\n\n## case\n case语句为多选择语句\n```shell\ncase 值 in\n模式1)\n    command1\n    command2\n    ...\n    commandN\n    ;;\n模式2）\n    command1\n    command2\n    ...\n    commandN\n    ;;\nesac\n```\n示例\n```shell\n\n#!/bin/bash\n\nfor i in 1 2 3 4 5;\ndo\n        case $i in\n                1)  echo '你选择了 1'\n                ;;\n                2)  echo '你选择了 2'\n                ;;\n                3)  echo '你选择了 3'\n                ;;\n                4)  echo '你选择了 4'\n                ;;\n                *)  echo '你没有输入 1 到 4 之间的数字'\n                ;;\n                esac\ndone\n```\n\n## for\n```shell\nfor var in item1 item2 ... itemN\ndo\n    command1\n    command2\n    ...\n    commandN\ndone\n```\n示例\n```shell\n#!/bin/bash\n\nfor i in 1 2 3 4;\ndo\n        echo $i\ndone\n```\n\n## while\n```shell\nwhile condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nwhile(( $i<=5 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n## until\nuntil循环执行一系列命令直至条件为真时停止。\n```shell\nuntil condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nuntil(( $i>3 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n# 函数\n调用函数不需要加`()`\n```shell\nvi=123546789\nf() {\n\techo $vi\n}\nf\n```\n\n## 带参数的函数\n参数名是固定的`$n`, 如果参数大于10的话就需要`${10}`\n```shell\nf() {\necho $1\n}\nf 789\n```\n\n## 函数的返回值\n函数返回值在调用该函数后通过 `$?` 来获得\n```shell\nf() {\necho $1\n}\nf 789\necho $?\n```\n如果不写`return`, 则直接返回0\n```shell\nf() {\necho $1\nreturn 569\n}\nf 789\necho $?\n```\n\n## 在当前shell里执行一个文件里的命令：\n```shell\nsource /home/user/file.name\n```\n","slug":"linux/shell","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihv9006uvjs6999qx92s"},{"date":"2016-05-29T16:00:00.000Z","title":"终端生成GIF文件","_content":"[ttystudio](https://github.com/chjj/ttystudio)可以将命令行操作制作成gif文件.\n\n安装\n```bash\nnpm install ttystudio\n```\n全局安装\n```bash\nnpm install ttystudio -g\n```\n使用\n```bash\nttystudio output.gif --log\n```\n上面这个命令最终生成一个output.gif文件, 同时将生成的过程输出\n\n除了上面简单的介绍外, 它还可以为我们添加边框, 录制部分帧\n\n> 还有其他的录制软件 [asciinema](https://asciinema.org)\n","source":"_posts/linux/ttystudio.md","raw":"category: linux\ndate: 2016-05-30\ntitle: 终端生成GIF文件\n---\n[ttystudio](https://github.com/chjj/ttystudio)可以将命令行操作制作成gif文件.\n\n安装\n```bash\nnpm install ttystudio\n```\n全局安装\n```bash\nnpm install ttystudio -g\n```\n使用\n```bash\nttystudio output.gif --log\n```\n上面这个命令最终生成一个output.gif文件, 同时将生成的过程输出\n\n除了上面简单的介绍外, 它还可以为我们添加边框, 录制部分帧\n\n> 还有其他的录制软件 [asciinema](https://asciinema.org)\n","slug":"linux/ttystudio","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihve006xvjs6fcw0f34f"},{"date":"2015-10-07T16:00:00.000Z","title":"iTerm2 plus Oh My Zsh","_content":"iTerm2是Mac下term的一个替代工具.\n\n快捷键\n* ⌘ + 数字在各 tab 标签直接来回切换\n* 选择即复制 + 鼠标中键粘贴，这个很实用\n* ⌘ + f 所查找的内容会被自动复制\n* ⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏\n* ⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏\n* ctrl + u 清空当前行，无论光标在什么位置\n* 输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令\n* ⌘ + shift + h 会列出剪切板历史\n\nOh my zsh 是bash的一个替代产品. 我们可以在\n```bash\n.oh-my-zsh/plugins\n```\n目录下见到N多插件.\n\n有些插件是没有开启的, 那么我们可以修改下面这个文件\n```bash\n.zshrc\n```\n然后在里面找到\n```bash\nplugins=(git)\n```\n这一行, 想要添加什么插件, 在里面添加就好了, 例如我们还想开启ruby插件\n```bash\nplugins=(git ruby)\n```\n","source":"_posts/linux/zsh iterm2.md","raw":"category: linux\ndate: 2015-10-08\ntitle: iTerm2 plus Oh My Zsh\n---\niTerm2是Mac下term的一个替代工具.\n\n快捷键\n* ⌘ + 数字在各 tab 标签直接来回切换\n* 选择即复制 + 鼠标中键粘贴，这个很实用\n* ⌘ + f 所查找的内容会被自动复制\n* ⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏\n* ⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏\n* ctrl + u 清空当前行，无论光标在什么位置\n* 输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令\n* ⌘ + shift + h 会列出剪切板历史\n\nOh my zsh 是bash的一个替代产品. 我们可以在\n```bash\n.oh-my-zsh/plugins\n```\n目录下见到N多插件.\n\n有些插件是没有开启的, 那么我们可以修改下面这个文件\n```bash\n.zshrc\n```\n然后在里面找到\n```bash\nplugins=(git)\n```\n这一行, 想要添加什么插件, 在里面添加就好了, 例如我们还想开启ruby插件\n```bash\nplugins=(git ruby)\n```\n","slug":"linux/zsh iterm2","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvh006zvjs67uxj9ppy"},{"date":"2015-05-07T16:00:00.000Z","title":"Flick Ticket Server","_content":"为什么采用Ticket Server？\n\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID\n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希\n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入)\n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装\n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n下面展示了一下Ticket64 schema\n```SQL\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```java\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n当我需要一个新的64位ID时,我执行面貌这个sql\n\n```SQL\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障)\n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```java\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n","source":"_posts/mgits/Flick Ticket Server.md","raw":"category: mgits\ndate: 2015-05-08\ntitle: Flick Ticket Server\n---\n为什么采用Ticket Server？\n\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID\n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希\n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入)\n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装\n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n下面展示了一下Ticket64 schema\n```SQL\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```java\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n当我需要一个新的64位ID时,我执行面貌这个sql\n\n```SQL\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障)\n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```java\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n","slug":"mgits/Flick Ticket Server","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvl0072vjs61uk2aequ"},{"date":"2015-08-07T16:00:00.000Z","title":"IDEA 设置","_content":"\n## 缩进设置\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/idea_indent.jpg)\n* `Use tab character` : 如果勾选则使用tab缩进,否则使用空格缩进\n* `Tab size` : 每个tab占用几个空格.\n* `Indent` : 每个缩进占用几个空格.\n\n## 2016-03-03\n刚刚来到了新的项目, 新的项目里使用Gradle作为编译工具.  说完前文说正题: 开发完新的模块后打算写单元测试来验证一下自己的功能. 但是在运行的时候遇到了一些问题, 由于整个项目都没进行单元测试的编写, 因此需要搭建起这个环境,\n\n其实环境很简单只要单元测试能编译通过运行就ok了，但是仍然发生了一些问题,由于项目是从JDK7升级上来的, 因此有些地方还是采用的配置, 因此当发现在编译时遇到了\n* class版本不支持\n* 提示:无效的源发行版: 1.8\n我们要检查俩个地方\n* build.gradle 这个文件里指定了编译器版本(例如sourceCompatibility, 需要注意的是看看是否依赖了其他的gradle配置, 我就踩中了这个坑)\n* Intellij IDEA -Preference-Build, Execution, Deployment-Gradle -Gradle JVM, 看一下这个配置里面的配置, 当我将gradle的配置修改之后如果不修改这里就会出现  无效的源发行版: 1.8\n\n另外我们一般在项目里会设置JDK版本(项目右击Open Moudle Setting), 这个只是设置整个idea的项目相关的, 也就是和你写代码相关, 和项目的构建等等没啥关系\n\n## 使用eclipse格式化文件\nIDEA如果要使用eclipse的格式化文件需要安装`Eclipse Code Formatter`插件, 然后在setting里的`Other Seetings`里的`Eclipse Code Formatter`里引用格式化文件就好了\n\n## Idea打包与classpath\n当我们使用maven创建一个项目的时候会创建出如下的目录\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/idea%20classpath.png)\n我们会看到如下的几个目录, 这几个目录都是设置在classpath上\n* Sources ：src/main/java\n* Resources : src/main/resources\n如果我们要新添加一个classpath时, 点击add Content Root就好. \n> 注意我们不要使用`Run/Debug Configurations`里的VM options, 这个路径有时候是让启动我们自己程序的Idea进程使用的.\n我们在程序里可以使用\n```java\nInputStream in = TestReadFile.class.getClassLoader().getResourceAsStream(\"./mybatis-config.xml\");\n```\n这种直接读取classpath也就是resources中的文件. 当使用Maven打包之后, 也可以直接从jar包中读取\n![]()\n我们看到resources目录直接放到了jar包的根目录下,但是我们需要配置一些maven的打包方式\n```xml\n\n```\n\n## 快捷键\n* 块选择 : `ALT Shift Insert`","source":"_posts/mgits/IDEA 设置.md","raw":"category: mgits\ndate: 2015-08-08\ntitle: IDEA 设置\n---\n\n## 缩进设置\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/idea_indent.jpg)\n* `Use tab character` : 如果勾选则使用tab缩进,否则使用空格缩进\n* `Tab size` : 每个tab占用几个空格.\n* `Indent` : 每个缩进占用几个空格.\n\n## 2016-03-03\n刚刚来到了新的项目, 新的项目里使用Gradle作为编译工具.  说完前文说正题: 开发完新的模块后打算写单元测试来验证一下自己的功能. 但是在运行的时候遇到了一些问题, 由于整个项目都没进行单元测试的编写, 因此需要搭建起这个环境,\n\n其实环境很简单只要单元测试能编译通过运行就ok了，但是仍然发生了一些问题,由于项目是从JDK7升级上来的, 因此有些地方还是采用的配置, 因此当发现在编译时遇到了\n* class版本不支持\n* 提示:无效的源发行版: 1.8\n我们要检查俩个地方\n* build.gradle 这个文件里指定了编译器版本(例如sourceCompatibility, 需要注意的是看看是否依赖了其他的gradle配置, 我就踩中了这个坑)\n* Intellij IDEA -Preference-Build, Execution, Deployment-Gradle -Gradle JVM, 看一下这个配置里面的配置, 当我将gradle的配置修改之后如果不修改这里就会出现  无效的源发行版: 1.8\n\n另外我们一般在项目里会设置JDK版本(项目右击Open Moudle Setting), 这个只是设置整个idea的项目相关的, 也就是和你写代码相关, 和项目的构建等等没啥关系\n\n## 使用eclipse格式化文件\nIDEA如果要使用eclipse的格式化文件需要安装`Eclipse Code Formatter`插件, 然后在setting里的`Other Seetings`里的`Eclipse Code Formatter`里引用格式化文件就好了\n\n## Idea打包与classpath\n当我们使用maven创建一个项目的时候会创建出如下的目录\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/idea%20classpath.png)\n我们会看到如下的几个目录, 这几个目录都是设置在classpath上\n* Sources ：src/main/java\n* Resources : src/main/resources\n如果我们要新添加一个classpath时, 点击add Content Root就好. \n> 注意我们不要使用`Run/Debug Configurations`里的VM options, 这个路径有时候是让启动我们自己程序的Idea进程使用的.\n我们在程序里可以使用\n```java\nInputStream in = TestReadFile.class.getClassLoader().getResourceAsStream(\"./mybatis-config.xml\");\n```\n这种直接读取classpath也就是resources中的文件. 当使用Maven打包之后, 也可以直接从jar包中读取\n![]()\n我们看到resources目录直接放到了jar包的根目录下,但是我们需要配置一些maven的打包方式\n```xml\n\n```\n\n## 快捷键\n* 块选择 : `ALT Shift Insert`","slug":"mgits/IDEA 设置","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvo0074vjs6a79b2bmw"},{"date":"2012-08-19T16:00:00.000Z","title":"SVN 总结","_content":"## 服务器搭建\n下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```java\n# password-db = passwd\n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n\n## 修改服务器地址\n当svn服务器地址变化之后我们使用如下命令进行修改\n```java\nsvn switch --relocate http://10.234.10.11/svn/server/ http://10.230.8.116/svn/server/\n```\n> 在修改前后我们可以使用`svn info`命令进行查看, 当前svn信息.\n\n## 无法clean up\n在TortoiseSVN执行clean up时报错“Previous operation has not finished; run 'cleanup' if it was interrupted”, 遇到这种情况只要在命令行里执行\n```bash\nsvn cleanup\n```\n就好了\n> 需要在安装TortoiseSVN时, 勾选上命令行工具","source":"_posts/mgits/SVN 总结.md","raw":"category: mgits\ndate: 2012-08-20\ntitle: SVN 总结\n---\n## 服务器搭建\n下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```java\n# password-db = passwd\n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n\n## 修改服务器地址\n当svn服务器地址变化之后我们使用如下命令进行修改\n```java\nsvn switch --relocate http://10.234.10.11/svn/server/ http://10.230.8.116/svn/server/\n```\n> 在修改前后我们可以使用`svn info`命令进行查看, 当前svn信息.\n\n## 无法clean up\n在TortoiseSVN执行clean up时报错“Previous operation has not finished; run 'cleanup' if it was interrupted”, 遇到这种情况只要在命令行里执行\n```bash\nsvn cleanup\n```\n就好了\n> 需要在安装TortoiseSVN时, 勾选上命令行工具","slug":"mgits/SVN 总结","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvs0077vjs6iyd82zh5"},{"date":"2015-06-07T16:00:00.000Z","title":"docker命令","_content":"## Docker命令\n### `service docker start`  \n安装之后启动 Docker 服务.\n\n### `docker pull`\n命令来从仓库获取所需要的镜像\n```java\ndocker pull ubuntu12.04\n```\n\n### `docker push`\n把自己创建的镜像上传到仓库中来共享\n```java\ndocker push ouruser/sinatra\n```\n\n### `docker images`\n显示本地已有的镜像.\n\n### `docker commit`\n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```java\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n### `docker build`\n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```java\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n### `docker tag`\n命令来修改镜像的标签.\n```java\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n### `docker import`\n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```java\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n### `docker save`\n导出镜像到本地文件\n```java\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n### `docker load`\n从导出的本地文件中再导入到本地镜像库\n```java\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n### `docker rmi`\n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```java\nsudo docker rmi training/sinatra\n```\n\n### `docker run`  \n基于镜像新建一个容器并启动\n```java\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n映射所有接口地址： 使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```java\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n此时默认会绑定本地所有接口上的所有地址。 映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```java\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n映射到指定地址的任意端口。 使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```java\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n### `docker start`\n直接将一个已经终止的容器启动运行\n\n### `docker stop`\n终止一个运行中的容器.\n\n### `docker restart`\n将一个运行态的容器终止,然后再重新启动它.\n\n### `docker attach`\n进入容器\n\n### `docker export `\n导出本地某个容器\n```java\ndocker export 7691a814370e > ubuntu.tar\n```\n\n### `docker import`\n从容器快照文件中再导入为镜像\n```java\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n### `docker rm`\n移除容器.删除一个处于终止状态的容器\n```java\ndocker rm  trusting_newton\n```\n\n### `docker search`\n查找官方仓库中的镜像\n\n### `docker ps`\n\n### `docker logs`\n获取容器的输出信息\n```java\ndocker logs insane_babbage\n```\n\n### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```java\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile\n\nDockerfile中每一条指令都创建镜像的一层,例如\n```java\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n`docker load` vs `docker import` 用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n","source":"_posts/mgits/docker命令.md","raw":"category: mgits\ndate: 2015-06-08\ntitle: docker命令\n---\n## Docker命令\n### `service docker start`  \n安装之后启动 Docker 服务.\n\n### `docker pull`\n命令来从仓库获取所需要的镜像\n```java\ndocker pull ubuntu12.04\n```\n\n### `docker push`\n把自己创建的镜像上传到仓库中来共享\n```java\ndocker push ouruser/sinatra\n```\n\n### `docker images`\n显示本地已有的镜像.\n\n### `docker commit`\n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```java\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n### `docker build`\n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```java\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n### `docker tag`\n命令来修改镜像的标签.\n```java\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n### `docker import`\n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```java\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n### `docker save`\n导出镜像到本地文件\n```java\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n### `docker load`\n从导出的本地文件中再导入到本地镜像库\n```java\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n### `docker rmi`\n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```java\nsudo docker rmi training/sinatra\n```\n\n### `docker run`  \n基于镜像新建一个容器并启动\n```java\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n映射所有接口地址： 使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```java\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n此时默认会绑定本地所有接口上的所有地址。 映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```java\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n映射到指定地址的任意端口。 使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```java\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n### `docker start`\n直接将一个已经终止的容器启动运行\n\n### `docker stop`\n终止一个运行中的容器.\n\n### `docker restart`\n将一个运行态的容器终止,然后再重新启动它.\n\n### `docker attach`\n进入容器\n\n### `docker export `\n导出本地某个容器\n```java\ndocker export 7691a814370e > ubuntu.tar\n```\n\n### `docker import`\n从容器快照文件中再导入为镜像\n```java\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n### `docker rm`\n移除容器.删除一个处于终止状态的容器\n```java\ndocker rm  trusting_newton\n```\n\n### `docker search`\n查找官方仓库中的镜像\n\n### `docker ps`\n\n### `docker logs`\n获取容器的输出信息\n```java\ndocker logs insane_babbage\n```\n\n### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```java\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile\n\nDockerfile中每一条指令都创建镜像的一层,例如\n```java\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n`docker load` vs `docker import` 用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n","slug":"mgits/docker命令","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvv0079vjs6vajilgpq"},{"date":"2016-03-15T16:00:00.000Z","title":"git","_content":"\n## 添加忽略文件\n如果想要忽略文件或者文件夹的话, 可以直接修改`.gitignore`文件.\n\n例如我要忽略pulic目录下所有的文件和文件夹, 只需要在`.gitignore`文件中添加如下一行\n```bash\npublic/*\n```\n> 需要注意的是, 如果你在master分之上将其忽略了, 那么当你跳转到其他分之的时候, 你还需要修改其他分支的`.gitignore`文件\n","source":"_posts/mgits/git.md","raw":"category: mgits\ndate: 2016-03-16\ntitle: git\n---\n\n## 添加忽略文件\n如果想要忽略文件或者文件夹的话, 可以直接修改`.gitignore`文件.\n\n例如我要忽略pulic目录下所有的文件和文件夹, 只需要在`.gitignore`文件中添加如下一行\n```bash\npublic/*\n```\n> 需要注意的是, 如果你在master分之上将其忽略了, 那么当你跳转到其他分之的时候, 你还需要修改其他分支的`.gitignore`文件\n","slug":"mgits/git","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihvz007bvjs6wg7l80l4"},{"date":"2014-09-07T16:00:00.000Z","title":"gitbook使用","_content":"# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n","source":"_posts/mgits/gitbook.md","raw":"category: mgits\ndate: 2014-09-08\ntitle: gitbook使用\n---\n# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n","slug":"mgits/gitbook","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihw2007evjs62zy6wlsc"},{"date":"2016-03-03T16:00:00.000Z","title":"Java游戏服务器设计","_content":"从毕业就开始在游戏行业摸爬滚打,至今4年将至,今天特意总结一下这四年来的心得.\n\n现在的游戏服务器大多采用Netty作为网络传输层,然后采用Reactor模型将消息转发到业务线程池中进行执行,然后在业务线程池中进行CPU计算,数据库IO操作,最后将结果返回给前端.\n\n这样的游戏服务器在压测的时候在线玩家不会超过2000人,而且经常会出现比较大的延迟,因为有的IO操作真的很耗时. \n\n在上个项目中我见到了这样一种设计,仍然是采用Netty完成网络层Socket数据读取发送工作,然后将解码出的数据扔到俩个消息队列里面去(采用Vertx的EventBus实现). 一个消息队列负责登录请求,一个消息队列负责整个游戏的业务逻辑. 这么着一来整个游戏的业务就不会出现数据竞争的情况. 然后再定时的将数据写到redis里面去. 这种设计在压测的时候达到了10000人的同时在线规模. (当然还有很多优化的地方, 例如在消息查找的时候采取ASM而不是低效的JDK反射, 但是并没有对JVM和Netty进行过特殊优化, 只是对JVM的新生代的分区将8:1:1改成了6:2:2)\n\n前俩天和一些游戏团队的人聊了聊,他们一致认为这种设计方式没有能充分的利用上主机多核的优势, 但是在Reactor的模型中, 主线程池和工作线程池都是需要CPU来运算的, 如果所有的CPU运算都来支持业务逻辑, 那么玩家一样会感觉到卡顿. 而且我们还可以对刚才的设计进行优化, 将不同模块业务放到不同的线程进行. 例如在Thread1中进行玩家自己的业务逻辑运算, 在Thread2中进行公会模块的业务计算, 当公会对玩家本身数据产生影响的时候, 我们可以让公会线程给玩家的业务线程发送消息(同样的使用消息队列). 这么着也能最大可能的利用多核优势同时让开发人员少的思考数据竞争出现的问题, 现在大多数的开发人员在处理数据竞争的时候还是较多的使用synchronized这种加锁方式(有些底层的接口也有可能使用读写锁, 但是使用锁, 在大规模用户的情况下,真的比较耗时).\n\n还有一点需要说的是, 在上个项目中,只使用到了很少的数据库表, 基本上玩家数据都存储到了一张表里, 当定时存储的时候,将玩家数据整个序列化成一个JSON串, 然后入库. 这么做有显而易见的好处,在分服的游戏中, 合服很容易而且在线上出现问题的时候,也很容易拿到一个玩家的数据进行问题排查. 而且在线上的时候也会出现因为异常而导致玩家刷材料等等, 因此如果在处理消息之前, 拿一个玩家备份的数据让玩家去操作,一旦出现数据异常也不会对玩家自己的数据造成影响. (需要考虑的是大量的序列号和反序列化会造成大量的GC操作.)","source":"_posts/mgits/java游戏服务器.md","raw":"category: mgits\ndate: 2016-03-04\ntitle: Java游戏服务器设计\n---\n从毕业就开始在游戏行业摸爬滚打,至今4年将至,今天特意总结一下这四年来的心得.\n\n现在的游戏服务器大多采用Netty作为网络传输层,然后采用Reactor模型将消息转发到业务线程池中进行执行,然后在业务线程池中进行CPU计算,数据库IO操作,最后将结果返回给前端.\n\n这样的游戏服务器在压测的时候在线玩家不会超过2000人,而且经常会出现比较大的延迟,因为有的IO操作真的很耗时. \n\n在上个项目中我见到了这样一种设计,仍然是采用Netty完成网络层Socket数据读取发送工作,然后将解码出的数据扔到俩个消息队列里面去(采用Vertx的EventBus实现). 一个消息队列负责登录请求,一个消息队列负责整个游戏的业务逻辑. 这么着一来整个游戏的业务就不会出现数据竞争的情况. 然后再定时的将数据写到redis里面去. 这种设计在压测的时候达到了10000人的同时在线规模. (当然还有很多优化的地方, 例如在消息查找的时候采取ASM而不是低效的JDK反射, 但是并没有对JVM和Netty进行过特殊优化, 只是对JVM的新生代的分区将8:1:1改成了6:2:2)\n\n前俩天和一些游戏团队的人聊了聊,他们一致认为这种设计方式没有能充分的利用上主机多核的优势, 但是在Reactor的模型中, 主线程池和工作线程池都是需要CPU来运算的, 如果所有的CPU运算都来支持业务逻辑, 那么玩家一样会感觉到卡顿. 而且我们还可以对刚才的设计进行优化, 将不同模块业务放到不同的线程进行. 例如在Thread1中进行玩家自己的业务逻辑运算, 在Thread2中进行公会模块的业务计算, 当公会对玩家本身数据产生影响的时候, 我们可以让公会线程给玩家的业务线程发送消息(同样的使用消息队列). 这么着也能最大可能的利用多核优势同时让开发人员少的思考数据竞争出现的问题, 现在大多数的开发人员在处理数据竞争的时候还是较多的使用synchronized这种加锁方式(有些底层的接口也有可能使用读写锁, 但是使用锁, 在大规模用户的情况下,真的比较耗时).\n\n还有一点需要说的是, 在上个项目中,只使用到了很少的数据库表, 基本上玩家数据都存储到了一张表里, 当定时存储的时候,将玩家数据整个序列化成一个JSON串, 然后入库. 这么做有显而易见的好处,在分服的游戏中, 合服很容易而且在线上出现问题的时候,也很容易拿到一个玩家的数据进行问题排查. 而且在线上的时候也会出现因为异常而导致玩家刷材料等等, 因此如果在处理消息之前, 拿一个玩家备份的数据让玩家去操作,一旦出现数据异常也不会对玩家自己的数据造成影响. (需要考虑的是大量的序列号和反序列化会造成大量的GC操作.)","slug":"mgits/java游戏服务器","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihw7007gvjs6tp6wxpco"},{"date":"2016-05-27T16:00:00.000Z","title":"mac","_content":"\n## 修改root密码\n```java\nsudo passwd root\n```\n直接输入新密码即可\n","source":"_posts/mgits/mac.md","raw":"category: mgits\ndate: 2016-05-28\ntitle: mac\n---\n\n## 修改root密码\n```java\nsudo passwd root\n```\n直接输入新密码即可\n","slug":"mgits/mac","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwb007jvjs61dns51ie"},{"date":"2012-08-19T16:00:00.000Z","title":"SVN 总结","_content":"## 服务器搭建\n下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```java\n# password-db = passwd\n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n\n## 修改服务器地址\n当svn服务器地址变化之后我们使用如下命令进行修改\n```java\nsvn switch --relocate http://10.234.10.11/svn/server/ http://10.230.8.116/svn/server/\n```\n> 在修改前后我们可以使用`svn info`命令进行查看, 当前svn信息.\n","source":"_posts/mgits/svn服务器搭建.md","raw":"category: mgits\ndate: 2012-08-20\ntitle: SVN 总结\n---\n## 服务器搭建\n下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```java\n# password-db = passwd\n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n\n## 修改服务器地址\n当svn服务器地址变化之后我们使用如下命令进行修改\n```java\nsvn switch --relocate http://10.234.10.11/svn/server/ http://10.230.8.116/svn/server/\n```\n> 在修改前后我们可以使用`svn info`命令进行查看, 当前svn信息.\n","slug":"mgits/svn服务器搭建","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwf007lvjs6mpdafqw1"},{"date":"2015-08-07T16:00:00.000Z","title":"unity命令行使用","_content":"# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```java\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```java\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```java\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```java\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n","source":"_posts/mgits/unity命令行使用.md","raw":"category: mgits\ndate: 2015-08-08\ntitle: unity命令行使用\n---\n# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```java\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```java\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```java\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```java\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n","slug":"mgits/unity命令行使用","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwj007nvjs6q8lgb5ze"},{"date":"2015-10-07T16:00:00.000Z","title":"GVIM","_content":"\n# _vimrc配置文件\n## GVIM打开即全屏\n`au GUIEnter * simalt ~x `\n\n## 设置VeraMono字体\n[VeraMono](http://www.vimer.cn/wp-content/uploads/2009/11/VeraMono.ttf)需要下载安装(百度字体安装就好)\n`set guifont=Bitstream_Vera_Sans_Mono:h10:cANSI`\n\n## python编译\n```java\nautocmd BufRead *.py set makeprg=python\\ -c\\ \\\"import\\ py_compile,sys;\\ sys.stderr=sys.stdout;\\ py_compile.compile(r'%')\\\"  \nautocmd BufRead *.py set efm=%C\\ %.%#,%A\\ \\ File\\ \\\"%f\\\"\\\\,\\ line\\ %l%.%#,%Z%[%^\\ ]%\\\\@=%m  \nautocmd BufRead *.py nmap <F5> :!python %<CR>  \nautocmd BufRead *.py nmap <F6> :make<CR>  \nautocmd BufRead *.py copen \"如果是py文件，则同时打开编译信息窗口  \n```\n\n# 快捷键\n* 搜索：`/`向下搜索. `?`向上搜索\n* 替换： `:%s/abc/123/g`, 将abc都替换为123\n* 删除行：`dd`删除整行. `5dd`从当前行开始向后删除5整行. `D`从光标删除到行尾\n* 删除字符：`x`向后删除一个字符. `X`向前删除一个字符\n* 撤销: `u`\n* 复制:`yy`复制一行. `5yy`从当前行开始向下复制5行\n* 粘贴: `p`光标向下移动. `P`光标不动\n* 块选择: `V`多行整行选择. `v`多行字符选择. `ctrl v`矩阵方式选择.\n* 光标移动：`$`移动到行尾. `0`移动到行首. `G`移动到最后一行. `gg`移动到最一行.\n* 窗口编辑: `：split`水平新建窗口. `：vsplit `垂直分割.\n* 在窗口间游走: `Ctrl W` 加 `h, j, k, l`一起使用\n* 分页编辑： `：tabnew`新建分页。 `：tabclose`关闭当前分页. `：tabonly `关闭其他所有的分页\n* 顶部底部跳转： 顶部``, 底部`shift + g`\n\n# 插件\n## [Pydiction ](http://www.vim.org/scripts/script.php?script_id=850)\npython自动补全插件\n\n配置,`_vimrc`文件追加\n```java\nfiletype plugin on\nlet g:pydiction_location = 'D:/Program Files/Vim/pydiction/complete-dict'\n```\n然后将`pydiction/after/ftplugin/python_pydiction.vim`复制到`Vim\\vimfiles\\ftplugin\\python_pydiction.vim`\n\n## [The NERD tree](http://www.vim.org/scripts/script.php?script_id=1658)\n文件树. 将下载下来的压缩包解压到`Vim\\vimfiles`\n* `:NERDTree` 打开当前文件所在目录树. 该命令后可跟需要打开的目录路径\n* `:NERDTreeClose` 关闭目录树\n\n修改_vimrc配置文件,添加映射\n```java\nnmap <F2> :NERDTreeToggle<CR>  \n```\n\n## [bsh.vim](http://www.vim.org/scripts/script.php?script_id=1202)\nShell语法高亮\n\n只需将`bsh.vim `文件拷贝到`Vim\\vimfiles\\syntax`就可以了\n","source":"_posts/mgits/vim.md","raw":"category: mgits\ndate: 2015-10-08\ntitle: GVIM\n---\n\n# _vimrc配置文件\n## GVIM打开即全屏\n`au GUIEnter * simalt ~x `\n\n## 设置VeraMono字体\n[VeraMono](http://www.vimer.cn/wp-content/uploads/2009/11/VeraMono.ttf)需要下载安装(百度字体安装就好)\n`set guifont=Bitstream_Vera_Sans_Mono:h10:cANSI`\n\n## python编译\n```java\nautocmd BufRead *.py set makeprg=python\\ -c\\ \\\"import\\ py_compile,sys;\\ sys.stderr=sys.stdout;\\ py_compile.compile(r'%')\\\"  \nautocmd BufRead *.py set efm=%C\\ %.%#,%A\\ \\ File\\ \\\"%f\\\"\\\\,\\ line\\ %l%.%#,%Z%[%^\\ ]%\\\\@=%m  \nautocmd BufRead *.py nmap <F5> :!python %<CR>  \nautocmd BufRead *.py nmap <F6> :make<CR>  \nautocmd BufRead *.py copen \"如果是py文件，则同时打开编译信息窗口  \n```\n\n# 快捷键\n* 搜索：`/`向下搜索. `?`向上搜索\n* 替换： `:%s/abc/123/g`, 将abc都替换为123\n* 删除行：`dd`删除整行. `5dd`从当前行开始向后删除5整行. `D`从光标删除到行尾\n* 删除字符：`x`向后删除一个字符. `X`向前删除一个字符\n* 撤销: `u`\n* 复制:`yy`复制一行. `5yy`从当前行开始向下复制5行\n* 粘贴: `p`光标向下移动. `P`光标不动\n* 块选择: `V`多行整行选择. `v`多行字符选择. `ctrl v`矩阵方式选择.\n* 光标移动：`$`移动到行尾. `0`移动到行首. `G`移动到最后一行. `gg`移动到最一行.\n* 窗口编辑: `：split`水平新建窗口. `：vsplit `垂直分割.\n* 在窗口间游走: `Ctrl W` 加 `h, j, k, l`一起使用\n* 分页编辑： `：tabnew`新建分页。 `：tabclose`关闭当前分页. `：tabonly `关闭其他所有的分页\n* 顶部底部跳转： 顶部``, 底部`shift + g`\n\n# 插件\n## [Pydiction ](http://www.vim.org/scripts/script.php?script_id=850)\npython自动补全插件\n\n配置,`_vimrc`文件追加\n```java\nfiletype plugin on\nlet g:pydiction_location = 'D:/Program Files/Vim/pydiction/complete-dict'\n```\n然后将`pydiction/after/ftplugin/python_pydiction.vim`复制到`Vim\\vimfiles\\ftplugin\\python_pydiction.vim`\n\n## [The NERD tree](http://www.vim.org/scripts/script.php?script_id=1658)\n文件树. 将下载下来的压缩包解压到`Vim\\vimfiles`\n* `:NERDTree` 打开当前文件所在目录树. 该命令后可跟需要打开的目录路径\n* `:NERDTreeClose` 关闭目录树\n\n修改_vimrc配置文件,添加映射\n```java\nnmap <F2> :NERDTreeToggle<CR>  \n```\n\n## [bsh.vim](http://www.vim.org/scripts/script.php?script_id=1202)\nShell语法高亮\n\n只需将`bsh.vim `文件拷贝到`Vim\\vimfiles\\syntax`就可以了\n","slug":"mgits/vim","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwm007pvjs6rkyk7tn1"},{"date":"2015-06-07T16:00:00.000Z","title":"在windows上搭建rust开发环境","_content":"在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","source":"_posts/mgits/windows rust.md","raw":"category: mgits\ndate: 2015-06-08\ntitle: 在windows上搭建rust开发环境\n---\n在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","slug":"mgits/windows rust","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwp007rvjs6q62ntath"},{"date":"2015-10-14T16:00:00.000Z","title":"技术CheckList","_content":"\n## FastJSON\n\n### 序列化bug\n在项目中运营团队给出了下面这样的一个公告\n```java\n================================================\n官方QQ群： 467027422\n官方微信号：gm-xyxmp\n微信订阅号：xyxmpsy\n\n亲爱的小伙伴：\n\n大家好，老猪给各位请安了！\n\n首款能交易的3D卡牌游戏，星爷独家正版授权《西游降魔篇3D》\n自2015年7月21日正式登陆iOS平台后，大量玩家热情涌入游戏\n，老猪我面对此景喜极而泣，为了让更多小伙伴加入到咱们的\n大团队中，老猪我决定[FFFF00]10月16日11：00开启新服N23-物华天宝 [-]，\n诚邀各位新老玩家的加入！\n\n\n新服开启，精彩纷呈的活动期待各位的参与，丰厚的大礼拿到手\n抽筋，在《西游降魔篇3D》西行的途中，让我们一同感受友情，\n感受激情，感受无限快乐！\n\n服务器名称：[FFFF00]N23-物华天宝 [-]\n开服时间：[FFFF00]2015年10月16日11：00（周五）[-]\n\n\n伴随开服的同时，多个活动前来助阵！\n[FFFF00]活动一：连续登陆送豪礼[-]\n[FFFF00]活动二：冲级领元宝[-]\n[FFFF00]活动三：战力大比拼[-]\n[FFFF00]活动四：五星神将双倍抽[-]\n[FFFF00]活动五：天天有礼送段小姐[-]\n[FFFF00]活动六：累积充值送玉帝[-]\n[FFFF00]活动七：每日礼包大回馈[-]\n[FFFF00]活动八：首充翻倍送豪礼[-]\n[FFFF00]活动九：签到送好礼[-]\n\n\n活动详情请查看游戏内公告！\n================================================\n                                                            《西游降魔篇3D》运营团队\n```\n当我将其赋值到一个对象`obj#value`时,然后使用`JSON.toJSONString(obj)`的时候遇到了下面的异常:\n```java\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 160\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:868)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:602)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeString(SerializeWriter.java:1366)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:49)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:34)\n\tat com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:369)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:430)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:418)\n\tat Print1.main(Print1.java:52)\n```\n出现的原因是:`服务器名称：[FFFF00]N23-物华天宝 [-]`物华天宝后面跟的空格，不是我们常用的ascii码为32的空格，而是一个ascii码为160特殊的空格符,导致JSON序列化时失败.\n\n## 用户名字符集\n用户可能输入emoji表情符号,这种符号普遍存在iOS与android系统中,这种表情不处理直接存储到MySQL5.5以下的版本会报错\n> 这种符号采用Unicode 6标准4个bytes作为存储单元,MySQL存储这种字符需要修改数据库字符集为utf8mb4,但数据回传给网页或者移动客户端时则需要做兼容处理\n\n## 日志问题\n在项目的开发过程中不允许使用debug模式, 一定要使用日志分析问题, 因为在线上时候, 没办法使用debug的方式, 因此在记录的日志的时候, 一定要记录的全(每个数据变化都要记录下来), 简(剩下来的就是钱)\n","source":"_posts/mgits/技术CheckList.md","raw":"category: mgits\ndate: 2015-10-15\ntitle: 技术CheckList\n---\n\n## FastJSON\n\n### 序列化bug\n在项目中运营团队给出了下面这样的一个公告\n```java\n================================================\n官方QQ群： 467027422\n官方微信号：gm-xyxmp\n微信订阅号：xyxmpsy\n\n亲爱的小伙伴：\n\n大家好，老猪给各位请安了！\n\n首款能交易的3D卡牌游戏，星爷独家正版授权《西游降魔篇3D》\n自2015年7月21日正式登陆iOS平台后，大量玩家热情涌入游戏\n，老猪我面对此景喜极而泣，为了让更多小伙伴加入到咱们的\n大团队中，老猪我决定[FFFF00]10月16日11：00开启新服N23-物华天宝 [-]，\n诚邀各位新老玩家的加入！\n\n\n新服开启，精彩纷呈的活动期待各位的参与，丰厚的大礼拿到手\n抽筋，在《西游降魔篇3D》西行的途中，让我们一同感受友情，\n感受激情，感受无限快乐！\n\n服务器名称：[FFFF00]N23-物华天宝 [-]\n开服时间：[FFFF00]2015年10月16日11：00（周五）[-]\n\n\n伴随开服的同时，多个活动前来助阵！\n[FFFF00]活动一：连续登陆送豪礼[-]\n[FFFF00]活动二：冲级领元宝[-]\n[FFFF00]活动三：战力大比拼[-]\n[FFFF00]活动四：五星神将双倍抽[-]\n[FFFF00]活动五：天天有礼送段小姐[-]\n[FFFF00]活动六：累积充值送玉帝[-]\n[FFFF00]活动七：每日礼包大回馈[-]\n[FFFF00]活动八：首充翻倍送豪礼[-]\n[FFFF00]活动九：签到送好礼[-]\n\n\n活动详情请查看游戏内公告！\n================================================\n                                                            《西游降魔篇3D》运营团队\n```\n当我将其赋值到一个对象`obj#value`时,然后使用`JSON.toJSONString(obj)`的时候遇到了下面的异常:\n```java\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 160\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:868)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:602)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeString(SerializeWriter.java:1366)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:49)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:34)\n\tat com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:369)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:430)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:418)\n\tat Print1.main(Print1.java:52)\n```\n出现的原因是:`服务器名称：[FFFF00]N23-物华天宝 [-]`物华天宝后面跟的空格，不是我们常用的ascii码为32的空格，而是一个ascii码为160特殊的空格符,导致JSON序列化时失败.\n\n## 用户名字符集\n用户可能输入emoji表情符号,这种符号普遍存在iOS与android系统中,这种表情不处理直接存储到MySQL5.5以下的版本会报错\n> 这种符号采用Unicode 6标准4个bytes作为存储单元,MySQL存储这种字符需要修改数据库字符集为utf8mb4,但数据回传给网页或者移动客户端时则需要做兼容处理\n\n## 日志问题\n在项目的开发过程中不允许使用debug模式, 一定要使用日志分析问题, 因为在线上时候, 没办法使用debug的方式, 因此在记录的日志的时候, 一定要记录的全(每个数据变化都要记录下来), 简(剩下来的就是钱)\n","slug":"mgits/技术CheckList","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwu007tvjs6ln6d4ia1"},{"date":"2016-03-15T16:00:00.000Z","title":"原码 反码 补码","_content":"在大学的时候曾经研究过计算机中数字补码存储方式. 但是时间太长了, 今天拿出点时间再回顾一下,做个笔记.\n\n我们来看一个简单的数字, byte类型的10.我们知道byte的存储单位是8个byte. 因此我们首先看一下10这个数字的原码表示形式\n```bash\n0000 1010\n```\n最左边的最高位表示数字的正反, 因此-10的原码表示形式为\n```bash\n1000 1010\n```\n\n接下来, 我们来看一下反码. 反码就是数字的二进制表示的最高位符号位不变, 其他位取反.\n```bash\n10的反码\n0111 0101\n-10的反码\n1111 0101\n```\n\n接着我们看一下数字的补码.\n* 正数的补码就是原码\n* 负数的补码是数字的反码加1\n\n```bash\n10的补码\n0000 1010\n-10的补码\n1111 0110\n```\n\n那么计算机为什么要采用补码的形式存储数字呢?\n\n第一点: 为了存储0.\n```bash\n正数的0的原码\n0000 0000\n负数的0的原码\n1000 0000\n```\n我们发现同一个数字却有俩种不同的存储形式, 那么如果采用补码呢?\n则`1000 0000`也变成了`0000 0000`\n\n第二点: 可以简化加减法运算. 采用补码的话, 可以将减法作为加法来运算.","source":"_posts/mgits/编码和补码.md","raw":"category: mgits\ndate: 2016-03-16\ntitle: 原码 反码 补码\n---\n在大学的时候曾经研究过计算机中数字补码存储方式. 但是时间太长了, 今天拿出点时间再回顾一下,做个笔记.\n\n我们来看一个简单的数字, byte类型的10.我们知道byte的存储单位是8个byte. 因此我们首先看一下10这个数字的原码表示形式\n```bash\n0000 1010\n```\n最左边的最高位表示数字的正反, 因此-10的原码表示形式为\n```bash\n1000 1010\n```\n\n接下来, 我们来看一下反码. 反码就是数字的二进制表示的最高位符号位不变, 其他位取反.\n```bash\n10的反码\n0111 0101\n-10的反码\n1111 0101\n```\n\n接着我们看一下数字的补码.\n* 正数的补码就是原码\n* 负数的补码是数字的反码加1\n\n```bash\n10的补码\n0000 1010\n-10的补码\n1111 0110\n```\n\n那么计算机为什么要采用补码的形式存储数字呢?\n\n第一点: 为了存储0.\n```bash\n正数的0的原码\n0000 0000\n负数的0的原码\n1000 0000\n```\n我们发现同一个数字却有俩种不同的存储形式, 那么如果采用补码呢?\n则`1000 0000`也变成了`0000 0000`\n\n第二点: 可以简化加减法运算. 采用补码的话, 可以将减法作为加法来运算.","slug":"mgits/编码和补码","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihwx007vvjs6sulxzste"},{"date":"2015-07-04T16:00:00.000Z","title":"项目CheckList","_content":"\n## 数据接口都尽量做成数组形式\n这是为了提高拓展性,以防策划将模块提出批处理\n\n## 代码中不要出现中文\n当要出现中文的时候,可以根据个英文索引到表里查国际化文字.\n\n服务器向客户端提示的时候发送错误号,由客户端进行国际化\n\n## 客户端打包\n在打包的时候，加上时间和svn版本号，方便渠道确定客户端的版本是一致的\n\n## 交易类模块\n交易类模块要慎重考虑,玩家可能刷元宝\n\n## 玩家使用模拟器登录\n这个要做技术处理\n\n## id\n项目里边每个模块的ID要是全区唯一的,保证合服顺利\n\n## GWF的问题\n参考[记今天域名和GWF的问题](http://blog.zhukunqian.com/?p=1377)\n\n## 模块次数\n每个模块活动都加一个每日次数限制。例如扫荡类的功能，加一个每日最大扫荡次数，避免出现角色刷货币的情况.\n\n## 道具\n* 道具信息里添加上获得来源途径信息. 将途径分类, 以区别特殊道具 \n\n## 数据备份\n每天备份玩家数据, 以便后期查bug和回档使用","source":"_posts/mgits/项目CheckList.md","raw":"category: mgits\ndate: 2015-07-05\ntitle: 项目CheckList\n---\n\n## 数据接口都尽量做成数组形式\n这是为了提高拓展性,以防策划将模块提出批处理\n\n## 代码中不要出现中文\n当要出现中文的时候,可以根据个英文索引到表里查国际化文字.\n\n服务器向客户端提示的时候发送错误号,由客户端进行国际化\n\n## 客户端打包\n在打包的时候，加上时间和svn版本号，方便渠道确定客户端的版本是一致的\n\n## 交易类模块\n交易类模块要慎重考虑,玩家可能刷元宝\n\n## 玩家使用模拟器登录\n这个要做技术处理\n\n## id\n项目里边每个模块的ID要是全区唯一的,保证合服顺利\n\n## GWF的问题\n参考[记今天域名和GWF的问题](http://blog.zhukunqian.com/?p=1377)\n\n## 模块次数\n每个模块活动都加一个每日次数限制。例如扫荡类的功能，加一个每日最大扫荡次数，避免出现角色刷货币的情况.\n\n## 道具\n* 道具信息里添加上获得来源途径信息. 将途径分类, 以区别特殊道具 \n\n## 数据备份\n每天备份玩家数据, 以便后期查bug和回档使用","slug":"mgits/项目CheckList","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihx0007xvjs60ok3a28r"},{"date":"2015-11-19T16:00:00.000Z","title":"Netty ByteBuf","_content":"首先我们来看一下netty buffer包的继承结构\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/bytebuf.jpg)\n接下来我会对几个类进行代码测试.\n\n首先我们来看一下如何使用Netty提供的工具类构建一个ByteBuf\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\nAssert.assertEquals(1024, buf.capacity());\n```\n我们使用`ByteBufAllocator`这个工具类构建了一个`1024`大小的`ByteBuf`出来.\n\nByteBuf提供了 `readerIndex` 和 `writerIndex` 进行缓冲区的顺序读写操作.\n* `readerIndex`标志读取索引\n* `writerIndex`标志写入索引\n* [0, readerIndex] 已经读取多的缓冲区区间\n* [readerIndex, writerIndex] 可读的缓冲区区间\n* [writerIndex, capacity]  可写的缓冲区区间\n\n> 每个索引移动的单位是`bytes`, 在下例中我们向ByteBuf写入一个int数值, `writerIdex`会移动4个`bytes`\n\n## ByteBuf API\n我们首先看一下ByteBuf提供的API\n\n### ByteBuf write\n接下来我们看一下向ByteBuf缓冲区写入数据的API\n```java\n@Test\npublic void testWriteInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(1);\n\t// 写入一个Int数值, writerIndex向后移动4个字节\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n@Test\npublic void testWriteChar() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeChar('a');\n\t// 写入一个Char字符, writerIndex向后移动2个字节\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbyte[] bytes = new byte[]{100};\n\tbuf.writeBytes(bytes);\n\t// 写入一个byte数组, 由于byte数组只有一个元素, writerIndex向后移动1个字节\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytesWithStartEndIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbyte[] bytes = new byte[]{100, 1, 3};\n\tbuf.writeBytes(bytes, 1, 1);\n\t// 我们将三个元素的byte数组写入ByteBuf中,但是在写入的时候我们指定了开始索引和结束索引,\n\t// 由于我们的开始索引和结束索引相等, 因此ByteBuf中只写入了1这个元素\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytes3() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf1.writeInt(1);\n\tbuf.writeBytes(buf1);\n\t// 我们向ByteBuf中写入另一个ByteBuf, 它的索引仍然是增长4. ByteBuf不仅仅可以写入BuyeBuf,还可以写入InputStream和ByteBuffer\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n\n@Test\npublic void testWriteFloat() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeFloat(0.1f);\n\t// 写入一个float, 由于float也是占用4个字节, 因此writerIndex向后移动4个字节\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n@Test\npublic void testWriteByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeByte(1);\n\tAssert.assertEquals(1, buf.writerIndex());\n\tbuf.writeByte(1000);\n\t// 写入一个byte, writerIndex向后移动1个字节,至于写进去的数字大于128,会发生什么,我们在read的时候看一下结果\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(1000);\n\t// 写入一个short, writerIndex向后移动2个字节\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteDouble() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeDouble(1000.0d);\n\t// 写入一个double, writerIndex向后移动8个字节\n\tAssert.assertEquals(8, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBoolean() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBoolean(false);\n\t// 写入一个boolean, writerIndex向后移动1个字节\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteLong() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeLong(100l);\n\t// 写入一个long, writerIndex向后移动8个字节\n\tAssert.assertEquals(8, buf.writerIndex());\n}\n\n@Test\npublic void testWriteOverLoadMaxCapacity() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(5);\n\tbuf.writeBytes(\"123456\".getBytes());\n\t// 虽然在分配的时候我们只分配了5个字节大小的缓冲区,但是我们写入6个字节它也并不报错,\n\t// 而且我们观察到writerIndex确实增长到了6,说明ByteBuf会进行自动拓容.\n\tAssert.assertEquals(6, buf.writerIndex());\n}\n```\n\n### ByteBuf read\n刚才我们看了向ByteBuf缓冲区写入数据的API,接下来我们看一下从ByteBuf缓冲区读取数据的API\n```java\n@Test\npublic void testReadInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(1);\n\tint read = buf.readInt();\n\t// 读取Int, readerIndex向后移动4字节\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(1, read);\n}\n\n@Test\npublic void testReadChar() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeChar('1');\n\tchar read = buf.readChar();\n\t// 读取Char, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n\tAssert.assertEquals('1', read);\n}\n\n@Test\npublic void testReadBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbyte[] read = new byte[10];\n\tbuf.readBytes(read);\n\t// 读取byte数组, 这里需要注意的是, read字节数组的长度不能大于ByteBuf的readerIndex的值,否则会产生数组越界\n\tAssert.assertEquals(10, buf.readerIndex());\n\tAssert.assertEquals(0, read[9]);\n}\n\n@Test\npublic void testReadBytesWithStartEndIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbyte[] read = new byte[10];\n\tbuf.readBytes(read, 2, 3);\n\t// 从第三个索引开始读取到第4个索引的位置, 读取2个字节, readerIndex移动到第4个索引位置上\n\tAssert.assertEquals(3, buf.readerIndex());\n\tAssert.assertEquals(3, read[0]);\n}\n\n@Test\npublic void testRead3Bytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbuf.readBytes(3);\n\t// 读取3个字节, readerIndex向后移动3字节\n\tAssert.assertEquals(3, buf.readerIndex());\n}\n\n@Test\npublic void testReadFloat() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeFloat(10.0f);\n\tfloat read = buf.readFloat();\n\t// 读取Float, readerIndex向后移动4字节\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(10.f, read);\n}\n\n@Test\npublic void testReadLong() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeLong(10l);\n\tbuf.readLong();\n\t// 读取long, readerIndex向后移动8字节\n\tAssert.assertEquals(8, buf.readerIndex());\n\n}\n\n@Test\npublic void testReadByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbuf.readByte();\n\t// 读取byte, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n}\n\n@Test\npublic void testReadShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(10);\n\tbuf.readShort();\n\t// 读取short, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n}\n\n@Test\npublic void testReadBoolean() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBoolean(true);\n\tbuf.readBoolean();\n\t// 读取boolean, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n}\n\n@Test\npublic void testReadDouble() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeDouble(10.0d);\n\tbuf.readDouble();\n\t// 读取double, readerIndex向后移动8字节\n\tAssert.assertEquals(8, buf.readerIndex());\n}\n\n@Test\npublic void testReadUnsignedByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeByte(-10);\n\tshort read = buf.readUnsignedByte();\n\t// 读取无符号byte, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n\tAssert.assertEquals(246, read);\n}\n\n@Test\npublic void testReadUnsignedShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(-1024);\n\t// 我们首先读取出-1024,这个负数,然后转化成无符号数字64512\n\tint read = buf.readUnsignedShort();\n\t// 读取无符号Short, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n\tAssert.assertEquals(64512, read);\n}\n\n@Test\npublic void testReaderIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tAssert.assertEquals(0, buf.readerIndex());\n}\n\n@Test\npublic void testReadableBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tAssert.assertEquals(10, buf.readableBytes());\n\tbuf.readByte();\n\t// 我们读取一个byte之后, 可读取字节变成了9个字节\n\tAssert.assertEquals(9, buf.readableBytes());\n}\n\n@Test\npublic void testReadUnsignedInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(10);\n\tlong read = buf.readUnsignedInt();\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(10, read);\n}\n\n@Test\npublic void testReadSlice() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tByteBuf read = buf.readSlice(5);\n\t// slice出来的ByteBuf与原ByteBuf共享缓冲区\n\tAssert.assertEquals(5, buf.readerIndex());\n\tAssert.assertEquals(1, read.readByte());\n\tAssert.assertEquals(6, buf.readByte());\n\n}\n\n@Test\npublic void testWriteBytesReadInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tint read = buf.readInt();\n\t// 从一个byte数组中读取一个int, 会读取出1, 2, 3, 4这四个byte转换成int为16909060\n\tAssert.assertEquals(16909060, read);\n}\n```\n\n### discard bytes\n在前面的测试中我们看到了,当向ByteBuf写入数据时,当超出分配内存大小时,ByteBuf会进行自动拓容(重新生成一个数组缓冲区,然后将原先的缓冲区内容拷贝到新的缓冲区中),这样一来ByteBuf占用的内从会越来越大. 我们可以是`discardReadBytes()`这个方法重用以前的缓冲区, 它会将[0, readerIndex]区间的内存舍弃掉(内部也是数组复制), 这么着就节间的重用了以前的缓冲区,但是这种方式有一点就是如果频繁的调用这个方法会带来性能问题.\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(\"123456789\".getBytes());\nbuf.readBytes(3);\t// 读取三个字节\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 3\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 9\nSystem.out.println(buf.readableBytes());\t// 可读字节 9 - 3 = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 9 = 41\n\n// 舍弃已读字节, readerIndex重置为0\nbuf.discardReadBytes();\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 6\nSystem.out.println(buf.readableBytes());\t// 可读字节 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 6 = 44\n```\n\n### clear\n这个操作并不会情况缓冲区的内容只是用来将readerIndex和writerIndex重置为0. 但是缓冲区的内容我们是仍然可以读到的. \n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(\"123456789\".getBytes());\nbuf.readBytes(3);\t// 读取三个字节\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 3\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 9\nSystem.out.println(buf.readableBytes());\t// 可读字节 9 - 3 = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 9 = 41\n\n// 重置readerIndex和writerIndex\nbuf.clear();\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 0\nSystem.out.println(buf.readableBytes());\t// 可读字节 readerIndex = 0\nSystem.out.println(buf.writableBytes());\t// 可写字节 capacity - writerIndex = 50\n// 设置writerIndex\nbuf.writerIndex(6);\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 6\nSystem.out.println(buf.readableBytes());\t// 可读字节 writerIndex - readerIndex = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 44\nSystem.out.println(buf.readByte());\n```\n\n### mark reset\nmark reset相关的四个方法也是对指针位置的操作\n* `markReaderIndex()` 记录readerIndex\n* `markWriterIndex()` 记录writerIndex\n* `resetReaderIndex()`  将记录的readerIndex重置到当前的readerIndex值\n* `resetWriterIndex()`  将记录的writerIndex重置到当前的writerIndex值\n\n```java\n@Test\npublic void testReaderIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\n\tbuf.writeBytes(\"123456789\".getBytes());\n\tbuf.readBytes(3);\n\tbuf.markReaderIndex();\n\tbuf.readBytes(1);\n\tAssert.assertEquals(4, buf.readerIndex());\n\tbuf.resetReaderIndex();\n\tAssert.assertEquals(3, buf.readerIndex());\n}\n\n@Test\npublic void testWriterIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\n\tbuf.writeBytes(\"123456789\".getBytes());\n\tbuf.markWriterIndex();\n\tbuf.writeByte(1);\n\tAssert.assertEquals(10, buf.writerIndex());\n\tbuf.resetWriterIndex();\n\tAssert.assertEquals(9, buf.writerIndex());\n}\n```\n\n### 查找\nByteBuf提供丰富的API让我查找某个Byte\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(new byte[]{1, 2, 3, 4 ,5, 6, 7, 8, 9});\n\n// 在指定的范围内查找某个byte\nint idx = buf.indexOf(0, buf.writerIndex(), (byte)2);\nSystem.out.println(idx);\t// 1\n\nidx = buf.indexOf(3, buf.writerIndex(), (byte)2);\nSystem.out.println(idx);\t// -1\n\n// 在[readerIndex, writerIndex]之间查找值\nidx = buf.bytesBefore((byte)2);\nSystem.out.println(idx);  // 4\n\nbuf.readBytes(3);\nidx = buf.bytesBefore((byte)2);\nSystem.out.println(idx); // -1\n\n// 在[readerIndex, writerIndex]之间遍历查找值\nidx = buf.forEachByte(b -> b == (byte) 6);\nSystem.out.println(idx); // 3\n```\n\n### derived buffers\nByteBuf提供多种API用于创建某个ByteBuf的视图或者复制版本\n* `duplicate()` 复制ByteBuf对象, 俩个对象共享同一个缓冲区,但是各自维护自己的索引(readerIndex, writerIndex)\n* `copy()` 复制ByteBuf对象, 俩个对象共享有自己的缓冲区, 缓冲区和索引都不共享\n* `slice()`  复制Bytebuf对象,但是只复制[readerIndex, writerIndex]区间的缓冲区, 俩个对象的缓冲区是共享的,但是维护各自的索引\n\n### get set\nByteBuf不仅仅支持read, write的顺序读写还支持get,set的随机读取。 但是get/set不会进行自动拓容.\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(new byte[]{1, 2, 3, 4 ,5, 6, 7, 8, 9});\n\nbyte b = buf.getByte(2);\nSystem.out.println(buf.readableBytes());\t// 9\nSystem.out.println(buf.readerIndex());\t\t// 0\nSystem.out.println(b);\t\t// 3\n```\n\n## 内存池\nNetty的内存池由`PoolArea`. `PoolArea`由多个`PoolChunk`组成. \n\n## ButeBuf 类型\n看完ByteBuf的API操作我们来看一下ByteBuf的分类,在内存使用种类上ByteBuf分为以下俩类\n* DirectByteBuf : 使用JVM堆外内存分配. 虽然分配和回收速度慢一些,但是从SocketChannel中写入或者读取数据由于少了一次内存复制,因此速度较快.(SocketIO通信时适合使用)\n* HeapByteBuf: 使用JVM堆内内存分配. 内存分配和回收速度较快,但是读写Socket IO的时候由于会额外进行一次内存复制,堆内存对应的缓冲区复制到内核Channel中,性能会有下降.(后端业务在编解码时适合使用)\n\n在内存使用种类上由分为以下俩类\n* PooledByteBuf: 基于内存对象池的ByteBuf, \n* UnpooledByteBuf: \n\n> UnpooledDirectByteBuf, UnpooledHeapByteBuf, UnpooledUnsafeDirectByteBuf ,PooledDirectByteBuf, PooledHeapByteBuf\n\n## AbstractByteBuf\n`AbstractByteBuf`继承自`ByteBuf`, 它内部并没有定义ByteBuf的缓冲区实现,只是通过定义`readerIndex`, `writerIndex`, `capacity`等实现ByteBuf接口中的各种API, 具体的缓冲区实现则由子类实现\n```java\nstatic final ResourceLeakDetector<ByteBuf> leakDetector = new ResourceLeakDetector<ByteBuf>(ByteBuf.class);\n\nint readerIndex;\nprivate int writerIndex;\nprivate int markedReaderIndex;\nprivate int markedWriterIndex;\n\nprivate int maxCapacity;\n\nprivate SwappedByteBuf swappedBuf;\n```\n\n除了操作具体缓冲区API没有实现之外 `AbstractByteBuf`为我们实现了大量的API,首先我们看一下读数据的API\n```java\n@Override\npublic ByteBuf readBytes(byte[] dst, int dstIndex, int length) {\n\t// 检查当前缓冲区中的可读数据是否满足length长度\n    checkReadableBytes(length);\n    // 将当前缓冲区的数据从readerIndex开始读取length个长度到目标dst缓冲区中. \n    // 这个方法也就是拷贝一部分数据到新的缓冲区中,但是并不会改变当前缓冲区的readerIndex和writerIndex\n    getBytes(readerIndex, dst, dstIndex, length);\n    readerIndex += length;\n    return this;\n}\n```\n下面我们看一下写数据的API实现\n```java\n@Override\npublic ByteBuf writeBytes(byte[] src, int srcIndex, int length) {\n    ensureWritable(length);\n    setBytes(writerIndex, src, srcIndex, length);\n    writerIndex += length;\n    return this;\n}\n```\n同样的`setBytes();`是由子类具体实现, 我们着重看一下`ensureWritable()`方法实现\n```java\n@Override\npublic ByteBuf ensureWritable(int minWritableBytes) {\n\t// 如果要写入数据的字节小于0的话, 则直接抛出异常\n    if (minWritableBytes < 0) {\n        throw new IllegalArgumentException(String.format(\n                \"minWritableBytes: %d (expected: >= 0)\", minWritableBytes));\n    }\n\n\t// minWritableBytes <= capacity() - writerIndex, 要写入的字节数小于可写的字节数则直接返回\n    if (minWritableBytes <= writableBytes()) {\n        return this;\n    }\n\n    if (minWritableBytes > maxCapacity - writerIndex) {\n        throw new IndexOutOfBoundsException(String.format(\n                \"writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\",\n                writerIndex, minWritableBytes, maxCapacity, this));\n    }\n\n    // Normalize the current capacity to the power of 2.\n    int newCapacity = calculateNewCapacity(writerIndex + minWritableBytes);\n\n    // Adjust to the new capacity.\n    capacity(newCapacity);\n    return this;\n}\n```\n\n### ResourceLeakDetector\n`ResourceLeakDetector`用于检测内存泄漏. 它被所有ByteBuf实例共享.\n\n### SwappedByteBuf\n\n## AbstractReferenceCountedByteBuf\n\n## UnPooledHeapByteBuf\n不使用对象池的基于堆内存分配的字节缓冲区. 每次IO读写的时候都会创建一个新的UnPooledHeapByteBuf.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/netty/ByteBuf.md","raw":"category: Netty\ndate: 2015-11-20\ntitle: Netty ByteBuf\n---\n首先我们来看一下netty buffer包的继承结构\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/bytebuf.jpg)\n接下来我会对几个类进行代码测试.\n\n首先我们来看一下如何使用Netty提供的工具类构建一个ByteBuf\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\nAssert.assertEquals(1024, buf.capacity());\n```\n我们使用`ByteBufAllocator`这个工具类构建了一个`1024`大小的`ByteBuf`出来.\n\nByteBuf提供了 `readerIndex` 和 `writerIndex` 进行缓冲区的顺序读写操作.\n* `readerIndex`标志读取索引\n* `writerIndex`标志写入索引\n* [0, readerIndex] 已经读取多的缓冲区区间\n* [readerIndex, writerIndex] 可读的缓冲区区间\n* [writerIndex, capacity]  可写的缓冲区区间\n\n> 每个索引移动的单位是`bytes`, 在下例中我们向ByteBuf写入一个int数值, `writerIdex`会移动4个`bytes`\n\n## ByteBuf API\n我们首先看一下ByteBuf提供的API\n\n### ByteBuf write\n接下来我们看一下向ByteBuf缓冲区写入数据的API\n```java\n@Test\npublic void testWriteInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(1);\n\t// 写入一个Int数值, writerIndex向后移动4个字节\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n@Test\npublic void testWriteChar() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeChar('a');\n\t// 写入一个Char字符, writerIndex向后移动2个字节\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbyte[] bytes = new byte[]{100};\n\tbuf.writeBytes(bytes);\n\t// 写入一个byte数组, 由于byte数组只有一个元素, writerIndex向后移动1个字节\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytesWithStartEndIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbyte[] bytes = new byte[]{100, 1, 3};\n\tbuf.writeBytes(bytes, 1, 1);\n\t// 我们将三个元素的byte数组写入ByteBuf中,但是在写入的时候我们指定了开始索引和结束索引,\n\t// 由于我们的开始索引和结束索引相等, 因此ByteBuf中只写入了1这个元素\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBytes3() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf1.writeInt(1);\n\tbuf.writeBytes(buf1);\n\t// 我们向ByteBuf中写入另一个ByteBuf, 它的索引仍然是增长4. ByteBuf不仅仅可以写入BuyeBuf,还可以写入InputStream和ByteBuffer\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n\n@Test\npublic void testWriteFloat() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeFloat(0.1f);\n\t// 写入一个float, 由于float也是占用4个字节, 因此writerIndex向后移动4个字节\n\tAssert.assertEquals(4, buf.writerIndex());\n}\n\n@Test\npublic void testWriteByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeByte(1);\n\tAssert.assertEquals(1, buf.writerIndex());\n\tbuf.writeByte(1000);\n\t// 写入一个byte, writerIndex向后移动1个字节,至于写进去的数字大于128,会发生什么,我们在read的时候看一下结果\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(1000);\n\t// 写入一个short, writerIndex向后移动2个字节\n\tAssert.assertEquals(2, buf.writerIndex());\n}\n\n@Test\npublic void testWriteDouble() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeDouble(1000.0d);\n\t// 写入一个double, writerIndex向后移动8个字节\n\tAssert.assertEquals(8, buf.writerIndex());\n}\n\n@Test\npublic void testWriteBoolean() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBoolean(false);\n\t// 写入一个boolean, writerIndex向后移动1个字节\n\tAssert.assertEquals(1, buf.writerIndex());\n}\n\n@Test\npublic void testWriteLong() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeLong(100l);\n\t// 写入一个long, writerIndex向后移动8个字节\n\tAssert.assertEquals(8, buf.writerIndex());\n}\n\n@Test\npublic void testWriteOverLoadMaxCapacity() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(5);\n\tbuf.writeBytes(\"123456\".getBytes());\n\t// 虽然在分配的时候我们只分配了5个字节大小的缓冲区,但是我们写入6个字节它也并不报错,\n\t// 而且我们观察到writerIndex确实增长到了6,说明ByteBuf会进行自动拓容.\n\tAssert.assertEquals(6, buf.writerIndex());\n}\n```\n\n### ByteBuf read\n刚才我们看了向ByteBuf缓冲区写入数据的API,接下来我们看一下从ByteBuf缓冲区读取数据的API\n```java\n@Test\npublic void testReadInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(1);\n\tint read = buf.readInt();\n\t// 读取Int, readerIndex向后移动4字节\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(1, read);\n}\n\n@Test\npublic void testReadChar() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeChar('1');\n\tchar read = buf.readChar();\n\t// 读取Char, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n\tAssert.assertEquals('1', read);\n}\n\n@Test\npublic void testReadBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbyte[] read = new byte[10];\n\tbuf.readBytes(read);\n\t// 读取byte数组, 这里需要注意的是, read字节数组的长度不能大于ByteBuf的readerIndex的值,否则会产生数组越界\n\tAssert.assertEquals(10, buf.readerIndex());\n\tAssert.assertEquals(0, read[9]);\n}\n\n@Test\npublic void testReadBytesWithStartEndIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbyte[] read = new byte[10];\n\tbuf.readBytes(read, 2, 3);\n\t// 从第三个索引开始读取到第4个索引的位置, 读取2个字节, readerIndex移动到第4个索引位置上\n\tAssert.assertEquals(3, buf.readerIndex());\n\tAssert.assertEquals(3, read[0]);\n}\n\n@Test\npublic void testRead3Bytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbuf.readBytes(3);\n\t// 读取3个字节, readerIndex向后移动3字节\n\tAssert.assertEquals(3, buf.readerIndex());\n}\n\n@Test\npublic void testReadFloat() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeFloat(10.0f);\n\tfloat read = buf.readFloat();\n\t// 读取Float, readerIndex向后移动4字节\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(10.f, read);\n}\n\n@Test\npublic void testReadLong() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeLong(10l);\n\tbuf.readLong();\n\t// 读取long, readerIndex向后移动8字节\n\tAssert.assertEquals(8, buf.readerIndex());\n\n}\n\n@Test\npublic void testReadByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tbuf.readByte();\n\t// 读取byte, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n}\n\n@Test\npublic void testReadShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(10);\n\tbuf.readShort();\n\t// 读取short, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n}\n\n@Test\npublic void testReadBoolean() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBoolean(true);\n\tbuf.readBoolean();\n\t// 读取boolean, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n}\n\n@Test\npublic void testReadDouble() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeDouble(10.0d);\n\tbuf.readDouble();\n\t// 读取double, readerIndex向后移动8字节\n\tAssert.assertEquals(8, buf.readerIndex());\n}\n\n@Test\npublic void testReadUnsignedByte() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeByte(-10);\n\tshort read = buf.readUnsignedByte();\n\t// 读取无符号byte, readerIndex向后移动1字节\n\tAssert.assertEquals(1, buf.readerIndex());\n\tAssert.assertEquals(246, read);\n}\n\n@Test\npublic void testReadUnsignedShort() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeShort(-1024);\n\t// 我们首先读取出-1024,这个负数,然后转化成无符号数字64512\n\tint read = buf.readUnsignedShort();\n\t// 读取无符号Short, readerIndex向后移动2字节\n\tAssert.assertEquals(2, buf.readerIndex());\n\tAssert.assertEquals(64512, read);\n}\n\n@Test\npublic void testReaderIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tAssert.assertEquals(0, buf.readerIndex());\n}\n\n@Test\npublic void testReadableBytes() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tAssert.assertEquals(10, buf.readableBytes());\n\tbuf.readByte();\n\t// 我们读取一个byte之后, 可读取字节变成了9个字节\n\tAssert.assertEquals(9, buf.readableBytes());\n}\n\n@Test\npublic void testReadUnsignedInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeInt(10);\n\tlong read = buf.readUnsignedInt();\n\tAssert.assertEquals(4, buf.readerIndex());\n\tAssert.assertEquals(10, read);\n}\n\n@Test\npublic void testReadSlice() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tByteBuf read = buf.readSlice(5);\n\t// slice出来的ByteBuf与原ByteBuf共享缓冲区\n\tAssert.assertEquals(5, buf.readerIndex());\n\tAssert.assertEquals(1, read.readByte());\n\tAssert.assertEquals(6, buf.readByte());\n\n}\n\n@Test\npublic void testWriteBytesReadInt() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);\n\tbuf.writeBytes(new byte[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0});\n\tint read = buf.readInt();\n\t// 从一个byte数组中读取一个int, 会读取出1, 2, 3, 4这四个byte转换成int为16909060\n\tAssert.assertEquals(16909060, read);\n}\n```\n\n### discard bytes\n在前面的测试中我们看到了,当向ByteBuf写入数据时,当超出分配内存大小时,ByteBuf会进行自动拓容(重新生成一个数组缓冲区,然后将原先的缓冲区内容拷贝到新的缓冲区中),这样一来ByteBuf占用的内从会越来越大. 我们可以是`discardReadBytes()`这个方法重用以前的缓冲区, 它会将[0, readerIndex]区间的内存舍弃掉(内部也是数组复制), 这么着就节间的重用了以前的缓冲区,但是这种方式有一点就是如果频繁的调用这个方法会带来性能问题.\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(\"123456789\".getBytes());\nbuf.readBytes(3);\t// 读取三个字节\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 3\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 9\nSystem.out.println(buf.readableBytes());\t// 可读字节 9 - 3 = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 9 = 41\n\n// 舍弃已读字节, readerIndex重置为0\nbuf.discardReadBytes();\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 6\nSystem.out.println(buf.readableBytes());\t// 可读字节 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 6 = 44\n```\n\n### clear\n这个操作并不会情况缓冲区的内容只是用来将readerIndex和writerIndex重置为0. 但是缓冲区的内容我们是仍然可以读到的. \n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(\"123456789\".getBytes());\nbuf.readBytes(3);\t// 读取三个字节\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 3\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 9\nSystem.out.println(buf.readableBytes());\t// 可读字节 9 - 3 = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 50 - 9 = 41\n\n// 重置readerIndex和writerIndex\nbuf.clear();\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 0\nSystem.out.println(buf.readableBytes());\t// 可读字节 readerIndex = 0\nSystem.out.println(buf.writableBytes());\t// 可写字节 capacity - writerIndex = 50\n// 设置writerIndex\nbuf.writerIndex(6);\nSystem.out.println(buf.readerIndex());\t\t// readerIndex位置 : 0\nSystem.out.println(buf.writerIndex());\t\t// writerIndex位置: 6\nSystem.out.println(buf.readableBytes());\t// 可读字节 writerIndex - readerIndex = 6\nSystem.out.println(buf.writableBytes());\t// 可写字节 44\nSystem.out.println(buf.readByte());\n```\n\n### mark reset\nmark reset相关的四个方法也是对指针位置的操作\n* `markReaderIndex()` 记录readerIndex\n* `markWriterIndex()` 记录writerIndex\n* `resetReaderIndex()`  将记录的readerIndex重置到当前的readerIndex值\n* `resetWriterIndex()`  将记录的writerIndex重置到当前的writerIndex值\n\n```java\n@Test\npublic void testReaderIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\n\tbuf.writeBytes(\"123456789\".getBytes());\n\tbuf.readBytes(3);\n\tbuf.markReaderIndex();\n\tbuf.readBytes(1);\n\tAssert.assertEquals(4, buf.readerIndex());\n\tbuf.resetReaderIndex();\n\tAssert.assertEquals(3, buf.readerIndex());\n}\n\n@Test\npublic void testWriterIndex() {\n\tByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\n\tbuf.writeBytes(\"123456789\".getBytes());\n\tbuf.markWriterIndex();\n\tbuf.writeByte(1);\n\tAssert.assertEquals(10, buf.writerIndex());\n\tbuf.resetWriterIndex();\n\tAssert.assertEquals(9, buf.writerIndex());\n}\n```\n\n### 查找\nByteBuf提供丰富的API让我查找某个Byte\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(new byte[]{1, 2, 3, 4 ,5, 6, 7, 8, 9});\n\n// 在指定的范围内查找某个byte\nint idx = buf.indexOf(0, buf.writerIndex(), (byte)2);\nSystem.out.println(idx);\t// 1\n\nidx = buf.indexOf(3, buf.writerIndex(), (byte)2);\nSystem.out.println(idx);\t// -1\n\n// 在[readerIndex, writerIndex]之间查找值\nidx = buf.bytesBefore((byte)2);\nSystem.out.println(idx);  // 4\n\nbuf.readBytes(3);\nidx = buf.bytesBefore((byte)2);\nSystem.out.println(idx); // -1\n\n// 在[readerIndex, writerIndex]之间遍历查找值\nidx = buf.forEachByte(b -> b == (byte) 6);\nSystem.out.println(idx); // 3\n```\n\n### derived buffers\nByteBuf提供多种API用于创建某个ByteBuf的视图或者复制版本\n* `duplicate()` 复制ByteBuf对象, 俩个对象共享同一个缓冲区,但是各自维护自己的索引(readerIndex, writerIndex)\n* `copy()` 复制ByteBuf对象, 俩个对象共享有自己的缓冲区, 缓冲区和索引都不共享\n* `slice()`  复制Bytebuf对象,但是只复制[readerIndex, writerIndex]区间的缓冲区, 俩个对象的缓冲区是共享的,但是维护各自的索引\n\n### get set\nByteBuf不仅仅支持read, write的顺序读写还支持get,set的随机读取。 但是get/set不会进行自动拓容.\n```java\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);\nbuf.writeBytes(new byte[]{1, 2, 3, 4 ,5, 6, 7, 8, 9});\n\nbyte b = buf.getByte(2);\nSystem.out.println(buf.readableBytes());\t// 9\nSystem.out.println(buf.readerIndex());\t\t// 0\nSystem.out.println(b);\t\t// 3\n```\n\n## 内存池\nNetty的内存池由`PoolArea`. `PoolArea`由多个`PoolChunk`组成. \n\n## ButeBuf 类型\n看完ByteBuf的API操作我们来看一下ByteBuf的分类,在内存使用种类上ByteBuf分为以下俩类\n* DirectByteBuf : 使用JVM堆外内存分配. 虽然分配和回收速度慢一些,但是从SocketChannel中写入或者读取数据由于少了一次内存复制,因此速度较快.(SocketIO通信时适合使用)\n* HeapByteBuf: 使用JVM堆内内存分配. 内存分配和回收速度较快,但是读写Socket IO的时候由于会额外进行一次内存复制,堆内存对应的缓冲区复制到内核Channel中,性能会有下降.(后端业务在编解码时适合使用)\n\n在内存使用种类上由分为以下俩类\n* PooledByteBuf: 基于内存对象池的ByteBuf, \n* UnpooledByteBuf: \n\n> UnpooledDirectByteBuf, UnpooledHeapByteBuf, UnpooledUnsafeDirectByteBuf ,PooledDirectByteBuf, PooledHeapByteBuf\n\n## AbstractByteBuf\n`AbstractByteBuf`继承自`ByteBuf`, 它内部并没有定义ByteBuf的缓冲区实现,只是通过定义`readerIndex`, `writerIndex`, `capacity`等实现ByteBuf接口中的各种API, 具体的缓冲区实现则由子类实现\n```java\nstatic final ResourceLeakDetector<ByteBuf> leakDetector = new ResourceLeakDetector<ByteBuf>(ByteBuf.class);\n\nint readerIndex;\nprivate int writerIndex;\nprivate int markedReaderIndex;\nprivate int markedWriterIndex;\n\nprivate int maxCapacity;\n\nprivate SwappedByteBuf swappedBuf;\n```\n\n除了操作具体缓冲区API没有实现之外 `AbstractByteBuf`为我们实现了大量的API,首先我们看一下读数据的API\n```java\n@Override\npublic ByteBuf readBytes(byte[] dst, int dstIndex, int length) {\n\t// 检查当前缓冲区中的可读数据是否满足length长度\n    checkReadableBytes(length);\n    // 将当前缓冲区的数据从readerIndex开始读取length个长度到目标dst缓冲区中. \n    // 这个方法也就是拷贝一部分数据到新的缓冲区中,但是并不会改变当前缓冲区的readerIndex和writerIndex\n    getBytes(readerIndex, dst, dstIndex, length);\n    readerIndex += length;\n    return this;\n}\n```\n下面我们看一下写数据的API实现\n```java\n@Override\npublic ByteBuf writeBytes(byte[] src, int srcIndex, int length) {\n    ensureWritable(length);\n    setBytes(writerIndex, src, srcIndex, length);\n    writerIndex += length;\n    return this;\n}\n```\n同样的`setBytes();`是由子类具体实现, 我们着重看一下`ensureWritable()`方法实现\n```java\n@Override\npublic ByteBuf ensureWritable(int minWritableBytes) {\n\t// 如果要写入数据的字节小于0的话, 则直接抛出异常\n    if (minWritableBytes < 0) {\n        throw new IllegalArgumentException(String.format(\n                \"minWritableBytes: %d (expected: >= 0)\", minWritableBytes));\n    }\n\n\t// minWritableBytes <= capacity() - writerIndex, 要写入的字节数小于可写的字节数则直接返回\n    if (minWritableBytes <= writableBytes()) {\n        return this;\n    }\n\n    if (minWritableBytes > maxCapacity - writerIndex) {\n        throw new IndexOutOfBoundsException(String.format(\n                \"writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\",\n                writerIndex, minWritableBytes, maxCapacity, this));\n    }\n\n    // Normalize the current capacity to the power of 2.\n    int newCapacity = calculateNewCapacity(writerIndex + minWritableBytes);\n\n    // Adjust to the new capacity.\n    capacity(newCapacity);\n    return this;\n}\n```\n\n### ResourceLeakDetector\n`ResourceLeakDetector`用于检测内存泄漏. 它被所有ByteBuf实例共享.\n\n### SwappedByteBuf\n\n## AbstractReferenceCountedByteBuf\n\n## UnPooledHeapByteBuf\n不使用对象池的基于堆内存分配的字节缓冲区. 每次IO读写的时候都会创建一个新的UnPooledHeapByteBuf.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"netty/ByteBuf","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihx4007zvjs6xqna4xe4"},{"date":"2015-11-22T16:00:00.000Z","title":"Netty Channel","_content":"`Channel`是Netty网络抽象类. 它的功能包括网络IO的读写,链路的连接和关闭, 通信双方的通信地址等.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/channel.jpg)\n\n下面我们看一下Channel提供的API\n\n* `parent()` : 获取父Channel\n* `unsafe()` :\n* `localAddress()` : 当前Channel的本地绑定地址\n* `eventLoop()` : 当前Channel注册到的EventLoop对象\n* `config()` : 获取当前Channel的配置信息\n* `remoteAddress()` : 当前Channel通信的远程Socket地址\n* `metadata()` : 当前Channel的元数据描述信息,例如TCP参数等等\n* `isOpen()` : 判断当初Channel是否已经打开\n* `isWritable()` : 当前Channel是否可写\n* `isRegistered()` : 是否注册当EventLoop上\n* `isActive()` : 当前Channel是否处于激活状态\n* `pipeline()` : 当前Channel的ChannelPipeline对象\n\n下面的网络IO操作会直接调用ChannelPipeline里的方法, 在ChannelPipeline里进行事件传播\n\n* `read()` : 从Channel中读取数据到inbound缓冲区\n* `write()` : 将消息通过ChannelPipeline写入到目标Channel中\n* `close()` : 主动关闭与网络对端的连接\n* `flush()` : 将之前写到环形队列里的消息全部写到目标Channel中,发送给网络对端\n* `connect()` : 与网络对端发起连接请求(一般由客户端调用这个方法)\n* `bind()` :\n* `disconnect()` : 请求关闭与网络对端的连接.\n\n## AbstractChannel\n我们首先看一下`AbstractChannel`里定义的成员\n```java\n// 链路已经关闭异常\nstatic final ClosedChannelException CLOSED_CHANNEL_EXCEPTION = new ClosedChannelException();\n// 链路尚未连接异常\nstatic final NotYetConnectedException NOT_YET_CONNECTED_EXCEPTION = new NotYetConnectedException();\n\nstatic {\n    CLOSED_CHANNEL_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE);\n    NOT_YET_CONNECTED_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE);\n}\n\n// 用于预测下一个报文的大小.\nprivate MessageSizeEstimator.Handle estimatorHandle;\n\nprivate final Channel parent;\nprivate final Unsafe unsafe;\nprivate final ChannelPipeline pipeline;\nprivate final ChannelFuture succeededFuture = new SucceededChannelFuture(this, null);\nprivate final VoidChannelPromise voidPromise = new VoidChannelPromise(this, true);\nprivate final VoidChannelPromise unsafeVoidPromise = new VoidChannelPromise(this, false);\nprivate final CloseFuture closeFuture = new CloseFuture(this);\n\n// 本地IP地址\nprivate volatile SocketAddress localAddress;\n// 网络通信对端的IP地址\nprivate volatile SocketAddress remoteAddress;\nprivate volatile EventLoop eventLoop;\n// Channel是否注册到了EventLoop上\nprivate volatile boolean registered;\n\n/** Cache for the string representation of this channel */\nprivate boolean strValActive;\nprivate String strVal;\n```\n`AbstractChannel`聚合了所有Channel使用到的能力的对象. 如果某个功能和子类相关则定义抽象方法,由子类去实现.\n\n在这里我们主要关注三个变量\n* `unsafe` : 真实网络IO的操作类\n* `pipeline` : 当前Channel对应的ChannelPipeline. 负责\n* `eventLoop` : 该Channel注册到的EventLoop\n在实例化的时候, 会对`pipeline`和`unsafe`进行赋值.\n```java\nprotected AbstractChannel(Channel parent) {\n      this.parent = parent;\n      unsafe = newUnsafe();\n      pipeline = new DefaultChannelPipeline(this);\n}\n```\n> unsafe实例化由子类实现, 这是因为unsafe的类型是个Unsafe接口, 而且AbstractChannel的内部类AbstractUnsafe是个抽象类, 那么我们就不知道如果要实例化这个类型究竟要使用哪个类型, 因此让AbstractChannel的子类继续实现自己的Unsafe接口的内部类和newUnsafe()方法, unsafe实质类型就有很大的可扩展性\n\n我们看到每一个Channel都有一个自己的`pipeline`和`unsafe`. `eventLoop`是在`AbstractUnsafe`中`register()`方法调用时进行赋值的\n```java\npublic final void register(EventLoop eventLoop, final ChannelPromise promise) {\n        AbstractChannel.this.eventLoop = eventLoop;\n}\n```\n`AbstractChannel`完成的功能很少, 只是实现了一些初始化的工作, 然后将网络相关的建立,数据读写操作等交给`pipeline`来完成.\n```java\n@Override\npublic ChannelFuture disconnect(ChannelPromise promise) {\n    return pipeline.disconnect(promise);\n}\n\n@Override\npublic ChannelFuture close(ChannelPromise promise) {\n    return pipeline.close(promise);\n}\n\n@Override\npublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n    return pipeline.bind(localAddress, promise);\n}\n\n@Override\npublic ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) {\n    return pipeline.connect(remoteAddress, promise);\n}\n\nOverride\npublic Channel read() {\n    pipeline.read();\n    return this;\n}\n\n@Override\npublic ChannelFuture write(Object msg) {\n    return pipeline.write(msg);\n}\n```\n还提供了一个`unsafe()`方法\n```java\npublic Unsafe unsafe() {\n   return unsafe;\n}\n```\n我们看一下`AbstractUnsafe`的定义`protected abstract class AbstractUnsafe implements Unsafe`, 它是作为一个`AbstractChannel`的抽象内部类, 这种关系也很容易让`AbstractUnsafe`访问`AbstractChannel`定义的一些空实现方法. 例如`AbstractUnsafe`中调用`AbstractChannel`的方法如下\n* `beginRead()` -> `doBeginRead()`\n* `doBind()` -> `doBind()`\n* `doDisconnect()` -> `doDisconnect()()`\n* `doClose()` -> `doClose()`\n* `register()` -> `doRegister()`以及调用pipeline的相关方法(fireChannelRegistered()和fireChannelActive())\n\n\n## AbstractNioChannel\n`AbstractNioChannel`主要是实现了`AbstractChannel`的`doRegister(), doDeregister(), doBeginRead()`方法. 通过下面的变量我们也可以看出这个类主要是为了完成`SelectableChannel`向`Selector`的注册功能.\n```java\nprivate final SelectableChannel ch;\nprotected final int readInterestOp;\nvolatile SelectionKey selectionKey;\n```\n`java.nio.channels.ServerSocketChannel`和`java.nio.channels.SocketChannel`都是实现了`java.nio.channels.SelectableChannel`接口. 而`NioSocketChannel`和`NioServerSocketChannel`实现了`AbstractNioChannel`接口, 因此我们在`AbstractNioChannel`内定义了一个`SelectableChannel`成员用于实现`ServerSocketChannel`和`SocketChannel`的共用\n\n然后我们看一下`doRegister()`方法\n```java\n@Override\nprotected void doRegister() throws Exception {\n    boolean selected = false;\n    for (;;) {\n        try {\n\t\t\t// 我们将ServerSocketChannel或者SocketChannel注册到NioEventLoop里的Selector上\n\t\t\t// 0表示我们对任何事件Channel里的任何事件都不感兴趣\n\t\t\t// 同时我们将this作为附件传送进去,\n            selectionKey = javaChannel().register(eventLoop().selector, 0, this);\n            return;\n        } catch (CancelledKeyException e) {\n            if (!selected) {\n                // Force the Selector to select now as the \"canceled\" SelectionKey may still be\n                // cached and not removed because no Select.select(..) operation was called yet.\n                eventLoop().selectNow();\n                selected = true;\n            } else {\n                // We forced a select operation on the selector before but the SelectionKey is still cached\n                // for whatever reason. JDK bug ?\n                throw e;\n            }\n        }\n    }\n}\n```\n最后我们看一下`doBeginRead()`方法\n```java\n@Override\nprotected void doBeginRead() throws Exception {\n    // Channel.read() or ChannelHandlerContext.read() was called\n    if (inputShutdown) {\n        return;\n    }\n\n    final SelectionKey selectionKey = this.selectionKey;\n    if (!selectionKey.isValid()) {\n        return;\n    }\n\n    readPending = true;\n\n    // 获取selectionKey的操作位\n    final int interestOps = selectionKey.interestOps();\n    if ((interestOps & readInterestOp) == 0) {\n        // 如果slectionKey不对读事件感兴趣, 那么就修改selectionKey的操作位, 开始设置对读事件感兴趣\n        selectionKey.interestOps(interestOps | readInterestOp);\n    }\n}\n```\n还记得在`AbstractChannel`中的`AbstractUnsafe`吗?里面有个`beginRead()`, 这个`doBeginRead()`正是由其调用的.\n\n## AbstractNioByteChannel\n`AbstractNioByteChannel`内部只有一个`Runnable`类型的`flushTask`属性, 它是用来写半包的, 当我们使用到它的时候,我们再具体分析. 我们来重点看一下`doWrite()`方法\n```java\nprotected void doWrite(ChannelOutboundBuffer in) throws Exception {\n       int writeSpinCount = -1;\n\n       for (;;) {\n           // 从环形数组ChannelOutboundBuffer中弹出一个消息对象\n           Object msg = in.current();\n           if (msg == null) {\n               // 如果全部消息都发送完毕累,则清除半包标志, clearOpWrite() 内部操作 TODO ???\n               clearOpWrite();\n               break;\n           }\n\n           if (msg instanceof ByteBuf) {\n               ByteBuf buf = (ByteBuf) msg;\n               int readableBytes = buf.readableBytes();\n               if (readableBytes == 0) {\n                   // 当前消息没有可读内容, 也就是没有内容需要向外发送,\n                   // 则将其从还行数组中删除, 然后继续处理下一个消息\n                   in.remove();\n                   continue;\n               }\n\n               //设置半包标志\n               boolean setOpWrite = false;\n               // 设置消息是否发送完毕\n               boolean done = false;\n               // 设置消息发送的总得数量\n               long flushedAmount = 0;\n               if (writeSpinCount == -1) {\n                   // 从配置中我们获取每次写半包消息进行的最大次数. 也即是如果环形数组里的消息一次性发送\n                   // 不完, 需要循环发送的次数,至于为什么不一直发送, 这是因为如果网络阻塞或者对方接受数据很慢,可能会造成网络IO线程假死\n                   writeSpinCount = config().getWriteSpinCount();\n               }\n               for (int i = writeSpinCount - 1; i >= 0; i --) {\n                   // 将buf内部的数据进行发送, 返回值是数据发送量\n                   int localFlushedAmount = doWriteBytes(buf);\n                   if (localFlushedAmount == 0) {\n                       // 数量为0,说明一个数据都没有发送出去, 可能是TCP缓冲区满了. 因此设置写半包标志\n                       // 同时退出写循环,这是因为下次写数据还可能TCP缓冲区处于已满状态,导致IO线程空循环\n                       setOpWrite = true;\n                       break;\n                   }\n\n                   // 数据发送成功, 将发送的数据量累加到flushedAmount上.\n                   flushedAmount += localFlushedAmount;\n                   if (!buf.isReadable()) {\n                       // 当前消息里的数据已经发送完毕, 退出buf发送循环,继续处理环形队列中下一个消息\n                       done = true;\n                       break;\n                   }\n               }\n\n               // 将发送的数据量同步到环形队列中\n               in.progress(flushedAmount);\n\n               if (done) {\n                   // buf数据已经发送完, 则将该消息从环形队列中删除\n                   in.remove();\n               } else {\n                   // 在写半包消息最大循环次数之内都没有将buf数据写完, 可能是数据量太多或者TCP缓冲区已满\n                   // 释放当前IO线程,让其进行其他工作.\n                   incompleteWrite(setOpWrite);\n                   break;\n               }\n           } else if (msg instanceof FileRegion) {\n               FileRegion region = (FileRegion) msg;\n               boolean done = region.transfered() >= region.count();\n               boolean setOpWrite = false;\n\n               if (!done) {\n                   long flushedAmount = 0;\n                   if (writeSpinCount == -1) {\n                       writeSpinCount = config().getWriteSpinCount();\n                   }\n\n                   for (int i = writeSpinCount - 1; i >= 0; i--) {\n                       long localFlushedAmount = doWriteFileRegion(region);\n                       if (localFlushedAmount == 0) {\n                           setOpWrite = true;\n                           break;\n                       }\n\n                       flushedAmount += localFlushedAmount;\n                       if (region.transfered() >= region.count()) {\n                           done = true;\n                           break;\n                       }\n                   }\n\n                   in.progress(flushedAmount);\n               }\n\n               if (done) {\n                   in.remove();\n               } else {\n                   incompleteWrite(setOpWrite);\n                   break;\n               }\n           } else {\n               // Should not reach here.\n               throw new Error();\n           }\n       }\n   }\n```\n`doWrite()`方法是由`AbstractUnsafe`的`flush()`调用的. 从`AbstractUnsafe`我们可以看到每个Unsafe类都有一个`ChannelOutboundBuffer`属性.\n\n下来我们看一下`incompleteWrite()`方法实现\n```java\nprotected final void incompleteWrite(boolean setOpWrite) {\n        // 从doWrite()方法中可以看到只有当TCP缓冲区已满的时候才会设置写半包操作\n        if (setOpWrite) {\n            // 设置累写半包的话,则将SelectionKey注册为OP_WRITE, 让多路复用器不断的轮训对应的Channel,\n            // 继续处理没有发送完的消息\n            setOpWrite();\n        } else {\n            // 如果没有半包,则让eventLoop继续执行写半包操作\n            Runnable flushTask = this.flushTask;\n            if (flushTask == null) {\n                flushTask = this.flushTask = new Runnable() {\n                    @Override\n                    public void run() {\n                        flush();\n                    }\n                };\n            }\n            eventLoop().execute(flushTask);\n        }\n    }\n```\n\n## AbstractNioMessageChannel\n\n```java\nprotected void doWrite(ChannelOutboundBuffer in) throws Exception {\n       final SelectionKey key = selectionKey();\n       final int interestOps = key.interestOps();\n\n       for (;;) {\n           // 从环形队列中获取一条消息\n           Object msg = in.current();\n           if (msg == null) {\n               // 消息为空,说明所有的消息都已经发送出去了. TODO\n               if ((interestOps & SelectionKey.OP_WRITE) != 0) {\n                   key.interestOps(interestOps & ~SelectionKey.OP_WRITE);\n               }\n               break;\n           }\n           try {\n               boolean done = false;\n               for (int i = config().getWriteSpinCount() - 1; i >= 0; i--) {\n                   // 在配置的最大次数下,将msg发送出去\n                   if (doWriteMessage(msg, in)) {\n                       done = true;\n                       break;\n                   }\n               }\n\n               if (done) {\n                   // 如果消息发送完毕累, 则将其从环形数组中删除\n                   in.remove();\n               } else {\n                   //  如果没有发送完毕, 则设置SelectionKey为写操作位, 让多路复用器不断的轮训channel,发送剩余的数据\n                   if ((interestOps & SelectionKey.OP_WRITE) == 0) {\n                       key.interestOps(interestOps | SelectionKey.OP_WRITE);\n                   }\n                   break;\n               }\n           } catch (IOException e) {\n               if (continueOnWriteError()) {\n                   in.remove(e);\n               } else {\n                   throw e;\n               }\n           }\n       }\n   }\n```\n\n## NioServerSocketChannel\n`NioServerSocketChannel`的主要作用是接受客户端连接\n```java\nprotected int doReadMessages(List<Object> buf) throws Exception {\n       SocketChannel ch = javaChannel().accept();\n\n       try {\n           if (ch != null) {\n               buf.add(new NioSocketChannel(this, ch));\n               return 1;\n           }\n       } catch (Throwable t) {\n           logger.warn(\"Failed to create a new channel from an accepted socket.\", t);\n\n           try {\n               ch.close();\n           } catch (Throwable t2) {\n               logger.warn(\"Failed to close a socket.\", t2);\n           }\n       }\n\n       return 0;\n   }\n```\n这个方法调用主要是由`NioMessageUnsafe`的`read()`方法调用\n\n## NioSocketChannel\n","source":"_posts/netty/Channel.md","raw":"category: Netty\ndate: 2015-11-23\ntitle: Netty Channel\n---\n`Channel`是Netty网络抽象类. 它的功能包括网络IO的读写,链路的连接和关闭, 通信双方的通信地址等.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/channel.jpg)\n\n下面我们看一下Channel提供的API\n\n* `parent()` : 获取父Channel\n* `unsafe()` :\n* `localAddress()` : 当前Channel的本地绑定地址\n* `eventLoop()` : 当前Channel注册到的EventLoop对象\n* `config()` : 获取当前Channel的配置信息\n* `remoteAddress()` : 当前Channel通信的远程Socket地址\n* `metadata()` : 当前Channel的元数据描述信息,例如TCP参数等等\n* `isOpen()` : 判断当初Channel是否已经打开\n* `isWritable()` : 当前Channel是否可写\n* `isRegistered()` : 是否注册当EventLoop上\n* `isActive()` : 当前Channel是否处于激活状态\n* `pipeline()` : 当前Channel的ChannelPipeline对象\n\n下面的网络IO操作会直接调用ChannelPipeline里的方法, 在ChannelPipeline里进行事件传播\n\n* `read()` : 从Channel中读取数据到inbound缓冲区\n* `write()` : 将消息通过ChannelPipeline写入到目标Channel中\n* `close()` : 主动关闭与网络对端的连接\n* `flush()` : 将之前写到环形队列里的消息全部写到目标Channel中,发送给网络对端\n* `connect()` : 与网络对端发起连接请求(一般由客户端调用这个方法)\n* `bind()` :\n* `disconnect()` : 请求关闭与网络对端的连接.\n\n## AbstractChannel\n我们首先看一下`AbstractChannel`里定义的成员\n```java\n// 链路已经关闭异常\nstatic final ClosedChannelException CLOSED_CHANNEL_EXCEPTION = new ClosedChannelException();\n// 链路尚未连接异常\nstatic final NotYetConnectedException NOT_YET_CONNECTED_EXCEPTION = new NotYetConnectedException();\n\nstatic {\n    CLOSED_CHANNEL_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE);\n    NOT_YET_CONNECTED_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE);\n}\n\n// 用于预测下一个报文的大小.\nprivate MessageSizeEstimator.Handle estimatorHandle;\n\nprivate final Channel parent;\nprivate final Unsafe unsafe;\nprivate final ChannelPipeline pipeline;\nprivate final ChannelFuture succeededFuture = new SucceededChannelFuture(this, null);\nprivate final VoidChannelPromise voidPromise = new VoidChannelPromise(this, true);\nprivate final VoidChannelPromise unsafeVoidPromise = new VoidChannelPromise(this, false);\nprivate final CloseFuture closeFuture = new CloseFuture(this);\n\n// 本地IP地址\nprivate volatile SocketAddress localAddress;\n// 网络通信对端的IP地址\nprivate volatile SocketAddress remoteAddress;\nprivate volatile EventLoop eventLoop;\n// Channel是否注册到了EventLoop上\nprivate volatile boolean registered;\n\n/** Cache for the string representation of this channel */\nprivate boolean strValActive;\nprivate String strVal;\n```\n`AbstractChannel`聚合了所有Channel使用到的能力的对象. 如果某个功能和子类相关则定义抽象方法,由子类去实现.\n\n在这里我们主要关注三个变量\n* `unsafe` : 真实网络IO的操作类\n* `pipeline` : 当前Channel对应的ChannelPipeline. 负责\n* `eventLoop` : 该Channel注册到的EventLoop\n在实例化的时候, 会对`pipeline`和`unsafe`进行赋值.\n```java\nprotected AbstractChannel(Channel parent) {\n      this.parent = parent;\n      unsafe = newUnsafe();\n      pipeline = new DefaultChannelPipeline(this);\n}\n```\n> unsafe实例化由子类实现, 这是因为unsafe的类型是个Unsafe接口, 而且AbstractChannel的内部类AbstractUnsafe是个抽象类, 那么我们就不知道如果要实例化这个类型究竟要使用哪个类型, 因此让AbstractChannel的子类继续实现自己的Unsafe接口的内部类和newUnsafe()方法, unsafe实质类型就有很大的可扩展性\n\n我们看到每一个Channel都有一个自己的`pipeline`和`unsafe`. `eventLoop`是在`AbstractUnsafe`中`register()`方法调用时进行赋值的\n```java\npublic final void register(EventLoop eventLoop, final ChannelPromise promise) {\n        AbstractChannel.this.eventLoop = eventLoop;\n}\n```\n`AbstractChannel`完成的功能很少, 只是实现了一些初始化的工作, 然后将网络相关的建立,数据读写操作等交给`pipeline`来完成.\n```java\n@Override\npublic ChannelFuture disconnect(ChannelPromise promise) {\n    return pipeline.disconnect(promise);\n}\n\n@Override\npublic ChannelFuture close(ChannelPromise promise) {\n    return pipeline.close(promise);\n}\n\n@Override\npublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n    return pipeline.bind(localAddress, promise);\n}\n\n@Override\npublic ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) {\n    return pipeline.connect(remoteAddress, promise);\n}\n\nOverride\npublic Channel read() {\n    pipeline.read();\n    return this;\n}\n\n@Override\npublic ChannelFuture write(Object msg) {\n    return pipeline.write(msg);\n}\n```\n还提供了一个`unsafe()`方法\n```java\npublic Unsafe unsafe() {\n   return unsafe;\n}\n```\n我们看一下`AbstractUnsafe`的定义`protected abstract class AbstractUnsafe implements Unsafe`, 它是作为一个`AbstractChannel`的抽象内部类, 这种关系也很容易让`AbstractUnsafe`访问`AbstractChannel`定义的一些空实现方法. 例如`AbstractUnsafe`中调用`AbstractChannel`的方法如下\n* `beginRead()` -> `doBeginRead()`\n* `doBind()` -> `doBind()`\n* `doDisconnect()` -> `doDisconnect()()`\n* `doClose()` -> `doClose()`\n* `register()` -> `doRegister()`以及调用pipeline的相关方法(fireChannelRegistered()和fireChannelActive())\n\n\n## AbstractNioChannel\n`AbstractNioChannel`主要是实现了`AbstractChannel`的`doRegister(), doDeregister(), doBeginRead()`方法. 通过下面的变量我们也可以看出这个类主要是为了完成`SelectableChannel`向`Selector`的注册功能.\n```java\nprivate final SelectableChannel ch;\nprotected final int readInterestOp;\nvolatile SelectionKey selectionKey;\n```\n`java.nio.channels.ServerSocketChannel`和`java.nio.channels.SocketChannel`都是实现了`java.nio.channels.SelectableChannel`接口. 而`NioSocketChannel`和`NioServerSocketChannel`实现了`AbstractNioChannel`接口, 因此我们在`AbstractNioChannel`内定义了一个`SelectableChannel`成员用于实现`ServerSocketChannel`和`SocketChannel`的共用\n\n然后我们看一下`doRegister()`方法\n```java\n@Override\nprotected void doRegister() throws Exception {\n    boolean selected = false;\n    for (;;) {\n        try {\n\t\t\t// 我们将ServerSocketChannel或者SocketChannel注册到NioEventLoop里的Selector上\n\t\t\t// 0表示我们对任何事件Channel里的任何事件都不感兴趣\n\t\t\t// 同时我们将this作为附件传送进去,\n            selectionKey = javaChannel().register(eventLoop().selector, 0, this);\n            return;\n        } catch (CancelledKeyException e) {\n            if (!selected) {\n                // Force the Selector to select now as the \"canceled\" SelectionKey may still be\n                // cached and not removed because no Select.select(..) operation was called yet.\n                eventLoop().selectNow();\n                selected = true;\n            } else {\n                // We forced a select operation on the selector before but the SelectionKey is still cached\n                // for whatever reason. JDK bug ?\n                throw e;\n            }\n        }\n    }\n}\n```\n最后我们看一下`doBeginRead()`方法\n```java\n@Override\nprotected void doBeginRead() throws Exception {\n    // Channel.read() or ChannelHandlerContext.read() was called\n    if (inputShutdown) {\n        return;\n    }\n\n    final SelectionKey selectionKey = this.selectionKey;\n    if (!selectionKey.isValid()) {\n        return;\n    }\n\n    readPending = true;\n\n    // 获取selectionKey的操作位\n    final int interestOps = selectionKey.interestOps();\n    if ((interestOps & readInterestOp) == 0) {\n        // 如果slectionKey不对读事件感兴趣, 那么就修改selectionKey的操作位, 开始设置对读事件感兴趣\n        selectionKey.interestOps(interestOps | readInterestOp);\n    }\n}\n```\n还记得在`AbstractChannel`中的`AbstractUnsafe`吗?里面有个`beginRead()`, 这个`doBeginRead()`正是由其调用的.\n\n## AbstractNioByteChannel\n`AbstractNioByteChannel`内部只有一个`Runnable`类型的`flushTask`属性, 它是用来写半包的, 当我们使用到它的时候,我们再具体分析. 我们来重点看一下`doWrite()`方法\n```java\nprotected void doWrite(ChannelOutboundBuffer in) throws Exception {\n       int writeSpinCount = -1;\n\n       for (;;) {\n           // 从环形数组ChannelOutboundBuffer中弹出一个消息对象\n           Object msg = in.current();\n           if (msg == null) {\n               // 如果全部消息都发送完毕累,则清除半包标志, clearOpWrite() 内部操作 TODO ???\n               clearOpWrite();\n               break;\n           }\n\n           if (msg instanceof ByteBuf) {\n               ByteBuf buf = (ByteBuf) msg;\n               int readableBytes = buf.readableBytes();\n               if (readableBytes == 0) {\n                   // 当前消息没有可读内容, 也就是没有内容需要向外发送,\n                   // 则将其从还行数组中删除, 然后继续处理下一个消息\n                   in.remove();\n                   continue;\n               }\n\n               //设置半包标志\n               boolean setOpWrite = false;\n               // 设置消息是否发送完毕\n               boolean done = false;\n               // 设置消息发送的总得数量\n               long flushedAmount = 0;\n               if (writeSpinCount == -1) {\n                   // 从配置中我们获取每次写半包消息进行的最大次数. 也即是如果环形数组里的消息一次性发送\n                   // 不完, 需要循环发送的次数,至于为什么不一直发送, 这是因为如果网络阻塞或者对方接受数据很慢,可能会造成网络IO线程假死\n                   writeSpinCount = config().getWriteSpinCount();\n               }\n               for (int i = writeSpinCount - 1; i >= 0; i --) {\n                   // 将buf内部的数据进行发送, 返回值是数据发送量\n                   int localFlushedAmount = doWriteBytes(buf);\n                   if (localFlushedAmount == 0) {\n                       // 数量为0,说明一个数据都没有发送出去, 可能是TCP缓冲区满了. 因此设置写半包标志\n                       // 同时退出写循环,这是因为下次写数据还可能TCP缓冲区处于已满状态,导致IO线程空循环\n                       setOpWrite = true;\n                       break;\n                   }\n\n                   // 数据发送成功, 将发送的数据量累加到flushedAmount上.\n                   flushedAmount += localFlushedAmount;\n                   if (!buf.isReadable()) {\n                       // 当前消息里的数据已经发送完毕, 退出buf发送循环,继续处理环形队列中下一个消息\n                       done = true;\n                       break;\n                   }\n               }\n\n               // 将发送的数据量同步到环形队列中\n               in.progress(flushedAmount);\n\n               if (done) {\n                   // buf数据已经发送完, 则将该消息从环形队列中删除\n                   in.remove();\n               } else {\n                   // 在写半包消息最大循环次数之内都没有将buf数据写完, 可能是数据量太多或者TCP缓冲区已满\n                   // 释放当前IO线程,让其进行其他工作.\n                   incompleteWrite(setOpWrite);\n                   break;\n               }\n           } else if (msg instanceof FileRegion) {\n               FileRegion region = (FileRegion) msg;\n               boolean done = region.transfered() >= region.count();\n               boolean setOpWrite = false;\n\n               if (!done) {\n                   long flushedAmount = 0;\n                   if (writeSpinCount == -1) {\n                       writeSpinCount = config().getWriteSpinCount();\n                   }\n\n                   for (int i = writeSpinCount - 1; i >= 0; i--) {\n                       long localFlushedAmount = doWriteFileRegion(region);\n                       if (localFlushedAmount == 0) {\n                           setOpWrite = true;\n                           break;\n                       }\n\n                       flushedAmount += localFlushedAmount;\n                       if (region.transfered() >= region.count()) {\n                           done = true;\n                           break;\n                       }\n                   }\n\n                   in.progress(flushedAmount);\n               }\n\n               if (done) {\n                   in.remove();\n               } else {\n                   incompleteWrite(setOpWrite);\n                   break;\n               }\n           } else {\n               // Should not reach here.\n               throw new Error();\n           }\n       }\n   }\n```\n`doWrite()`方法是由`AbstractUnsafe`的`flush()`调用的. 从`AbstractUnsafe`我们可以看到每个Unsafe类都有一个`ChannelOutboundBuffer`属性.\n\n下来我们看一下`incompleteWrite()`方法实现\n```java\nprotected final void incompleteWrite(boolean setOpWrite) {\n        // 从doWrite()方法中可以看到只有当TCP缓冲区已满的时候才会设置写半包操作\n        if (setOpWrite) {\n            // 设置累写半包的话,则将SelectionKey注册为OP_WRITE, 让多路复用器不断的轮训对应的Channel,\n            // 继续处理没有发送完的消息\n            setOpWrite();\n        } else {\n            // 如果没有半包,则让eventLoop继续执行写半包操作\n            Runnable flushTask = this.flushTask;\n            if (flushTask == null) {\n                flushTask = this.flushTask = new Runnable() {\n                    @Override\n                    public void run() {\n                        flush();\n                    }\n                };\n            }\n            eventLoop().execute(flushTask);\n        }\n    }\n```\n\n## AbstractNioMessageChannel\n\n```java\nprotected void doWrite(ChannelOutboundBuffer in) throws Exception {\n       final SelectionKey key = selectionKey();\n       final int interestOps = key.interestOps();\n\n       for (;;) {\n           // 从环形队列中获取一条消息\n           Object msg = in.current();\n           if (msg == null) {\n               // 消息为空,说明所有的消息都已经发送出去了. TODO\n               if ((interestOps & SelectionKey.OP_WRITE) != 0) {\n                   key.interestOps(interestOps & ~SelectionKey.OP_WRITE);\n               }\n               break;\n           }\n           try {\n               boolean done = false;\n               for (int i = config().getWriteSpinCount() - 1; i >= 0; i--) {\n                   // 在配置的最大次数下,将msg发送出去\n                   if (doWriteMessage(msg, in)) {\n                       done = true;\n                       break;\n                   }\n               }\n\n               if (done) {\n                   // 如果消息发送完毕累, 则将其从环形数组中删除\n                   in.remove();\n               } else {\n                   //  如果没有发送完毕, 则设置SelectionKey为写操作位, 让多路复用器不断的轮训channel,发送剩余的数据\n                   if ((interestOps & SelectionKey.OP_WRITE) == 0) {\n                       key.interestOps(interestOps | SelectionKey.OP_WRITE);\n                   }\n                   break;\n               }\n           } catch (IOException e) {\n               if (continueOnWriteError()) {\n                   in.remove(e);\n               } else {\n                   throw e;\n               }\n           }\n       }\n   }\n```\n\n## NioServerSocketChannel\n`NioServerSocketChannel`的主要作用是接受客户端连接\n```java\nprotected int doReadMessages(List<Object> buf) throws Exception {\n       SocketChannel ch = javaChannel().accept();\n\n       try {\n           if (ch != null) {\n               buf.add(new NioSocketChannel(this, ch));\n               return 1;\n           }\n       } catch (Throwable t) {\n           logger.warn(\"Failed to create a new channel from an accepted socket.\", t);\n\n           try {\n               ch.close();\n           } catch (Throwable t2) {\n               logger.warn(\"Failed to close a socket.\", t2);\n           }\n       }\n\n       return 0;\n   }\n```\n这个方法调用主要是由`NioMessageUnsafe`的`read()`方法调用\n\n## NioSocketChannel\n","slug":"netty/Channel","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihxa0081vjs6vkst79bp"},{"date":"2016-01-22T16:00:00.000Z","title":"Netty ChannelHandler","_content":"首先我们看一下`ChannelHandler`的继承结构\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/netty%20ChannelHadler.jpg)\n* `ChannelHandler`\n* `ChannelInboundHandler`\n* `ChannelOutboundHandler`\n* `ChannelInboundHandlerAdapter`\n* `ChannelOutboundHandlerAdapter`\n* `ChannelHandlerAdapter`\n\n```java\npublic interface ChannelHandler\npublic interface ChannelInboundHandler extends ChannelHandler\npublic interface ChannelOutboundHandler extends ChannelHandler\npublic abstract class ChannelHandlerAdapter implements ChannelHandler\npublic class ChannelInboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelInboundHandler\npublic class ChannelOutboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelOutboundHandler\n```\n之所以在提供了handle的接口之后还提供Adapter, 是因为如果我们直接实现handler接口的话, 那么我们就需要实现handler里的所有方法, 但是我们可能要在不同的handler里实现不同的功能, 而这些功能恰巧由不同的handler里的方法实现, 那么每个实现了handler接口的类都会有大量的冗余代码. 但是如果我们继承Adapter的话, 我们只需要重写需要实现功能的方法就可以了.\n\n> IdleStateHandler\n\n\n\n## 解码器\n为了解决网络数据流的拆包粘包问题,Netty为我们内置了如下的解码器\n* ByteToMessageDecoder\n* MessageToMessageDecoder\n* LineBasedFrameDecoder\n* StringDecoder\n* DelimiterBasedFrameDecoder\n* FixedLengthFrameDecoder\n* ProtoBufVarint32FrameDecoder\n* ProtobufDecoder\n* LengthFieldBasedFrameDecoder\n\nNetty还内置了如下的编码器\n* ProtobufEncoder\n* MessageToByteEncoder\n* MessageToMessageEncoder\n* LengthFieldPrepender\n\nNetty还为我们提供HTTP相关的编解码器\n* `HttpRequestDecoder` : Http消息解码器\n* `HttpObjectAggregator` : 将多个消息转换为单一的`FullHttpRequest`或者`FullHttpResponse`\n* `HttpResponseEncoder` : 对Http消息影响进行编码\n* `ChunkedWriteHandler` : 异步大码流消息发送\n\n\n## ByteToMessageDecoder\n如果我们自己想要实现自己的半包解码器,我们可以继承`ByteToMessageDecoder`, 实现更加复杂的半包解码\n```java\npublic abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter\n```\n> [ChannelInboundHandlerAdapter]()参考\n\n我们只需要继承该类并实现\n```java\nprotected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception;\n```\n这个方法, 在这个方法里完成byte字节到java对象的转换, 也就是我们将`ByteBuf`解析成java对象然后抛给`List<Object> out`就可以了.\n> 需要注意的这个类没有实现粘包组包等情况, 这个就需要我们自己实现了.\n\n## MessageToMessageDecoder\n`MessageToMessageDecoder`一般作为二次解码器, 当我们在`ByteToMessageDecoder`将一个bytes数组转换成一个java对象的时候, 我们可能还需要将这个对象进行二次解码成其他对象, 我们就可以继承这个类,\n```java\npublic abstract class MessageToMessageDecoder<I> extends ChannelInboundHandlerAdapter\n```\n然后实现\n```java\nprotected abstract void decode(ChannelHandlerContext ctx, I msg, List<Object> out) throws Exception;\n```\n这个方法就可以了\n\n## LineBasedFrameDecoder\n`LineBasedFrameDecoder`的原理是从`ByteBuf`的可读字节中找到`\\n`或者`\\r\\n`,找到之后就以此为结束,然后将当前读取到的数据组成一行.\n\n如果我们设置每一行的最大长度, 但是当达到最大长度之后还没有找到结束符,就会抛出异常,同时将读取的数据舍弃掉.\n\n`LineBasedFrameDecoder`的用法很简单, 我们可以向其指定大小或者不指定大小\n```java\n...\nch.pipline().addLast(new LineBasedFrameDecoder());\n...\n或者\n...\nch.pipline().addLast(new LineBasedFrameDecoder(1024));\n...\n```\n\n## DelimiterBasedFrameDecoder\n使用`DelimiterBasedFrameDecoder`我们可以自定义设定分隔符\n```java\n...\nByteBuf delimiter = Unpooled.copiedBuffer(\"$_\".getBytes());\nch.pipline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter));\n```\n在上面的例子中我们使用了自定义的分隔符`$_`, 同样的如果在1024个字节中找不到`$_`, 也会抛出.\n\n## FixedLengthFrameDecoder\n`FixedLengthFrameDecoder`为定长解码器, 它会按照指定长度对消息进行解码.\n```java\nch.pipline().addLast(new FixedLengthFrameDecoder(1024));\n```\n上面的例子会每隔1024个长度之后进行消息解码,如果不足1024,则会将消息缓存起来,然后再进行解码\n\n## ProtobufVarint32FrameDecoder\n`ProtoBufVarint32FrameDecoder`是Netty为我们提供的Protobuf半包解码器, 通过它配合使用`ProtobufDecoder`和`ProtobufEncoder`我们就可以使用Protobuf进行通信了\n```java\nch.pipline().addLast(new ProtobufVarint32FrameDecoder());\nch.pipline().addLast(new ProtobufDecoder());\nch.pipline().addLast(new ProtobufEncoder());\n```\n\n## LengthFieldBasedFrameDecoder\n`LengthFieldBasedFrameDecoder`是Netty为我们提供的通用半包解码器.\n```java\npublic class LengthFieldBasedFrameDecoder extends ByteToMessageDecoder\n```\n这个类的半包读取策略由下面的属性控制\n* `lengthFieldOffset` : 标志长度字段的偏移量. 也就是在一个bytes字节流中,表示消息长度的字段是从流中哪个位置开始的.\n* `lengthFieldLength` : 长度字段的长度(单位byte)\n* `lengthAdjustment` : 当消息长度包含了消息头的长度的时候,需要使用这个变量进行校正, 例如lengthFieldOffset为0,lengthFieldLength为2, 那么消息正体在解析时就需要校正2个字节, 故这里为-2.\n* `initialBytesToStrip`: 这个是当我们解析`ByteBuf`时要跳过的那些字段, (一般为lengthFieldOffset + lengthFieldLength)\n\n## MessageToByteEncoder\n该类负责将java对象编码成`ByteBuf`, 我们只需要继承该类然后实现\n```java\nprotected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception;\n```\n方法就可以了\n\n## MessageToMessageEncoder\n如果要将java对象不编码成`ByteBuf`, 而是编译成, 其他对象, 那我们可以继承这个类实现\n```java\nprotected abstract void encode(ChannelHandlerContext ctx, I msg, List<Object> out) throws Exception;\n```\n这个方法就可以了\n\n> 这个类与`MessageToByteEncoder`的不同是, 将java对象放到一个`List<Object> out`, 而不是编码成`ByteBuf`发送\n\n## LengthFieldPrepender\n`LengthFieldPrepender`是一个非常实用的工具类, 如果我们在发送消息的时候采用的是:消息长度字段+原始消息的形式, 那么我们就可以使用`LengthFieldPrepender`了. 这是因为`LengthFieldPrepender`可以将待发送消息的长度(二进制字节长度)写到`ByteBuf`的前俩个字节.例如:\n```java\nHello,World\n```\n编码前是12个字节,但是经过`LengthFieldPrepender`编码后变成了\n```java\n0x000E Hello,World\n```\n成为了14个字节\n\n## HTTP解码器\n\n> 使用`HttpObjectAggregator`是因为在解码Http消息中会产生多个对象(`HttpRequest`, `HttpResponse`, `HttpContent`, `LastHttpContent`), 使用`HttpObjectAggregator`我们可以将这些对象都组合到一起去. 然后当我们自己在处理消息时就可以直接使用`FullHttpRequest了`\n\n\n```java\nch.pipline().addLast(\"http-decoder\", new HttpRequestDecoder());\nch.pipline().addLast(\"http-aggregator\", new HttpObjectAggregator());\nch.pipline().addLast(\"http-encoder\", new HttpResponseEncoder());\nch.pipline().addLast(\"http-chunked\", new ChunkedWriteHandler());\n```\n","source":"_posts/netty/ChannelHandler.md","raw":"category: Netty\ndate: 2016-01-23\ntitle: Netty ChannelHandler\n---\n首先我们看一下`ChannelHandler`的继承结构\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/netty%20ChannelHadler.jpg)\n* `ChannelHandler`\n* `ChannelInboundHandler`\n* `ChannelOutboundHandler`\n* `ChannelInboundHandlerAdapter`\n* `ChannelOutboundHandlerAdapter`\n* `ChannelHandlerAdapter`\n\n```java\npublic interface ChannelHandler\npublic interface ChannelInboundHandler extends ChannelHandler\npublic interface ChannelOutboundHandler extends ChannelHandler\npublic abstract class ChannelHandlerAdapter implements ChannelHandler\npublic class ChannelInboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelInboundHandler\npublic class ChannelOutboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelOutboundHandler\n```\n之所以在提供了handle的接口之后还提供Adapter, 是因为如果我们直接实现handler接口的话, 那么我们就需要实现handler里的所有方法, 但是我们可能要在不同的handler里实现不同的功能, 而这些功能恰巧由不同的handler里的方法实现, 那么每个实现了handler接口的类都会有大量的冗余代码. 但是如果我们继承Adapter的话, 我们只需要重写需要实现功能的方法就可以了.\n\n> IdleStateHandler\n\n\n\n## 解码器\n为了解决网络数据流的拆包粘包问题,Netty为我们内置了如下的解码器\n* ByteToMessageDecoder\n* MessageToMessageDecoder\n* LineBasedFrameDecoder\n* StringDecoder\n* DelimiterBasedFrameDecoder\n* FixedLengthFrameDecoder\n* ProtoBufVarint32FrameDecoder\n* ProtobufDecoder\n* LengthFieldBasedFrameDecoder\n\nNetty还内置了如下的编码器\n* ProtobufEncoder\n* MessageToByteEncoder\n* MessageToMessageEncoder\n* LengthFieldPrepender\n\nNetty还为我们提供HTTP相关的编解码器\n* `HttpRequestDecoder` : Http消息解码器\n* `HttpObjectAggregator` : 将多个消息转换为单一的`FullHttpRequest`或者`FullHttpResponse`\n* `HttpResponseEncoder` : 对Http消息影响进行编码\n* `ChunkedWriteHandler` : 异步大码流消息发送\n\n\n## ByteToMessageDecoder\n如果我们自己想要实现自己的半包解码器,我们可以继承`ByteToMessageDecoder`, 实现更加复杂的半包解码\n```java\npublic abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter\n```\n> [ChannelInboundHandlerAdapter]()参考\n\n我们只需要继承该类并实现\n```java\nprotected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception;\n```\n这个方法, 在这个方法里完成byte字节到java对象的转换, 也就是我们将`ByteBuf`解析成java对象然后抛给`List<Object> out`就可以了.\n> 需要注意的这个类没有实现粘包组包等情况, 这个就需要我们自己实现了.\n\n## MessageToMessageDecoder\n`MessageToMessageDecoder`一般作为二次解码器, 当我们在`ByteToMessageDecoder`将一个bytes数组转换成一个java对象的时候, 我们可能还需要将这个对象进行二次解码成其他对象, 我们就可以继承这个类,\n```java\npublic abstract class MessageToMessageDecoder<I> extends ChannelInboundHandlerAdapter\n```\n然后实现\n```java\nprotected abstract void decode(ChannelHandlerContext ctx, I msg, List<Object> out) throws Exception;\n```\n这个方法就可以了\n\n## LineBasedFrameDecoder\n`LineBasedFrameDecoder`的原理是从`ByteBuf`的可读字节中找到`\\n`或者`\\r\\n`,找到之后就以此为结束,然后将当前读取到的数据组成一行.\n\n如果我们设置每一行的最大长度, 但是当达到最大长度之后还没有找到结束符,就会抛出异常,同时将读取的数据舍弃掉.\n\n`LineBasedFrameDecoder`的用法很简单, 我们可以向其指定大小或者不指定大小\n```java\n...\nch.pipline().addLast(new LineBasedFrameDecoder());\n...\n或者\n...\nch.pipline().addLast(new LineBasedFrameDecoder(1024));\n...\n```\n\n## DelimiterBasedFrameDecoder\n使用`DelimiterBasedFrameDecoder`我们可以自定义设定分隔符\n```java\n...\nByteBuf delimiter = Unpooled.copiedBuffer(\"$_\".getBytes());\nch.pipline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter));\n```\n在上面的例子中我们使用了自定义的分隔符`$_`, 同样的如果在1024个字节中找不到`$_`, 也会抛出.\n\n## FixedLengthFrameDecoder\n`FixedLengthFrameDecoder`为定长解码器, 它会按照指定长度对消息进行解码.\n```java\nch.pipline().addLast(new FixedLengthFrameDecoder(1024));\n```\n上面的例子会每隔1024个长度之后进行消息解码,如果不足1024,则会将消息缓存起来,然后再进行解码\n\n## ProtobufVarint32FrameDecoder\n`ProtoBufVarint32FrameDecoder`是Netty为我们提供的Protobuf半包解码器, 通过它配合使用`ProtobufDecoder`和`ProtobufEncoder`我们就可以使用Protobuf进行通信了\n```java\nch.pipline().addLast(new ProtobufVarint32FrameDecoder());\nch.pipline().addLast(new ProtobufDecoder());\nch.pipline().addLast(new ProtobufEncoder());\n```\n\n## LengthFieldBasedFrameDecoder\n`LengthFieldBasedFrameDecoder`是Netty为我们提供的通用半包解码器.\n```java\npublic class LengthFieldBasedFrameDecoder extends ByteToMessageDecoder\n```\n这个类的半包读取策略由下面的属性控制\n* `lengthFieldOffset` : 标志长度字段的偏移量. 也就是在一个bytes字节流中,表示消息长度的字段是从流中哪个位置开始的.\n* `lengthFieldLength` : 长度字段的长度(单位byte)\n* `lengthAdjustment` : 当消息长度包含了消息头的长度的时候,需要使用这个变量进行校正, 例如lengthFieldOffset为0,lengthFieldLength为2, 那么消息正体在解析时就需要校正2个字节, 故这里为-2.\n* `initialBytesToStrip`: 这个是当我们解析`ByteBuf`时要跳过的那些字段, (一般为lengthFieldOffset + lengthFieldLength)\n\n## MessageToByteEncoder\n该类负责将java对象编码成`ByteBuf`, 我们只需要继承该类然后实现\n```java\nprotected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception;\n```\n方法就可以了\n\n## MessageToMessageEncoder\n如果要将java对象不编码成`ByteBuf`, 而是编译成, 其他对象, 那我们可以继承这个类实现\n```java\nprotected abstract void encode(ChannelHandlerContext ctx, I msg, List<Object> out) throws Exception;\n```\n这个方法就可以了\n\n> 这个类与`MessageToByteEncoder`的不同是, 将java对象放到一个`List<Object> out`, 而不是编码成`ByteBuf`发送\n\n## LengthFieldPrepender\n`LengthFieldPrepender`是一个非常实用的工具类, 如果我们在发送消息的时候采用的是:消息长度字段+原始消息的形式, 那么我们就可以使用`LengthFieldPrepender`了. 这是因为`LengthFieldPrepender`可以将待发送消息的长度(二进制字节长度)写到`ByteBuf`的前俩个字节.例如:\n```java\nHello,World\n```\n编码前是12个字节,但是经过`LengthFieldPrepender`编码后变成了\n```java\n0x000E Hello,World\n```\n成为了14个字节\n\n## HTTP解码器\n\n> 使用`HttpObjectAggregator`是因为在解码Http消息中会产生多个对象(`HttpRequest`, `HttpResponse`, `HttpContent`, `LastHttpContent`), 使用`HttpObjectAggregator`我们可以将这些对象都组合到一起去. 然后当我们自己在处理消息时就可以直接使用`FullHttpRequest了`\n\n\n```java\nch.pipline().addLast(\"http-decoder\", new HttpRequestDecoder());\nch.pipline().addLast(\"http-aggregator\", new HttpObjectAggregator());\nch.pipline().addLast(\"http-encoder\", new HttpResponseEncoder());\nch.pipline().addLast(\"http-chunked\", new ChunkedWriteHandler());\n```\n","slug":"netty/ChannelHandler","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihxe0084vjs66axnqhfd"},{"date":"2016-02-01T16:00:00.000Z","title":"Netty ChannelPipeline","_content":"\n## 简介\n`ChannelPipeline`是一个`ChannelHandler`的集合, 用于处理或者截断`Channel`的`inbound events`和`outbound operations`. `ChannelPipeline`是[Intercepting Filter](http://www.oracle.com/technetwork/java/interceptingfilter-142169.html)的一个高级实现, 它保证了用户对事件处理的完整控制权以及确保了`ChannelHandler`在pipeline中的运行方式.\n\n每当创建一个`Channel`的时候, 都会创建出一个对应的`ChannelPipeline`, 也就是说每个`Channel`都有其自己的`ChannelPipeline`\n\n下面的图给出了IO事件是如何在`ChannelPipeline`里的`ChannelHandler`进行传递处理的. IO事件由`ChannelInboundHandler`或者`ChannelOutboundHandler`处理, 我们在handler中调用`ChannelHandlerContext`中的事件传播方法将event传播给下一个handler继续执行, 例如调用`ChannelHandlerContext#fireChannelRead(Object)`和`ChannelHandlerContext#write(Object)`\n```java\n                                               I/O Request\n                                          via Channel} or\n                                      ChannelHandlerContext}\n                                                    |\n+---------------------------------------------------+---------------+\n|                           ChannelPipeline         |               |\n|                                                  \\|/              |\n|    +---------------------+            +-----------+----------+    |\n|    | Inbound Handler  N  |            | Outbound Handler  1  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n|               |                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler N-1 |            | Outbound Handler  2  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  .               |\n|               .                                   .               |\n| ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|\n|        [ method call]                       [method call]         |\n|               .                                   .               |\n|               .                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler  2  |            | Outbound Handler M-1 |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n|               |                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler  1  |            | Outbound Handler  M  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n+---------------+-----------------------------------+---------------+\n                |                                  \\|/\n+---------------+-----------------------------------+---------------+\n|               |                                   |               |\n|       [ Socket.read() ]                    [ Socket.write() ]     |\n|                                                                   |\n|  Netty Internal I/O Threads (Transport Implementation)            |\n+-------------------------------------------------------------------+\n```\n从上图中我们可以看出左边是`inbound`handler(从下向上进行处理), 右图是`outbound`流程(从上向下进行处理).`inbound`handler通常处理的是由IO线程生成的`inbound`数据(例如`SocketChannel#read(ByteBuffer)`).\n`outbound`handler一般由write请求生成或者转换传输数据. 如果`outbound`数据传输到上图的底部后, 它就会被绑定到`Channel`上的IO线程进行操作. IO线程一般会进行`SocketChannel#write(ByteBuffer)`数据输出操作.\n\n> 底层的`SocketChannel#read()`方法读取`ByteBuf`, 然后由IO线程`NioEventLoop`调用`ChannelPipeline#fireChannelRead()`方法,将消息`ByteBuf`传递到`ChannelPipeline`中.\n\n## handler实现\n下面我们看一下如何自己实现一个inbound和outbound handler\n```java\npublic class MyInboundHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) {\n        System.out.println(\"Connected!\");\n        ctx.fireChannelActive();\n    }\n}\n\npublic clas MyOutboundHandler extends ChannelOutboundHandlerAdapter {\n    @Override\n    public void close(ChannelHandlerContext ctx, ChannelPromise} promise) {\n        System.out.println(\"Closing ..\");\n        ctx.close(promise);\n    }\n}\n```\n\n可以预想到的是, 用户在使用pipeline中肯定最少会有一个`ChannelHandler`用来接受IO事件(例如read操作)和响应IO操作(例如write和close). 例如一个标准的服务器在每个channel中的pipeline中会有如下的handler\n* Protocol Decoder ： 将二进制的字节码(例如`ByteBuf`中的数据)解析成Java对象\n* Protocol Encoder :  将Java对象转换成二进制数据进行网络传输\n* Business Logic Handler : 执行真正的业务逻辑\n\n下面我们将上面的流程转换成一个真实的示例\n```java\nstatic final EventExecutorGroup group = new DefaultEventExecutorGroup(16);\n...\n\nChannelPipeline} pipeline = ch.pipeline();\n\npipeline.addLast(\"decoder\", new MyProtocolDecoder());\npipeline.addLast(\"encoder\", new MyProtocolEncoder());\n\n// Tell the pipeline to run MyBusinessLogicHandler's event handler methods\n// in a different thread than an I/O thread so that the I/O thread is not blocked by\n// a time-consuming task.\n// If your business logic is fully asynchronous or finished very quickly, you don't\n// need to specify a group.\npipeline.addLast(group, \"handler\", new MyBusinessLogicHandler());\n```\n\n我们可以在任何时间在`ChannelPipeline`上添加或者移除`ChannelHandler`, 因为`ChannelPipeline`是线程安全的. 例如我们可以在线上环境中因为业务原因动态的添加或者移除handler.\n\n## 事件处理过程\n在下面的示例中我们分别在pipeline中添加俩个`inbound`handler和俩个`outbound`handler.(以`Inbound`开头的类名表示为一个`inbound`handler, 以`Outbound`开头的类名表示为一个`outbound`handler.)\n```java\nChannelPipeline p = ...;\np.addLast(\"1\", new InboundHandlerA());\np.addLast(\"2\", new InboundHandlerB());\np.addLast(\"3\", new OutboundHandlerA());\np.addLast(\"4\", new OutboundHandlerB());\np.addLast(\"5\", new InboundOutboundHandlerX());\n```\n事件在`inbound`handler中的执行过程是`1, 2, 3, 4, 5`. 事件在`outbound`handler中的执行过程是`5, 4, 3, 2, 1`.\n\n但是在真实的执行过程中, 由于`3, 4`并没有实现`ChannelInboundHandler`, 因此inbound流程中真正执行的handler只有`1, 2, 5`. 而由于`1, 2`并没有实现`ChannelOutboundHandler`因此在outbound流程中真正执行的handler只有`5, 4, 3`.\n如果`5`都实现了`ChannelInboundHandler`和`ChannelOutboundHandler`, 那么事件的执行顺序分别是`125`和`543`.\n\n## 源码剖析\n下来我们看一下`ChannelPipeline`的默认实现`DefaultChannelPipeline`里的数据结构\n```java\nfinal AbstractChannel channel;\n\nfinal DefaultChannelHandlerContext head;\nfinal DefaultChannelHandlerContext tail;\n```\n`DefaultChannelPipeline`采用链式方式存储`ChannelHandlerContext`(内部存储的的是`ChannelHandler`). 在构造器中, 它将头尾相连了起来\n```java\npublic DefaultChannelPipeline(AbstractChannel channel) {\n        if (channel == null) {\n            throw new NullPointerException(\"channel\");\n        }\n        this.channel = channel;\n\n        tail = new TailContext(this);\n        head = new HeadContext(this);\n\n        // 将链表首尾相连\n        head.next = tail;\n        tail.prev = head;\n}\n```\n当我们增加一个`ChannelHandler`时\n```java\n@Override\npublic ChannelPipeline addFirst(EventExecutorGroup group, final String name, ChannelHandler handler) {\n    synchronized (this) {\n        checkDuplicateName(name);\n        // 我们将handler和ChannelPipeline, EventLoop封装到一个Context里\n        DefaultChannelHandlerContext newCtx = new DefaultChannelHandlerContext(this, group, name, handler);\n        addFirst0(name, newCtx);\n    }\n\n    return this;\n}\n\nprivate void addFirst0(String name, DefaultChannelHandlerContext newCtx) {\n    checkMultiplicity(newCtx);\n\n    // 我们将添加的handler放到链表的第一个位置上\n    DefaultChannelHandlerContext nextCtx = head.next;\n    newCtx.prev = head;\n    newCtx.next = nextCtx;\n    head.next = newCtx;\n    nextCtx.prev = newCtx;\n\n    name2ctx.put(name, newCtx);\n\n    callHandlerAdded(newCtx);\n}\n\nprivate void callHandlerAdded(final ChannelHandlerContext ctx) {\n    if (ctx.channel().isRegistered() && !ctx.executor().inEventLoop()) {\n        // 如果Channel已经注册到eventLoop上, 且当前线程与eventLoop中的线程不是同一个, 也就是说当前操作是多线程进行的,\n        // 则将callHandlerAdded0()逻辑放到任务队列中进行执行\n        ctx.executor().execute(new Runnable() {\n            @Override\n            public void run() {\n                callHandlerAdded0(ctx);\n            }\n        });\n        return;\n    }\n    callHandlerAdded0(ctx);\n}\n\nprivate void callHandlerAdded0(final ChannelHandlerContext ctx) {\n    try {\n        ctx.handler().handlerAdded(ctx);\n    } catch (Throwable t) {\n\n    }\n}\n```\n我们看到最终的时候在`ChannelHandler`里添加了`ChannelHandlerContext`. 但是经过查看`ByteToMessageDecoder`, `ChannelInboundHandlerAdapter`, `ChannelHandlerAdapter`\n这个都是空实现, 也就是说, 如果用户自己没有重载的话, 那么这里不会有任何的逻辑产生.\n\n最终我们看到了, 在`DeaultChannelPipeline`的内部只是维持了一个链表头和链表尾.那么当`Unsafe`里调用`fireXXX()`相关的方法时就会由头或者尾context来触发\n```java\n@Override\n    public ChannelPipeline fireChannelActive() {\n        head.fireChannelActive();\n\n        if (channel.config().isAutoRead()) {\n            channel.read();\n        }\n\n        return this;\n    }\n\n    @Override\n    public ChannelPipeline fireChannelRead(Object msg) {\n        head.fireChannelRead(msg);\n        return this;\n    }\n```\n在上面我们贴出了俩个方法, 下面我们看一下`fireChannelRead()`的处理流程.\n\n在`AbstractChannelHandlerContext#fireChannelRead()`\n```java\n@Override\n    public ChannelHandlerContext fireChannelRead(final Object msg) {\n        final AbstractChannelHandlerContext next = findContextInbound();\n        EventExecutor executor = next.executor();\n        if (executor.inEventLoop()) {\n            next.invokeChannelRead(msg);\n        } else {\n            executor.execute(new OneTimeTask() {\n                @Override\n                public void run() {\n                    next.invokeChannelRead(msg);\n                }\n            });\n        }\n        return this;\n    }\n\n    private AbstractChannelHandlerContext findContextInbound() {\n        AbstractChannelHandlerContext ctx = this;\n        do {\n            ctx = ctx.next;\n        } while (!ctx.inbound);\n        return ctx;\n    }\n```\n> 直接fireChannelRead() 会跳过第一个handler???\n\n上面的`fireChannelRead()`逻辑很简单, 我们接下来看一下`invokeChannelRead()`\n```java\nprivate void invokeChannelRead(Object msg) {\n        try {\n            ((ChannelInboundHandler) handler()).channelRead(this, msg);\n        } catch (Throwable t) {\n            notifyHandlerException(t);\n        }\n    }\n```\n这里就直接找到了handler, 触发了我们最终自己实现的`channelRead()`方法.\n\n也许你已经注意到了, 在handler中不得不调用`ChannelHandlerContext`的事件传播方法, 将事件传递给下一个handler. 下面的是\n能够触发`inbound`事件的方法\n* `ChannelHandlerContext#fireChannelRegistered()` Channel注册事件. (``触发)\n* `ChannelHandlerContext#fireChannelActive()` TCP链路建立成功,Channel激活事件. (``触发)\n* `ChannelHandlerContext#fireChannelRead(Object var1)` 读事件. (``触发)\n* `ChannelHandlerContext#fireChannelReadComplete()` 读操作完成通知事件. (``触发)\n* `ChannelHandlerContext#fireExceptionCaught(Throwable var1)` 异常通知事件. (``触发)\n* `ChannelHandlerContext#fireUserEventTriggered(Object var1)` 用户自定义事件. (``触发)\n* `ChannelHandlerContext#fireChannelWritabilityChanged()` Channel的可写状态变化通知事件. (``触发)\n* `ChannelHandlerContext#fireChannelInactive()` TCP链路关闭, 链路不可用通知事件. (``触发)\n触发`outbound`事件的方法有\n* `ChannelHandlerContext#bind(SocketAddress var1, ChannelPromise var2)` 绑定本地地址事件\n* `ChannelHandlerContext#connect(SocketAddress var1, ChannelPromise var2)` 连接服务端事件\n* `ChannelHandlerContext#flush()` 刷新事件\n* `ChannelHandlerContext#read()` 读事件\n* `ChannelHandlerContext#disconnect(ChannelPromise var1)` 断开连接事件\n* `ChannelHandlerContext#close(ChannelPromise var1)` 关闭当前Channel事件\n","source":"_posts/netty/ChannelPipeline.md","raw":"category: Netty\ndate: 2016-02-02\ntitle: Netty ChannelPipeline\n---\n\n## 简介\n`ChannelPipeline`是一个`ChannelHandler`的集合, 用于处理或者截断`Channel`的`inbound events`和`outbound operations`. `ChannelPipeline`是[Intercepting Filter](http://www.oracle.com/technetwork/java/interceptingfilter-142169.html)的一个高级实现, 它保证了用户对事件处理的完整控制权以及确保了`ChannelHandler`在pipeline中的运行方式.\n\n每当创建一个`Channel`的时候, 都会创建出一个对应的`ChannelPipeline`, 也就是说每个`Channel`都有其自己的`ChannelPipeline`\n\n下面的图给出了IO事件是如何在`ChannelPipeline`里的`ChannelHandler`进行传递处理的. IO事件由`ChannelInboundHandler`或者`ChannelOutboundHandler`处理, 我们在handler中调用`ChannelHandlerContext`中的事件传播方法将event传播给下一个handler继续执行, 例如调用`ChannelHandlerContext#fireChannelRead(Object)`和`ChannelHandlerContext#write(Object)`\n```java\n                                               I/O Request\n                                          via Channel} or\n                                      ChannelHandlerContext}\n                                                    |\n+---------------------------------------------------+---------------+\n|                           ChannelPipeline         |               |\n|                                                  \\|/              |\n|    +---------------------+            +-----------+----------+    |\n|    | Inbound Handler  N  |            | Outbound Handler  1  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n|               |                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler N-1 |            | Outbound Handler  2  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  .               |\n|               .                                   .               |\n| ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|\n|        [ method call]                       [method call]         |\n|               .                                   .               |\n|               .                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler  2  |            | Outbound Handler M-1 |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n|               |                                  \\|/              |\n|    +----------+----------+            +-----------+----------+    |\n|    | Inbound Handler  1  |            | Outbound Handler  M  |    |\n|    +----------+----------+            +-----------+----------+    |\n|              /|\\                                  |               |\n+---------------+-----------------------------------+---------------+\n                |                                  \\|/\n+---------------+-----------------------------------+---------------+\n|               |                                   |               |\n|       [ Socket.read() ]                    [ Socket.write() ]     |\n|                                                                   |\n|  Netty Internal I/O Threads (Transport Implementation)            |\n+-------------------------------------------------------------------+\n```\n从上图中我们可以看出左边是`inbound`handler(从下向上进行处理), 右图是`outbound`流程(从上向下进行处理).`inbound`handler通常处理的是由IO线程生成的`inbound`数据(例如`SocketChannel#read(ByteBuffer)`).\n`outbound`handler一般由write请求生成或者转换传输数据. 如果`outbound`数据传输到上图的底部后, 它就会被绑定到`Channel`上的IO线程进行操作. IO线程一般会进行`SocketChannel#write(ByteBuffer)`数据输出操作.\n\n> 底层的`SocketChannel#read()`方法读取`ByteBuf`, 然后由IO线程`NioEventLoop`调用`ChannelPipeline#fireChannelRead()`方法,将消息`ByteBuf`传递到`ChannelPipeline`中.\n\n## handler实现\n下面我们看一下如何自己实现一个inbound和outbound handler\n```java\npublic class MyInboundHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) {\n        System.out.println(\"Connected!\");\n        ctx.fireChannelActive();\n    }\n}\n\npublic clas MyOutboundHandler extends ChannelOutboundHandlerAdapter {\n    @Override\n    public void close(ChannelHandlerContext ctx, ChannelPromise} promise) {\n        System.out.println(\"Closing ..\");\n        ctx.close(promise);\n    }\n}\n```\n\n可以预想到的是, 用户在使用pipeline中肯定最少会有一个`ChannelHandler`用来接受IO事件(例如read操作)和响应IO操作(例如write和close). 例如一个标准的服务器在每个channel中的pipeline中会有如下的handler\n* Protocol Decoder ： 将二进制的字节码(例如`ByteBuf`中的数据)解析成Java对象\n* Protocol Encoder :  将Java对象转换成二进制数据进行网络传输\n* Business Logic Handler : 执行真正的业务逻辑\n\n下面我们将上面的流程转换成一个真实的示例\n```java\nstatic final EventExecutorGroup group = new DefaultEventExecutorGroup(16);\n...\n\nChannelPipeline} pipeline = ch.pipeline();\n\npipeline.addLast(\"decoder\", new MyProtocolDecoder());\npipeline.addLast(\"encoder\", new MyProtocolEncoder());\n\n// Tell the pipeline to run MyBusinessLogicHandler's event handler methods\n// in a different thread than an I/O thread so that the I/O thread is not blocked by\n// a time-consuming task.\n// If your business logic is fully asynchronous or finished very quickly, you don't\n// need to specify a group.\npipeline.addLast(group, \"handler\", new MyBusinessLogicHandler());\n```\n\n我们可以在任何时间在`ChannelPipeline`上添加或者移除`ChannelHandler`, 因为`ChannelPipeline`是线程安全的. 例如我们可以在线上环境中因为业务原因动态的添加或者移除handler.\n\n## 事件处理过程\n在下面的示例中我们分别在pipeline中添加俩个`inbound`handler和俩个`outbound`handler.(以`Inbound`开头的类名表示为一个`inbound`handler, 以`Outbound`开头的类名表示为一个`outbound`handler.)\n```java\nChannelPipeline p = ...;\np.addLast(\"1\", new InboundHandlerA());\np.addLast(\"2\", new InboundHandlerB());\np.addLast(\"3\", new OutboundHandlerA());\np.addLast(\"4\", new OutboundHandlerB());\np.addLast(\"5\", new InboundOutboundHandlerX());\n```\n事件在`inbound`handler中的执行过程是`1, 2, 3, 4, 5`. 事件在`outbound`handler中的执行过程是`5, 4, 3, 2, 1`.\n\n但是在真实的执行过程中, 由于`3, 4`并没有实现`ChannelInboundHandler`, 因此inbound流程中真正执行的handler只有`1, 2, 5`. 而由于`1, 2`并没有实现`ChannelOutboundHandler`因此在outbound流程中真正执行的handler只有`5, 4, 3`.\n如果`5`都实现了`ChannelInboundHandler`和`ChannelOutboundHandler`, 那么事件的执行顺序分别是`125`和`543`.\n\n## 源码剖析\n下来我们看一下`ChannelPipeline`的默认实现`DefaultChannelPipeline`里的数据结构\n```java\nfinal AbstractChannel channel;\n\nfinal DefaultChannelHandlerContext head;\nfinal DefaultChannelHandlerContext tail;\n```\n`DefaultChannelPipeline`采用链式方式存储`ChannelHandlerContext`(内部存储的的是`ChannelHandler`). 在构造器中, 它将头尾相连了起来\n```java\npublic DefaultChannelPipeline(AbstractChannel channel) {\n        if (channel == null) {\n            throw new NullPointerException(\"channel\");\n        }\n        this.channel = channel;\n\n        tail = new TailContext(this);\n        head = new HeadContext(this);\n\n        // 将链表首尾相连\n        head.next = tail;\n        tail.prev = head;\n}\n```\n当我们增加一个`ChannelHandler`时\n```java\n@Override\npublic ChannelPipeline addFirst(EventExecutorGroup group, final String name, ChannelHandler handler) {\n    synchronized (this) {\n        checkDuplicateName(name);\n        // 我们将handler和ChannelPipeline, EventLoop封装到一个Context里\n        DefaultChannelHandlerContext newCtx = new DefaultChannelHandlerContext(this, group, name, handler);\n        addFirst0(name, newCtx);\n    }\n\n    return this;\n}\n\nprivate void addFirst0(String name, DefaultChannelHandlerContext newCtx) {\n    checkMultiplicity(newCtx);\n\n    // 我们将添加的handler放到链表的第一个位置上\n    DefaultChannelHandlerContext nextCtx = head.next;\n    newCtx.prev = head;\n    newCtx.next = nextCtx;\n    head.next = newCtx;\n    nextCtx.prev = newCtx;\n\n    name2ctx.put(name, newCtx);\n\n    callHandlerAdded(newCtx);\n}\n\nprivate void callHandlerAdded(final ChannelHandlerContext ctx) {\n    if (ctx.channel().isRegistered() && !ctx.executor().inEventLoop()) {\n        // 如果Channel已经注册到eventLoop上, 且当前线程与eventLoop中的线程不是同一个, 也就是说当前操作是多线程进行的,\n        // 则将callHandlerAdded0()逻辑放到任务队列中进行执行\n        ctx.executor().execute(new Runnable() {\n            @Override\n            public void run() {\n                callHandlerAdded0(ctx);\n            }\n        });\n        return;\n    }\n    callHandlerAdded0(ctx);\n}\n\nprivate void callHandlerAdded0(final ChannelHandlerContext ctx) {\n    try {\n        ctx.handler().handlerAdded(ctx);\n    } catch (Throwable t) {\n\n    }\n}\n```\n我们看到最终的时候在`ChannelHandler`里添加了`ChannelHandlerContext`. 但是经过查看`ByteToMessageDecoder`, `ChannelInboundHandlerAdapter`, `ChannelHandlerAdapter`\n这个都是空实现, 也就是说, 如果用户自己没有重载的话, 那么这里不会有任何的逻辑产生.\n\n最终我们看到了, 在`DeaultChannelPipeline`的内部只是维持了一个链表头和链表尾.那么当`Unsafe`里调用`fireXXX()`相关的方法时就会由头或者尾context来触发\n```java\n@Override\n    public ChannelPipeline fireChannelActive() {\n        head.fireChannelActive();\n\n        if (channel.config().isAutoRead()) {\n            channel.read();\n        }\n\n        return this;\n    }\n\n    @Override\n    public ChannelPipeline fireChannelRead(Object msg) {\n        head.fireChannelRead(msg);\n        return this;\n    }\n```\n在上面我们贴出了俩个方法, 下面我们看一下`fireChannelRead()`的处理流程.\n\n在`AbstractChannelHandlerContext#fireChannelRead()`\n```java\n@Override\n    public ChannelHandlerContext fireChannelRead(final Object msg) {\n        final AbstractChannelHandlerContext next = findContextInbound();\n        EventExecutor executor = next.executor();\n        if (executor.inEventLoop()) {\n            next.invokeChannelRead(msg);\n        } else {\n            executor.execute(new OneTimeTask() {\n                @Override\n                public void run() {\n                    next.invokeChannelRead(msg);\n                }\n            });\n        }\n        return this;\n    }\n\n    private AbstractChannelHandlerContext findContextInbound() {\n        AbstractChannelHandlerContext ctx = this;\n        do {\n            ctx = ctx.next;\n        } while (!ctx.inbound);\n        return ctx;\n    }\n```\n> 直接fireChannelRead() 会跳过第一个handler???\n\n上面的`fireChannelRead()`逻辑很简单, 我们接下来看一下`invokeChannelRead()`\n```java\nprivate void invokeChannelRead(Object msg) {\n        try {\n            ((ChannelInboundHandler) handler()).channelRead(this, msg);\n        } catch (Throwable t) {\n            notifyHandlerException(t);\n        }\n    }\n```\n这里就直接找到了handler, 触发了我们最终自己实现的`channelRead()`方法.\n\n也许你已经注意到了, 在handler中不得不调用`ChannelHandlerContext`的事件传播方法, 将事件传递给下一个handler. 下面的是\n能够触发`inbound`事件的方法\n* `ChannelHandlerContext#fireChannelRegistered()` Channel注册事件. (``触发)\n* `ChannelHandlerContext#fireChannelActive()` TCP链路建立成功,Channel激活事件. (``触发)\n* `ChannelHandlerContext#fireChannelRead(Object var1)` 读事件. (``触发)\n* `ChannelHandlerContext#fireChannelReadComplete()` 读操作完成通知事件. (``触发)\n* `ChannelHandlerContext#fireExceptionCaught(Throwable var1)` 异常通知事件. (``触发)\n* `ChannelHandlerContext#fireUserEventTriggered(Object var1)` 用户自定义事件. (``触发)\n* `ChannelHandlerContext#fireChannelWritabilityChanged()` Channel的可写状态变化通知事件. (``触发)\n* `ChannelHandlerContext#fireChannelInactive()` TCP链路关闭, 链路不可用通知事件. (``触发)\n触发`outbound`事件的方法有\n* `ChannelHandlerContext#bind(SocketAddress var1, ChannelPromise var2)` 绑定本地地址事件\n* `ChannelHandlerContext#connect(SocketAddress var1, ChannelPromise var2)` 连接服务端事件\n* `ChannelHandlerContext#flush()` 刷新事件\n* `ChannelHandlerContext#read()` 读事件\n* `ChannelHandlerContext#disconnect(ChannelPromise var1)` 断开连接事件\n* `ChannelHandlerContext#close(ChannelPromise var1)` 关闭当前Channel事件\n","slug":"netty/ChannelPipeline","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihxi0086vjs6jzg4rjsu"},{"date":"2016-03-16T16:00:00.000Z","title":"Netty 压测","_content":"我们知道Netty的性能是非常好的,那究竟有多好呢? 今天我写了一个小程序测试了一下\n```java\npublic class NettyServer {\n    public static void main(String[] args) throws InterruptedException {\n        int cpuSize = Runtime.getRuntime().availableProcessors();\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize);\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .option(ChannelOption.SO_BACKLOG, 128)\n                    .option(ChannelOption.TCP_NODELAY, true)\n                    .option(ChannelOption.AUTO_READ, true)\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch) {\n                            ch.pipeline().addLast(new InHandler());\n                        }\n                    });\n\n            ChannelFuture f = b.bind(8881).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\nclass InHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ctx.write(msg);\n    }\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) {\n        ctx.flush();\n    }\n}\n```\n上面是一个简单的Socket服务器, 不做任何的编解码工作, 当接收到数据之后, 直接返回给客户端.\n\n在启动的这个服务器的时候加上指定虚拟机的堆大小(我们指定了大小为固定的30M)\n```java\n-Xmx30m -Xms30m\n````\n然后写一个Socket客户端程序(原谅我客户端是用python写的, 现在我正在把我业余时间写代码的语言替换成python)\n```python\nimport socket\nimport threading\nimport time\n\ncount = 0\ndef socketSendData():\n    client=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    client.connect(('localhost',8881))\n    client.send('2')\n    time.sleep(60)\n\n\n\nfor i in range(0, 2000, 1):\n    try:\n       t = threading.Thread(target=socketSendData)\n       info = t.start()\n    except:\n       count += 1\n       print \"Error: unable to start thread  \" + str(count)\n```\n由于测试机配置问题, 我的python程序只能启动2000个Socket连接, 但是也无所谓, 我们看一下在这俩千个Socket连接时, Netty服务器的消耗\n\n我们首先看一下客户端连接运行之前的Netty程序的内存占用\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/netty%20压测1.jpg)\n我们看到了在top中为46M, 在visualVM中分配的30M堆内存也只使用了10M, 而且一直在GC.\n\n那么我们再看一下压测之后的内?\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/Netty%20压测2.jpg)\ntop中显示占用了58M的内存, 而在visualVM只不过偶尔比10M多一点的内存,而且又很快的GC掉了.\n\n那么top中多出的12M内存是怎么回事呢?这是因为Netty默认的使用的是UnpooledDirectByteBuf(姑且是这么个名字吧), 它使用的是非池化的直接内存, 也就是说在接受网络连接数据的时候,它并没有直接使用堆内内存,而是使用的堆外的.\n","source":"_posts/netty/Netty 压测.md","raw":"category: Netty\ndate: 2016-03-17\ntitle: Netty 压测\n---\n我们知道Netty的性能是非常好的,那究竟有多好呢? 今天我写了一个小程序测试了一下\n```java\npublic class NettyServer {\n    public static void main(String[] args) throws InterruptedException {\n        int cpuSize = Runtime.getRuntime().availableProcessors();\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize);\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .option(ChannelOption.SO_BACKLOG, 128)\n                    .option(ChannelOption.TCP_NODELAY, true)\n                    .option(ChannelOption.AUTO_READ, true)\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch) {\n                            ch.pipeline().addLast(new InHandler());\n                        }\n                    });\n\n            ChannelFuture f = b.bind(8881).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\nclass InHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ctx.write(msg);\n    }\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) {\n        ctx.flush();\n    }\n}\n```\n上面是一个简单的Socket服务器, 不做任何的编解码工作, 当接收到数据之后, 直接返回给客户端.\n\n在启动的这个服务器的时候加上指定虚拟机的堆大小(我们指定了大小为固定的30M)\n```java\n-Xmx30m -Xms30m\n````\n然后写一个Socket客户端程序(原谅我客户端是用python写的, 现在我正在把我业余时间写代码的语言替换成python)\n```python\nimport socket\nimport threading\nimport time\n\ncount = 0\ndef socketSendData():\n    client=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    client.connect(('localhost',8881))\n    client.send('2')\n    time.sleep(60)\n\n\n\nfor i in range(0, 2000, 1):\n    try:\n       t = threading.Thread(target=socketSendData)\n       info = t.start()\n    except:\n       count += 1\n       print \"Error: unable to start thread  \" + str(count)\n```\n由于测试机配置问题, 我的python程序只能启动2000个Socket连接, 但是也无所谓, 我们看一下在这俩千个Socket连接时, Netty服务器的消耗\n\n我们首先看一下客户端连接运行之前的Netty程序的内存占用\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/netty%20压测1.jpg)\n我们看到了在top中为46M, 在visualVM中分配的30M堆内存也只使用了10M, 而且一直在GC.\n\n那么我们再看一下压测之后的内?\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/Netty%20压测2.jpg)\ntop中显示占用了58M的内存, 而在visualVM只不过偶尔比10M多一点的内存,而且又很快的GC掉了.\n\n那么top中多出的12M内存是怎么回事呢?这是因为Netty默认的使用的是UnpooledDirectByteBuf(姑且是这么个名字吧), 它使用的是非池化的直接内存, 也就是说在接受网络连接数据的时候,它并没有直接使用堆内内存,而是使用的堆外的.\n","slug":"netty/Netty 压测","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihxl0088vjs6toihhku2"},{"date":"2016-03-13T16:00:00.000Z","title":"Netty NioEventLoop","_content":"在真实的业务环境中, 我们都是使用主从Reactor线程模型. 在Netty中主从线程池都是使用的`NioEventLoopGroup`, 它实现了\n`java.util.concurrent.Executor`. 虽然在编程中我们使用的是`NioEventLoopGroup`, 但是主要的逻辑确是在`MultithreadEventExecutorGroup`里实现的.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/NioEventLoopGroup.jpg)\n下来我们首先看一下`MultithreadEventExecutorGroup`的数据成员\n```java\nprivate final EventExecutor[] children;\nprivate final EventExecutorChooser chooser;\n\nprotected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) {\n        children = new SingleThreadEventExecutor[nThreads];\n        if (isPowerOfTwo(children.length)) {\n            chooser = new PowerOfTwoEventExecutorChooser();\n        } else {\n            chooser = new GenericEventExecutorChooser();\n        }\n\n        for (int i = 0; i < nThreads; i ++) {\n            boolean success = false;\n            try {\n                children[i] = newChild(threadFactory, args);\n                success = true;\n            } catch (Exception e) {\n                // TODO: Think about if this is a good exception type\n                throw new IllegalStateException(\"failed to create a child event loop\", e);\n            }\n        }\n```\n我们看到了`NioEventLoopGroup`内部聚合了一个`EventExecutor`的数组. 这个数组就构成了主从线程池. 线程的选择由`EventExecutorChooser chooser`来实现\n```java\n@Override\npublic EventExecutor next() {\n    return chooser.next();\n}\n\nprivate final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser {\n    @Override\n    public EventExecutor next() {\n        return children[childIndex.getAndIncrement() & children.length - 1];\n    }\n}\n\nprivate final class GenericEventExecutorChooser implements EventExecutorChooser {\n    @Override\n    public EventExecutor next() {\n        return children[Math.abs(childIndex.getAndIncrement() % children.length)];\n    }\n}\n```\n而`newChild()`的方法实现是由子类来确定的, 我们来直接看一下`NioEventLoopGroup`的内部实现\n```java\n@Override\nprotected EventExecutor newChild(ThreadFactory threadFactory, Object... args) throws Exception {\n    return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0]);\n}\n```\n它是直接生成了一个`NioEventLoop`的实例出来. 下来我们看一下`NioEventLoop`的实现\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/NioEventLoop.jpg)\n我们看一下`NioEventLoop`的属性成员\n```java\n// 多路选择复用器\nSelector selector;\n// Netty优化过的SelectedSelectionKeys\nprivate SelectedSelectionKeySet selectedKeys;\n// SelectorProvider.provider()提供, 在NioEventLoopGroup构造器中实现\nprivate final SelectorProvider provider;\n```\n我们看到`NioEventLoop`主要是实现了IO多路复用, 它的任务执行是由父类`SingleThreadEventExecutor`实现的, 下面我们从它的构造器来追溯到`SingleThreadEventExecutor`上\n```java\nNioEventLoop(NioEventLoopGroup parent, ThreadFactory threadFactory, SelectorProvider selectorProvider) {\n    super(parent, threadFactory, false);\n    if (selectorProvider == null) {\n        throw new NullPointerException(\"selectorProvider\");\n    }\n    provider = selectorProvider;\n    selector = openSelector();\n}\n```\n`SingleThreadEventExecutor`这个类主要是实现了主从线程池中的线程功能, 所有的任务都在单线程中执行, 因此将这个线程池串行化, 可以将其看待成一个线程. 在`SingleThreadEventExecutor`中的构造器中,添加向任务队列中添加一个调用`NioEventLoop`的`run()`方法的任务\n```java\nprotected SingleThreadEventExecutor(\n            EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) {\n        thread = threadFactory.newThread(new Runnable() {\n            @Override\n            public void run() {\n                boolean success = false;\n                updateLastExecutionTime();\n                try {\n                    SingleThreadEventExecutor.this.run();\n                    success = true;\n                } catch (Throwable t) {\n                } finally {\n                    for (;;) {\n                        int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this);\n                        if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(\n                                SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {\n                            break;\n                        }\n                    }\n                    // Check if confirmShutdown() was called at the end of the loop.\n                    if (success && gracefulShutdownStartTime == 0) {\n                        logger.error(\"Buggy \" + EventExecutor.class.getSimpleName());\n                    }\n\n                    try {\n                        // Run all remaining tasks and shutdown hooks.\n                        for (;;) {\n                            if (confirmShutdown()) {\n                                break;\n                            }\n                        }\n                    } finally {\n                        try {\n                            cleanup();\n                        } finally {\n                            STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);\n                            threadLock.release();\n                            terminationFuture.setSuccess(null);\n                        }\n                    }\n                }\n            }\n        });\n        taskQueue = newTaskQueue();\n    }\n\n```\n我们看到了一行关键性代码`SingleThreadEventExecutor.this.run()`, 它调用了自己的`run()`方法\n```java\nprotected abstract void run();\n```\n而这个方法是在`NioEventLoop`中实现的,也是我们要重点分析的代码\n```java\n@Override\n    protected void run() {\n        for (;;) {\n            boolean oldWakenUp = wakenUp.getAndSet(false);\n            try {\n                // 查看taskQueue里是否有任务, 如果有任务的话, 则直接selector.selectNow();\n                if (hasTasks()) {\n                    selectNow();\n                } else {\n                    select(oldWakenUp);\n\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                }\n\n                cancelledKeys = 0;\n                needsToSelectAgain = false;\n                final int ioRatio = this.ioRatio;\n                // 如果当前线程是百分百执行的话, 则直接处理所有的任务\n                if (ioRatio == 100) {\n                    processSelectedKeys();\n                    runAllTasks();\n                } else {\n                    final long ioStartTime = System.nanoTime();\n\n                    processSelectedKeys();\n\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n\n                //\n                if (isShuttingDown()) {\n                    closeAll();\n                    if (confirmShutdown()) {\n                        break;\n                    }\n                }\n            } catch (Throwable t) {\n            }\n        }\n    }\n```\n上面的`run()`就是不断的轮询当前`NioEventLoop`里是否有任务. 然后处理Selector上已经就绪的Channel和任务队列里的任务.\n然后我们接着往下看`processSelectedKeys()`方法\n```java\nprivate void processSelectedKeys() {\n       if (selectedKeys != null) {\n           processSelectedKeysOptimized(selectedKeys.flip());\n       } else {\n           processSelectedKeysPlain(selector.selectedKeys());\n       }\n   }\n\n\n   private void processSelectedKeysPlain(Set<SelectionKey> selectedKeys) {\n           // check if the set is empty and if so just return to not create garbage by\n           // creating a new Iterator every time even if there is nothing to process.\n           // See https://github.com/netty/netty/issues/597\n           if (selectedKeys.isEmpty()) {\n               return;\n           }\n\n           Iterator<SelectionKey> i = selectedKeys.iterator();\n           for (;;) {\n               final SelectionKey k = i.next();\n               // 取出SelectionKey的附件\n               final Object a = k.attachment();\n               i.remove();\n\n               if (a instanceof AbstractNioChannel) {\n                 // a有可能是NioServerSocketChannel或者NioSocketChannel\n                   processSelectedKey(k, (AbstractNioChannel) a);\n               } else {\n                   // 如果a不是Channel的话, 那就是NioTask了\n                   @SuppressWarnings(\"unchecked\")\n                   NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n                   processSelectedKey(k, task);\n               }\n\n               if (!i.hasNext()) {\n                   break;\n               }\n\n               if (needsToSelectAgain) {\n                   selectAgain();\n                   selectedKeys = selector.selectedKeys();\n\n                   // Create the iterator again to avoid ConcurrentModificationException\n                   if (selectedKeys.isEmpty()) {\n                       break;\n                   } else {\n                       i = selectedKeys.iterator();\n                   }\n               }\n           }\n       }\n```\n然后咱们接着往下看对Channel的处理\n```java\nprivate static void processSelectedKey(SelectionKey k, AbstractNioChannel ch) {\n    final NioUnsafe unsafe = ch.unsafe();\n\n    try {\n        int readyOps = k.readyOps();\n        // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead\n        // to a spin loop\n        if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {\n            // 如果是读事件或者连接的事件,则直接调用read方法\n            unsafe.read();\n            if (!ch.isOpen()) {\n                // Connection already closed - no need to handle write.\n                return;\n            }\n        }\n        if ((readyOps & SelectionKey.OP_WRITE) != 0) {\n            // 如果是写操作位, 则说明有半包消息没有写完, 需要继续\n            ch.unsafe().forceFlush();\n        }\n        if ((readyOps & SelectionKey.OP_CONNECT) != 0) {\n            // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking\n            // See https://github.com/netty/netty/issues/924\n            int ops = k.interestOps();\n            ops &= ~SelectionKey.OP_CONNECT;\n            k.interestOps(ops);\n\n            unsafe.finishConnect();\n        }\n    } catch (CancelledKeyException ignored) {\n        unsafe.close(unsafe.voidPromise());\n    }\n}\n```\n\n> 在unsafe的多态这我们要多说一些, 我们知道NioEventLoop内部处理的Channel其实是有俩种类型的, 一个是`NioServerScoketChannel`一个是`NioSocketChannel`.\n>\n> `NioServerSocketChannel`继承自`AbstractNioMessageChannel`, 而这个父类实现了一个`NioMessageUnsafe`的一个内部类, 这个内部类的`read()`方法会调用Channel里的`doReadMessage()`方法. 父类的`doReadMessage()`方法是由子类来具体实现的. 在`NioServerScoketChannel`中是生成了一个`NioSocketChannel`的列表作为消息返回, 然后再让`ServerBootstrapAcceptor`将`NioSocketChannel`绑定到从Reactor上.\n>\n> `NioSocketChannel`继承自`AbstractNioByteChannel`, 这个父类实现了一个`NioByteUnsafe`, 这个Unsafe就负责创建ByteBuf, 接受真正的网络数据了.\n","source":"_posts/netty/NioEventLoop.md","raw":"category: Netty\ndate: 2016-03-14\ntitle: Netty NioEventLoop\n---\n在真实的业务环境中, 我们都是使用主从Reactor线程模型. 在Netty中主从线程池都是使用的`NioEventLoopGroup`, 它实现了\n`java.util.concurrent.Executor`. 虽然在编程中我们使用的是`NioEventLoopGroup`, 但是主要的逻辑确是在`MultithreadEventExecutorGroup`里实现的.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/NioEventLoopGroup.jpg)\n下来我们首先看一下`MultithreadEventExecutorGroup`的数据成员\n```java\nprivate final EventExecutor[] children;\nprivate final EventExecutorChooser chooser;\n\nprotected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) {\n        children = new SingleThreadEventExecutor[nThreads];\n        if (isPowerOfTwo(children.length)) {\n            chooser = new PowerOfTwoEventExecutorChooser();\n        } else {\n            chooser = new GenericEventExecutorChooser();\n        }\n\n        for (int i = 0; i < nThreads; i ++) {\n            boolean success = false;\n            try {\n                children[i] = newChild(threadFactory, args);\n                success = true;\n            } catch (Exception e) {\n                // TODO: Think about if this is a good exception type\n                throw new IllegalStateException(\"failed to create a child event loop\", e);\n            }\n        }\n```\n我们看到了`NioEventLoopGroup`内部聚合了一个`EventExecutor`的数组. 这个数组就构成了主从线程池. 线程的选择由`EventExecutorChooser chooser`来实现\n```java\n@Override\npublic EventExecutor next() {\n    return chooser.next();\n}\n\nprivate final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser {\n    @Override\n    public EventExecutor next() {\n        return children[childIndex.getAndIncrement() & children.length - 1];\n    }\n}\n\nprivate final class GenericEventExecutorChooser implements EventExecutorChooser {\n    @Override\n    public EventExecutor next() {\n        return children[Math.abs(childIndex.getAndIncrement() % children.length)];\n    }\n}\n```\n而`newChild()`的方法实现是由子类来确定的, 我们来直接看一下`NioEventLoopGroup`的内部实现\n```java\n@Override\nprotected EventExecutor newChild(ThreadFactory threadFactory, Object... args) throws Exception {\n    return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0]);\n}\n```\n它是直接生成了一个`NioEventLoop`的实例出来. 下来我们看一下`NioEventLoop`的实现\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/NioEventLoop.jpg)\n我们看一下`NioEventLoop`的属性成员\n```java\n// 多路选择复用器\nSelector selector;\n// Netty优化过的SelectedSelectionKeys\nprivate SelectedSelectionKeySet selectedKeys;\n// SelectorProvider.provider()提供, 在NioEventLoopGroup构造器中实现\nprivate final SelectorProvider provider;\n```\n我们看到`NioEventLoop`主要是实现了IO多路复用, 它的任务执行是由父类`SingleThreadEventExecutor`实现的, 下面我们从它的构造器来追溯到`SingleThreadEventExecutor`上\n```java\nNioEventLoop(NioEventLoopGroup parent, ThreadFactory threadFactory, SelectorProvider selectorProvider) {\n    super(parent, threadFactory, false);\n    if (selectorProvider == null) {\n        throw new NullPointerException(\"selectorProvider\");\n    }\n    provider = selectorProvider;\n    selector = openSelector();\n}\n```\n`SingleThreadEventExecutor`这个类主要是实现了主从线程池中的线程功能, 所有的任务都在单线程中执行, 因此将这个线程池串行化, 可以将其看待成一个线程. 在`SingleThreadEventExecutor`中的构造器中,添加向任务队列中添加一个调用`NioEventLoop`的`run()`方法的任务\n```java\nprotected SingleThreadEventExecutor(\n            EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) {\n        thread = threadFactory.newThread(new Runnable() {\n            @Override\n            public void run() {\n                boolean success = false;\n                updateLastExecutionTime();\n                try {\n                    SingleThreadEventExecutor.this.run();\n                    success = true;\n                } catch (Throwable t) {\n                } finally {\n                    for (;;) {\n                        int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this);\n                        if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(\n                                SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {\n                            break;\n                        }\n                    }\n                    // Check if confirmShutdown() was called at the end of the loop.\n                    if (success && gracefulShutdownStartTime == 0) {\n                        logger.error(\"Buggy \" + EventExecutor.class.getSimpleName());\n                    }\n\n                    try {\n                        // Run all remaining tasks and shutdown hooks.\n                        for (;;) {\n                            if (confirmShutdown()) {\n                                break;\n                            }\n                        }\n                    } finally {\n                        try {\n                            cleanup();\n                        } finally {\n                            STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);\n                            threadLock.release();\n                            terminationFuture.setSuccess(null);\n                        }\n                    }\n                }\n            }\n        });\n        taskQueue = newTaskQueue();\n    }\n\n```\n我们看到了一行关键性代码`SingleThreadEventExecutor.this.run()`, 它调用了自己的`run()`方法\n```java\nprotected abstract void run();\n```\n而这个方法是在`NioEventLoop`中实现的,也是我们要重点分析的代码\n```java\n@Override\n    protected void run() {\n        for (;;) {\n            boolean oldWakenUp = wakenUp.getAndSet(false);\n            try {\n                // 查看taskQueue里是否有任务, 如果有任务的话, 则直接selector.selectNow();\n                if (hasTasks()) {\n                    selectNow();\n                } else {\n                    select(oldWakenUp);\n\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                }\n\n                cancelledKeys = 0;\n                needsToSelectAgain = false;\n                final int ioRatio = this.ioRatio;\n                // 如果当前线程是百分百执行的话, 则直接处理所有的任务\n                if (ioRatio == 100) {\n                    processSelectedKeys();\n                    runAllTasks();\n                } else {\n                    final long ioStartTime = System.nanoTime();\n\n                    processSelectedKeys();\n\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n\n                //\n                if (isShuttingDown()) {\n                    closeAll();\n                    if (confirmShutdown()) {\n                        break;\n                    }\n                }\n            } catch (Throwable t) {\n            }\n        }\n    }\n```\n上面的`run()`就是不断的轮询当前`NioEventLoop`里是否有任务. 然后处理Selector上已经就绪的Channel和任务队列里的任务.\n然后我们接着往下看`processSelectedKeys()`方法\n```java\nprivate void processSelectedKeys() {\n       if (selectedKeys != null) {\n           processSelectedKeysOptimized(selectedKeys.flip());\n       } else {\n           processSelectedKeysPlain(selector.selectedKeys());\n       }\n   }\n\n\n   private void processSelectedKeysPlain(Set<SelectionKey> selectedKeys) {\n           // check if the set is empty and if so just return to not create garbage by\n           // creating a new Iterator every time even if there is nothing to process.\n           // See https://github.com/netty/netty/issues/597\n           if (selectedKeys.isEmpty()) {\n               return;\n           }\n\n           Iterator<SelectionKey> i = selectedKeys.iterator();\n           for (;;) {\n               final SelectionKey k = i.next();\n               // 取出SelectionKey的附件\n               final Object a = k.attachment();\n               i.remove();\n\n               if (a instanceof AbstractNioChannel) {\n                 // a有可能是NioServerSocketChannel或者NioSocketChannel\n                   processSelectedKey(k, (AbstractNioChannel) a);\n               } else {\n                   // 如果a不是Channel的话, 那就是NioTask了\n                   @SuppressWarnings(\"unchecked\")\n                   NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n                   processSelectedKey(k, task);\n               }\n\n               if (!i.hasNext()) {\n                   break;\n               }\n\n               if (needsToSelectAgain) {\n                   selectAgain();\n                   selectedKeys = selector.selectedKeys();\n\n                   // Create the iterator again to avoid ConcurrentModificationException\n                   if (selectedKeys.isEmpty()) {\n                       break;\n                   } else {\n                       i = selectedKeys.iterator();\n                   }\n               }\n           }\n       }\n```\n然后咱们接着往下看对Channel的处理\n```java\nprivate static void processSelectedKey(SelectionKey k, AbstractNioChannel ch) {\n    final NioUnsafe unsafe = ch.unsafe();\n\n    try {\n        int readyOps = k.readyOps();\n        // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead\n        // to a spin loop\n        if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {\n            // 如果是读事件或者连接的事件,则直接调用read方法\n            unsafe.read();\n            if (!ch.isOpen()) {\n                // Connection already closed - no need to handle write.\n                return;\n            }\n        }\n        if ((readyOps & SelectionKey.OP_WRITE) != 0) {\n            // 如果是写操作位, 则说明有半包消息没有写完, 需要继续\n            ch.unsafe().forceFlush();\n        }\n        if ((readyOps & SelectionKey.OP_CONNECT) != 0) {\n            // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking\n            // See https://github.com/netty/netty/issues/924\n            int ops = k.interestOps();\n            ops &= ~SelectionKey.OP_CONNECT;\n            k.interestOps(ops);\n\n            unsafe.finishConnect();\n        }\n    } catch (CancelledKeyException ignored) {\n        unsafe.close(unsafe.voidPromise());\n    }\n}\n```\n\n> 在unsafe的多态这我们要多说一些, 我们知道NioEventLoop内部处理的Channel其实是有俩种类型的, 一个是`NioServerScoketChannel`一个是`NioSocketChannel`.\n>\n> `NioServerSocketChannel`继承自`AbstractNioMessageChannel`, 而这个父类实现了一个`NioMessageUnsafe`的一个内部类, 这个内部类的`read()`方法会调用Channel里的`doReadMessage()`方法. 父类的`doReadMessage()`方法是由子类来具体实现的. 在`NioServerScoketChannel`中是生成了一个`NioSocketChannel`的列表作为消息返回, 然后再让`ServerBootstrapAcceptor`将`NioSocketChannel`绑定到从Reactor上.\n>\n> `NioSocketChannel`继承自`AbstractNioByteChannel`, 这个父类实现了一个`NioByteUnsafe`, 这个Unsafe就负责创建ByteBuf, 接受真正的网络数据了.\n","slug":"netty/NioEventLoop","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihxp008bvjs69gsl21kv"},{"date":"2016-02-21T16:00:00.000Z","title":"NettyServerBootstrap","_content":"我们首先给出一个Netty上的一个Example示例\n```java\npublic class NettyServer {\n    public static void main(String[] args) throws InterruptedException {\n        int cpuSize = Runtime.getRuntime().availableProcessors();\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize);\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .option(ChannelOption.SO_BACKLOG, 128)\n                    .option(ChannelOption.TCP_NODELAY, true)\n                    .option(ChannelOption.AUTO_READ, true)\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch) {\n                            ch.pipeline().addLast(new InHandler());\n                        }\n                    });\n\n            ChannelFuture f = b.bind(8881).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\nclass InHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ctx.write(msg);\n    }\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) {\n        ctx.flush();\n    }\n}\n```\n在这个示例中, 我们采用了主从Reactor线程模型, 然后将接受到的数据写回给客户端.\n\n下来我们分析一下`ServerBootstrap`的源码. 我们从`bind()`方法入手.\n\n由于`bind()`最终调用的是父类`AbstractBootstrap`的`doBind()`方法, 因此我们从父类入手\n```java\nprivate ChannelFuture doBind(final SocketAddress localAddress) {\n\t\t\t\t// 初始化NioServerSocketChannel, 并将其注册主Reactor线程池的IO多路复用器上\n        final ChannelFuture regFuture = initAndRegister();\n        final Channel channel = regFuture.channel();\n        if (regFuture.isDone()) {\n            ChannelPromise promise = channel.newPromise();\n            doBind0(regFuture, channel, localAddress, promise);\n            return promise;\n        } else {\n            ...\n            return promise;\n        }\n    }\n```\n\n接下来我们看一下`AbstractBootstrap#initAndRegister()`方法\n```java\nfinal ChannelFuture initAndRegister() {\n\t\t\t\t// 因为我们调用过channel(NioServerSocketChannel.class)方法, 因此下面这个Channel是NioServerSocketChannel类型\n        final Channel channel = channelFactory().newChannel();\n        try {\n\t\t\t\t\t  // init方法主要是对NioServerSocketChannel添加一个ServerBootstrapAcceptor的Handler(继承自ChannelInboundHandlerAdapter)\n            // 当channel接受到网络连接的时候, 会生成NioSocketChannel, 将NioSocketChannel与从Reactor进行绑定\n            init(channel);\n        } catch (Throwable t) {\n\n        }\n\n\t\t\t\t// 将Reactor模型中的主Reactor线程注册到NioServerSocketChannel的Unsafe对象里.\n\t\t\t\t// 此时就将NioServerSocketChannel与Reactor主线程关联起来了\n\t\t\t\tChannelFuture regFuture = group().register(channel);\n        if (regFuture.cause() != null) {\n            if (channel.isRegistered()) {\n                channel.close();\n            } else {\n                channel.unsafe().closeForcibly();\n            }\n        }\n    }\n```\n\n`init()`的`ServerBootstrap`实现的. 这个方法主要是在`NioServerSocketChannel`的pipeline里增加一个`ServerBootstrapAcceptor`handler.\n这个handler就是用于处理`NioMessageUnsafe#read()`方法调用`NioServerSocketChannel#doReadMessage()`方法后`List<NioSocketChannel>`的消息列表\n```java\n@Override\nvoid init(Channel channel) throws Exception {\n\t\t\t // 获取NioServerSocketChannel的Pipeline\n\t\t\t ChannelPipeline p = channel.pipeline();\n\t\t\t if (handler() != null) {\n\t\t\t\t\t p.addLast(handler());\n\t\t\t }\n\n\t\t\t final EventLoopGroup currentChildGroup = childGroup;\n\t\t\t final ChannelHandler currentChildHandler = childHandler;\n\t\t\t final Entry<ChannelOption<?>, Object>[] currentChildOptions;\n\t\t\t final Entry<AttributeKey<?>, Object>[] currentChildAttrs;\n\n\t\t\t p.addLast(new ChannelInitializer<Channel>() {\n\t\t\t\t\t @Override\n\t\t\t\t\t public void initChannel(Channel ch) throws Exception {\n\t\t\t\t\t\t \t // 这里主要是产生网络连接时将处理数据的channel与Reactor从线程关联起来\n\t\t\t\t\t\t\t ch.pipeline().addLast(new ServerBootstrapAcceptor(\n\t\t\t\t\t\t\t\t\t\t\t currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs));\n\t\t\t\t\t }\n\t\t\t });\n\t }\n```\n\n我们看到`ServerBootstrapAcceptor`也是实现自`ChannelInboundHandlerAdapter`, 因此它也是一个handler. 在`NioMessageUnsafe#read()`方法里会遍历\n`List<NioSocketChannel>`这个消息列表后触发`NioServerSocketChannel`的pipeline的`fireChannelRead()`方法, 接着就会触发`ServerBootstrapAcceptor#channelRead()`,\n```java\nprivate static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter {\n\n        private final EventLoopGroup childGroup;\n        private final ChannelHandler childHandler;\n        ServerBootstrapAcceptor(\n                EventLoopGroup childGroup, ChannelHandler childHandler) {\n            this.childGroup = childGroup;\n            this.childHandler = childHandler;\n        }\n\n        @Override\n        public void channelRead(ChannelHandlerContext ctx, Object msg) {\n            // msg实际是NioSocketChannel类型\n            final Channel child = (Channel) msg;\n            child.pipeline().addLast(childHandler);\n            try {\n\t\t\t\t\t\t\t  // 将处理数据的NioSocketChannel与主从Reactor模型中的从Reactor线程关联起来\n                childGroup.register(child).addListener(new ChannelFutureListener());\n            } catch (Throwable t) {\n            }\n        }\n    }\n```\n然后我们看一下`NioEventLoop`的`register()`方法过程. 这个方法调用其实最终调用的是\n```java\nSingleThreadEventLoop\n\n@Override\n\t public ChannelFuture register(final Channel channel, final ChannelPromise promise) {\n\t\t\t channel.unsafe().register(this, promise);\n\t\t\t return promise;\n\t }\n```\n然后后续调用到了`AbstractUnsafe`的`register()`方法\n```java\n@Override\n        public final void register(EventLoop eventLoop, final ChannelPromise promise) {\n              AbstractChannel.this.eventLoop = eventLoop;\n\n            if (eventLoop.inEventLoop()) {\n                register0(promise);\n            } else {\n                try {\n                    eventLoop.execute(new OneTimeTask() {\n                        @Override\n                        public void run() {\n                            register0(promise);\n                        }\n                    });\n                } catch (Throwable t) {\n                }\n            }\n        }\n\n\t\t\t\tprivate void register0(ChannelPromise promise) {\n            try {\n                doRegister();\n                pipeline.fireChannelRegistered();\n                // Only fire a channelActive if the channel has never been registered. This prevents firing\n                // multiple channel actives if the channel is deregistered and re-registered.\n                if (firstRegistration && isActive()) {\n                    pipeline.fireChannelActive();\n                }\n            } catch (Throwable t) {\n            }\n        }\n```\n接着调用`AbstractNioChannel`的`doRegister()`\n```java\nprotected void doRegister() throws Exception {\n        boolean selected = false;\n        for (;;) {\n            try {\n                selectionKey = javaChannel().register(eventLoop().selector, 0, this);\n                return;\n            } catch (CancelledKeyException e) {\n            }\n        }\n    }\n```\n最终我们看到了, 当前JDK里的Channel注册到了EventLoop的IO多路复用器上面\n\n看到这里之后, 我们再接着返回到`doBind()`方法继续看`doBind0()`方法\n```java\nprivate static void doBind0(\n            final ChannelFuture regFuture, final Channel channel,\n            final SocketAddress localAddress, final ChannelPromise promise) {\n\n        // This method is invoked before channelRegistered() is triggered.  Give user handlers a chance to set up\n        // the pipeline in its channelRegistered() implementation.\n        channel.eventLoop().execute(new Runnable() {\n            @Override\n            public void run() {\n                if (regFuture.isSuccess()) {\n                    channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n                } else {\n                    promise.setFailure(regFuture.cause());\n                }\n            }\n        });\n    }\n```\n我们看到当在bind的时候也是调用的channel的bind(), 真实的bind是在`AbstractChannel`里发生的\n```java\npublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n\t\treturn pipeline.bind(localAddress, promise);\n}\n```\n然后调用的是`DefaultChannelPipeline`的`bind()`方法\n```java\n@Override\n public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n\t\t return tail.bind(localAddress, promise);\n }\n```\n再具体的bind的话, 就要参考`DeaultChannelPipeline`的实现了\n\n最后我们总结一下\n1. 首先将NioServerSocketChannel与主Reactor线程池的Selector进行注册绑定\n2. 当NioServerSocketChannel接收到网络连接的时候(doReadMessage())会生成一个`NioSocketChannel`的消息列表\n3. 然后`ServerBootstrapAcceptor`负责将`NioSocketChannel`与从Reactor的Selector进行注册绑定\n4. 最后由从Reactor线程池中的Selector进行IO调度, 读写网络数据\n","source":"_posts/netty/ServerBootstrap.md","raw":"category: Netty\ndate: 2016-02-22\ntitle: NettyServerBootstrap\n---\n我们首先给出一个Netty上的一个Example示例\n```java\npublic class NettyServer {\n    public static void main(String[] args) throws InterruptedException {\n        int cpuSize = Runtime.getRuntime().availableProcessors();\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize);\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .option(ChannelOption.SO_BACKLOG, 128)\n                    .option(ChannelOption.TCP_NODELAY, true)\n                    .option(ChannelOption.AUTO_READ, true)\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch) {\n                            ch.pipeline().addLast(new InHandler());\n                        }\n                    });\n\n            ChannelFuture f = b.bind(8881).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\nclass InHandler extends ChannelInboundHandlerAdapter {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n        ctx.write(msg);\n    }\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) {\n        ctx.flush();\n    }\n}\n```\n在这个示例中, 我们采用了主从Reactor线程模型, 然后将接受到的数据写回给客户端.\n\n下来我们分析一下`ServerBootstrap`的源码. 我们从`bind()`方法入手.\n\n由于`bind()`最终调用的是父类`AbstractBootstrap`的`doBind()`方法, 因此我们从父类入手\n```java\nprivate ChannelFuture doBind(final SocketAddress localAddress) {\n\t\t\t\t// 初始化NioServerSocketChannel, 并将其注册主Reactor线程池的IO多路复用器上\n        final ChannelFuture regFuture = initAndRegister();\n        final Channel channel = regFuture.channel();\n        if (regFuture.isDone()) {\n            ChannelPromise promise = channel.newPromise();\n            doBind0(regFuture, channel, localAddress, promise);\n            return promise;\n        } else {\n            ...\n            return promise;\n        }\n    }\n```\n\n接下来我们看一下`AbstractBootstrap#initAndRegister()`方法\n```java\nfinal ChannelFuture initAndRegister() {\n\t\t\t\t// 因为我们调用过channel(NioServerSocketChannel.class)方法, 因此下面这个Channel是NioServerSocketChannel类型\n        final Channel channel = channelFactory().newChannel();\n        try {\n\t\t\t\t\t  // init方法主要是对NioServerSocketChannel添加一个ServerBootstrapAcceptor的Handler(继承自ChannelInboundHandlerAdapter)\n            // 当channel接受到网络连接的时候, 会生成NioSocketChannel, 将NioSocketChannel与从Reactor进行绑定\n            init(channel);\n        } catch (Throwable t) {\n\n        }\n\n\t\t\t\t// 将Reactor模型中的主Reactor线程注册到NioServerSocketChannel的Unsafe对象里.\n\t\t\t\t// 此时就将NioServerSocketChannel与Reactor主线程关联起来了\n\t\t\t\tChannelFuture regFuture = group().register(channel);\n        if (regFuture.cause() != null) {\n            if (channel.isRegistered()) {\n                channel.close();\n            } else {\n                channel.unsafe().closeForcibly();\n            }\n        }\n    }\n```\n\n`init()`的`ServerBootstrap`实现的. 这个方法主要是在`NioServerSocketChannel`的pipeline里增加一个`ServerBootstrapAcceptor`handler.\n这个handler就是用于处理`NioMessageUnsafe#read()`方法调用`NioServerSocketChannel#doReadMessage()`方法后`List<NioSocketChannel>`的消息列表\n```java\n@Override\nvoid init(Channel channel) throws Exception {\n\t\t\t // 获取NioServerSocketChannel的Pipeline\n\t\t\t ChannelPipeline p = channel.pipeline();\n\t\t\t if (handler() != null) {\n\t\t\t\t\t p.addLast(handler());\n\t\t\t }\n\n\t\t\t final EventLoopGroup currentChildGroup = childGroup;\n\t\t\t final ChannelHandler currentChildHandler = childHandler;\n\t\t\t final Entry<ChannelOption<?>, Object>[] currentChildOptions;\n\t\t\t final Entry<AttributeKey<?>, Object>[] currentChildAttrs;\n\n\t\t\t p.addLast(new ChannelInitializer<Channel>() {\n\t\t\t\t\t @Override\n\t\t\t\t\t public void initChannel(Channel ch) throws Exception {\n\t\t\t\t\t\t \t // 这里主要是产生网络连接时将处理数据的channel与Reactor从线程关联起来\n\t\t\t\t\t\t\t ch.pipeline().addLast(new ServerBootstrapAcceptor(\n\t\t\t\t\t\t\t\t\t\t\t currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs));\n\t\t\t\t\t }\n\t\t\t });\n\t }\n```\n\n我们看到`ServerBootstrapAcceptor`也是实现自`ChannelInboundHandlerAdapter`, 因此它也是一个handler. 在`NioMessageUnsafe#read()`方法里会遍历\n`List<NioSocketChannel>`这个消息列表后触发`NioServerSocketChannel`的pipeline的`fireChannelRead()`方法, 接着就会触发`ServerBootstrapAcceptor#channelRead()`,\n```java\nprivate static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter {\n\n        private final EventLoopGroup childGroup;\n        private final ChannelHandler childHandler;\n        ServerBootstrapAcceptor(\n                EventLoopGroup childGroup, ChannelHandler childHandler) {\n            this.childGroup = childGroup;\n            this.childHandler = childHandler;\n        }\n\n        @Override\n        public void channelRead(ChannelHandlerContext ctx, Object msg) {\n            // msg实际是NioSocketChannel类型\n            final Channel child = (Channel) msg;\n            child.pipeline().addLast(childHandler);\n            try {\n\t\t\t\t\t\t\t  // 将处理数据的NioSocketChannel与主从Reactor模型中的从Reactor线程关联起来\n                childGroup.register(child).addListener(new ChannelFutureListener());\n            } catch (Throwable t) {\n            }\n        }\n    }\n```\n然后我们看一下`NioEventLoop`的`register()`方法过程. 这个方法调用其实最终调用的是\n```java\nSingleThreadEventLoop\n\n@Override\n\t public ChannelFuture register(final Channel channel, final ChannelPromise promise) {\n\t\t\t channel.unsafe().register(this, promise);\n\t\t\t return promise;\n\t }\n```\n然后后续调用到了`AbstractUnsafe`的`register()`方法\n```java\n@Override\n        public final void register(EventLoop eventLoop, final ChannelPromise promise) {\n              AbstractChannel.this.eventLoop = eventLoop;\n\n            if (eventLoop.inEventLoop()) {\n                register0(promise);\n            } else {\n                try {\n                    eventLoop.execute(new OneTimeTask() {\n                        @Override\n                        public void run() {\n                            register0(promise);\n                        }\n                    });\n                } catch (Throwable t) {\n                }\n            }\n        }\n\n\t\t\t\tprivate void register0(ChannelPromise promise) {\n            try {\n                doRegister();\n                pipeline.fireChannelRegistered();\n                // Only fire a channelActive if the channel has never been registered. This prevents firing\n                // multiple channel actives if the channel is deregistered and re-registered.\n                if (firstRegistration && isActive()) {\n                    pipeline.fireChannelActive();\n                }\n            } catch (Throwable t) {\n            }\n        }\n```\n接着调用`AbstractNioChannel`的`doRegister()`\n```java\nprotected void doRegister() throws Exception {\n        boolean selected = false;\n        for (;;) {\n            try {\n                selectionKey = javaChannel().register(eventLoop().selector, 0, this);\n                return;\n            } catch (CancelledKeyException e) {\n            }\n        }\n    }\n```\n最终我们看到了, 当前JDK里的Channel注册到了EventLoop的IO多路复用器上面\n\n看到这里之后, 我们再接着返回到`doBind()`方法继续看`doBind0()`方法\n```java\nprivate static void doBind0(\n            final ChannelFuture regFuture, final Channel channel,\n            final SocketAddress localAddress, final ChannelPromise promise) {\n\n        // This method is invoked before channelRegistered() is triggered.  Give user handlers a chance to set up\n        // the pipeline in its channelRegistered() implementation.\n        channel.eventLoop().execute(new Runnable() {\n            @Override\n            public void run() {\n                if (regFuture.isSuccess()) {\n                    channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n                } else {\n                    promise.setFailure(regFuture.cause());\n                }\n            }\n        });\n    }\n```\n我们看到当在bind的时候也是调用的channel的bind(), 真实的bind是在`AbstractChannel`里发生的\n```java\npublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n\t\treturn pipeline.bind(localAddress, promise);\n}\n```\n然后调用的是`DefaultChannelPipeline`的`bind()`方法\n```java\n@Override\n public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {\n\t\t return tail.bind(localAddress, promise);\n }\n```\n再具体的bind的话, 就要参考`DeaultChannelPipeline`的实现了\n\n最后我们总结一下\n1. 首先将NioServerSocketChannel与主Reactor线程池的Selector进行注册绑定\n2. 当NioServerSocketChannel接收到网络连接的时候(doReadMessage())会生成一个`NioSocketChannel`的消息列表\n3. 然后`ServerBootstrapAcceptor`负责将`NioSocketChannel`与从Reactor的Selector进行注册绑定\n4. 最后由从Reactor线程池中的Selector进行IO调度, 读写网络数据\n","slug":"netty/ServerBootstrap","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihy4008dvjs6jaucu09w"},{"date":"2016-03-18T16:00:00.000Z","title":"Netty Unsafe","_content":"首先我们来看一下`Unsafe`的继承\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/unsafe.jpg)\n\n## Unsafe\n`Unsafe`是`Channel`的内部接口, 它定义了下面的相关功能\n\n* `localAddress()` : 获得本地绑定的`SocketAddress`对象\n* `remoteAddress()` : 返回与网络对等端绑定的地址`SocketAddress`\n* `register()` : 将`EventLoop`注册到`Channel`上, 一旦注册成功就返回`ChannelFuture`\n* `bind()` : 将`SocketAddress`绑定到`Channel`上.\n* `connect()` : `Channel`与对端的`SocketAddress`进行连接\n* `disconnect()` : `Channel`与网络对端断开连接\n* `close()` : 关闭`Channel`与网络对端的连接\n* `deregister()` : `Channel`与`EventLoop`解除注册关系\n* `beginRead()` : Schedules a read operation that fills the inbound buffer of the first {@link ChannelInboundHandler} in the {@link ChannelPipeline}.  If there's already a pending read operation, this method does nothing.\n* `write()` : 调度一个写操作\n* `flush()` : 通过`write()`将全部的写操作进行调用\n* `outboundBuffer()` : Returns the {@link ChannelOutboundBuffer} of the {@link Channel} where the pending write requests are stored.\n\n## AbstractUnsafe\n`AbstractUnsafe`是`AbstractChannel`的内部类, 主要是提供了对`AbstractChannel`的辅助功能, 它内部实现了N个, 这些方法最终都会调用`AbstractChannel`子类实现的`doXXX()`相关方法. 例如:\n* `register()` -> `doRegister()`(`AbstractNioChannel`实现), 调用完成之后调用pipline的`fireChannelRegistered()`和`fireChannelActive()`.\n* `bind()` -> `doBind()`\n* `disconnect()` -> `doDisconnect()`\n* `close()` -> `doClose()`\n* `deregister` -> `doDeregister()`(`AbstractNioChannel`实现)\n* `beginRead()` -> `doBeginRead()`(`AbstractNioChannel`实现)\n* `flush()` -> `doWrite()`\n\n需要仔细看一下的是`AbstractUnsafe`内部消息存储的一个环形数组`ChannelOutboundBuffer`成员\n```java\nprivate ChannelOutboundBuffer outboundBuffer = new ChannelOutboundBuffer(AbstractChannel.this);\n```\n下来我们看一下它的`write()`方法\n```java\n@Override\n        public final void write(Object msg, ChannelPromise promise) {\n            ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n            if (outboundBuffer == null) {\n                // outboundBuffer为空, 说明channel已经关闭了, 那么现在就需要立刻做快速失败处理\n                safeSetFailure(promise, CLOSED_CHANNEL_EXCEPTION);\n                // 将消息释放掉, 避免发生内存泄漏\n                ReferenceCountUtil.release(msg);\n                return;\n            }\n\n            int size;\n            try {\n                msg = filterOutboundMessage(msg);\n                size = estimatorHandle().size(msg);\n                if (size < 0) {\n                    size = 0;\n                }\n            } catch (Throwable t) {\n                safeSetFailure(promise, t);\n                ReferenceCountUtil.release(msg);\n                return;\n            }\n\n            // 我们看到, 在写消息的时候,最后就是将msg写到了一个环形数组里\n            outboundBuffer.addMessage(msg, size, promise);\n        }\n```\n将消息写到`outboundBuffer`之后, 最终我们还是需要调用`flush()`将其真正刷到TCP中\n```java\n@Override\n        public final void flush() {\n            ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n            outboundBuffer.addFlush();\n            flush0();\n        }\n\n        protected void flush0() {\n            final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n\n            try {\n                doWrite(outboundBuffer);\n            } catch (Throwable t) {\n\n            } finally {\n                inFlush0 = false;\n            }\n        }\n\n```\n我们看到最终的写到channel中也是由`doWrite()`方法实现的.\n\n## AbstractNioUnsafe\n`AbstractNioUnsafe`是`AbstactNioChannel`的内部类. 与`AbstractUnsafe`类似, 它也是提供了一些对Channel的代理调用\n* `connect()` -> `doConnect()`\n* `finishConnect()` -> `doFinishConnect()`\n\n## NioByteUnsafe\n我们重点看一下`read()`和`write()`方法\n\n我们首先看一下`read()`方法\n```java\n@Override\n        public void read() {\n            final ChannelConfig config = config();\n            if (!config.isAutoRead() && !isReadPending()) {\n                // ChannelConfig.setAutoRead(false) was called in the meantime\n                removeReadOp();\n                return;\n            }\n\n            final ChannelPipeline pipeline = pipeline();\n            final ByteBufAllocator allocator = config.getAllocator();\n            // 我们配置的每次读取数据最多读取的数据量\n            final int maxMessagesPerRead = config.getMaxMessagesPerRead();\n            RecvByteBufAllocator.Handle allocHandle = this.allocHandle;\n            if (allocHandle == null) {\n                this.allocHandle = allocHandle = config.getRecvByteBufAllocator().newHandle();\n            }\n\n            ByteBuf byteBuf = null;\n            int messages = 0;\n            boolean close = false;\n            try {\n                // 读取的总量\n                int totalReadAmount = 0;\n                //\n                boolean readPendingReset = false;\n                do {\n                    // 获取一个byteBuf对象, 用于这次读取数据, 具体的获取策略, 本文最后有介绍\n                    byteBuf = allocHandle.allocate(allocator);\n                    int writable = byteBuf.writableBytes();\n                    // 调用NioSocketChannel的doReadBytes()实现, 将数据读进byteBuf中\n                    int localReadAmount = doReadBytes(byteBuf);\n                    if (localReadAmount <= 0) {\n                        // 如果没有读到数据,则将ByteBuf释放掉\n                        byteBuf.release();\n                        close = localReadAmount < 0;\n                        break;\n                    }\n                    if (!readPendingReset) {\n                        readPendingReset = true;\n                        setReadPending(false);\n                    }\n                    // 开始在pipeline里进行ByteBuf数据传播\n                    pipeline.fireChannelRead(byteBuf);\n                    byteBuf = null;\n\n                    if (totalReadAmount >= Integer.MAX_VALUE - localReadAmount) {\n                        // Avoid overflow.\n                        totalReadAmount = Integer.MAX_VALUE;\n                        break;\n                    }\n\n                    // 统计所有的读到的数据\n                    totalReadAmount += localReadAmount;\n\n                    // stop reading\n                    if (!config.isAutoRead()) {\n                        break;\n                    }\n\n                    if (localReadAmount < writable) {\n                        // Read less than what the buffer can hold,\n                        // which might mean we drained the recv buffer completely.\n                        break;\n                    }\n                    // 如果仍然有未读数据的话, 则继续读取\n                } while (++ messages < maxMessagesPerRead);\n\n                // 当前所有数据都读取完了, 触发\n                pipeline.fireChannelReadComplete();\n                // 根据当前读到的字节数预测下个消息的字节数大小\n                allocHandle.record(totalReadAmount);\n\n                if (close) {\n                    closeOnRead(pipeline);\n                    close = false;\n                }\n            } catch (Throwable t) {\n                handleReadException(pipeline, byteBuf, t, close);\n            } finally {\n                // Check if there is a readPending which was not processed yet.\n                // This could be for two reasons:\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method\n                //\n                // See https://github.com/netty/netty/issues/2254\n                if (!config.isAutoRead() && !isReadPending()) {\n                    removeReadOp();\n                }\n            }\n        }\n    }\n```\n\n## NioMessageUnsafe\n`NioMessageUnsafe`是`AbstractNioMessageChannel`的内部类. 它的`read()`方法与`NioByteMessage`的类似, 只不过这个是用于\n服务`NioServerSocketChannel`的, 它内部的`doReadMessages()`会调用的`NioServerSocketChannel`的实现. `readBuf`每个`NioMessageUnsafe`对象都会生成一个\n```java\nprivate final List<Object> readBuf = new ArrayList<Object>();\n\n@Override\n        public void read() {\n            assert eventLoop().inEventLoop();\n            final ChannelConfig config = config();\n            if (!config.isAutoRead() && !isReadPending()) {\n                // ChannelConfig.setAutoRead(false) was called in the meantime\n                removeReadOp();\n                return;\n            }\n\n            // 从配置中获取每次读取消息的最大字节数\n            final int maxMessagesPerRead = config.getMaxMessagesPerRead();\n            final ChannelPipeline pipeline = pipeline();\n            boolean closed = false;\n            Throwable exception = null;\n            try {\n                try {\n                    for (;;) {\n                        // 从NioServerSocketChannel中读取NioSocketChannel进readBuf中\n                        int localRead = doReadMessages(readBuf);\n                        if (localRead == 0) {\n                          // 如果没有新的连接, 则不再读取\n                            break;\n                        }\n                        if (localRead < 0) {\n                            closed = true;\n                            break;\n                        }\n\n                        // stop reading and remove op\n                        if (!config.isAutoRead()) {\n                            break;\n                        }\n\n                        if (readBuf.size() >= maxMessagesPerRead) {\n                            break;\n                        }\n                    }\n                } catch (Throwable t) {\n                    exception = t;\n                }\n                setReadPending(false);\n                int size = readBuf.size();\n                for (int i = 0; i < size; i ++) {\n                    // 触发NioServerSocketChannel的pipeline的fireChannelRead()方法\n                    // 从而触发ServerBoostTrap的read方法, 将readBuf里的NioSocketChannel与从Reactor进行注册绑定\n                    pipeline.fireChannelRead(readBuf.get(i));\n                }\n\n                // 将所有的NioSocketChannel与从Reactor都完成注册之后, 将readBuf清空\n                readBuf.clear();\n                // 最后调用NioServerSocketChannel的fireChannelReadComplete\n                pipeline.fireChannelReadComplete();\n\n                if (exception != null) {\n                    if (exception instanceof IOException && !(exception instanceof PortUnreachableException)) {\n                        // ServerChannel should not be closed even on IOException because it can often continue\n                        // accepting incoming connections. (e.g. too many open files)\n                        closed = !(AbstractNioMessageChannel.this instanceof ServerChannel);\n                    }\n\n                    pipeline.fireExceptionCaught(exception);\n                }\n\n                if (closed) {\n                    if (isOpen()) {\n                        close(voidPromise());\n                    }\n                }\n            } finally {\n                // Check if there is a readPending which was not processed yet.\n                // This could be for two reasons:\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method\n                //\n                // See https://github.com/netty/netty/issues/2254\n                if (!config.isAutoRead() && !isReadPending()) {\n                    removeReadOp();\n                }\n            }\n        }\n    }\n```\n\n## AdaptiveRecvByteBufAllocator\n由于`RecvByteBufAllocator`只在Unsafe体系中用到了, 就不再单独拿个章节出来讲它, 在这里我们重点分析一个`AdaptiveRecvByteBufAllocator`\n\n我们首先看一下他的内部成员属性\n```java\nstatic final int DEFAULT_MINIMUM = 64;\nstatic final int DEFAULT_INITIAL = 1024;\nstatic final int DEFAULT_MAXIMUM = 65536;\n\nprivate static final int INDEX_INCREMENT = 4;\nprivate static final int INDEX_DECREMENT = 1;\n\nprivate static final int[] SIZE_TABLE;\n```\n* `DEFAULT_MINIMUM` : 默认的每个ByteBuf的最小值\n* `DEFAULT_INITIAL` : 默认的每个ByteBuf的初始值\n* `DEFAULT_MAXIMUM` : 默认的每个ByteBuf的最大值\n* `INDEX_INCREMENT` : 默认的每个ByteBuf的增大步进大小\n* `INDEX_DECREMENT` : 默认的每个ByteBuf的减小步进大小\n* `SIZE_TABLE` : 所有ByteBuf消息可能会用到的大小值\n\n然后我们看一下他的静态初始化\n```java\nstatic {\n        List<Integer> sizeTable = new ArrayList<Integer>();\n        // 当消息小于512的时候, 每次步进16字节, 也就是预测下个消息比当前消息仍然大16字节\n        for (int i = 16; i < 512; i += 16) {\n            sizeTable.add(i);\n        }\n\n        // 当消息大小大于512的时候, 则采取倍增的方式\n        for (int i = 512; i > 0; i <<= 1) {\n            sizeTable.add(i);\n        }\n\n        SIZE_TABLE = new int[sizeTable.size()];\n        for (int i = 0; i < SIZE_TABLE.length; i ++) {\n            SIZE_TABLE[i] = sizeTable.get(i);\n        }\n    }\n```\n下面我们看一下`getSizeTableIndex()`这个方法, 这个方法主要是根据入参然后推算出下一个消息的大小, 内部算法采用的是一个二分查找\n```java\nprivate static int getSizeTableIndex(final int size) {\n        // 遍历所有的SIZE_TABLE\n        for (int low = 0, high = SIZE_TABLE.length - 1;;) {\n            if (high < low) {\n                return low;\n            }\n            if (high == low) {\n                return high;\n            }\n\n            // 找到中间位置索引\n            int mid = low + high >>> 1;\n            int a = SIZE_TABLE[mid];\n            int b = SIZE_TABLE[mid + 1];\n            if (size > b) {\n                // size大于中间值则向前查找\n                low = mid + 1;\n            } else if (size < a) {\n                // size小于中间值则向后查找\n                high = mid - 1;\n            } else if (size == a) {\n                // 取a值\n                return mid;\n            } else {\n                // 取b值\n                return mid + 1;\n            }\n        }\n    }\n```\n但是真正的预测下一个消息的逻辑是放在了`AdaptiveRecvByteBufAllocator`的内部类`HandleImpl`中.\n我们重点看一下他的`record`方法\n```java\n@Override\n       public void record(int actualReadBytes) {\n           if (actualReadBytes <= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) {\n               // 判断当前可读字节是否小于当前字节数的前一个大小, 如果小于, 则判断是否需要缩小容量\n               if (decreaseNow) {\n                   // 如果需要的话, 则算出前一个索引位置进行缩小下个消息的ByteBuf的大小\n                   index = Math.max(index - INDEX_DECREMENT, minIndex);\n                   nextReceiveBufferSize = SIZE_TABLE[index];\n                   decreaseNow = false;\n               } else {\n                   decreaseNow = true;\n               }\n           } else if (actualReadBytes >= nextReceiveBufferSize) {\n               // 当前可读字节数大于下个可读字节数, 则对其下个ByteBuf进行扩容处理\n               index = Math.min(index + INDEX_INCREMENT, maxIndex);\n               nextReceiveBufferSize = SIZE_TABLE[index];\n               decreaseNow = false;\n           }\n       }\n```\n","source":"_posts/netty/Unsafe.md","raw":"category: Netty\ndate: 2016-03-19\ntitle: Netty Unsafe\n---\n首先我们来看一下`Unsafe`的继承\n![](https://raw.githubusercontent.com/ming15/blog-website/images/netty/unsafe.jpg)\n\n## Unsafe\n`Unsafe`是`Channel`的内部接口, 它定义了下面的相关功能\n\n* `localAddress()` : 获得本地绑定的`SocketAddress`对象\n* `remoteAddress()` : 返回与网络对等端绑定的地址`SocketAddress`\n* `register()` : 将`EventLoop`注册到`Channel`上, 一旦注册成功就返回`ChannelFuture`\n* `bind()` : 将`SocketAddress`绑定到`Channel`上.\n* `connect()` : `Channel`与对端的`SocketAddress`进行连接\n* `disconnect()` : `Channel`与网络对端断开连接\n* `close()` : 关闭`Channel`与网络对端的连接\n* `deregister()` : `Channel`与`EventLoop`解除注册关系\n* `beginRead()` : Schedules a read operation that fills the inbound buffer of the first {@link ChannelInboundHandler} in the {@link ChannelPipeline}.  If there's already a pending read operation, this method does nothing.\n* `write()` : 调度一个写操作\n* `flush()` : 通过`write()`将全部的写操作进行调用\n* `outboundBuffer()` : Returns the {@link ChannelOutboundBuffer} of the {@link Channel} where the pending write requests are stored.\n\n## AbstractUnsafe\n`AbstractUnsafe`是`AbstractChannel`的内部类, 主要是提供了对`AbstractChannel`的辅助功能, 它内部实现了N个, 这些方法最终都会调用`AbstractChannel`子类实现的`doXXX()`相关方法. 例如:\n* `register()` -> `doRegister()`(`AbstractNioChannel`实现), 调用完成之后调用pipline的`fireChannelRegistered()`和`fireChannelActive()`.\n* `bind()` -> `doBind()`\n* `disconnect()` -> `doDisconnect()`\n* `close()` -> `doClose()`\n* `deregister` -> `doDeregister()`(`AbstractNioChannel`实现)\n* `beginRead()` -> `doBeginRead()`(`AbstractNioChannel`实现)\n* `flush()` -> `doWrite()`\n\n需要仔细看一下的是`AbstractUnsafe`内部消息存储的一个环形数组`ChannelOutboundBuffer`成员\n```java\nprivate ChannelOutboundBuffer outboundBuffer = new ChannelOutboundBuffer(AbstractChannel.this);\n```\n下来我们看一下它的`write()`方法\n```java\n@Override\n        public final void write(Object msg, ChannelPromise promise) {\n            ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n            if (outboundBuffer == null) {\n                // outboundBuffer为空, 说明channel已经关闭了, 那么现在就需要立刻做快速失败处理\n                safeSetFailure(promise, CLOSED_CHANNEL_EXCEPTION);\n                // 将消息释放掉, 避免发生内存泄漏\n                ReferenceCountUtil.release(msg);\n                return;\n            }\n\n            int size;\n            try {\n                msg = filterOutboundMessage(msg);\n                size = estimatorHandle().size(msg);\n                if (size < 0) {\n                    size = 0;\n                }\n            } catch (Throwable t) {\n                safeSetFailure(promise, t);\n                ReferenceCountUtil.release(msg);\n                return;\n            }\n\n            // 我们看到, 在写消息的时候,最后就是将msg写到了一个环形数组里\n            outboundBuffer.addMessage(msg, size, promise);\n        }\n```\n将消息写到`outboundBuffer`之后, 最终我们还是需要调用`flush()`将其真正刷到TCP中\n```java\n@Override\n        public final void flush() {\n            ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n            outboundBuffer.addFlush();\n            flush0();\n        }\n\n        protected void flush0() {\n            final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n\n            try {\n                doWrite(outboundBuffer);\n            } catch (Throwable t) {\n\n            } finally {\n                inFlush0 = false;\n            }\n        }\n\n```\n我们看到最终的写到channel中也是由`doWrite()`方法实现的.\n\n## AbstractNioUnsafe\n`AbstractNioUnsafe`是`AbstactNioChannel`的内部类. 与`AbstractUnsafe`类似, 它也是提供了一些对Channel的代理调用\n* `connect()` -> `doConnect()`\n* `finishConnect()` -> `doFinishConnect()`\n\n## NioByteUnsafe\n我们重点看一下`read()`和`write()`方法\n\n我们首先看一下`read()`方法\n```java\n@Override\n        public void read() {\n            final ChannelConfig config = config();\n            if (!config.isAutoRead() && !isReadPending()) {\n                // ChannelConfig.setAutoRead(false) was called in the meantime\n                removeReadOp();\n                return;\n            }\n\n            final ChannelPipeline pipeline = pipeline();\n            final ByteBufAllocator allocator = config.getAllocator();\n            // 我们配置的每次读取数据最多读取的数据量\n            final int maxMessagesPerRead = config.getMaxMessagesPerRead();\n            RecvByteBufAllocator.Handle allocHandle = this.allocHandle;\n            if (allocHandle == null) {\n                this.allocHandle = allocHandle = config.getRecvByteBufAllocator().newHandle();\n            }\n\n            ByteBuf byteBuf = null;\n            int messages = 0;\n            boolean close = false;\n            try {\n                // 读取的总量\n                int totalReadAmount = 0;\n                //\n                boolean readPendingReset = false;\n                do {\n                    // 获取一个byteBuf对象, 用于这次读取数据, 具体的获取策略, 本文最后有介绍\n                    byteBuf = allocHandle.allocate(allocator);\n                    int writable = byteBuf.writableBytes();\n                    // 调用NioSocketChannel的doReadBytes()实现, 将数据读进byteBuf中\n                    int localReadAmount = doReadBytes(byteBuf);\n                    if (localReadAmount <= 0) {\n                        // 如果没有读到数据,则将ByteBuf释放掉\n                        byteBuf.release();\n                        close = localReadAmount < 0;\n                        break;\n                    }\n                    if (!readPendingReset) {\n                        readPendingReset = true;\n                        setReadPending(false);\n                    }\n                    // 开始在pipeline里进行ByteBuf数据传播\n                    pipeline.fireChannelRead(byteBuf);\n                    byteBuf = null;\n\n                    if (totalReadAmount >= Integer.MAX_VALUE - localReadAmount) {\n                        // Avoid overflow.\n                        totalReadAmount = Integer.MAX_VALUE;\n                        break;\n                    }\n\n                    // 统计所有的读到的数据\n                    totalReadAmount += localReadAmount;\n\n                    // stop reading\n                    if (!config.isAutoRead()) {\n                        break;\n                    }\n\n                    if (localReadAmount < writable) {\n                        // Read less than what the buffer can hold,\n                        // which might mean we drained the recv buffer completely.\n                        break;\n                    }\n                    // 如果仍然有未读数据的话, 则继续读取\n                } while (++ messages < maxMessagesPerRead);\n\n                // 当前所有数据都读取完了, 触发\n                pipeline.fireChannelReadComplete();\n                // 根据当前读到的字节数预测下个消息的字节数大小\n                allocHandle.record(totalReadAmount);\n\n                if (close) {\n                    closeOnRead(pipeline);\n                    close = false;\n                }\n            } catch (Throwable t) {\n                handleReadException(pipeline, byteBuf, t, close);\n            } finally {\n                // Check if there is a readPending which was not processed yet.\n                // This could be for two reasons:\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method\n                //\n                // See https://github.com/netty/netty/issues/2254\n                if (!config.isAutoRead() && !isReadPending()) {\n                    removeReadOp();\n                }\n            }\n        }\n    }\n```\n\n## NioMessageUnsafe\n`NioMessageUnsafe`是`AbstractNioMessageChannel`的内部类. 它的`read()`方法与`NioByteMessage`的类似, 只不过这个是用于\n服务`NioServerSocketChannel`的, 它内部的`doReadMessages()`会调用的`NioServerSocketChannel`的实现. `readBuf`每个`NioMessageUnsafe`对象都会生成一个\n```java\nprivate final List<Object> readBuf = new ArrayList<Object>();\n\n@Override\n        public void read() {\n            assert eventLoop().inEventLoop();\n            final ChannelConfig config = config();\n            if (!config.isAutoRead() && !isReadPending()) {\n                // ChannelConfig.setAutoRead(false) was called in the meantime\n                removeReadOp();\n                return;\n            }\n\n            // 从配置中获取每次读取消息的最大字节数\n            final int maxMessagesPerRead = config.getMaxMessagesPerRead();\n            final ChannelPipeline pipeline = pipeline();\n            boolean closed = false;\n            Throwable exception = null;\n            try {\n                try {\n                    for (;;) {\n                        // 从NioServerSocketChannel中读取NioSocketChannel进readBuf中\n                        int localRead = doReadMessages(readBuf);\n                        if (localRead == 0) {\n                          // 如果没有新的连接, 则不再读取\n                            break;\n                        }\n                        if (localRead < 0) {\n                            closed = true;\n                            break;\n                        }\n\n                        // stop reading and remove op\n                        if (!config.isAutoRead()) {\n                            break;\n                        }\n\n                        if (readBuf.size() >= maxMessagesPerRead) {\n                            break;\n                        }\n                    }\n                } catch (Throwable t) {\n                    exception = t;\n                }\n                setReadPending(false);\n                int size = readBuf.size();\n                for (int i = 0; i < size; i ++) {\n                    // 触发NioServerSocketChannel的pipeline的fireChannelRead()方法\n                    // 从而触发ServerBoostTrap的read方法, 将readBuf里的NioSocketChannel与从Reactor进行注册绑定\n                    pipeline.fireChannelRead(readBuf.get(i));\n                }\n\n                // 将所有的NioSocketChannel与从Reactor都完成注册之后, 将readBuf清空\n                readBuf.clear();\n                // 最后调用NioServerSocketChannel的fireChannelReadComplete\n                pipeline.fireChannelReadComplete();\n\n                if (exception != null) {\n                    if (exception instanceof IOException && !(exception instanceof PortUnreachableException)) {\n                        // ServerChannel should not be closed even on IOException because it can often continue\n                        // accepting incoming connections. (e.g. too many open files)\n                        closed = !(AbstractNioMessageChannel.this instanceof ServerChannel);\n                    }\n\n                    pipeline.fireExceptionCaught(exception);\n                }\n\n                if (closed) {\n                    if (isOpen()) {\n                        close(voidPromise());\n                    }\n                }\n            } finally {\n                // Check if there is a readPending which was not processed yet.\n                // This could be for two reasons:\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method\n                // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method\n                //\n                // See https://github.com/netty/netty/issues/2254\n                if (!config.isAutoRead() && !isReadPending()) {\n                    removeReadOp();\n                }\n            }\n        }\n    }\n```\n\n## AdaptiveRecvByteBufAllocator\n由于`RecvByteBufAllocator`只在Unsafe体系中用到了, 就不再单独拿个章节出来讲它, 在这里我们重点分析一个`AdaptiveRecvByteBufAllocator`\n\n我们首先看一下他的内部成员属性\n```java\nstatic final int DEFAULT_MINIMUM = 64;\nstatic final int DEFAULT_INITIAL = 1024;\nstatic final int DEFAULT_MAXIMUM = 65536;\n\nprivate static final int INDEX_INCREMENT = 4;\nprivate static final int INDEX_DECREMENT = 1;\n\nprivate static final int[] SIZE_TABLE;\n```\n* `DEFAULT_MINIMUM` : 默认的每个ByteBuf的最小值\n* `DEFAULT_INITIAL` : 默认的每个ByteBuf的初始值\n* `DEFAULT_MAXIMUM` : 默认的每个ByteBuf的最大值\n* `INDEX_INCREMENT` : 默认的每个ByteBuf的增大步进大小\n* `INDEX_DECREMENT` : 默认的每个ByteBuf的减小步进大小\n* `SIZE_TABLE` : 所有ByteBuf消息可能会用到的大小值\n\n然后我们看一下他的静态初始化\n```java\nstatic {\n        List<Integer> sizeTable = new ArrayList<Integer>();\n        // 当消息小于512的时候, 每次步进16字节, 也就是预测下个消息比当前消息仍然大16字节\n        for (int i = 16; i < 512; i += 16) {\n            sizeTable.add(i);\n        }\n\n        // 当消息大小大于512的时候, 则采取倍增的方式\n        for (int i = 512; i > 0; i <<= 1) {\n            sizeTable.add(i);\n        }\n\n        SIZE_TABLE = new int[sizeTable.size()];\n        for (int i = 0; i < SIZE_TABLE.length; i ++) {\n            SIZE_TABLE[i] = sizeTable.get(i);\n        }\n    }\n```\n下面我们看一下`getSizeTableIndex()`这个方法, 这个方法主要是根据入参然后推算出下一个消息的大小, 内部算法采用的是一个二分查找\n```java\nprivate static int getSizeTableIndex(final int size) {\n        // 遍历所有的SIZE_TABLE\n        for (int low = 0, high = SIZE_TABLE.length - 1;;) {\n            if (high < low) {\n                return low;\n            }\n            if (high == low) {\n                return high;\n            }\n\n            // 找到中间位置索引\n            int mid = low + high >>> 1;\n            int a = SIZE_TABLE[mid];\n            int b = SIZE_TABLE[mid + 1];\n            if (size > b) {\n                // size大于中间值则向前查找\n                low = mid + 1;\n            } else if (size < a) {\n                // size小于中间值则向后查找\n                high = mid - 1;\n            } else if (size == a) {\n                // 取a值\n                return mid;\n            } else {\n                // 取b值\n                return mid + 1;\n            }\n        }\n    }\n```\n但是真正的预测下一个消息的逻辑是放在了`AdaptiveRecvByteBufAllocator`的内部类`HandleImpl`中.\n我们重点看一下他的`record`方法\n```java\n@Override\n       public void record(int actualReadBytes) {\n           if (actualReadBytes <= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) {\n               // 判断当前可读字节是否小于当前字节数的前一个大小, 如果小于, 则判断是否需要缩小容量\n               if (decreaseNow) {\n                   // 如果需要的话, 则算出前一个索引位置进行缩小下个消息的ByteBuf的大小\n                   index = Math.max(index - INDEX_DECREMENT, minIndex);\n                   nextReceiveBufferSize = SIZE_TABLE[index];\n                   decreaseNow = false;\n               } else {\n                   decreaseNow = true;\n               }\n           } else if (actualReadBytes >= nextReceiveBufferSize) {\n               // 当前可读字节数大于下个可读字节数, 则对其下个ByteBuf进行扩容处理\n               index = Math.min(index + INDEX_INCREMENT, maxIndex);\n               nextReceiveBufferSize = SIZE_TABLE[index];\n               decreaseNow = false;\n           }\n       }\n```\n","slug":"netty/Unsafe","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihy9008gvjs67a2q1du5"},{"date":"2016-03-05T16:00:00.000Z","title":"Nginx安装与启动,关闭","_content":"## 安装\n在MAC上安装Nginx\n\n使用命令\n```shell\nbrew install nginx\n```\nhomebrew会自动为我们安装. 程序会安装在\n```shell\n/usr/local/Cellar/nginx/1.6.2\n```\nnginx的配置文件在\n```shell\ncd /usr/local/etc/nginx\n```\n\n> 一般通过Homebrew安装的程序都会放在`/usr/local/Cellar/`里, 而配置文件会存储在`/usr/local/etc/`里\n\n## 启动\n我们可以通过下面这个简单的命令直接启动\n```shell\n/usr/bin/nginx\n```\n或者使用一个经过配置化的参数启动\n```shell\n/usr/bin/nginx -t -c ~/mynginx.conf -g \"pid /var/run/nginx.pid; worker_processes 2;\"\n```\n\n## 关闭\n一般我们可以通过\n```shell\n/usr/bin/nginx -s stop\n```\n但是我们还可以通过想Nginx 主进程发送信号的方式来关闭它.\n```shell\nkill -QUIT $( cat /usr/local/nginx/logs/nginx.pid )\n```\n一般我们推荐第二种方式, 让Nginx自己去停掉所有的主从进程\n\nNginx还接受如下参数\n* TERM, INT\t: Quick shutdown\n* QUIT :\tGraceful shutdown\n* KILL :\tHalts a stubborn process\n* HUP : Configuration reload, Start the new worker processes with a new configuration, Gracefully shutdown the old worker processes\n* USR1 :\tReopen the log files\n* USR2 :\tUpgrade Executable on the fly\n* WINCH :\tGracefully shutdown the worker processes\n","source":"_posts/nginx/nginx安装与命令.md","raw":"category: Nginx\ndate: 2016-03-06\ntitle: Nginx安装与启动,关闭\n---\n## 安装\n在MAC上安装Nginx\n\n使用命令\n```shell\nbrew install nginx\n```\nhomebrew会自动为我们安装. 程序会安装在\n```shell\n/usr/local/Cellar/nginx/1.6.2\n```\nnginx的配置文件在\n```shell\ncd /usr/local/etc/nginx\n```\n\n> 一般通过Homebrew安装的程序都会放在`/usr/local/Cellar/`里, 而配置文件会存储在`/usr/local/etc/`里\n\n## 启动\n我们可以通过下面这个简单的命令直接启动\n```shell\n/usr/bin/nginx\n```\n或者使用一个经过配置化的参数启动\n```shell\n/usr/bin/nginx -t -c ~/mynginx.conf -g \"pid /var/run/nginx.pid; worker_processes 2;\"\n```\n\n## 关闭\n一般我们可以通过\n```shell\n/usr/bin/nginx -s stop\n```\n但是我们还可以通过想Nginx 主进程发送信号的方式来关闭它.\n```shell\nkill -QUIT $( cat /usr/local/nginx/logs/nginx.pid )\n```\n一般我们推荐第二种方式, 让Nginx自己去停掉所有的主从进程\n\nNginx还接受如下参数\n* TERM, INT\t: Quick shutdown\n* QUIT :\tGraceful shutdown\n* KILL :\tHalts a stubborn process\n* HUP : Configuration reload, Start the new worker processes with a new configuration, Gracefully shutdown the old worker processes\n* USR1 :\tReopen the log files\n* USR2 :\tUpgrade Executable on the fly\n* WINCH :\tGracefully shutdown the worker processes\n","slug":"nginx/nginx安装与命令","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihyd008ivjs6p0uvs9to"},{"date":"2016-04-22T16:00:00.000Z","title":"nginx web服务器","_content":"官方文档[](https://www.nginx.com/resources/admin-guide/nginx-web-server/)学习\n\n在Nginx中每个用来处理HTTP请求的virtual server都被称为`location`. `location`可以参与请求处理的整个过程. `location`可以代理一个请求或者直接返回一个文件. 不但如此, 在`location`中我们还可以修改URI访问路径, 这样我们就可以将该请求指向其他的`location`或者其他的virtual server. \n\n## Setting Up Virtual Servers\n\nNginx插件配置必须最少包含一个`server`指令(用于定义虚拟服务器-virtual server). 当Nginx插件处理一个请求时, 它首先会选择处理该请求的虚拟服务器. 一个虚拟服务器定义在`http`上下文里, 例如:\n```jaon\nhttp {\n    server {\n        # Server configuration\n    }\n}\n```\n在`http`上下文里可以定义多个`server`指令, 这样一来就可以实现多个虚拟服务器了.\n\n在`server`指令里通常包含一个`listen`指令, 通过`listen`指令来指定监听请求的IP地址和端口号(或者Unix domain socket and path). IPv4 和 IPv6 地址都可进行配置\n\n下面的例子展示了在IP地址`127.0.0.1`和端口`8080`上进行网络事件监听\n```json\nserver {\n    listen 127.0.0.1:8080;\n    # The rest of server configuration\n}\n```\n如果端口忽略不写的话, Nginx插件会使用标准端口. 还有如果IP地址忽略不填的话, Nginx插件会在所有的IP地址上进行网络事件监听. 如果没有配置`listen`指令的话, 在超级用户权限下, 标准端口是`80/tcp`, 默认端口`8000/tcp`.\n\n如果有多个`server`指令里配置的IP地址和端口匹配到请求, 那么Nginx插件会根据请求的`Host header`字段与`server_name`指令进行匹配. 我们可以将`server_name`指令配置成一个全名称的地址, 或者使用通配符, 正则表达式. 如果想要使用通配符的话, 可以在地址的开头或者结尾使用`*`.\n\n```json\nserver {\n    listen      80;\n    server_name example.org www.example.org;\n    ...\n}\n```\n\n如果有多个`server_name`指令匹配到`Host header`, Nginx插件会根据如下顺序进行匹配查找, 直到找到第一个.\n\n1. 名字完全符合\n2. 以`*`开始的, 最符合的名字, 例如`*.example.org`\n3. 以`*`结束的, 最符合的名字, 例如`mail.*`\n4. 第一个匹配正则表达式的\n\n如果请求中的`Host header`没有匹配到一个合适的server name, Nginx插件会将该消息路由到默认服上面去. 默认服是在`nginx.conf`文件里进行配置的. 我们也可以使用`default_server`参数在`listen`指令中进行显示设定.\n```json\nserver {\n    listen      80 default_server;\n    ...\n}\n```\n\n## Configuring Locations\n\nNginx插件可以根据请求的URI将请求派发到不同的代理上, 或者处理不同的文件. 这种功能是通过`server`指令里的`location`指令完成的.\n\n例如你可以定义三个`location`指令, 一个用来将请求派发到一个代理服务器, 一个用来将其他的请求派发到另外的一个代理服务器,最后的一个用来提供本地文件系统服务.\n\nNGINX Plus tests request URIs against the parameters of all location directives and applies the directives defined in the matching location. Inside each location block, it is usually possible (with a few exceptions) to place even more location directives to further refine the processing for specific groups of requests.\n\n> 注意, 在这篇教程中, location这个字指的是一个单独的`location`上下文.\n\n有俩种`location`指令参数\n* prefix strings : 请求的URI是以固定的字符串开头, 例如prefix strings是`/some/path/`, 那么`/some/path/document.html`就是这种类型的, 但是`/my-site/some/path`就不是.\n* regular expressions :\n\n```json\nlocation /some/path/ {\n    ...\n}\n```\n\n当使用表达式的时候, 如果使用`~`开头则表示要区分大小写. 如果以`~*`开头,则表示忽略大小写. 下面的例子是只要请求包含`.html`或者`.htm`这些字符串就都匹配\n```json\nlocation ~ \\.html? {\n    ...\n}\n```\n\nNginx插件进行location匹配时, 优先进行`prefix string`匹配, 如果`prefix string`匹配不到再进行正则匹配.\n\nHigher priority is given to regular expressions, unless the ^~ modifier is used. Among the prefix strings NGINX Plus selects the most specific one (that is, the longest and most complete string). The exact logic for selecting a location to process a request is given below:\n\n1. Test the URI against all prefix strings.\n2. The = (equals sign) modifier defines an exact match of the URI and a prefix string. If the exact match is found, the search stops.\n3. If the ^~ (caret-tilde) modifier prepends the longest matching prefix string, the regular expressions are not checked.\n4. Store the longest matching prefix string.\n5. Test the URI against regular expressions.\n6. Break on the first matching regular expression and use the corresponding location.\n7. If no regular expression matches, use the location corresponding to the stored prefix string.\n\n`=`的典型用例是请求`/`, 如果请求`/`是非常频繁的, 在`location`指令上设置`= /`可以大幅提升访问速度, 这是因为在路径搜索匹配时, 一旦匹配到就不再继续搜素匹配了, 节约了时间.\n```json\nlocation = / {\n    ...\n}\n```\n\n`location`上下文中可以包含多个指令, 用于说明如何处理一个请求, 例如是想提供静态文件服务还是想向一个代理服务器派发请求. 例如, 在下面的例子中, 第一个请求就是提供`/data`目录下的静态文件服务, 第二个请求就是向一个代理服务器`www.example.com`派发请求.\n```json\nserver {\n    location /images/ {\n        root /data;\n    }\n\n    location / {\n        proxy_pass http://www.example.com;\n    }\n}\n\n```\n* `root`指令用于指定提供静态文件服务的文件系统路径. 如果有一个请求`/images/example.png`, 那么nginx插件会在文件系统中进行如下搜索`/data/images/example.png`.\n* `proxy_pass`指令会将请求派发到代理服务器上. 在上面的例子中, 只要是请求不是以`/images/`开头的, 那么请求都会派发到那个代理服务器上.\n\n## Using Variables\n\n你可以在配置文件里使用变量, 以便Nginx插件可以根据不同的情况进行不同的处理. 变量在运行时进行计算, 然后将值传递给指令使用. 我们可以通过`$`来引用一个变量(例如`$time`).\n\n在Nginx里已经为我们提前定义好了一些变量, 例如[core HTTP](http://nginx.org/en/docs/http/ngx_http_core_module.html?&_ga=1.54594219.1025068217.1457188479#variables). 而且你也可以使用`set`, `map`, `geo`等指令自定义一些变量.\n\n## Returning Specific Status Codes\n\n在一些web站点中, 由于资源移除或者其他原因, 我们需要直接给前端返回一个错误码, 那么我们可以使用`return`指令来完成.\n```json\nlocation /wrong/url {\n    return 404;\n}\n```\n\n下面的例子中, 第一个参数是一个错误码. 第二个参数是一个可选参数(代表一个重连接的URL)\n```json\nlocation /permanently/moved/url {\n    return 301 http://www.example.com/moved/here;\n}\n```\n`return`指令既可以放在`location`指令里, 也可以放在`server`指令里\n\n## Rewriting URIs in Requests\n\n请求URI可以在被处理时通过`rewrite`指令被多次修改, `rewrite`指令包含一个可选参数和俩个必选参数.\n* 第一个参数(必填)是用来匹配请求的正则表达式.\n* 第二个参数(必填)是用来指向重连接所需要匹配的URI.(下面的例子中我们采用的是正则表达式进行匹配)\n* 第三个参数(选填)是用来标记是继续执行下一个重连接还是执行其他操作(例如返回一个错误码)\n```json\nlocation /users/ {\n    rewrite ^/users/(.*)$ /show?user=$1 break;\n}\n```\n\n在`server`或者`location`指令中可以包含多个`rewrite`指令. Nginx插件会根据`rewrite`指令出现的顺序依次执行.\n\nAfter NGINX processes a set of rewriting instructions, it selects a location context according to the new URI. If the selected location contains rewrite directives, they are executed in turn. If the URI matches any of those, a search for the new location starts after all defined rewrite directives are processed.\n\n\n\n下面的例子展示里`rewrite`和`return`指令混合使用的方式\n```json\nserver {\n    ...\n    rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n    rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra  last;\n    return  403;\n    ...\n}\n```\n\n上面的例子区分了俩组URI. `/download/some/media/file`的URI会被替换成`/download/some/mp3/file.mp3`. 由于这个`rewrite`指令后面跟里一个`last`标记, 因此下面的`rewrite`和`return`指令就不会再执行到了. 但是如果URI例如`/download/some/audio/file`并不符合第一个,那么Nginx插件会继续匹配到第二个, 当然第二个符合, 于是URI被替换成`/download/some/mp3/file.ra`. 如果前俩个都不符合的话, 那么就会返回`403`错误码.\n\n下面, 我们会介绍俩种终止URI`rewrite`执行的方式:\n* `last` – 这种方式只是会在当前的`server`或者`location`上下文中停止, 但是Nginx插件会对重写的URI继续在`location`里进行查找.\n* `break` – 它不会对新的URI在当前上下文中进行查找, 而是简单的终止掉整个过程.\n\n## Rewriting HTTP Responses\n\n有时候你可能需要重写或者替换HTTP响应中的内容, 或者将一个字符串替换为另一个. `sub_filter`指令可以实现类似于这种的需求. `sub_filter`支持变量以及链式替换, 以便实现更加复杂的重写功能.\n\n```json\nlocation / {\n    sub_filter      /blog/ /blog-staging/;\n    sub_filter_once off;\n}\n```\n\n另一个例子是将`http://`改变为`https://`, 而且将localhost地址改变为请求头中的主机名. `sub_filter_once`指令是告诉NGINX在`location`指令里可以开启多个`sub_filter`.\n```json\nlocation / {\n    sub_filter     'href=\"http://127.0.0.1:8080/'    'href=\"http://$host/';\n    sub_filter     'img src=\"http://127.0.0.1:8080/' 'img src=\"http://$host/';\n    sub_filter_once on;\n}\n```\n\n> 注意, 如果响应已经在一个`sub_filter`修改过里, 那么即使另一个`sub_filter`也匹配到了,但是不会再次修改.\n\n## Handling Errors\n\n使用`error_page`指令, 我们可以配置Nginx插件返回一个自定义的界面或者响应一个不同的错误码,甚至可以重定向到一个新的地址上面去. 在下面的例子中, `error_page`指令会在发生错误时返回一个指定的界面`/404.html`, 而不是像默认的返回一个404错误码.\n```json\nerror_page 404 /404.html;\n```\n\n> 注意, 这个指令并不是直接就返回了(`return`指令直接返回), 而是指定一种当错误发生时的一种处理方式.\n\n在下面的例子中, 当Nginx找不到文件时, 它会返回`301`错误码, 同时告诉客户端重定向到`http:/example.com/new/path.html`这个界面上.\n```json\nlocation /old/path.html {\n    error_page 404 =301 http:/example.com/new/path.html;\n}\n\n```\n\nThe following configuration is an example of passing a request to the back end when a file is not found. Because there is no status code specified after the equals sign in the error_page directive, the response to the client has the status code returned by the proxied server (not necessarily 404).\n\n```json\nserver {\n    ...\n    location /images/ {\n        # Set the root directory to search for the file\n        root /data/www;\n\n        # Disable logging of errors related to file existence\n        open_file_cache_errors off;\n\n        # Make an internal redirect if the file is not found\n        error_page 404 = /fetch$uri;\n    }\n\n    location /fetch/ {\n        proxy_pass http://backend/;\n    }\n}\n```\nThe error_page directive instructs NGINX Plus to make an internal redirect when a file is not found. The $uri variable in the final parameter to the error_page directive holds the URI of the current request, which gets passed in the redirect.\n\nFor example, if /images/some/file is not found, it is replaced with /fetch/images/some/file and a new search for a location starts. As a result, the request ends up in the second location context and is proxied to http://backend/.\n\nThe open_file_cache_errors directive prevents writing an error message if a file is not found. This is not necessary here since missing files are correctly handled.\n","source":"_posts/nginx/nginx web服务器.md","raw":"category: Nginx\ndate: 2016-04-23\ntitle: nginx web服务器\n---\n官方文档[](https://www.nginx.com/resources/admin-guide/nginx-web-server/)学习\n\n在Nginx中每个用来处理HTTP请求的virtual server都被称为`location`. `location`可以参与请求处理的整个过程. `location`可以代理一个请求或者直接返回一个文件. 不但如此, 在`location`中我们还可以修改URI访问路径, 这样我们就可以将该请求指向其他的`location`或者其他的virtual server. \n\n## Setting Up Virtual Servers\n\nNginx插件配置必须最少包含一个`server`指令(用于定义虚拟服务器-virtual server). 当Nginx插件处理一个请求时, 它首先会选择处理该请求的虚拟服务器. 一个虚拟服务器定义在`http`上下文里, 例如:\n```jaon\nhttp {\n    server {\n        # Server configuration\n    }\n}\n```\n在`http`上下文里可以定义多个`server`指令, 这样一来就可以实现多个虚拟服务器了.\n\n在`server`指令里通常包含一个`listen`指令, 通过`listen`指令来指定监听请求的IP地址和端口号(或者Unix domain socket and path). IPv4 和 IPv6 地址都可进行配置\n\n下面的例子展示了在IP地址`127.0.0.1`和端口`8080`上进行网络事件监听\n```json\nserver {\n    listen 127.0.0.1:8080;\n    # The rest of server configuration\n}\n```\n如果端口忽略不写的话, Nginx插件会使用标准端口. 还有如果IP地址忽略不填的话, Nginx插件会在所有的IP地址上进行网络事件监听. 如果没有配置`listen`指令的话, 在超级用户权限下, 标准端口是`80/tcp`, 默认端口`8000/tcp`.\n\n如果有多个`server`指令里配置的IP地址和端口匹配到请求, 那么Nginx插件会根据请求的`Host header`字段与`server_name`指令进行匹配. 我们可以将`server_name`指令配置成一个全名称的地址, 或者使用通配符, 正则表达式. 如果想要使用通配符的话, 可以在地址的开头或者结尾使用`*`.\n\n```json\nserver {\n    listen      80;\n    server_name example.org www.example.org;\n    ...\n}\n```\n\n如果有多个`server_name`指令匹配到`Host header`, Nginx插件会根据如下顺序进行匹配查找, 直到找到第一个.\n\n1. 名字完全符合\n2. 以`*`开始的, 最符合的名字, 例如`*.example.org`\n3. 以`*`结束的, 最符合的名字, 例如`mail.*`\n4. 第一个匹配正则表达式的\n\n如果请求中的`Host header`没有匹配到一个合适的server name, Nginx插件会将该消息路由到默认服上面去. 默认服是在`nginx.conf`文件里进行配置的. 我们也可以使用`default_server`参数在`listen`指令中进行显示设定.\n```json\nserver {\n    listen      80 default_server;\n    ...\n}\n```\n\n## Configuring Locations\n\nNginx插件可以根据请求的URI将请求派发到不同的代理上, 或者处理不同的文件. 这种功能是通过`server`指令里的`location`指令完成的.\n\n例如你可以定义三个`location`指令, 一个用来将请求派发到一个代理服务器, 一个用来将其他的请求派发到另外的一个代理服务器,最后的一个用来提供本地文件系统服务.\n\nNGINX Plus tests request URIs against the parameters of all location directives and applies the directives defined in the matching location. Inside each location block, it is usually possible (with a few exceptions) to place even more location directives to further refine the processing for specific groups of requests.\n\n> 注意, 在这篇教程中, location这个字指的是一个单独的`location`上下文.\n\n有俩种`location`指令参数\n* prefix strings : 请求的URI是以固定的字符串开头, 例如prefix strings是`/some/path/`, 那么`/some/path/document.html`就是这种类型的, 但是`/my-site/some/path`就不是.\n* regular expressions :\n\n```json\nlocation /some/path/ {\n    ...\n}\n```\n\n当使用表达式的时候, 如果使用`~`开头则表示要区分大小写. 如果以`~*`开头,则表示忽略大小写. 下面的例子是只要请求包含`.html`或者`.htm`这些字符串就都匹配\n```json\nlocation ~ \\.html? {\n    ...\n}\n```\n\nNginx插件进行location匹配时, 优先进行`prefix string`匹配, 如果`prefix string`匹配不到再进行正则匹配.\n\nHigher priority is given to regular expressions, unless the ^~ modifier is used. Among the prefix strings NGINX Plus selects the most specific one (that is, the longest and most complete string). The exact logic for selecting a location to process a request is given below:\n\n1. Test the URI against all prefix strings.\n2. The = (equals sign) modifier defines an exact match of the URI and a prefix string. If the exact match is found, the search stops.\n3. If the ^~ (caret-tilde) modifier prepends the longest matching prefix string, the regular expressions are not checked.\n4. Store the longest matching prefix string.\n5. Test the URI against regular expressions.\n6. Break on the first matching regular expression and use the corresponding location.\n7. If no regular expression matches, use the location corresponding to the stored prefix string.\n\n`=`的典型用例是请求`/`, 如果请求`/`是非常频繁的, 在`location`指令上设置`= /`可以大幅提升访问速度, 这是因为在路径搜索匹配时, 一旦匹配到就不再继续搜素匹配了, 节约了时间.\n```json\nlocation = / {\n    ...\n}\n```\n\n`location`上下文中可以包含多个指令, 用于说明如何处理一个请求, 例如是想提供静态文件服务还是想向一个代理服务器派发请求. 例如, 在下面的例子中, 第一个请求就是提供`/data`目录下的静态文件服务, 第二个请求就是向一个代理服务器`www.example.com`派发请求.\n```json\nserver {\n    location /images/ {\n        root /data;\n    }\n\n    location / {\n        proxy_pass http://www.example.com;\n    }\n}\n\n```\n* `root`指令用于指定提供静态文件服务的文件系统路径. 如果有一个请求`/images/example.png`, 那么nginx插件会在文件系统中进行如下搜索`/data/images/example.png`.\n* `proxy_pass`指令会将请求派发到代理服务器上. 在上面的例子中, 只要是请求不是以`/images/`开头的, 那么请求都会派发到那个代理服务器上.\n\n## Using Variables\n\n你可以在配置文件里使用变量, 以便Nginx插件可以根据不同的情况进行不同的处理. 变量在运行时进行计算, 然后将值传递给指令使用. 我们可以通过`$`来引用一个变量(例如`$time`).\n\n在Nginx里已经为我们提前定义好了一些变量, 例如[core HTTP](http://nginx.org/en/docs/http/ngx_http_core_module.html?&_ga=1.54594219.1025068217.1457188479#variables). 而且你也可以使用`set`, `map`, `geo`等指令自定义一些变量.\n\n## Returning Specific Status Codes\n\n在一些web站点中, 由于资源移除或者其他原因, 我们需要直接给前端返回一个错误码, 那么我们可以使用`return`指令来完成.\n```json\nlocation /wrong/url {\n    return 404;\n}\n```\n\n下面的例子中, 第一个参数是一个错误码. 第二个参数是一个可选参数(代表一个重连接的URL)\n```json\nlocation /permanently/moved/url {\n    return 301 http://www.example.com/moved/here;\n}\n```\n`return`指令既可以放在`location`指令里, 也可以放在`server`指令里\n\n## Rewriting URIs in Requests\n\n请求URI可以在被处理时通过`rewrite`指令被多次修改, `rewrite`指令包含一个可选参数和俩个必选参数.\n* 第一个参数(必填)是用来匹配请求的正则表达式.\n* 第二个参数(必填)是用来指向重连接所需要匹配的URI.(下面的例子中我们采用的是正则表达式进行匹配)\n* 第三个参数(选填)是用来标记是继续执行下一个重连接还是执行其他操作(例如返回一个错误码)\n```json\nlocation /users/ {\n    rewrite ^/users/(.*)$ /show?user=$1 break;\n}\n```\n\n在`server`或者`location`指令中可以包含多个`rewrite`指令. Nginx插件会根据`rewrite`指令出现的顺序依次执行.\n\nAfter NGINX processes a set of rewriting instructions, it selects a location context according to the new URI. If the selected location contains rewrite directives, they are executed in turn. If the URI matches any of those, a search for the new location starts after all defined rewrite directives are processed.\n\n\n\n下面的例子展示里`rewrite`和`return`指令混合使用的方式\n```json\nserver {\n    ...\n    rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n    rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra  last;\n    return  403;\n    ...\n}\n```\n\n上面的例子区分了俩组URI. `/download/some/media/file`的URI会被替换成`/download/some/mp3/file.mp3`. 由于这个`rewrite`指令后面跟里一个`last`标记, 因此下面的`rewrite`和`return`指令就不会再执行到了. 但是如果URI例如`/download/some/audio/file`并不符合第一个,那么Nginx插件会继续匹配到第二个, 当然第二个符合, 于是URI被替换成`/download/some/mp3/file.ra`. 如果前俩个都不符合的话, 那么就会返回`403`错误码.\n\n下面, 我们会介绍俩种终止URI`rewrite`执行的方式:\n* `last` – 这种方式只是会在当前的`server`或者`location`上下文中停止, 但是Nginx插件会对重写的URI继续在`location`里进行查找.\n* `break` – 它不会对新的URI在当前上下文中进行查找, 而是简单的终止掉整个过程.\n\n## Rewriting HTTP Responses\n\n有时候你可能需要重写或者替换HTTP响应中的内容, 或者将一个字符串替换为另一个. `sub_filter`指令可以实现类似于这种的需求. `sub_filter`支持变量以及链式替换, 以便实现更加复杂的重写功能.\n\n```json\nlocation / {\n    sub_filter      /blog/ /blog-staging/;\n    sub_filter_once off;\n}\n```\n\n另一个例子是将`http://`改变为`https://`, 而且将localhost地址改变为请求头中的主机名. `sub_filter_once`指令是告诉NGINX在`location`指令里可以开启多个`sub_filter`.\n```json\nlocation / {\n    sub_filter     'href=\"http://127.0.0.1:8080/'    'href=\"http://$host/';\n    sub_filter     'img src=\"http://127.0.0.1:8080/' 'img src=\"http://$host/';\n    sub_filter_once on;\n}\n```\n\n> 注意, 如果响应已经在一个`sub_filter`修改过里, 那么即使另一个`sub_filter`也匹配到了,但是不会再次修改.\n\n## Handling Errors\n\n使用`error_page`指令, 我们可以配置Nginx插件返回一个自定义的界面或者响应一个不同的错误码,甚至可以重定向到一个新的地址上面去. 在下面的例子中, `error_page`指令会在发生错误时返回一个指定的界面`/404.html`, 而不是像默认的返回一个404错误码.\n```json\nerror_page 404 /404.html;\n```\n\n> 注意, 这个指令并不是直接就返回了(`return`指令直接返回), 而是指定一种当错误发生时的一种处理方式.\n\n在下面的例子中, 当Nginx找不到文件时, 它会返回`301`错误码, 同时告诉客户端重定向到`http:/example.com/new/path.html`这个界面上.\n```json\nlocation /old/path.html {\n    error_page 404 =301 http:/example.com/new/path.html;\n}\n\n```\n\nThe following configuration is an example of passing a request to the back end when a file is not found. Because there is no status code specified after the equals sign in the error_page directive, the response to the client has the status code returned by the proxied server (not necessarily 404).\n\n```json\nserver {\n    ...\n    location /images/ {\n        # Set the root directory to search for the file\n        root /data/www;\n\n        # Disable logging of errors related to file existence\n        open_file_cache_errors off;\n\n        # Make an internal redirect if the file is not found\n        error_page 404 = /fetch$uri;\n    }\n\n    location /fetch/ {\n        proxy_pass http://backend/;\n    }\n}\n```\nThe error_page directive instructs NGINX Plus to make an internal redirect when a file is not found. The $uri variable in the final parameter to the error_page directive holds the URI of the current request, which gets passed in the redirect.\n\nFor example, if /images/some/file is not found, it is replaced with /fetch/images/some/file and a new search for a location starts. As a result, the request ends up in the second location context and is proxied to http://backend/.\n\nThe open_file_cache_errors directive prevents writing an error message if a file is not found. This is not necessary here since missing files are correctly handled.\n","slug":"nginx/nginx web服务器","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihyh008kvjs6qbpj6yr7"},{"date":"2016-03-05T16:00:00.000Z","title":"Nginx 静态资源服务","_content":"官方文档[](https://www.nginx.com/resources/admin-guide/serving-static-content/)学习\n## Root Directory and Index Files\n\nThe root directive specifies the root directory that will be used to search for a file. To obtain the path of a requested file, NGINX appends the request URI to the path specified by the root directive. The directive can be placed on any level within the http, server, or location contexts. In the example below, the root directive is defined for a virtual server. It applies to all location blocks where the root directive is not included to explicitly redefine the root:\n\nserver {\n    root /www/data;\n\n    location / {\n    }\n\n    location /images/ {\n    }\n\n    location ~ \\.(mp3|mp4) {\n        root /www/media;\n    }\n}\nHere, NGINX searches for a URI that starts with /images/ in the /www/data/images/ directory on the file system. But if the URI ends with the .mp3 or .mp4 extension, NGINX instead searches for the file in the /www/media/ directory because it is defined in the matching location block.\n\nIf a request ends with a slash, NGINX treats it as a request for a directory and tries to find an index file in the directory. The index directive defines the index file’s name (the default value is index.html). To continue with the example, if the request URI is /images/some/path/, NGINX delivers the file /www/data/images/some/path/index.html if it exists. If it does not, NGINX returns HTTP code 404 (Not found) by default. To configure NGINX to return an automatically generated directory listing instead, include the on parameter to the autoindex directive:\n\nlocation /images/ {\n    autoindex on;\n}\nYou can list more than one filename in the index directive. NGINX searches for files in the specified order and returns the first one it finds.\n\nlocation / {\n    index index.$geo.html index.htm index.html;\n}\nThe $geo variable used here here is a custom variable set through the geo directive. The value of the variable depends on the client’s IP address.\n\nTo return the index file, NGINX checks for its existence and then makes an internal redirect to the URI obtained by appending the name of the index file to the base URI. The internal redirect results in a new search of a location and can end up in another location as in the following example:\n\nlocation / {\n    root /data;\n    index index.html index.php;\n}\n\nlocation ~ \\.php {\n    fastcgi_pass localhost:8000;\n    ...\n}\nHere, if the URI in a request is /path/, and /data/path/index.html does not exist but /data/path/index.php does, the internal redirect to /path/index.php is mapped to the second location. As a result, the request is proxied.\n\n## Trying Several Options\n\nThe try_files directive can be used to check whether the specified file or directory exists and make an internal redirect, or return a specific status code if they don’t. For example, to check the existence of a file corresponding to the request URI, use the try_files directive and the $uri variable as follows:\n\nserver {\n    root /www/data;\n\n    location /images/ {\n        try_files $uri /images/default.gif;\n    }\n}\nThe file is specified in the form of the URI, which is processed using the root or alias directives set in the context of the current location or virtual server. In this case, if the file corresponding to the original URI doesn’t exist, NGINX makes an internal redirect to the URI specified in the last parameter, returning /www/data/images/default.gif.\n\nThe last parameter can also be a status code (directly preceded by the equals sign [=])< or the name of a location. In the following example, a 404 error is returned if none of the parameters to the try_files directive resolve to an existing file or directory.\n\nlocation / {\n    try_files $uri $uri/ $uri.html =404;\n}\nIn the next example, if neither the original URI nor the URI with the appended trailing slash resolve into an existing file or directory, the request is redirected to the named location which passes it to a proxied server.\n\nlocation / {\n    try_files $uri $uri/ @backend;\n}\n\nlocation @backend {\n    proxy_pass http://backend.example.com;\n}\nFor more information, watch the Content Caching on-demand webinar to learn how to dramatically improve the performance of a website, and get a deep-dive into NGINX’s caching capabilities.\n\n## Optimizing NGINX Speed for Serving Content\n\nLoading speed is a crucial factor of serving any content. Making minor optimizations to your NGINX configuration may boost the productivity and help reach optimal performance.\n\nEnabling sendfile\n\nBy default, NGINX handles file transmission itself and copies the file into the buffer before sending it. Enabling the sendfile directive will eliminate the step of copying the data into the buffer and enables direct copying data from one file descriptor to another. Alternatively, to prevent one fast connection to entirely occupy the worker process, you can limit the amount of data transferred in a single sendfile() call by defining the sendfile_max_chunk directive:\n\nlocation /mp3 {\n    sendfile           on;\n    sendfile_max_chunk 1m;\n    ...\n}\nEnabling tcp_nopush\n\nUse the tcp_nopush option together with sendfile on;. The option will enable NGINX to send HTTP response headers in one packet right after the chunk of data has been obtained by sendfile\n\nlocation /mp3 {\n    sendfile   on;\n    tcp_nopush on;\n    ...\n}\nEnabling tcp_nodelay\n\nThe tcp_nodelay option allows overriding the Nagle’s algorithm, originally designed to solve problems with small packets in slow networks. The algorithm consolidates a number of small packets into the larger one and sends the packet with the 200 ms delay. Nowadays, when serving large static files, the data can be sent immediately regardless of the packet size. The delay would also affect online applications (ssh, online games, online trading). By default, the tcp_nodelay directive is set to on which means that the Nagle’s algorithm is disabled. The option is used only for keepalive connections:\n\nlocation /mp3  {\n    tcp_nodelay       on;\n    keepalive_timeout 65;\n    ...\n}\nOptimizing the Backlog Queue\n\nOne of the important factors is how fast NGINX can handle incoming connections. The general rule is when a connection is established, it is put into the “listen” queue of a listen socket. Under normal load, there is either low queue, or there is no queue at all. But under high load, the queue may dramatically grow which may result in uneven performance, connections dropping, and latency.\n\nMeasuring the Listen Queue\n\nLet’s measure the current listen queue. Run the command:\n\nnetstat -Lan\nThe command output may be the following:\n\nCurrent listen queue sizes (qlen/incqlen/maxqlen)\nListen         Local Address         \n0/0/128        *.12345            \n10/0/128        *.80       \n0/0/128        *.8080\nThe command output shows that there are 10 unaccepted connections in the listen queue on Port 80, while the connection limit is 128 connections, and this situation is normal.\n\nHowever, the command output may be as follows:\n\nCurrent listen queue sizes (qlen/incqlen/maxqlen)\nListen         Local Address         \n0/0/128        *.12345            \n192/0/128        *.80       \n0/0/128        *.8080\nThe command output shows 192 unaccepted connections which exceeds the limit of 128 connections. This is quite common when a web site experience heavy traffic. To achieve optimal performance you will need to increase the maximum number of connections that can be queued for acceptance by NGINX in both your operating system and NGINX configuration.\n\nTuning the Operating System\n\nIncrease the value of the net.core.somaxconn key from its default value (128) to the value high enough to be able to handle a high burst of traffic:\n\nFor FreeBSD, run the command:\nsudo sysctl kern.ipc.somaxconn=4096\nFor Linux, run the command:\nsudo sysctl -w net.core.somaxconn=4096\nOpen the file: /etc/sysctl.conf\n\nvi   /etc/sysctl.conf\nAdd the line to the file and save the file:\n\nnet.core.somaxconn = 4096\nTuning NGINX\n\nIf you set the somaxconn key to a value greater than 512, change the backlog parameter of the NGINX listen directive to match:\n\nserver {\n    listen 80 backlog 4096;\n    # The rest of server configuration\n}\n","source":"_posts/nginx/nginx文件服务器.md","raw":"category: Nginx\ndate: 2016-03-06\ntitle: Nginx 静态资源服务\n---\n官方文档[](https://www.nginx.com/resources/admin-guide/serving-static-content/)学习\n## Root Directory and Index Files\n\nThe root directive specifies the root directory that will be used to search for a file. To obtain the path of a requested file, NGINX appends the request URI to the path specified by the root directive. The directive can be placed on any level within the http, server, or location contexts. In the example below, the root directive is defined for a virtual server. It applies to all location blocks where the root directive is not included to explicitly redefine the root:\n\nserver {\n    root /www/data;\n\n    location / {\n    }\n\n    location /images/ {\n    }\n\n    location ~ \\.(mp3|mp4) {\n        root /www/media;\n    }\n}\nHere, NGINX searches for a URI that starts with /images/ in the /www/data/images/ directory on the file system. But if the URI ends with the .mp3 or .mp4 extension, NGINX instead searches for the file in the /www/media/ directory because it is defined in the matching location block.\n\nIf a request ends with a slash, NGINX treats it as a request for a directory and tries to find an index file in the directory. The index directive defines the index file’s name (the default value is index.html). To continue with the example, if the request URI is /images/some/path/, NGINX delivers the file /www/data/images/some/path/index.html if it exists. If it does not, NGINX returns HTTP code 404 (Not found) by default. To configure NGINX to return an automatically generated directory listing instead, include the on parameter to the autoindex directive:\n\nlocation /images/ {\n    autoindex on;\n}\nYou can list more than one filename in the index directive. NGINX searches for files in the specified order and returns the first one it finds.\n\nlocation / {\n    index index.$geo.html index.htm index.html;\n}\nThe $geo variable used here here is a custom variable set through the geo directive. The value of the variable depends on the client’s IP address.\n\nTo return the index file, NGINX checks for its existence and then makes an internal redirect to the URI obtained by appending the name of the index file to the base URI. The internal redirect results in a new search of a location and can end up in another location as in the following example:\n\nlocation / {\n    root /data;\n    index index.html index.php;\n}\n\nlocation ~ \\.php {\n    fastcgi_pass localhost:8000;\n    ...\n}\nHere, if the URI in a request is /path/, and /data/path/index.html does not exist but /data/path/index.php does, the internal redirect to /path/index.php is mapped to the second location. As a result, the request is proxied.\n\n## Trying Several Options\n\nThe try_files directive can be used to check whether the specified file or directory exists and make an internal redirect, or return a specific status code if they don’t. For example, to check the existence of a file corresponding to the request URI, use the try_files directive and the $uri variable as follows:\n\nserver {\n    root /www/data;\n\n    location /images/ {\n        try_files $uri /images/default.gif;\n    }\n}\nThe file is specified in the form of the URI, which is processed using the root or alias directives set in the context of the current location or virtual server. In this case, if the file corresponding to the original URI doesn’t exist, NGINX makes an internal redirect to the URI specified in the last parameter, returning /www/data/images/default.gif.\n\nThe last parameter can also be a status code (directly preceded by the equals sign [=])< or the name of a location. In the following example, a 404 error is returned if none of the parameters to the try_files directive resolve to an existing file or directory.\n\nlocation / {\n    try_files $uri $uri/ $uri.html =404;\n}\nIn the next example, if neither the original URI nor the URI with the appended trailing slash resolve into an existing file or directory, the request is redirected to the named location which passes it to a proxied server.\n\nlocation / {\n    try_files $uri $uri/ @backend;\n}\n\nlocation @backend {\n    proxy_pass http://backend.example.com;\n}\nFor more information, watch the Content Caching on-demand webinar to learn how to dramatically improve the performance of a website, and get a deep-dive into NGINX’s caching capabilities.\n\n## Optimizing NGINX Speed for Serving Content\n\nLoading speed is a crucial factor of serving any content. Making minor optimizations to your NGINX configuration may boost the productivity and help reach optimal performance.\n\nEnabling sendfile\n\nBy default, NGINX handles file transmission itself and copies the file into the buffer before sending it. Enabling the sendfile directive will eliminate the step of copying the data into the buffer and enables direct copying data from one file descriptor to another. Alternatively, to prevent one fast connection to entirely occupy the worker process, you can limit the amount of data transferred in a single sendfile() call by defining the sendfile_max_chunk directive:\n\nlocation /mp3 {\n    sendfile           on;\n    sendfile_max_chunk 1m;\n    ...\n}\nEnabling tcp_nopush\n\nUse the tcp_nopush option together with sendfile on;. The option will enable NGINX to send HTTP response headers in one packet right after the chunk of data has been obtained by sendfile\n\nlocation /mp3 {\n    sendfile   on;\n    tcp_nopush on;\n    ...\n}\nEnabling tcp_nodelay\n\nThe tcp_nodelay option allows overriding the Nagle’s algorithm, originally designed to solve problems with small packets in slow networks. The algorithm consolidates a number of small packets into the larger one and sends the packet with the 200 ms delay. Nowadays, when serving large static files, the data can be sent immediately regardless of the packet size. The delay would also affect online applications (ssh, online games, online trading). By default, the tcp_nodelay directive is set to on which means that the Nagle’s algorithm is disabled. The option is used only for keepalive connections:\n\nlocation /mp3  {\n    tcp_nodelay       on;\n    keepalive_timeout 65;\n    ...\n}\nOptimizing the Backlog Queue\n\nOne of the important factors is how fast NGINX can handle incoming connections. The general rule is when a connection is established, it is put into the “listen” queue of a listen socket. Under normal load, there is either low queue, or there is no queue at all. But under high load, the queue may dramatically grow which may result in uneven performance, connections dropping, and latency.\n\nMeasuring the Listen Queue\n\nLet’s measure the current listen queue. Run the command:\n\nnetstat -Lan\nThe command output may be the following:\n\nCurrent listen queue sizes (qlen/incqlen/maxqlen)\nListen         Local Address         \n0/0/128        *.12345            \n10/0/128        *.80       \n0/0/128        *.8080\nThe command output shows that there are 10 unaccepted connections in the listen queue on Port 80, while the connection limit is 128 connections, and this situation is normal.\n\nHowever, the command output may be as follows:\n\nCurrent listen queue sizes (qlen/incqlen/maxqlen)\nListen         Local Address         \n0/0/128        *.12345            \n192/0/128        *.80       \n0/0/128        *.8080\nThe command output shows 192 unaccepted connections which exceeds the limit of 128 connections. This is quite common when a web site experience heavy traffic. To achieve optimal performance you will need to increase the maximum number of connections that can be queued for acceptance by NGINX in both your operating system and NGINX configuration.\n\nTuning the Operating System\n\nIncrease the value of the net.core.somaxconn key from its default value (128) to the value high enough to be able to handle a high burst of traffic:\n\nFor FreeBSD, run the command:\nsudo sysctl kern.ipc.somaxconn=4096\nFor Linux, run the command:\nsudo sysctl -w net.core.somaxconn=4096\nOpen the file: /etc/sysctl.conf\n\nvi   /etc/sysctl.conf\nAdd the line to the file and save the file:\n\nnet.core.somaxconn = 4096\nTuning NGINX\n\nIf you set the somaxconn key to a value greater than 512, change the backlog parameter of the NGINX listen directive to match:\n\nserver {\n    listen 80 backlog 4096;\n    # The rest of server configuration\n}\n","slug":"nginx/nginx文件服务器","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihyk008nvjs6xq18fovk"},{"date":"2016-03-05T16:00:00.000Z","title":"Nginx负载均衡实战","_content":"我们测试一次Nginx的负载均衡配置.\n\n首先我们使用python启动俩个HTTP服务器\n```python\nimport BaseHTTPServer\nimport urlparse\nimport sys\n\nport = sys.argv[1]\nclass WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"\n        \"\"\"\n        print port\n\nserver = BaseHTTPServer.HTTPServer(('0.0.0.0',int(sys.argv[1])), WebRequestHandler)\nserver.serve_forever()\n```\n然后在命令行分别启动\n```shell\npython ./PyHttpServer.py 8091\npython ./PyHttpServer.py 8092\n```\n\n然后我们配置nginx.conf文件\n```shell\n#user  nobody;\nworker_processes  1;\n\npid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n    upstream big_server_com {\n      server 127.0.0.1:8091 weight=5;\n      server 127.0.0.1:8092 weight=5;\n    }\n\n    server {\n        listen       8090;\n        server_name  localhost;\n\n        location / {\n            root   html;\n            index  index.html index.htm;\n            proxy_pass      http://big_server_com;\n\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n我们让nginx在8090端口上监听, 然后将其反向代理到`8091`和`8092`端口上.\n\n> 还有一点很重要的是, 要代理的服务必须在Nginx启动之前都启动完毕, 否则Nginx没办法完成代理工作.\n\n最后我们在浏览器上发送HTTP请求\n```shell\nhttp://localhost:8090\n```\n我们发现那俩个python的HTTP服务器果真都有输出了.\n\n但是我们发现, 就是那俩个服务器同时都有输出, 而不是应该只有其中一个有输出. 所以下来还需要研究一下如何配置Upstream, 看看如何让其真正实现负载均衡和单点失败\n","source":"_posts/nginx/nginx负载均衡.md","raw":"category: Nginx\ndate: 2016-03-06\ntitle: Nginx负载均衡实战\n---\n我们测试一次Nginx的负载均衡配置.\n\n首先我们使用python启动俩个HTTP服务器\n```python\nimport BaseHTTPServer\nimport urlparse\nimport sys\n\nport = sys.argv[1]\nclass WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"\n        \"\"\"\n        print port\n\nserver = BaseHTTPServer.HTTPServer(('0.0.0.0',int(sys.argv[1])), WebRequestHandler)\nserver.serve_forever()\n```\n然后在命令行分别启动\n```shell\npython ./PyHttpServer.py 8091\npython ./PyHttpServer.py 8092\n```\n\n然后我们配置nginx.conf文件\n```shell\n#user  nobody;\nworker_processes  1;\n\npid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n    upstream big_server_com {\n      server 127.0.0.1:8091 weight=5;\n      server 127.0.0.1:8092 weight=5;\n    }\n\n    server {\n        listen       8090;\n        server_name  localhost;\n\n        location / {\n            root   html;\n            index  index.html index.htm;\n            proxy_pass      http://big_server_com;\n\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n我们让nginx在8090端口上监听, 然后将其反向代理到`8091`和`8092`端口上.\n\n> 还有一点很重要的是, 要代理的服务必须在Nginx启动之前都启动完毕, 否则Nginx没办法完成代理工作.\n\n最后我们在浏览器上发送HTTP请求\n```shell\nhttp://localhost:8090\n```\n我们发现那俩个python的HTTP服务器果真都有输出了.\n\n但是我们发现, 就是那俩个服务器同时都有输出, 而不是应该只有其中一个有输出. 所以下来还需要研究一下如何配置Upstream, 看看如何让其真正实现负载均衡和单点失败\n","slug":"nginx/nginx负载均衡","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihyp008pvjs6ktsetlxq"},{"date":"2016-03-04T16:00:00.000Z","title":"Nginx配置大全","_content":"下面我们看一下Nginx官方给出的nginx.config可有的全部配置内容\n```shell\nuser       www www;  ## Default: nobody\n# 在Nginx启动的时候会启动一个Master进程,和N个worker进程,Master讲接收到的任务分配给worker进程执行. worker进程数一般与主机的CPU的核心数相等\nworker_processes  5;  ## Default: 1\n# 错误日志的输出位置. (TODO 错误日志指的是哪些?)\nerror_log  logs/error.log;\n# Nginx启动时的主进程ID\npid        logs/nginx.pid;\n# worker进程能打开的最多的文件数(TODO 在正式环境中Nginx都会打开什么文件? 指的是Socket连接吗?)\nworker_rlimit_nofile 8192;\n\n# events模块, 包含nginx中所有处理连接的设置\nevents {\n  # worker进程能打开的最大的连接数 (小于worker_rlimit_nofile数)\n  worker_connections  4096;  ## Default: 1024\n}\n\n# http模块, 用于处理http请求\nhttp {\n  # 引用mime.types配置, 主要是配置HTTP请求中的mineType类型\n  include    conf/mime.types;\n  # 引用nginx的代理配置. (TODO)\n  include    /etc/nginx/proxy.conf;\n  # 为nginx引用cgi配置\n  include    /etc/nginx/fastcgi.conf;\n  # 指定当HTTP请求没有任何请求路径时展示的界面.\n  index    index.html index.htm index.php;\n\n  #\n  default_type application/octet-stream;\n  # log输出格式\n  log_format   main '$remote_addr - $remote_user [$time_local]  $status '\n    '\"$request\" $body_bytes_sent \"$http_referer\" '\n    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n  # 访问nginx时, 记录的http请求的日志存储位置 (TODO  如何以时间分割文件?)\n  access_log   logs/access.log  main;\n  # sendfile并不是发送文件, 而是设置磁盘和TCP Socket传输数据时直接通过系统缓存实现, 不再经过用户区的Read, write操作\n  sendfile     on;\n  # 设置在发送HTTP头文件时一次性全部发送, 而不是一个接一个的发送. (TODO)\n  tcp_nopush   on;\n  # TODO\n  server_names_hash_bucket_size 128; # this seems to be required for some vhosts\n\n  # 开启一个网络监听服务\n  server { # php/fastcgi\n    # 该server监听的端口\n    listen       80;\n    # 绑定到的域名地址, 一般我们在主机都是使用localhost\n    server_name  domain1.com www.domain1.com;\n    # 该server生成的日志的保存地址\n    access_log   logs/domain1.access.log  main;\n    # 指定http请求中主机资源起始位置, 也就是`http://localhost:8090/`后面的位置\n    root         html;\n\n    # 所有请求以.php结尾的文件都到下面的代理地址中进行代理请求\n    location ~ \\.php$ {\n      fastcgi_pass   127.0.0.1:1025;\n    }\n  }\n\n  # 再设置一个网络服务\n  server { # simple reverse-proxy\n    listen       80;\n    server_name  domain2.com www.domain2.com;\n    access_log   logs/domain2.access.log  main;\n\n    # serve static files\n    location ~ ^/(images|javascript|js|css|flash|media|static)/  {\n      root    /var/www/virtual/big.server.com/htdocs;\n      expires 30d;\n    }\n\n    # 反向代理设置, 将/下所有的请求进行转发\n    location / {\n      #设置反向代理的地址, 將80端口接受到的请求转发到localhost的8080端口上\n      proxy_pass      http://127.0.0.1:8080;\n    }\n  }\n\n  # 设置反向代理\n  upstream big_server_com {\n    # 按照权重将代理过来的请求代理到俩个代理服务器上\n    server 127.0.0.3:8000 weight=5;\n    server 127.0.0.3:8001 weight=5;\n    server 192.168.0.1:8000;\n    server 192.168.0.1:8001;\n  }\n\n  server { # simple load balancing\n    listen          80;\n    server_name     big.server.com;\n    access_log      logs/big.server.access.log main;\n\n    location / {\n      # 设置反向代理, 代理到big_server_com上(upstream刚刚定义的)\n      proxy_pass      http://big_server_com;\n    }\n  }\n}\n```\n上面谈到的location涉及到的内容较多, 我们单独介绍一下:\n\nnginx location语法\n```shell\nlocation [=|~|~*|^~] /uri/ { … }\n```\n* `=` 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。\n* `~` 为区分大小写匹配(可用正则表达式)\n* `~*` 为不区分大小写匹配(可用正则表达式)\n* `!~` 区分大小写不匹配\n* `!~*` 不区分大小写不匹配\n* `^~` 如果路径匹配那么不测试正则表达式。\n\n\n\n上面的配置引用里其他的配置文件,而且很多配置没有配置选项,下面是Nginx官网给出的另一种配置\n```shell\nuser  www www;\nworker_processes  2;\npid /var/run/nginx.pid;\n\n# [ debug | info | notice | warn | error | crit ]\nerror_log  /var/log/nginx.error_log  info;\n\nevents {\n  worker_connections   2000;\n  # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n  use kqueue;\n}\n\nhttp {\n  include       conf/mime.types;\n  default_type  application/octet-stream;\n\n  log_format main      '$remote_addr - $remote_user [$time_local]  '\n    '\"$request\" $status $bytes_sent '\n    '\"$http_referer\" \"$http_user_agent\" '\n    '\"$gzip_ratio\"';\n\n  log_format download  '$remote_addr - $remote_user [$time_local]  '\n    '\"$request\" $status $bytes_sent '\n    '\"$http_referer\" \"$http_user_agent\" '\n    '\"$http_range\" \"$sent_http_content_range\"';\n\n  # HTTP请求,客户端相关设置\n  client_header_timeout  3m;\n  client_body_timeout    3m;\n  send_timeout           3m;\n\n  client_header_buffer_size    1k;\n  large_client_header_buffers  4 4k;\n\n  # 消息发送时开启gzip设置\n  gzip on;\n  gzip_min_length  1100;\n  gzip_buffers     4 8k;\n  gzip_types       text/plain;\n\n  output_buffers   1 32k;\n  postpone_output  1460;\n\n  sendfile         on;\n  tcp_nopush       on;\n\n  tcp_nodelay      on;\n  send_lowat       12000;\n\n  keepalive_timeout  75 20;\n\n  # lingering_time     30;\n  # lingering_timeout  10;\n  # reset_timedout_connection  on;\n\n\n  server {\n    listen        one.example.com;\n    server_name   one.example.com  www.one.example.com;\n\n    access_log   /var/log/nginx.access_log  main;\n\n    location / {\n      proxy_pass         http://127.0.0.1/;\n      proxy_redirect     off;\n\n      proxy_set_header   Host             $host;\n      proxy_set_header   X-Real-IP        $remote_addr;\n      # proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n      client_max_body_size       10m;\n      client_body_buffer_size    128k;\n\n      client_body_temp_path      /var/nginx/client_body_temp;\n\n      proxy_connect_timeout      90;\n      proxy_send_timeout         90;\n      proxy_read_timeout         90;\n      proxy_send_lowat           12000;\n\n      proxy_buffer_size          4k;\n      proxy_buffers              4 32k;\n      proxy_busy_buffers_size    64k;\n      proxy_temp_file_write_size 64k;\n\n      proxy_temp_path            /var/nginx/proxy_temp;\n\n      charset  koi8-r;\n    }\n\n    error_page  404  /404.html;\n\n    location /404.html {\n      root  /spool/www;\n\n      charset         on;\n      source_charset  koi8-r;\n    }\n\n    location /old_stuff/ {\n      rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n    }\n\n    location /download/ {\n      valid_referers  none  blocked  server_names  *.example.com;\n\n      if ($invalid_referer) {\n        #rewrite   ^/   http://www.example.com/;\n        return   403;\n      }\n\n      # rewrite_log  on;\n      # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n      rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break;\n\n      root         /spool/www;\n      # autoindex    on;\n      access_log   /var/log/nginx-download.access_log  download;\n    }\n\n    location ~* ^.+\\.(jpg|jpeg|gif)$ {\n      root         /spool/www;\n      access_log   off;\n      expires      30d;\n    }\n  }\n}\n```\n","source":"_posts/nginx/nginx配置.md","raw":"category: Nginx\ndate: 2016-03-05\ntitle: Nginx配置大全\n---\n下面我们看一下Nginx官方给出的nginx.config可有的全部配置内容\n```shell\nuser       www www;  ## Default: nobody\n# 在Nginx启动的时候会启动一个Master进程,和N个worker进程,Master讲接收到的任务分配给worker进程执行. worker进程数一般与主机的CPU的核心数相等\nworker_processes  5;  ## Default: 1\n# 错误日志的输出位置. (TODO 错误日志指的是哪些?)\nerror_log  logs/error.log;\n# Nginx启动时的主进程ID\npid        logs/nginx.pid;\n# worker进程能打开的最多的文件数(TODO 在正式环境中Nginx都会打开什么文件? 指的是Socket连接吗?)\nworker_rlimit_nofile 8192;\n\n# events模块, 包含nginx中所有处理连接的设置\nevents {\n  # worker进程能打开的最大的连接数 (小于worker_rlimit_nofile数)\n  worker_connections  4096;  ## Default: 1024\n}\n\n# http模块, 用于处理http请求\nhttp {\n  # 引用mime.types配置, 主要是配置HTTP请求中的mineType类型\n  include    conf/mime.types;\n  # 引用nginx的代理配置. (TODO)\n  include    /etc/nginx/proxy.conf;\n  # 为nginx引用cgi配置\n  include    /etc/nginx/fastcgi.conf;\n  # 指定当HTTP请求没有任何请求路径时展示的界面.\n  index    index.html index.htm index.php;\n\n  #\n  default_type application/octet-stream;\n  # log输出格式\n  log_format   main '$remote_addr - $remote_user [$time_local]  $status '\n    '\"$request\" $body_bytes_sent \"$http_referer\" '\n    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n  # 访问nginx时, 记录的http请求的日志存储位置 (TODO  如何以时间分割文件?)\n  access_log   logs/access.log  main;\n  # sendfile并不是发送文件, 而是设置磁盘和TCP Socket传输数据时直接通过系统缓存实现, 不再经过用户区的Read, write操作\n  sendfile     on;\n  # 设置在发送HTTP头文件时一次性全部发送, 而不是一个接一个的发送. (TODO)\n  tcp_nopush   on;\n  # TODO\n  server_names_hash_bucket_size 128; # this seems to be required for some vhosts\n\n  # 开启一个网络监听服务\n  server { # php/fastcgi\n    # 该server监听的端口\n    listen       80;\n    # 绑定到的域名地址, 一般我们在主机都是使用localhost\n    server_name  domain1.com www.domain1.com;\n    # 该server生成的日志的保存地址\n    access_log   logs/domain1.access.log  main;\n    # 指定http请求中主机资源起始位置, 也就是`http://localhost:8090/`后面的位置\n    root         html;\n\n    # 所有请求以.php结尾的文件都到下面的代理地址中进行代理请求\n    location ~ \\.php$ {\n      fastcgi_pass   127.0.0.1:1025;\n    }\n  }\n\n  # 再设置一个网络服务\n  server { # simple reverse-proxy\n    listen       80;\n    server_name  domain2.com www.domain2.com;\n    access_log   logs/domain2.access.log  main;\n\n    # serve static files\n    location ~ ^/(images|javascript|js|css|flash|media|static)/  {\n      root    /var/www/virtual/big.server.com/htdocs;\n      expires 30d;\n    }\n\n    # 反向代理设置, 将/下所有的请求进行转发\n    location / {\n      #设置反向代理的地址, 將80端口接受到的请求转发到localhost的8080端口上\n      proxy_pass      http://127.0.0.1:8080;\n    }\n  }\n\n  # 设置反向代理\n  upstream big_server_com {\n    # 按照权重将代理过来的请求代理到俩个代理服务器上\n    server 127.0.0.3:8000 weight=5;\n    server 127.0.0.3:8001 weight=5;\n    server 192.168.0.1:8000;\n    server 192.168.0.1:8001;\n  }\n\n  server { # simple load balancing\n    listen          80;\n    server_name     big.server.com;\n    access_log      logs/big.server.access.log main;\n\n    location / {\n      # 设置反向代理, 代理到big_server_com上(upstream刚刚定义的)\n      proxy_pass      http://big_server_com;\n    }\n  }\n}\n```\n上面谈到的location涉及到的内容较多, 我们单独介绍一下:\n\nnginx location语法\n```shell\nlocation [=|~|~*|^~] /uri/ { … }\n```\n* `=` 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。\n* `~` 为区分大小写匹配(可用正则表达式)\n* `~*` 为不区分大小写匹配(可用正则表达式)\n* `!~` 区分大小写不匹配\n* `!~*` 不区分大小写不匹配\n* `^~` 如果路径匹配那么不测试正则表达式。\n\n\n\n上面的配置引用里其他的配置文件,而且很多配置没有配置选项,下面是Nginx官网给出的另一种配置\n```shell\nuser  www www;\nworker_processes  2;\npid /var/run/nginx.pid;\n\n# [ debug | info | notice | warn | error | crit ]\nerror_log  /var/log/nginx.error_log  info;\n\nevents {\n  worker_connections   2000;\n  # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n  use kqueue;\n}\n\nhttp {\n  include       conf/mime.types;\n  default_type  application/octet-stream;\n\n  log_format main      '$remote_addr - $remote_user [$time_local]  '\n    '\"$request\" $status $bytes_sent '\n    '\"$http_referer\" \"$http_user_agent\" '\n    '\"$gzip_ratio\"';\n\n  log_format download  '$remote_addr - $remote_user [$time_local]  '\n    '\"$request\" $status $bytes_sent '\n    '\"$http_referer\" \"$http_user_agent\" '\n    '\"$http_range\" \"$sent_http_content_range\"';\n\n  # HTTP请求,客户端相关设置\n  client_header_timeout  3m;\n  client_body_timeout    3m;\n  send_timeout           3m;\n\n  client_header_buffer_size    1k;\n  large_client_header_buffers  4 4k;\n\n  # 消息发送时开启gzip设置\n  gzip on;\n  gzip_min_length  1100;\n  gzip_buffers     4 8k;\n  gzip_types       text/plain;\n\n  output_buffers   1 32k;\n  postpone_output  1460;\n\n  sendfile         on;\n  tcp_nopush       on;\n\n  tcp_nodelay      on;\n  send_lowat       12000;\n\n  keepalive_timeout  75 20;\n\n  # lingering_time     30;\n  # lingering_timeout  10;\n  # reset_timedout_connection  on;\n\n\n  server {\n    listen        one.example.com;\n    server_name   one.example.com  www.one.example.com;\n\n    access_log   /var/log/nginx.access_log  main;\n\n    location / {\n      proxy_pass         http://127.0.0.1/;\n      proxy_redirect     off;\n\n      proxy_set_header   Host             $host;\n      proxy_set_header   X-Real-IP        $remote_addr;\n      # proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n      client_max_body_size       10m;\n      client_body_buffer_size    128k;\n\n      client_body_temp_path      /var/nginx/client_body_temp;\n\n      proxy_connect_timeout      90;\n      proxy_send_timeout         90;\n      proxy_read_timeout         90;\n      proxy_send_lowat           12000;\n\n      proxy_buffer_size          4k;\n      proxy_buffers              4 32k;\n      proxy_busy_buffers_size    64k;\n      proxy_temp_file_write_size 64k;\n\n      proxy_temp_path            /var/nginx/proxy_temp;\n\n      charset  koi8-r;\n    }\n\n    error_page  404  /404.html;\n\n    location /404.html {\n      root  /spool/www;\n\n      charset         on;\n      source_charset  koi8-r;\n    }\n\n    location /old_stuff/ {\n      rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n    }\n\n    location /download/ {\n      valid_referers  none  blocked  server_names  *.example.com;\n\n      if ($invalid_referer) {\n        #rewrite   ^/   http://www.example.com/;\n        return   403;\n      }\n\n      # rewrite_log  on;\n      # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n      rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break;\n\n      root         /spool/www;\n      # autoindex    on;\n      access_log   /var/log/nginx-download.access_log  download;\n    }\n\n    location ~* ^.+\\.(jpg|jpeg|gif)$ {\n      root         /spool/www;\n      access_log   off;\n      expires      30d;\n    }\n  }\n}\n```\n","slug":"nginx/nginx配置","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihys008rvjs6tc19nizp"},{"date":"2015-03-07T16:00:00.000Z","title":"MongoDB Replica","_content":"# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n### Start each member of the replica set with the appropriate options.\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```shell\nmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```shell\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样.\n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n### Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```shell\nmongo\n```\n\n### Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```shell\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n### Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```shell\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n### Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```shell\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n### Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```shell\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n","source":"_posts/nosql/MongoDB Replica.md","raw":"category: NoSql\ndate: 2015-03-08\ntitle: MongoDB Replica\n---\n# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n### Start each member of the replica set with the appropriate options.\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```shell\nmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```shell\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样.\n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n### Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```shell\nmongo\n```\n\n### Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```shell\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n### Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```shell\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n### Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```shell\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n### Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```shell\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n","slug":"nosql/MongoDB Replica","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihyx008uvjs6w87lf6jz"},{"date":"2015-11-17T16:00:00.000Z","title":"memcached","_content":"## 原理\nmemcached是一个高性能内存对象缓存系统. 它基于libevent,可方便地拓展为任意大小, 而且对防止内存swap和使用非阻塞IO做了大量优化工作.\n\nmemcached内存分配：\n![](https://raw.githubusercontent.com/ming15/blog-website/images/memcached/20120314163538_438.png)\nmemcached默认情况下采用了名为Slab Allocator的机制分配、管理内存.\n\n如果我们在启动memcached时没有指定`-m`参数的话, 那么memcached能使用的最大内存为默认的64M,但是memcached启动的时候并不会一次性就都分配出来,而是当发现memcached已被分配的内存不够用的时候才会进行申请. memcached申请内存时一次会申请一个Slab(默认为1M). 然后会将这一个Slab分成不同的Class, 每个Class内部都有N个大小相等的Chunk.每个chunk中都保存了一个item结构体、一对key value键值对.\n\n## 安装\nMemcached依赖libevent,所以我们首先需要安装libevent\n```shell\nwget http://jaist.dl.sourceforge.net/project/levent/libevent/libevent-2.0/libevent-2.0.22-stable.tar.gz\ntar -zxvf libevent-2.0.22-stable.tar.gz\ncd libevent-2.0.22-stable\n./configure --prefix=/usr && make && make install\n```\n接下来安装Memcached\n```shell\nwget http://memcached.org/latest\ntar -zxvf memcached-1.x.x.tar.gz\ncd memcached-1.x.x\n./configure --with-libevent=/usr && make && make test && sudo make install\n```\n\n## `memcached`命令选项\n\n网络相关\n* `-s <file>` : Unix socket path to listen on (disables network support).\n* `-a <perms>` : 当通过s选项创建socket的时候,我们可以通过-a选项指定创建socket使用的权限(权限为八进制).\n* `-l <ip_addr>` : 监听的主机地址. 默认是本机任何可用的地址.\n* `-d` : 以后台进程方式运行memcached\n* `-u <username>` : memcached不能以root用户运行，如果当前用户为root, 我们需要通过该参数指定用户为root\n* `-c <num>` : 设置最大同时连接数.(默认是1024).\n* `-C` : 关闭CAS. (每个对象都会减少8bytes大小).\n* `-p <num>` : 设置监听TCP端口号, 默认是11211.\n* `-P` : 设置pid存储文件.\n* `-U <num>` : 设置监听UDP端口号, 默认是11211, 0 表示关闭UDP监听.\n* `-r` : 将最大的核心文件大小限制提升到允许的最大值.\n* `-v` : 设置为verbose 同时会输出发生的errors 和warnings.\n* `-i` : 打印memcached 和libevent 授权.\n* `-R <num>` : 这个选项是设置服务器可以处理一个独立客户端连接顺序请求的数量,以防止产生其他客户端饥饿的情况. 一旦设置了这个值当服务器处理一个连接超过20个(默认值)请求之后,就会尝试处理其他的连接请求.\n\n内存相关\n* `-m <num>` : 设置对象存储能使用的最大内存(单位是MB,默认是64M)\n* `-M` : 关闭对象存储所需内存超过最大内存时,自动删除缓存对象的功能. 如果memcached的配置内存达到最大值就不可再存储新的对象.\n* `-f <factor>` : Class的成长因子(默认是1.25). 也就是说如果Class1是100B,那么Class2就是125B.\n* `-n <size>` : key, value, and flags分配到的最小字节数(默认是48字节). 如果你的键值对的值都很小,你可以调低这个值来达到更高的性能. 如果你的成长因子比较大,那么你可以调高这个值,提升命中率.\n* `-t <threads>` : 处理请求的线程数(默认是4). 这个选项只有memcached被编译的时候指定了线程开启才有用.\n* `-k` : 锁定所有的分页内存. 在巨大的缓存系统中,使用这个选项是非常危险的,使用的使用要参考README文件和memcached homepage进行配置.\n* `-L` : 尝试使用尽可能使用到的内存叶. 增加内存叶大小可以减少TLB未命中和提供性能. 为了可以从OS获得更大的内存页,memcached会在一个巨大的chunk上分配所有的item\n* `-I <size>` : 指定slab page大小(默认是1mb,最小是1k, 最大是128m). 改变这个值会增加每个item大小的值.  使用-vv来查看更改后的值\n* `-F` : 关闭`flush_all`命令.\n\n```shell\nmemcached  -d -p 10021 -l 10.234.10.12 -u root -c 1024  -P ./memcached1.pid\n```\n\n## java使用\n我们使用spymemcached作为java客户端连接memcached. 在Maven项目中添加以下依赖\n```xml\n<groupId>net.spy</groupId>\n\t<artifactId>spymemcached</artifactId>\n<version>2.12.0</version>\n```\n然后连接memcached\n```java\nMemcachedClient client = new MemcachedClient(new InetSocketAddress(\"10.234.10.12\", 10021));\n```\n通过这一行我们就成功的连接上了memcached.然后我们就可以使用spymemcached提供的大量api来操作memcached\n\n## memcached信息统计\n我们可以使用telnet命令直接连接memcached`telnet 127.0.0.1 10021`,然后输入下列命令查看相关信息\n\n### stats\n统计memcached的各种信息\n* `STAT pid 20401` memcache服务器的进程ID\n* `STAT uptime 47`  服务器已经运行的秒数\n* `STAT time 1447835371` 服务器当前的unix时间戳\n* `STAT version 1.4.24`  memcache版本\n* `STAT libevent 2.0.22-stable` libevent版本\n* `STAT pointer_size 64` 当前操作系统的指针大小（32位系统一般是32bit）\n* `STAT rusage_user 0.002999` 进程的累计用户时间\n* `STAT rusage_system 0.001999` 进程的累计系统时间\n* `STAT curr_connections 10` 当前打开着的连接数\n* `STAT total_connections 11` 从服务器启动以后曾经打开过的连接数\n* `STAT connection_structures 11` 服务器分配的连接构造数\n* `STAT reserved_fds 20`\n* `STAT cmd_get 0`  get命令（获取）总请求次数\n* `STAT cmd_set 0`  set命令（保存）总请求次数\n* `STAT cmd_flush 0`\n* `STAT cmd_touch 0`\n* `STAT get_hits 0`  总命中次数\n* `STAT get_misses 0` 总未命中次数\n* `STAT delete_misses 0` delete命令未命中次数\n* `STAT delete_hits 0`  delete命令命中次数\n* `STAT incr_misses 0`  incr命令未命中次数\n* `STAT incr_hits 0`  incr命令命中次数\n* `STAT decr_misses 0`  decr命令未命中次数\n* `STAT decr_hits 0`  decr命令命中次数\n* `STAT cas_misses 0`  cas命令未命中次数\n* `STAT cas_hits 0`  cas命令命中次数\n* `STAT cas_badval 0`\n* `STAT touch_hits 0`  touch命令命中次数\n* `STAT touch_misses 0`  touch命令未命中次数\n* `STAT auth_cmds 0`\n* `STAT auth_errors 0`\n* `STAT bytes_read 7` 总读取字节数（请求字节数）\n* `STAT bytes_written 0` 总发送字节数（结果字节数）\n* `STAT limit_maxbytes 67108864`   分配给memcache的内存大小（字节）\n* `STAT accepting_conns 1`\n* `STAT listen_disabled_num 0`\n* `STAT threads 4`     当前线程数\n* `STAT conn_yields 0`\n* `STAT hash_power_level 16`  hash等级\n* `STAT hash_bytes 524288`  hash字节数\n* `STAT hash_is_expanding 0`    \n* `STAT malloc_fails 0`  分配失败次数\n* `STAT bytes 0`   当前服务器存储items占用的字节数\n* `STAT curr_items 0` 服务器当前存储的items数量\n* `STAT total_items 0` 从服务器启动以后存储的items总数量\n* `STAT expired_unfetched 0`\n* `STAT evicted_unfetched 0`\n* `STAT evictions 0` 为获取空闲内存而删除的items数（分配给memcache的空间用满后需\n* `STAT reclaimed 0`\n* `STAT crawler_reclaimed 0`\n* `STAT crawler_items_checked 0`\n* `STAT lrutail_reflocked 0`\n\n我们也可以使用java获取这些信息\n```java\nMemcachedClient client = new MemcachedClient(new InetSocketAddress(\"10.234.10.12\", 10021));\nclient.getStats().entrySet().stream().forEach(entry -> {\n\tSystem.out.println(\"Node : \" + entry.getKey());\n\tentry.getValue().entrySet().stream().forEach(value -> {\n\t\tSystem.out.println(\"    \" + value.getKey() + \" : \" + value.getValue());\n\t});\n});\n```\n\n### stats reset\n重新统计数据\n\n### stats slabs\n显示slabs信息，可以详细看到数据的分段存储情况\n* `STAT active_slabs 0`\n* `STAT total_malloced 0`\n\n### stats items\n显示slab中的item数目\n\n### stats cachedump 1 0\n列出slabs第一段里存的KEY值\n\n\n### STAT evictions 0\n表示要腾出新空间给新的item而移动的合法item数目\n","source":"_posts/nosql/Memcache.md","raw":"category: NoSql\ndate: 2015-11-18\ntitle: memcached\n---\n## 原理\nmemcached是一个高性能内存对象缓存系统. 它基于libevent,可方便地拓展为任意大小, 而且对防止内存swap和使用非阻塞IO做了大量优化工作.\n\nmemcached内存分配：\n![](https://raw.githubusercontent.com/ming15/blog-website/images/memcached/20120314163538_438.png)\nmemcached默认情况下采用了名为Slab Allocator的机制分配、管理内存.\n\n如果我们在启动memcached时没有指定`-m`参数的话, 那么memcached能使用的最大内存为默认的64M,但是memcached启动的时候并不会一次性就都分配出来,而是当发现memcached已被分配的内存不够用的时候才会进行申请. memcached申请内存时一次会申请一个Slab(默认为1M). 然后会将这一个Slab分成不同的Class, 每个Class内部都有N个大小相等的Chunk.每个chunk中都保存了一个item结构体、一对key value键值对.\n\n## 安装\nMemcached依赖libevent,所以我们首先需要安装libevent\n```shell\nwget http://jaist.dl.sourceforge.net/project/levent/libevent/libevent-2.0/libevent-2.0.22-stable.tar.gz\ntar -zxvf libevent-2.0.22-stable.tar.gz\ncd libevent-2.0.22-stable\n./configure --prefix=/usr && make && make install\n```\n接下来安装Memcached\n```shell\nwget http://memcached.org/latest\ntar -zxvf memcached-1.x.x.tar.gz\ncd memcached-1.x.x\n./configure --with-libevent=/usr && make && make test && sudo make install\n```\n\n## `memcached`命令选项\n\n网络相关\n* `-s <file>` : Unix socket path to listen on (disables network support).\n* `-a <perms>` : 当通过s选项创建socket的时候,我们可以通过-a选项指定创建socket使用的权限(权限为八进制).\n* `-l <ip_addr>` : 监听的主机地址. 默认是本机任何可用的地址.\n* `-d` : 以后台进程方式运行memcached\n* `-u <username>` : memcached不能以root用户运行，如果当前用户为root, 我们需要通过该参数指定用户为root\n* `-c <num>` : 设置最大同时连接数.(默认是1024).\n* `-C` : 关闭CAS. (每个对象都会减少8bytes大小).\n* `-p <num>` : 设置监听TCP端口号, 默认是11211.\n* `-P` : 设置pid存储文件.\n* `-U <num>` : 设置监听UDP端口号, 默认是11211, 0 表示关闭UDP监听.\n* `-r` : 将最大的核心文件大小限制提升到允许的最大值.\n* `-v` : 设置为verbose 同时会输出发生的errors 和warnings.\n* `-i` : 打印memcached 和libevent 授权.\n* `-R <num>` : 这个选项是设置服务器可以处理一个独立客户端连接顺序请求的数量,以防止产生其他客户端饥饿的情况. 一旦设置了这个值当服务器处理一个连接超过20个(默认值)请求之后,就会尝试处理其他的连接请求.\n\n内存相关\n* `-m <num>` : 设置对象存储能使用的最大内存(单位是MB,默认是64M)\n* `-M` : 关闭对象存储所需内存超过最大内存时,自动删除缓存对象的功能. 如果memcached的配置内存达到最大值就不可再存储新的对象.\n* `-f <factor>` : Class的成长因子(默认是1.25). 也就是说如果Class1是100B,那么Class2就是125B.\n* `-n <size>` : key, value, and flags分配到的最小字节数(默认是48字节). 如果你的键值对的值都很小,你可以调低这个值来达到更高的性能. 如果你的成长因子比较大,那么你可以调高这个值,提升命中率.\n* `-t <threads>` : 处理请求的线程数(默认是4). 这个选项只有memcached被编译的时候指定了线程开启才有用.\n* `-k` : 锁定所有的分页内存. 在巨大的缓存系统中,使用这个选项是非常危险的,使用的使用要参考README文件和memcached homepage进行配置.\n* `-L` : 尝试使用尽可能使用到的内存叶. 增加内存叶大小可以减少TLB未命中和提供性能. 为了可以从OS获得更大的内存页,memcached会在一个巨大的chunk上分配所有的item\n* `-I <size>` : 指定slab page大小(默认是1mb,最小是1k, 最大是128m). 改变这个值会增加每个item大小的值.  使用-vv来查看更改后的值\n* `-F` : 关闭`flush_all`命令.\n\n```shell\nmemcached  -d -p 10021 -l 10.234.10.12 -u root -c 1024  -P ./memcached1.pid\n```\n\n## java使用\n我们使用spymemcached作为java客户端连接memcached. 在Maven项目中添加以下依赖\n```xml\n<groupId>net.spy</groupId>\n\t<artifactId>spymemcached</artifactId>\n<version>2.12.0</version>\n```\n然后连接memcached\n```java\nMemcachedClient client = new MemcachedClient(new InetSocketAddress(\"10.234.10.12\", 10021));\n```\n通过这一行我们就成功的连接上了memcached.然后我们就可以使用spymemcached提供的大量api来操作memcached\n\n## memcached信息统计\n我们可以使用telnet命令直接连接memcached`telnet 127.0.0.1 10021`,然后输入下列命令查看相关信息\n\n### stats\n统计memcached的各种信息\n* `STAT pid 20401` memcache服务器的进程ID\n* `STAT uptime 47`  服务器已经运行的秒数\n* `STAT time 1447835371` 服务器当前的unix时间戳\n* `STAT version 1.4.24`  memcache版本\n* `STAT libevent 2.0.22-stable` libevent版本\n* `STAT pointer_size 64` 当前操作系统的指针大小（32位系统一般是32bit）\n* `STAT rusage_user 0.002999` 进程的累计用户时间\n* `STAT rusage_system 0.001999` 进程的累计系统时间\n* `STAT curr_connections 10` 当前打开着的连接数\n* `STAT total_connections 11` 从服务器启动以后曾经打开过的连接数\n* `STAT connection_structures 11` 服务器分配的连接构造数\n* `STAT reserved_fds 20`\n* `STAT cmd_get 0`  get命令（获取）总请求次数\n* `STAT cmd_set 0`  set命令（保存）总请求次数\n* `STAT cmd_flush 0`\n* `STAT cmd_touch 0`\n* `STAT get_hits 0`  总命中次数\n* `STAT get_misses 0` 总未命中次数\n* `STAT delete_misses 0` delete命令未命中次数\n* `STAT delete_hits 0`  delete命令命中次数\n* `STAT incr_misses 0`  incr命令未命中次数\n* `STAT incr_hits 0`  incr命令命中次数\n* `STAT decr_misses 0`  decr命令未命中次数\n* `STAT decr_hits 0`  decr命令命中次数\n* `STAT cas_misses 0`  cas命令未命中次数\n* `STAT cas_hits 0`  cas命令命中次数\n* `STAT cas_badval 0`\n* `STAT touch_hits 0`  touch命令命中次数\n* `STAT touch_misses 0`  touch命令未命中次数\n* `STAT auth_cmds 0`\n* `STAT auth_errors 0`\n* `STAT bytes_read 7` 总读取字节数（请求字节数）\n* `STAT bytes_written 0` 总发送字节数（结果字节数）\n* `STAT limit_maxbytes 67108864`   分配给memcache的内存大小（字节）\n* `STAT accepting_conns 1`\n* `STAT listen_disabled_num 0`\n* `STAT threads 4`     当前线程数\n* `STAT conn_yields 0`\n* `STAT hash_power_level 16`  hash等级\n* `STAT hash_bytes 524288`  hash字节数\n* `STAT hash_is_expanding 0`    \n* `STAT malloc_fails 0`  分配失败次数\n* `STAT bytes 0`   当前服务器存储items占用的字节数\n* `STAT curr_items 0` 服务器当前存储的items数量\n* `STAT total_items 0` 从服务器启动以后存储的items总数量\n* `STAT expired_unfetched 0`\n* `STAT evicted_unfetched 0`\n* `STAT evictions 0` 为获取空闲内存而删除的items数（分配给memcache的空间用满后需\n* `STAT reclaimed 0`\n* `STAT crawler_reclaimed 0`\n* `STAT crawler_items_checked 0`\n* `STAT lrutail_reflocked 0`\n\n我们也可以使用java获取这些信息\n```java\nMemcachedClient client = new MemcachedClient(new InetSocketAddress(\"10.234.10.12\", 10021));\nclient.getStats().entrySet().stream().forEach(entry -> {\n\tSystem.out.println(\"Node : \" + entry.getKey());\n\tentry.getValue().entrySet().stream().forEach(value -> {\n\t\tSystem.out.println(\"    \" + value.getKey() + \" : \" + value.getValue());\n\t});\n});\n```\n\n### stats reset\n重新统计数据\n\n### stats slabs\n显示slabs信息，可以详细看到数据的分段存储情况\n* `STAT active_slabs 0`\n* `STAT total_malloced 0`\n\n### stats items\n显示slab中的item数目\n\n### stats cachedump 1 0\n列出slabs第一段里存的KEY值\n\n\n### STAT evictions 0\n表示要腾出新空间给新的item而移动的合法item数目\n","slug":"nosql/Memcache","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihz4008wvjs65o3ur937"},{"date":"2015-03-07T16:00:00.000Z","title":"运行MongoDB","_content":"\n## Run MongoDB On Windows\n如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n\n### 设置MOngoDB环境\n\n#### 设置环境变量\n在环境变量里添加环境变量 `D:\\Program Files\\MongoDB\\Server\\3.0\\` 然后在Path里添加： `%MONGODB_HOME%\\bin`\n\n#### data directory\nMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是`\\data\\db`,\n所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: `D:\\mongodb\\data\\db`.\n\n你可以通过--dbpath选项给mongod.exe设置另一个data directory.\n```java\nmongod.exe --dbpath D:\\mongodb\\data\\db\n```\n如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\n```java\nmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n### 使用mongod.exe命令启动mongoDB\n```shell\n\tmongod.exe\n```\n\n### 启动日志\n最后我们在启动日志里看到\n```shell\nwaiting for connections on port 27017\n```\n\n### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```shell\nmongod --dbpath=/data/db\n```\n\n### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```shell\ncat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```shell\nmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n```shell\nmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n##### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n* Control-C\n* shutdownServer()指令\n```shell\nmongo --port 28013\nuse admin\ndb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```shell\nmkdir E:/mongoData/data/r0\nmkdir E:/mongoData/data/r1\nmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```shell\nmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```shell\nmkdir E:/mongoData/key\necho \"this is rs1 super secret key\" > E:/mongoData/key/r0\necho \"this is rs1 super secret key\" > E:/mongoData/key/r1\necho \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```shell\nmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```shell\nmongo -port 28010\n```\n","source":"_posts/nosql/MongoDB.md","raw":"category: NoSql\ndate: 2015-03-08\ntitle: 运行MongoDB\n---\n\n## Run MongoDB On Windows\n如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n\n### 设置MOngoDB环境\n\n#### 设置环境变量\n在环境变量里添加环境变量 `D:\\Program Files\\MongoDB\\Server\\3.0\\` 然后在Path里添加： `%MONGODB_HOME%\\bin`\n\n#### data directory\nMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是`\\data\\db`,\n所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: `D:\\mongodb\\data\\db`.\n\n你可以通过--dbpath选项给mongod.exe设置另一个data directory.\n```java\nmongod.exe --dbpath D:\\mongodb\\data\\db\n```\n如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\n```java\nmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n### 使用mongod.exe命令启动mongoDB\n```shell\n\tmongod.exe\n```\n\n### 启动日志\n最后我们在启动日志里看到\n```shell\nwaiting for connections on port 27017\n```\n\n### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```shell\nmongod --dbpath=/data/db\n```\n\n### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```shell\ncat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```shell\nmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n```shell\nmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n##### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n* Control-C\n* shutdownServer()指令\n```shell\nmongo --port 28013\nuse admin\ndb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```shell\nmkdir E:/mongoData/data/r0\nmkdir E:/mongoData/data/r1\nmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```shell\nmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```shell\nmkdir E:/mongoData/key\necho \"this is rs1 super secret key\" > E:/mongoData/key/r0\necho \"this is rs1 super secret key\" > E:/mongoData/key/r1\necho \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```shell\nmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```shell\nmongo -port 28010\n```\n","slug":"nosql/MongoDB","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihz8008zvjs6f1si7878"},{"date":"2015-03-07T16:00:00.000Z","title":"MongoDB客户端","_content":"## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n>\nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```java\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n","source":"_posts/nosql/MongoDB客户端.md","raw":"category: NoSql\ndate: 2015-03-08\ntitle: MongoDB客户端\n---\n## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n>\nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```java\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n","slug":"nosql/MongoDB客户端","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzc0091vjs6joa9exr8"},{"date":"2015-11-15T16:00:00.000Z","title":"Redis SortedSet","_content":"\n> 在命令行中使用Redis客户端连接Redis服务器： `redis-cli -h 127.0.0.1 -p 7000`\n\n## 增加成员\n\n### ZADD\n语法：`ZADD key score member [[score member] [score member] ...]`.   \n* `ZADD` redis命令\n* `key` 有序集合名\n* `score`  值 (可以是整数值或双精度浮点数)\n* `member` 键\n\n这个命令也就是将键值对(member score)插入到有序集合key中. 如果集合不存在就创建一个集合,如果键已经存在就代替原来的值.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZADD test1 10 a\n(integer) 1\n```\n\n## 修改成员\n\n### ZINCRBY\n语法`ZINCRBY key increment member`\n* `ZINCRBY` redis命令\n* `key` 有序集合名\n* `increment`  score值的增量\n* `member`  针对哪个成员进行改变\n\n这个命令就是对某个成员进行增加或者减少(通过负数实现). (member 成员的新 score 值,以字符串形式表示)\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd test1 23 t\n(integer) 1\nredis 127.0.0.1:7006> ZINCRBY test1 10 t\n\"33\"\nredis 127.0.0.1:7006> zincrby test1 -20 t\n\"13\"\n```\n\n## 删除成员\n\n### ZREM\n语法`ZREM key member [member ...]`\n* `ZREM` redis命令\n* `key` 有序集合名\n* `member` 成员名\n\n移除有序集 key 中的一个或多个成员,不存在的成员将被忽略.\n\n示例\n```shell\nredis 127.0.0.1:7006> zcard test1\n(integer) 7\nredis 127.0.0.1:7006> zrem test1 a\n(integer) 1\nredis 127.0.0.1:7006> zcard test1\n(integer) 6\n```\n\n### ZREMRANGEBYRANK\n语法`ZREMRANGEBYRANK key start stop`\n* `ZREMRANGEBYRANK` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n\n移除有序集 key 中,指定排名(rank)区间内的所有成员.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREMRANGEBYRANK test1 1 2 # 将第二名和第三名移除\n(integer) 2\n```\n\n### ZREMRANGEBYSCORE\n\n语法`ZREMRANGEBYSCORE key min max`\n* `ZREMRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n\n将集合key里的score值区间为[min,max]的成员删除\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREMRANGEBYSCORE test1 10 20\n(integer) 1\n```\n\n## 合并集合\n\n### ZUNIONSTORE\n语法`ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]`\n* `ZUNIONSTORE` redis命令\n* `destination` 有序集合名\n* `numkeys`  需要合并的集合数量\n* `key`  需要合并的集合\n* `WEIGHTS`  指定该值,则在合并的时候,对每个score值都乘以该元素\n* `AGGREGATE` 指定并集的结果集的聚合方式\n\n对多个集合采取并集\n> AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd a 10 a1 20 a2 30 a3 40 a4 50 a5\n(integer) 5\nredis 127.0.0.1:7006> zadd b 11 b1 12 b2 13 b3 14 b4 15 b5\n(integer) 5\nredis 127.0.0.1:7006> ZUNIONSTORE c 2 a b\n(integer) 10\nredis 127.0.0.1:7006> ZRANGE c 0 -1 WITHSCORES\n 1) \"a1\"\n 2) \"10\"\n 3) \"b1\"\n 4) \"11\"\n 5) \"b2\"\n 6) \"12\"\n 7) \"b3\"\n 8) \"13\"\n 9) \"b4\"\n10) \"14\"\n11) \"b5\"\n12) \"15\"\n13) \"a2\"\n14) \"20\"\n15) \"a3\"\n16) \"30\"\n17) \"a4\"\n18) \"40\"\n19) \"a5\"\n20) \"50\"\nredis 127.0.0.1:7006> ZUNIONSTORE e 2 c a\n(integer) 10\nredis 127.0.0.1:7006> ZRANGE e  0 -1 WITHSCORES\n 1) \"b1\"\n 2) \"11\"\n 3) \"b2\"\n 4) \"12\"\n 5) \"b3\"\n 6) \"13\"\n 7) \"b4\"\n 8) \"14\"\n 9) \"b5\"\n10) \"15\"\n11) \"a1\"\n12) \"20\"\n13) \"a2\"\n14) \"40\"\n15) \"a3\"\n16) \"60\"\n17) \"a4\"\n18) \"80\"\n19) \"a5\"\n20) \"100\"\n```\n\n### ZINTERSTORE\n语法`ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]`\n* `ZINTERSTORE` redis命令\n* `destination` 有序集合名\n* `numkeys`  需要合并的集合数量\n* `key`  需要合并的集合\n* `WEIGHTS`  指定该值,则在合并的时候,对每个score值都乘以该元素\n* `AGGREGATE` 指定并集的结果集的聚合方式\n\n对多个集合采取交集\n> AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值\n\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd h 1 a1 2 a2\n(integer) 2\nredis 127.0.0.1:7006> ZINTERSTORE j 2 e h\n(integer) 2\nredis 127.0.0.1:7006> zrange j 0 -1 WITHSCORES\n1) \"a1\"\n2) \"21\"\n3) \"a2\"\n4) \"42\"\nredis 127.0.0.1:7006>\n```\n\n## 获取集合数量\n\n### ZCARD\n语法`ZCARD key`\n* `ZCARD` redis命令\n* `key` 有序集合名\n\n获得集合大小\n\n示例\n```shell\nredis 127.0.0.1:7006> ZCARD test1\n(integer) 2\n```\n\n### ZCOUNT\n语法`ZCOUNT key min max`\n* `ZCOUNT` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n这个命令就是统计score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZCOUNT test 10 50\n(integer) 6\n```\n\n## 获取集合列表\n\n### ZRANGE\n语法`ZRANGE key start stop [WITHSCORES]`\n* `ZRANGE` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES`  同时也返回成员对应的值\n\n返回有序集key中指定区间内的成员,得到的成员是递增(从小到大)排序的.\n> 索引从0开始, 如果索引为负数则代表从倒序,即-1代表最后一个,-2代表倒数第二个. ( `ZRANGE test1 0 -1 WITHSCORES`显示整个有序集成员)\n\n示例\n```shell\nredis 127.0.0.1:7006> zrange test1 0 3\n1) \"a\"\n2) \"c\"\n3) \"t\"\n4) \"b\"\nredis 127.0.0.1:7006> zrange test1 0 3 WITHSCORES\n1) \"a\"\n2) \"10\"\n3) \"c\"\n4) \"12\"\n5) \"t\"\n6) \"13\"\n7) \"b\"\n8) \"20\"\n```\n\n### ZREVRANGE\n语法`ZREVRANGE key start stop [WITHSCORES]`\n* `ZREVRANGE` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n\n和`ZRANGE`命令不同的是它是从按 score 值递减(从大到小)来排列,其他和ZRANGE命令一样\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANGE test1 1 100\n1) \"d\"\n2) \"f\"\n```\n\n### ZRANGEBYSCORE\n语法`ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]`\n* `ZRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n* `LIMIT offset count`\n\n返回有序集key中,score值介于 [min, max]之间(闭区间)的成员,按 score 值递增(从小到大)次序排列\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 10 56 WITHSCORES\t# 闭区间\n 1) \"a\"\n 2) \"10\"\n 3) \"c\"\n 4) \"12\"\n 5) \"t\"\n 6) \"13\"\n 7) \"b\"\n 8) \"20\"\n 9) \"f\"\n10) \"42\"\n11) \"d\"\n12) \"56\"\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 (10 (56 WITHSCORES # 开区间\n1) \"c\"\n2) \"12\"\n3) \"t\"\n4) \"13\"\n5) \"b\"\n6) \"20\"\n7) \"f\"\n8) \"42\"\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 10 56 WITHSCORES LIMIT 0 3 # 从第一个成员开始选择三个成员\n1) \"a\"\n2) \"10\"\n3) \"c\"\n4) \"12\"\n5) \"t\"\n6) \"13\"\n```\n\n### ZREVRANGEBYSCORE\n语法`ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]`\n* `ZREVRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n* `LIMIT offset count`  \n\n除了成员按 score 值递减的次序排列这一点外, ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样.\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANGE test1 1 100 WITHSCORES\n 1) \"f\"\n 2) \"42\"\n 3) \"d\"\n 4) \"40\"\n 5) \"c\"\n 6) \"30\"\n 7) \"b\"\n 8) \"20\"\n 9) \"a\"\n10) \"10\"\n```\n\n### ZRANGEBYLEX\n语法`ZRANGEBYLEX key min max [LIMIT offset count]`\n* `ZRANGEBYLEX` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n\n根据成员进行排序而不是根据score值排序,然后返回[min, max]区间内的成员\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANGEBYLEX test1 10 30\n```\n\n## 查询某个成员\n\n### ZRANK\n语法`ZRANK key member`\n* `ZRANK` redis命令\n* `key` 有序集合名\n* `member`  成员值\n\n返回有序集 key 中成员 member 的排名.其中有序集成员按 score 值递增(从小到大)顺序排列.（排名从0开始）\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANK test1 d\n(integer) 5\n```\n\n### ZREVRANK\n语法`ZREVRANK key member`\n* `ZREVRANK` redis命令\n* `key` 有序集合名\n* `member`  成员值\n除了成员按 score 值递减的次序排列这一点外, ZREVRANK 命令的其他方面和 ZRANK 命令一样.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANK test1 c\n(integer) 3\n```\n\n### ZSCORE\n语法`ZSCORE key member`\n* `ZSCORE` redis命令\n* `key` 有序集合名\n* `member` 成员\n\n返回有序集 key 中,成员 member 的 score 值.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZSCORE test1 a\n\"10\"\n```\n","source":"_posts/nosql/Redis_SortedSet.md","raw":"category: NoSql\ndate: 2015-11-16\ntitle: Redis SortedSet\n---\n\n> 在命令行中使用Redis客户端连接Redis服务器： `redis-cli -h 127.0.0.1 -p 7000`\n\n## 增加成员\n\n### ZADD\n语法：`ZADD key score member [[score member] [score member] ...]`.   \n* `ZADD` redis命令\n* `key` 有序集合名\n* `score`  值 (可以是整数值或双精度浮点数)\n* `member` 键\n\n这个命令也就是将键值对(member score)插入到有序集合key中. 如果集合不存在就创建一个集合,如果键已经存在就代替原来的值.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZADD test1 10 a\n(integer) 1\n```\n\n## 修改成员\n\n### ZINCRBY\n语法`ZINCRBY key increment member`\n* `ZINCRBY` redis命令\n* `key` 有序集合名\n* `increment`  score值的增量\n* `member`  针对哪个成员进行改变\n\n这个命令就是对某个成员进行增加或者减少(通过负数实现). (member 成员的新 score 值,以字符串形式表示)\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd test1 23 t\n(integer) 1\nredis 127.0.0.1:7006> ZINCRBY test1 10 t\n\"33\"\nredis 127.0.0.1:7006> zincrby test1 -20 t\n\"13\"\n```\n\n## 删除成员\n\n### ZREM\n语法`ZREM key member [member ...]`\n* `ZREM` redis命令\n* `key` 有序集合名\n* `member` 成员名\n\n移除有序集 key 中的一个或多个成员,不存在的成员将被忽略.\n\n示例\n```shell\nredis 127.0.0.1:7006> zcard test1\n(integer) 7\nredis 127.0.0.1:7006> zrem test1 a\n(integer) 1\nredis 127.0.0.1:7006> zcard test1\n(integer) 6\n```\n\n### ZREMRANGEBYRANK\n语法`ZREMRANGEBYRANK key start stop`\n* `ZREMRANGEBYRANK` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n\n移除有序集 key 中,指定排名(rank)区间内的所有成员.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREMRANGEBYRANK test1 1 2 # 将第二名和第三名移除\n(integer) 2\n```\n\n### ZREMRANGEBYSCORE\n\n语法`ZREMRANGEBYSCORE key min max`\n* `ZREMRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n\n将集合key里的score值区间为[min,max]的成员删除\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREMRANGEBYSCORE test1 10 20\n(integer) 1\n```\n\n## 合并集合\n\n### ZUNIONSTORE\n语法`ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]`\n* `ZUNIONSTORE` redis命令\n* `destination` 有序集合名\n* `numkeys`  需要合并的集合数量\n* `key`  需要合并的集合\n* `WEIGHTS`  指定该值,则在合并的时候,对每个score值都乘以该元素\n* `AGGREGATE` 指定并集的结果集的聚合方式\n\n对多个集合采取并集\n> AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd a 10 a1 20 a2 30 a3 40 a4 50 a5\n(integer) 5\nredis 127.0.0.1:7006> zadd b 11 b1 12 b2 13 b3 14 b4 15 b5\n(integer) 5\nredis 127.0.0.1:7006> ZUNIONSTORE c 2 a b\n(integer) 10\nredis 127.0.0.1:7006> ZRANGE c 0 -1 WITHSCORES\n 1) \"a1\"\n 2) \"10\"\n 3) \"b1\"\n 4) \"11\"\n 5) \"b2\"\n 6) \"12\"\n 7) \"b3\"\n 8) \"13\"\n 9) \"b4\"\n10) \"14\"\n11) \"b5\"\n12) \"15\"\n13) \"a2\"\n14) \"20\"\n15) \"a3\"\n16) \"30\"\n17) \"a4\"\n18) \"40\"\n19) \"a5\"\n20) \"50\"\nredis 127.0.0.1:7006> ZUNIONSTORE e 2 c a\n(integer) 10\nredis 127.0.0.1:7006> ZRANGE e  0 -1 WITHSCORES\n 1) \"b1\"\n 2) \"11\"\n 3) \"b2\"\n 4) \"12\"\n 5) \"b3\"\n 6) \"13\"\n 7) \"b4\"\n 8) \"14\"\n 9) \"b5\"\n10) \"15\"\n11) \"a1\"\n12) \"20\"\n13) \"a2\"\n14) \"40\"\n15) \"a3\"\n16) \"60\"\n17) \"a4\"\n18) \"80\"\n19) \"a5\"\n20) \"100\"\n```\n\n### ZINTERSTORE\n语法`ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]`\n* `ZINTERSTORE` redis命令\n* `destination` 有序集合名\n* `numkeys`  需要合并的集合数量\n* `key`  需要合并的集合\n* `WEIGHTS`  指定该值,则在合并的时候,对每个score值都乘以该元素\n* `AGGREGATE` 指定并集的结果集的聚合方式\n\n对多个集合采取交集\n> AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值\n\n\n示例\n```shell\nredis 127.0.0.1:7006> zadd h 1 a1 2 a2\n(integer) 2\nredis 127.0.0.1:7006> ZINTERSTORE j 2 e h\n(integer) 2\nredis 127.0.0.1:7006> zrange j 0 -1 WITHSCORES\n1) \"a1\"\n2) \"21\"\n3) \"a2\"\n4) \"42\"\nredis 127.0.0.1:7006>\n```\n\n## 获取集合数量\n\n### ZCARD\n语法`ZCARD key`\n* `ZCARD` redis命令\n* `key` 有序集合名\n\n获得集合大小\n\n示例\n```shell\nredis 127.0.0.1:7006> ZCARD test1\n(integer) 2\n```\n\n### ZCOUNT\n语法`ZCOUNT key min max`\n* `ZCOUNT` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n这个命令就是统计score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZCOUNT test 10 50\n(integer) 6\n```\n\n## 获取集合列表\n\n### ZRANGE\n语法`ZRANGE key start stop [WITHSCORES]`\n* `ZRANGE` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES`  同时也返回成员对应的值\n\n返回有序集key中指定区间内的成员,得到的成员是递增(从小到大)排序的.\n> 索引从0开始, 如果索引为负数则代表从倒序,即-1代表最后一个,-2代表倒数第二个. ( `ZRANGE test1 0 -1 WITHSCORES`显示整个有序集成员)\n\n示例\n```shell\nredis 127.0.0.1:7006> zrange test1 0 3\n1) \"a\"\n2) \"c\"\n3) \"t\"\n4) \"b\"\nredis 127.0.0.1:7006> zrange test1 0 3 WITHSCORES\n1) \"a\"\n2) \"10\"\n3) \"c\"\n4) \"12\"\n5) \"t\"\n6) \"13\"\n7) \"b\"\n8) \"20\"\n```\n\n### ZREVRANGE\n语法`ZREVRANGE key start stop [WITHSCORES]`\n* `ZREVRANGE` redis命令\n* `key` 有序集合名\n* `start` 开始索引从0开始(默认闭区间,使用`(`表示开区间)\n* `stop`  结束索引从0开始(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n\n和`ZRANGE`命令不同的是它是从按 score 值递减(从大到小)来排列,其他和ZRANGE命令一样\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANGE test1 1 100\n1) \"d\"\n2) \"f\"\n```\n\n### ZRANGEBYSCORE\n语法`ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]`\n* `ZRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n* `LIMIT offset count`\n\n返回有序集key中,score值介于 [min, max]之间(闭区间)的成员,按 score 值递增(从小到大)次序排列\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 10 56 WITHSCORES\t# 闭区间\n 1) \"a\"\n 2) \"10\"\n 3) \"c\"\n 4) \"12\"\n 5) \"t\"\n 6) \"13\"\n 7) \"b\"\n 8) \"20\"\n 9) \"f\"\n10) \"42\"\n11) \"d\"\n12) \"56\"\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 (10 (56 WITHSCORES # 开区间\n1) \"c\"\n2) \"12\"\n3) \"t\"\n4) \"13\"\n5) \"b\"\n6) \"20\"\n7) \"f\"\n8) \"42\"\nredis 127.0.0.1:7006> ZRANGEBYSCORE test1 10 56 WITHSCORES LIMIT 0 3 # 从第一个成员开始选择三个成员\n1) \"a\"\n2) \"10\"\n3) \"c\"\n4) \"12\"\n5) \"t\"\n6) \"13\"\n```\n\n### ZREVRANGEBYSCORE\n语法`ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]`\n* `ZREVRANGEBYSCORE` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n* `WITHSCORES` 输出score值\n* `LIMIT offset count`  \n\n除了成员按 score 值递减的次序排列这一点外, ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样.\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANGE test1 1 100 WITHSCORES\n 1) \"f\"\n 2) \"42\"\n 3) \"d\"\n 4) \"40\"\n 5) \"c\"\n 6) \"30\"\n 7) \"b\"\n 8) \"20\"\n 9) \"a\"\n10) \"10\"\n```\n\n### ZRANGEBYLEX\n语法`ZRANGEBYLEX key min max [LIMIT offset count]`\n* `ZRANGEBYLEX` redis命令\n* `key` 有序集合名\n* `min`最小值(默认闭区间,使用`(`表示开区间)\n* `max` 最大值(默认闭区间,使用`(`表示开区间)\n\n根据成员进行排序而不是根据score值排序,然后返回[min, max]区间内的成员\n> `+`和`-`在 min 参数以及 max 参数中表示正无限和负无限.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANGEBYLEX test1 10 30\n```\n\n## 查询某个成员\n\n### ZRANK\n语法`ZRANK key member`\n* `ZRANK` redis命令\n* `key` 有序集合名\n* `member`  成员值\n\n返回有序集 key 中成员 member 的排名.其中有序集成员按 score 值递增(从小到大)顺序排列.（排名从0开始）\n\n示例\n```shell\nredis 127.0.0.1:7006> ZRANK test1 d\n(integer) 5\n```\n\n### ZREVRANK\n语法`ZREVRANK key member`\n* `ZREVRANK` redis命令\n* `key` 有序集合名\n* `member`  成员值\n除了成员按 score 值递减的次序排列这一点外, ZREVRANK 命令的其他方面和 ZRANK 命令一样.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZREVRANK test1 c\n(integer) 3\n```\n\n### ZSCORE\n语法`ZSCORE key member`\n* `ZSCORE` redis命令\n* `key` 有序集合名\n* `member` 成员\n\n返回有序集 key 中,成员 member 的 score 值.\n\n示例\n```shell\nredis 127.0.0.1:7006> ZSCORE test1 a\n\"10\"\n```\n","slug":"nosql/Redis_SortedSet","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzh0094vjs6hzgkr025"},{"date":"2015-11-18T16:00:00.000Z","title":"Redis事务","_content":"\n## 普通事务\n首先介绍普通事务`MULTI`，`EXEC`，`DISCARD`:\n\n* `MULTI`告诉 redis 服务器开启一个事务\n* `EXEC`告诉 redis 开始执行事务\n* `DISCARD`告诉 redis 取消事务\n\n`MULTI`命令执行后, redis进入事务状态,redis会持续缓存某个客户端的命令(其他客户端处于饥饿状态).\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis-multi.png)\n当redis接受到客户端的`EXEC`命令后会开始执行刚才缓存在事务队列里的任务. `DISCARD` 会将事务队列清空.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis-tranactions.png)\n```shell\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET a \"\"redis 127.0.0.1:7006> SET a \"\"\nQUEUED\nredis 127.0.0.1:7006> SET a \"a\"\nQUEUED\nredis 127.0.0.1:7006>  EXEC\n1) OK\n2) OK\nredis 127.0.0.1:7006> SET b \"b\"\nOK\nredis 127.0.0.1:7006> EXEC\n(error) ERR EXEC without MULTI\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET n \"n\"\nQUEUED\nredis 127.0.0.1:7006> EXEC\n1) OK\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET c \"c\"\nQUEUED\nredis 127.0.0.1:7006> DISCARD\nOK\nredis 127.0.0.1:7006> GET a\n\"a\"\nredis 127.0.0.1:7006> GET b\n\"b\"\nredis 127.0.0.1:7006> Get c\n(error) ERR Operation against a key holding the wrong kind of value\nredis 127.0.0.1:7006> GET n\n\"n\"\nredis 127.0.0.1:7006>\n```\n1. 使用`MULTI`命令开启事务\n2. 输入一个错误的命令,点击回车,redis并没有报错,说明这个命令确实是被缓存起来了没有执行\n3. 使用`SET`命令将a设置为\"a\"\n4. 然后执行事务,我们看到俩条事务都执行完了,但是第一条命令并没有报错\n5. 然后再次使用`SET`命令将b设置为\"b\"\n6. 再次执行事务, 并不成功,提示我们要开启事务,说明事务一旦执行完就自动退出了\n7. 再次开启事务,然后使用`SET`命令将n设置为\"n\"\n8. 退出事务\n9. 接下来我们依次使用`GET`命令获取值,但是n取不到,说明退出事务确实没有执行事务队列里的命令\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis_transaction.png)\n\n## watch机制\n下来我们来看一下redis的watch机制\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis_watched_keys.png)\n\n## pipline机制\n\n\n参考文章\n* [](http://redisbook.readthedocs.org/en/latest/feature/transaction.html)\n* [](http://ju.outofmemory.cn/entry/81786)\n* [](http://redisdoc.com/topic/transaction.html#id2)\n","source":"_posts/nosql/Redis事务.md","raw":"category: NoSql\ndate: 2015-11-19\ntitle: Redis事务\n---\n\n## 普通事务\n首先介绍普通事务`MULTI`，`EXEC`，`DISCARD`:\n\n* `MULTI`告诉 redis 服务器开启一个事务\n* `EXEC`告诉 redis 开始执行事务\n* `DISCARD`告诉 redis 取消事务\n\n`MULTI`命令执行后, redis进入事务状态,redis会持续缓存某个客户端的命令(其他客户端处于饥饿状态).\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis-multi.png)\n当redis接受到客户端的`EXEC`命令后会开始执行刚才缓存在事务队列里的任务. `DISCARD` 会将事务队列清空.\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis-tranactions.png)\n```shell\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET a \"\"redis 127.0.0.1:7006> SET a \"\"\nQUEUED\nredis 127.0.0.1:7006> SET a \"a\"\nQUEUED\nredis 127.0.0.1:7006>  EXEC\n1) OK\n2) OK\nredis 127.0.0.1:7006> SET b \"b\"\nOK\nredis 127.0.0.1:7006> EXEC\n(error) ERR EXEC without MULTI\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET n \"n\"\nQUEUED\nredis 127.0.0.1:7006> EXEC\n1) OK\nredis 127.0.0.1:7006> MULTI\nOK\nredis 127.0.0.1:7006> SET c \"c\"\nQUEUED\nredis 127.0.0.1:7006> DISCARD\nOK\nredis 127.0.0.1:7006> GET a\n\"a\"\nredis 127.0.0.1:7006> GET b\n\"b\"\nredis 127.0.0.1:7006> Get c\n(error) ERR Operation against a key holding the wrong kind of value\nredis 127.0.0.1:7006> GET n\n\"n\"\nredis 127.0.0.1:7006>\n```\n1. 使用`MULTI`命令开启事务\n2. 输入一个错误的命令,点击回车,redis并没有报错,说明这个命令确实是被缓存起来了没有执行\n3. 使用`SET`命令将a设置为\"a\"\n4. 然后执行事务,我们看到俩条事务都执行完了,但是第一条命令并没有报错\n5. 然后再次使用`SET`命令将b设置为\"b\"\n6. 再次执行事务, 并不成功,提示我们要开启事务,说明事务一旦执行完就自动退出了\n7. 再次开启事务,然后使用`SET`命令将n设置为\"n\"\n8. 退出事务\n9. 接下来我们依次使用`GET`命令获取值,但是n取不到,说明退出事务确实没有执行事务队列里的命令\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis_transaction.png)\n\n## watch机制\n下来我们来看一下redis的watch机制\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch1.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch2.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch3.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/watch4.png)\n![](https://raw.githubusercontent.com/ming15/blog-website/images/redis/redis_watched_keys.png)\n\n## pipline机制\n\n\n参考文章\n* [](http://redisbook.readthedocs.org/en/latest/feature/transaction.html)\n* [](http://ju.outofmemory.cn/entry/81786)\n* [](http://redisdoc.com/topic/transaction.html#id2)\n","slug":"nosql/Redis事务","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzl0096vjs6ga09n1yy"},{"date":"2015-04-01T16:00:00.000Z","title":"Redis 部署","_content":"\n[Redis安装 使用](http://www.redis.cn/download.html)\n\n下载，解压和安装：\n```shell\n$ wget http://download.redis.io/releases/redis-2.8.19.tar.gz\n$ tar xzf redis-2.8.19.tar.gz\n$ cd redis-2.8.19\n$ make\n```\n\n编译后的可执行文件在src目录中，可以使用下面的命令运行Redis:\n```shell\n$ src/redis-server\n```\n\n你可以使用内置的客户端连接Redis:\n```shell\n$ src/redis-cli\nredis> set foo bar\nOK\nredis> get foo\n\"bar\"\n```\n\n### 启动redis服务器\n```shell\n#!/bin/bash\ncd redis-2.8.19\nsrc/redis-server\n```\n","source":"_posts/nosql/Redis部署.md","raw":"category: NoSql\ndate: 2015-04-02\ntitle: Redis 部署\n---\n\n[Redis安装 使用](http://www.redis.cn/download.html)\n\n下载，解压和安装：\n```shell\n$ wget http://download.redis.io/releases/redis-2.8.19.tar.gz\n$ tar xzf redis-2.8.19.tar.gz\n$ cd redis-2.8.19\n$ make\n```\n\n编译后的可执行文件在src目录中，可以使用下面的命令运行Redis:\n```shell\n$ src/redis-server\n```\n\n你可以使用内置的客户端连接Redis:\n```shell\n$ src/redis-cli\nredis> set foo bar\nOK\nredis> get foo\n\"bar\"\n```\n\n### 启动redis服务器\n```shell\n#!/bin/bash\ncd redis-2.8.19\nsrc/redis-server\n```\n","slug":"nosql/Redis部署","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzp0099vjs612ztraz5"},{"date":"2016-03-01T16:00:00.000Z","title":"Jedis 初探","_content":"## using Jedis in a multithreaded environment\n我们不应该在多线程的情况下使用同一个Jedis实例对象, 因为在Jedis本身不是线程安全的, 它可能会引发一些奇奇怪怪的问题. 但是如果我们在每个线程中都创建一个Jedis实例对象的话这也是不可取的, 因为每个Jedis对象的创建都意味着socket和网络连接的创建. 为了避免这种情况,我们应该使用`JedisPool`, 它是一个线程安全的网络连接池. 我们可以通过池子创建多个Jedis实例对象, 当使用完之后再将它返回给池子.\n\n在下面的实例中我们初始化一个池子\n```java\nJedisPool pool = new JedisPool(new JedisPoolConfig(), \"localhost\");\n```\n因为JedisPool是线程安全的, 因此我们可以将它缓存起来, 供所有线程使用.\n\n`JedisPoolConfig`包含了一个丰富有用的Redis连接配置参数. `JedisPoolConfig`基于[Commons Pool 2](http://commons.apache.org/proper/commons-pool/apidocs/org/apache/commons/pool2/impl/GenericObjectPoolConfig.html)\n\n```java\n/// Jedis implements Closable. Hence, the jedis instance will be auto-closed after the last statement.\ntry (Jedis jedis = pool.getResource()) {\n  /// ... do stuff here ... for example\n  jedis.set(\"foo\", \"bar\");\n  String foobar = jedis.get(\"foo\");\n  jedis.zadd(\"sose\", 0, \"car\"); jedis.zadd(\"sose\", 0, \"bike\");\n  Set<String> sose = jedis.zrange(\"sose\", 0, -1);\n}\n/// ... when closing your application:\npool.destroy();\n```\n如果你不喜欢`try-with-resource`这种语法, 那么你可以使用`Jedis.close()`.\n```java\nJedis jedis = null;\ntry {\n  jedis = pool.getResource();\n  /// ... do stuff here ... for example\n  jedis.set(\"foo\", \"bar\");\n  String foobar = jedis.get(\"foo\");\n  jedis.zadd(\"sose\", 0, \"car\"); jedis.zadd(\"sose\", 0, \"bike\");\n  Set<String> sose = jedis.zrange(\"sose\", 0, -1);\n} finally {\n  if (jedis != null) {\n    jedis.close();\n  }\n}\n/// ... when closing your application:\npool.destroy();\n```\n\nIf Jedis was borrowed from pool, it will be returned to pool with proper method since it already determines there was JedisConnectionException occurred. If Jedis wasn't borrowed from pool, it will be disconnected and closed.\n\n下来我们来看一段测试代码\n```java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.JedisPool;\nimport redis.clients.jedis.JedisPoolConfig;\n\npublic class JedisTest {\n\n    public static void main(String[] args) {\n        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();\n        jedisPoolConfig.setMaxTotal(10);\n        JedisPool pool = new JedisPool(jedisPoolConfig, \"10.1.4.110\");\n        System.out.println(\"begin : \" + pool.getNumActive());\n        System.out.println(\"begin : \" + pool.getNumIdle());\n        System.out.println(\"begin : \" + pool.getNumWaiters());\n        Jedis jedis = null;\n        try {\n            jedis = pool.getResource();\n            System.out.println(\"borrow : \" + pool.getNumActive());\n            System.out.println(\"borrow : \" + pool.getNumIdle());\n            System.out.println(\"borrow : \" + pool.getNumWaiters());\n        } finally {\n            if (jedis != null) {\n                jedis.close();\n            }\n        }\n        System.out.println(\"return : \" + pool.getNumActive());\n        System.out.println(\"return : \" + pool.getNumIdle());\n        System.out.println(\"return : \" + pool.getNumWaiters());\n        pool.destroy();\n    }\n}\n```\n结果为\n```java\nbegin : 0\nbegin : 0\nbegin : 0\nborrow : 1\nborrow : 0\nborrow : 0\nreturn : 0\nreturn : 1\nreturn : 0\n```\n当调用`jedis.close();`后,池子里空闲的Jedis对象就多了1个, 可是如果我们注释掉这一行后的结果为\n```java\nbegin : 0\nbegin : 0\nbegin : 0\nborrow : 1\nborrow : 0\nborrow : 0\nreturn : 1\nreturn : 0\nreturn : 0\n```\n我们发现那个Jedis仍然处于激活状态, 在Jedis 2.8.0版本以前当我们从池子里借用一个Jedis之后还需要将其还回去\n```java\npublic void close(Jedis resource) {\n    jedisPool.returnResource(resource);\n}\n```\n但是现在已经不需要了, 而且Jedis已经将这个`returnResource()`的方法舍弃掉了\n```java\n/** @deprecated */\n@Deprecated\npublic void returnResource(Jedis resource) {\n    if(resource != null) {\n        try {\n            resource.resetState();\n            this.returnResourceObject(resource);\n        } catch (Exception var3) {\n            this.returnBrokenResource(resource);\n            throw new JedisException(\"Could not return the resource to the pool\", var3);\n        }\n    }\n\n}\n```\n\n接下来我们看一下多线程情况\n```java\npublic class JedisTest {\n\n    public static void main(String[] args) throws InterruptedException {\n        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();\n        jedisPoolConfig.setMaxTotal(3);\n        JedisPool pool = new JedisPool(jedisPoolConfig, \"10.1.4.110\");\n        List<Thread> list = new ArrayList<>();\n        for (int i = 0; i < 5; i++) {\n            Runnable runnable = () -> {\n                Jedis jedis = null;\n                try {\n                    jedis = pool.getResource();\n                    int sleep = new Random().nextInt(5);\n                    System.out.println(\"sleep:\" + sleep + \". time:\" + new Date().toLocaleString() + \". active: \" + pool.getNumActive() + \". idle: \" + pool.getNumIdle());\n\n                    TimeUnit.SECONDS.sleep(sleep);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    if (jedis != null) {\n                        jedis.close();\n                    }\n                }\n            };\n            list.add(new Thread(runnable));\n        }\n        list.forEach(thread -> thread.start());\n\n        Thread.currentThread().join();\n        pool.destroy();\n    }\n}\n```\n结果为\n```java\nsleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:06. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:07. active: 2. idle: 1\n```\n","source":"_posts/nosql/jedis.md","raw":"category: NoSql\ndate: 2016-03-02\ntitle: Jedis 初探\n---\n## using Jedis in a multithreaded environment\n我们不应该在多线程的情况下使用同一个Jedis实例对象, 因为在Jedis本身不是线程安全的, 它可能会引发一些奇奇怪怪的问题. 但是如果我们在每个线程中都创建一个Jedis实例对象的话这也是不可取的, 因为每个Jedis对象的创建都意味着socket和网络连接的创建. 为了避免这种情况,我们应该使用`JedisPool`, 它是一个线程安全的网络连接池. 我们可以通过池子创建多个Jedis实例对象, 当使用完之后再将它返回给池子.\n\n在下面的实例中我们初始化一个池子\n```java\nJedisPool pool = new JedisPool(new JedisPoolConfig(), \"localhost\");\n```\n因为JedisPool是线程安全的, 因此我们可以将它缓存起来, 供所有线程使用.\n\n`JedisPoolConfig`包含了一个丰富有用的Redis连接配置参数. `JedisPoolConfig`基于[Commons Pool 2](http://commons.apache.org/proper/commons-pool/apidocs/org/apache/commons/pool2/impl/GenericObjectPoolConfig.html)\n\n```java\n/// Jedis implements Closable. Hence, the jedis instance will be auto-closed after the last statement.\ntry (Jedis jedis = pool.getResource()) {\n  /// ... do stuff here ... for example\n  jedis.set(\"foo\", \"bar\");\n  String foobar = jedis.get(\"foo\");\n  jedis.zadd(\"sose\", 0, \"car\"); jedis.zadd(\"sose\", 0, \"bike\");\n  Set<String> sose = jedis.zrange(\"sose\", 0, -1);\n}\n/// ... when closing your application:\npool.destroy();\n```\n如果你不喜欢`try-with-resource`这种语法, 那么你可以使用`Jedis.close()`.\n```java\nJedis jedis = null;\ntry {\n  jedis = pool.getResource();\n  /// ... do stuff here ... for example\n  jedis.set(\"foo\", \"bar\");\n  String foobar = jedis.get(\"foo\");\n  jedis.zadd(\"sose\", 0, \"car\"); jedis.zadd(\"sose\", 0, \"bike\");\n  Set<String> sose = jedis.zrange(\"sose\", 0, -1);\n} finally {\n  if (jedis != null) {\n    jedis.close();\n  }\n}\n/// ... when closing your application:\npool.destroy();\n```\n\nIf Jedis was borrowed from pool, it will be returned to pool with proper method since it already determines there was JedisConnectionException occurred. If Jedis wasn't borrowed from pool, it will be disconnected and closed.\n\n下来我们来看一段测试代码\n```java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.JedisPool;\nimport redis.clients.jedis.JedisPoolConfig;\n\npublic class JedisTest {\n\n    public static void main(String[] args) {\n        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();\n        jedisPoolConfig.setMaxTotal(10);\n        JedisPool pool = new JedisPool(jedisPoolConfig, \"10.1.4.110\");\n        System.out.println(\"begin : \" + pool.getNumActive());\n        System.out.println(\"begin : \" + pool.getNumIdle());\n        System.out.println(\"begin : \" + pool.getNumWaiters());\n        Jedis jedis = null;\n        try {\n            jedis = pool.getResource();\n            System.out.println(\"borrow : \" + pool.getNumActive());\n            System.out.println(\"borrow : \" + pool.getNumIdle());\n            System.out.println(\"borrow : \" + pool.getNumWaiters());\n        } finally {\n            if (jedis != null) {\n                jedis.close();\n            }\n        }\n        System.out.println(\"return : \" + pool.getNumActive());\n        System.out.println(\"return : \" + pool.getNumIdle());\n        System.out.println(\"return : \" + pool.getNumWaiters());\n        pool.destroy();\n    }\n}\n```\n结果为\n```java\nbegin : 0\nbegin : 0\nbegin : 0\nborrow : 1\nborrow : 0\nborrow : 0\nreturn : 0\nreturn : 1\nreturn : 0\n```\n当调用`jedis.close();`后,池子里空闲的Jedis对象就多了1个, 可是如果我们注释掉这一行后的结果为\n```java\nbegin : 0\nbegin : 0\nbegin : 0\nborrow : 1\nborrow : 0\nborrow : 0\nreturn : 1\nreturn : 0\nreturn : 0\n```\n我们发现那个Jedis仍然处于激活状态, 在Jedis 2.8.0版本以前当我们从池子里借用一个Jedis之后还需要将其还回去\n```java\npublic void close(Jedis resource) {\n    jedisPool.returnResource(resource);\n}\n```\n但是现在已经不需要了, 而且Jedis已经将这个`returnResource()`的方法舍弃掉了\n```java\n/** @deprecated */\n@Deprecated\npublic void returnResource(Jedis resource) {\n    if(resource != null) {\n        try {\n            resource.resetState();\n            this.returnResourceObject(resource);\n        } catch (Exception var3) {\n            this.returnBrokenResource(resource);\n            throw new JedisException(\"Could not return the resource to the pool\", var3);\n        }\n    }\n\n}\n```\n\n接下来我们看一下多线程情况\n```java\npublic class JedisTest {\n\n    public static void main(String[] args) throws InterruptedException {\n        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();\n        jedisPoolConfig.setMaxTotal(3);\n        JedisPool pool = new JedisPool(jedisPoolConfig, \"10.1.4.110\");\n        List<Thread> list = new ArrayList<>();\n        for (int i = 0; i < 5; i++) {\n            Runnable runnable = () -> {\n                Jedis jedis = null;\n                try {\n                    jedis = pool.getResource();\n                    int sleep = new Random().nextInt(5);\n                    System.out.println(\"sleep:\" + sleep + \". time:\" + new Date().toLocaleString() + \". active: \" + pool.getNumActive() + \". idle: \" + pool.getNumIdle());\n\n                    TimeUnit.SECONDS.sleep(sleep);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    if (jedis != null) {\n                        jedis.close();\n                    }\n                }\n            };\n            list.add(new Thread(runnable));\n        }\n        list.forEach(thread -> thread.start());\n\n        Thread.currentThread().join();\n        pool.destroy();\n    }\n}\n```\n结果为\n```java\nsleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:03. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:06. active: 3. idle: 0\nsleep:3. time:2016-3-4 10:04:07. active: 2. idle: 1\n```\n","slug":"nosql/jedis","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzt009bvjs6ti22lp1w"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 json","_content":"使用`dump()`方法将对象序列化成json,然后使用`load()`将字符串反序列化成对象\n```python\n#-*- coding=utf-8 -*-\nimport json\n\nlist = [123, \"ad\"]\nlistJson = json.dumps(list)\nlistR = json.loads(listJson)\nprint \"列表序列化 : \" + listJson\nprint \"列表反序列化 : \" + str(listR[0])\n\ntumple = (123, \"adf\")\ntumpleJson = json.dumps(tumple)\ntumpleR = json.loads(tumpleJson)\nprint \"元组序列化 : \" + tumpleJson\nprint \"元组反序列化 : \" + str(tumpleR[1])\n\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nmapJson = json.dumps(map)\nmapR = json.loads(mapJson)\nprint \"字典序列化 : \" + mapJson\nprint \"字典反序列化 : \" + str(mapR[\"key1\"])\n\nseq = ['apple', 'mango', 'carrot', 'banana']\nseqJson = json.dumps(seq)\nseqR = json.loads(seqJson)\nprint \"序列序列化 : \" + seqJson\nprint \"序列反序列化 : \" + str(seqR[1])\n\n\ntype tumpleR[1]\ntype mapR[\"key1\"]\ntype seqR[1]\n\n```\n\n","source":"_posts/python/python2 JSON.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 json\n---\n使用`dump()`方法将对象序列化成json,然后使用`load()`将字符串反序列化成对象\n```python\n#-*- coding=utf-8 -*-\nimport json\n\nlist = [123, \"ad\"]\nlistJson = json.dumps(list)\nlistR = json.loads(listJson)\nprint \"列表序列化 : \" + listJson\nprint \"列表反序列化 : \" + str(listR[0])\n\ntumple = (123, \"adf\")\ntumpleJson = json.dumps(tumple)\ntumpleR = json.loads(tumpleJson)\nprint \"元组序列化 : \" + tumpleJson\nprint \"元组反序列化 : \" + str(tumpleR[1])\n\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nmapJson = json.dumps(map)\nmapR = json.loads(mapJson)\nprint \"字典序列化 : \" + mapJson\nprint \"字典反序列化 : \" + str(mapR[\"key1\"])\n\nseq = ['apple', 'mango', 'carrot', 'banana']\nseqJson = json.dumps(seq)\nseqR = json.loads(seqJson)\nprint \"序列序列化 : \" + seqJson\nprint \"序列反序列化 : \" + str(seqR[1])\n\n\ntype tumpleR[1]\ntype mapR[\"key1\"]\ntype seqR[1]\n\n```\n\n","slug":"python/python2 JSON","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ihzx009evjs6h9dk2476"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 函数","_content":"\n### 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n## 调用函数\nprintHelloworld()\n```\n\n### 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n## 调用函数\nprintHelloworld(\"hello world\")\n```\n\n### 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n## 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n### 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat ## 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n### 默认参数值\n我们也可以给函数参数指定默认值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n### 可变参数\npython函数也可以接受不定参数\n```python\ndef f(*args):\n\tprint(args)\n\nf(1)\nf(1, 2)\n```\n输出为\n```python\n(1,)\n(1, 2)\n```\n\n### return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n### 高阶函数\n如果函数A里的参数或者返回值是另一个函数,那么函数A就是高阶函数.\n```python\ndef add5(v1):\n\treturn v1 + 5;\n\ndef add(v1, v2, add5):\n\treturn add5(v1) + add5(v2)\n\nprint(add(2, 4, add5))\n```\n\n#### 内置高阶函数\n`map()`函数：它接受一个函数和一个列表,然后遍历列表中的每个元素作用在函数参数中\n```python\nprint(map(add5, [1, 2, 3]))\n\n// 结果为\n[6, 7, 8]\n```\n\n`reduce()`函数\n```python\n\n```\n\n`filter()`函数\n```python\n\n```\n\n### 闭包\n在2.7版本中必须要如下声明一个闭包\n```python\ndef outerF():\n\tcount = [10]\n\tdef innerF():\n\t\tprint(count[0])\n\t\tcount[0] = 20\n\treturn innerF\n\nf = outerF()\nf()\nf()\n```\n\n### 匿名函数\npython通过lambda表达式完成匿名函数\n```python\ndef nonameF(f, v1):\n\treturn f(v1)\n\nvalue = nonameF(lambda x: x + 1, 5)\nprint(value)\n```\n不过python只是有限的支持匿名函数, 匿名函数只能是一个表达式,而且不能拥有return,表达式的结果就是返回值\n\n### 偏函数\n偏函数就是通过`functools.partial`函数将函数A中的参数指定一个值然后返回一个新的函数\n```python\nimport functools\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfb = functools.partial(fa, var2=2, var3=3)\n\nfa(1, 2, 3)\nfb(1)\n```\n最后我们看到了相同的结果\n\n### 重定义\n我们可以对一个已经存在的函数重新定义行为\n```python\ndef f(*args):\n\tprint(args)\n\n\nf = lambda : 15\nprint(f())\n\nn = f\n\ndef f():\n\treturn 20\n\nprint(n())\nprint(f())\n```\n从这一点可以验证在python中函数也是对象.\n\n### 装饰器\n装饰器本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。\n\npython通过`@`语法内置实现装饰器\n```python\ndef fb(f):\n\tprint(\"fb\")\n\treturn f\n\n@fb\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfa(1, 2, 3)\n```\n上面这个例子每次在调用`fa`方法时都会输出一个`fb`字符串\n","source":"_posts/python/python2函数.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 函数\n---\n\n### 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n## 调用函数\nprintHelloworld()\n```\n\n### 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n## 调用函数\nprintHelloworld(\"hello world\")\n```\n\n### 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n## 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n### 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat ## 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n### 默认参数值\n我们也可以给函数参数指定默认值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n### 可变参数\npython函数也可以接受不定参数\n```python\ndef f(*args):\n\tprint(args)\n\nf(1)\nf(1, 2)\n```\n输出为\n```python\n(1,)\n(1, 2)\n```\n\n### return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n### 高阶函数\n如果函数A里的参数或者返回值是另一个函数,那么函数A就是高阶函数.\n```python\ndef add5(v1):\n\treturn v1 + 5;\n\ndef add(v1, v2, add5):\n\treturn add5(v1) + add5(v2)\n\nprint(add(2, 4, add5))\n```\n\n#### 内置高阶函数\n`map()`函数：它接受一个函数和一个列表,然后遍历列表中的每个元素作用在函数参数中\n```python\nprint(map(add5, [1, 2, 3]))\n\n// 结果为\n[6, 7, 8]\n```\n\n`reduce()`函数\n```python\n\n```\n\n`filter()`函数\n```python\n\n```\n\n### 闭包\n在2.7版本中必须要如下声明一个闭包\n```python\ndef outerF():\n\tcount = [10]\n\tdef innerF():\n\t\tprint(count[0])\n\t\tcount[0] = 20\n\treturn innerF\n\nf = outerF()\nf()\nf()\n```\n\n### 匿名函数\npython通过lambda表达式完成匿名函数\n```python\ndef nonameF(f, v1):\n\treturn f(v1)\n\nvalue = nonameF(lambda x: x + 1, 5)\nprint(value)\n```\n不过python只是有限的支持匿名函数, 匿名函数只能是一个表达式,而且不能拥有return,表达式的结果就是返回值\n\n### 偏函数\n偏函数就是通过`functools.partial`函数将函数A中的参数指定一个值然后返回一个新的函数\n```python\nimport functools\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfb = functools.partial(fa, var2=2, var3=3)\n\nfa(1, 2, 3)\nfb(1)\n```\n最后我们看到了相同的结果\n\n### 重定义\n我们可以对一个已经存在的函数重新定义行为\n```python\ndef f(*args):\n\tprint(args)\n\n\nf = lambda : 15\nprint(f())\n\nn = f\n\ndef f():\n\treturn 20\n\nprint(n())\nprint(f())\n```\n从这一点可以验证在python中函数也是对象.\n\n### 装饰器\n装饰器本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。\n\npython通过`@`语法内置实现装饰器\n```python\ndef fb(f):\n\tprint(\"fb\")\n\treturn f\n\n@fb\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfa(1, 2, 3)\n```\n上面这个例子每次在调用`fa`方法时都会输出一个`fb`字符串\n","slug":"python/python2函数","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii02009gvjs6szlq7mde"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 多线程","_content":"## 启动多线程\n```python\nimport socket\nimport threading\nimport time\n\ncount = 0\ndef socketSendData():\n    client=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    client.connect(('www.baidu.com',80))\n    time.sleep(1)\n\n\nfor i in range(0, 20000, 1):\n    try:\n       t = threading.Thread(target=socketSendData)\n       info = t.start()\n    except:\n       count += 1\n       print \"Error: unable to start thread  \" + str(count)\n```\n","source":"_posts/python/python2多线程.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 多线程\n---\n## 启动多线程\n```python\nimport socket\nimport threading\nimport time\n\ncount = 0\ndef socketSendData():\n    client=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    client.connect(('www.baidu.com',80))\n    time.sleep(1)\n\n\nfor i in range(0, 20000, 1):\n    try:\n       t = threading.Thread(target=socketSendData)\n       info = t.start()\n    except:\n       count += 1\n       print \"Error: unable to start thread  \" + str(count)\n```\n","slug":"python/python2多线程","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii09009jvjs6m9uwsdep"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 字符串函数","_content":"\n* `capitalize(...)` : Python capitalize()将字符串的第一个字母变成大写,其他字母变小写。`print \"abc\".capitalize()`\n\n* `center(...)` : 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格。`print \"abc\".center(10, \"1\")`结果为`111abc1111`\n··\n* `count(...)` : 用于统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置。`\"abcdefg\".count(\"c\", 2, 4)`结果为`1`\n\n* `encode(...)` : encoding 指定的编码格式编码字符串。errors参数可以指定不同的错误处理方案。`S.encode(encoding='utf-8', errors='strict') -> bytes` \n\n* `endswith(...)` : 用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数\"start\"与\"end\"为检索字符串的开始与结束位置。`\"abcdefg\".endswith(\"d\", 2, 4)`结果为true\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str` 把字符串中的 tab 符号('\\t')转为空格，默认的空格数 tabsize 是 8。\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int` 检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int` 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。\n\n* `format(...)` : `\"abcd{0}fg\".format(\"sdf\")` {0}被替换成sdf\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int` 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。\n\n* `isalnum(...)` : `S.isalnum() -> bool` 判断字符串是否包含字母数字。\n\n* `isalpha(...)` : `S.isalpha() -> bool` 检测字符串是否只由字母组成。\n\n* `isdecimal(...)` : `S.isdecimal() -> bool` 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。\n\n* `isdigit(...)` : `S.isdigit() -> bool` 检测字符串是否只由数字组成。\n\n* `islower(...)` : `S.islower() -> bool` 检测字符串是否由小写字母组成。\n\n* `isnumeric(...)` : `S.isnumeric() -> bool` 检查是否只有数字字符组成的字符串。这种方法目前只对unicode对象。\n\n* `isspace(...)` : `S.isspace() -> bool` 是否只由空格组成。\n\n* `istitle(...)` : `S.istitle() -> bool` 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。\n\n* `isupper(...)` : `S.isupper() -> bool` 检测字符串中所有的字母是否都为大写。\n\n* `join(...)` : `S.join(iterable) -> str` 用于将序列中的元素以指定的字符连接生成一个新的字符串。\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str` 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str` 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。\n\n* `lower(...)` : `S.lower() -> str` 转换字符串中所有大写字符为小写。\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str` 用于截掉字符串左边的空格或指定字符。\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)` Search for the separator sep in S, and return the part before it,the separator itself, and the part after it.  If the separator is not found, return S and two empty strings.\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)` 类似于 partition()函数,不过是从右边开始查找.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str` 把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings` 通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串. 另外参考`rsplit(...)`\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings` 返回一个字符串的所有行，可选包括换行符列表(如果num提供，则为true)\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool` 用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\n\n* `strip(...)` : `S.strip([chars]) -> str` 用于移除字符串头尾指定的字符（默认为空格）。\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str` 删除 string 字符串末尾的指定字符（默认为空格）.\n\n* `swapcase(...)` : `S.swapcase() -> str` 用于对字符串的大小写字母进行转换。\n\n* `title(...)` : `S.title() -> str` 返回\"标题化\"的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())。\n\n* `translate(...)` : `S.translate(table) -> str` 根据参数table给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。\n\n* `upper(...)` : `S.upper() -> str` 将字符串中的小写字母转为大写字母。\n\n* `zfill(...)` : `S.zfill(width) -> str` 返回指定长度的字符串，原字符串右对齐，前面填充0。\n\n","source":"_posts/python/python2字符串.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 字符串函数\n---\n\n* `capitalize(...)` : Python capitalize()将字符串的第一个字母变成大写,其他字母变小写。`print \"abc\".capitalize()`\n\n* `center(...)` : 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格。`print \"abc\".center(10, \"1\")`结果为`111abc1111`\n··\n* `count(...)` : 用于统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置。`\"abcdefg\".count(\"c\", 2, 4)`结果为`1`\n\n* `encode(...)` : encoding 指定的编码格式编码字符串。errors参数可以指定不同的错误处理方案。`S.encode(encoding='utf-8', errors='strict') -> bytes` \n\n* `endswith(...)` : 用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数\"start\"与\"end\"为检索字符串的开始与结束位置。`\"abcdefg\".endswith(\"d\", 2, 4)`结果为true\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str` 把字符串中的 tab 符号('\\t')转为空格，默认的空格数 tabsize 是 8。\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int` 检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int` 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。\n\n* `format(...)` : `\"abcd{0}fg\".format(\"sdf\")` {0}被替换成sdf\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int` 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。\n\n* `isalnum(...)` : `S.isalnum() -> bool` 判断字符串是否包含字母数字。\n\n* `isalpha(...)` : `S.isalpha() -> bool` 检测字符串是否只由字母组成。\n\n* `isdecimal(...)` : `S.isdecimal() -> bool` 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。\n\n* `isdigit(...)` : `S.isdigit() -> bool` 检测字符串是否只由数字组成。\n\n* `islower(...)` : `S.islower() -> bool` 检测字符串是否由小写字母组成。\n\n* `isnumeric(...)` : `S.isnumeric() -> bool` 检查是否只有数字字符组成的字符串。这种方法目前只对unicode对象。\n\n* `isspace(...)` : `S.isspace() -> bool` 是否只由空格组成。\n\n* `istitle(...)` : `S.istitle() -> bool` 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。\n\n* `isupper(...)` : `S.isupper() -> bool` 检测字符串中所有的字母是否都为大写。\n\n* `join(...)` : `S.join(iterable) -> str` 用于将序列中的元素以指定的字符连接生成一个新的字符串。\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str` 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str` 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。\n\n* `lower(...)` : `S.lower() -> str` 转换字符串中所有大写字符为小写。\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str` 用于截掉字符串左边的空格或指定字符。\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)` Search for the separator sep in S, and return the part before it,the separator itself, and the part after it.  If the separator is not found, return S and two empty strings.\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)` 类似于 partition()函数,不过是从右边开始查找.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str` 把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings` 通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串. 另外参考`rsplit(...)`\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings` 返回一个字符串的所有行，可选包括换行符列表(如果num提供，则为true)\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool` 用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\n\n* `strip(...)` : `S.strip([chars]) -> str` 用于移除字符串头尾指定的字符（默认为空格）。\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str` 删除 string 字符串末尾的指定字符（默认为空格）.\n\n* `swapcase(...)` : `S.swapcase() -> str` 用于对字符串的大小写字母进行转换。\n\n* `title(...)` : `S.title() -> str` 返回\"标题化\"的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())。\n\n* `translate(...)` : `S.translate(table) -> str` 根据参数table给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。\n\n* `upper(...)` : `S.upper() -> str` 将字符串中的小写字母转为大写字母。\n\n* `zfill(...)` : `S.zfill(width) -> str` 返回指定长度的字符串，原字符串右对齐，前面填充0。\n\n","slug":"python/python2字符串","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0d009lvjs618s2hhtx"},{"date":"2016-03-11T16:00:00.000Z","title":"PYTHON2 异常","_content":"捕获异常\n```python\ntry:\n   fh = open(\"test\", \"w\")\nexcept IOError:\n   print \"Error: open error\"\nelse:\n   print \"hava open file\"\n   fh.close()\n```\n抛出异常`raise [Exception [, args [, traceback]]]`例如\n```python\nif(num < 100):\n  raise RuntimeError(\"num is greater than 100!\")\n```\n","source":"_posts/python/python2异常.md","raw":"category: python2\ndate: 2016-03-12\ntitle: PYTHON2 异常\n---\n捕获异常\n```python\ntry:\n   fh = open(\"test\", \"w\")\nexcept IOError:\n   print \"Error: open error\"\nelse:\n   print \"hava open file\"\n   fh.close()\n```\n抛出异常`raise [Exception [, args [, traceback]]]`例如\n```python\nif(num < 100):\n  raise RuntimeError(\"num is greater than 100!\")\n```\n","slug":"python/python2异常","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0h009ovjs6vgxlvm3v"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 控制流","_content":"### if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n### while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n### for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n或者\n```python\n#  从0开始步增到10\nfor i in range(0, 10, 1)\n    print(i)\n```","source":"_posts/python/python2控制流.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 控制流\n---\n### if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n### while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n### for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n或者\n```python\n#  从0开始步增到10\nfor i in range(0, 10, 1)\n    print(i)\n```","slug":"python/python2控制流","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0k009qvjs6upjmnxpz"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 文件操作","_content":"打开一个文件\n```python\nf = open(name, [mode], [size])\n```\n* name: 文件名\n* mode: 打开方式\n* size: 操作的字节数\n\n### mode值:\n* `r`: 只读方式打开(文件必须存在)\n* `w`: 只写方式打开(文件不存在创建文件,文件存在清空文件)\n* `a`: 追加方式打开(文件不存在创建文件)\n* `r+/w+`: 读写方式打开\n* `a+`: 读写方式打开\n* `rb,wb,ab,rb+,wb+,ab+`: 二进制方式打开\n\n> 注意:如果我们使用非二进制模式输出时`\\n(0A)`会被自动替换为`\\r\\n(0D 0A)`,因此在文件输出时,我们要注意这个问题.\n\n### f对象常用方法\n* `read([size])` : 读取文件(size有值则读取size个字节),如果不填写size则读取全部\n* `readline([size])` : 每次读取一行(size值为当前行的长度,但是如果每次读取不完的话,下次再调用readline时会继续在当前行读取)\n* `readlines([size])` : 读取多行,返回每一行组成的列表. 如果不填写size则读取全部内容(不推荐使用这种方式读取所有行)\n* `write(str)` : 将字符串直接写入文件中\n* `writelines(lines)`: 将字符串或者字符串列表写入文件中.\n* `close()`: 关闭文件操作\n\n我们可以使用for循环遍历整个文件\n```python\nfile = open(\"demo.txt\")\nfor line in file:\n\tprint(line)\n```\n\n### OS模块文件操作\n```python\nfd = os.open(filename, flag, [mode])\n```\nfilename和mode我们通过上面的描述都知道了,现在我们看一下flag属性值(文件打开方式)\n* os.O_CREAT : 创建文件\n* os.O_RDONLY : 只读方式打开\n* os.O_WRONLY : 只写方式打开\n* os.O_RDWR : 读写方式打开\n\n示例\n```python\nfd = os.open(\"test.txt\", os.O_CREAT | os.O_RDWR)\nos.write(fd, \"helloworld\")\n```\n\n### 中文乱码\n写入文件时,如果输出中文,我们经常会遇到乱码的问题.只需要在python文件顶部加上以下内容就可以了\n```python\n#-*- coding=utf-8 -*-\n```\n","source":"_posts/python/python2文件操作.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 文件操作\n---\n打开一个文件\n```python\nf = open(name, [mode], [size])\n```\n* name: 文件名\n* mode: 打开方式\n* size: 操作的字节数\n\n### mode值:\n* `r`: 只读方式打开(文件必须存在)\n* `w`: 只写方式打开(文件不存在创建文件,文件存在清空文件)\n* `a`: 追加方式打开(文件不存在创建文件)\n* `r+/w+`: 读写方式打开\n* `a+`: 读写方式打开\n* `rb,wb,ab,rb+,wb+,ab+`: 二进制方式打开\n\n> 注意:如果我们使用非二进制模式输出时`\\n(0A)`会被自动替换为`\\r\\n(0D 0A)`,因此在文件输出时,我们要注意这个问题.\n\n### f对象常用方法\n* `read([size])` : 读取文件(size有值则读取size个字节),如果不填写size则读取全部\n* `readline([size])` : 每次读取一行(size值为当前行的长度,但是如果每次读取不完的话,下次再调用readline时会继续在当前行读取)\n* `readlines([size])` : 读取多行,返回每一行组成的列表. 如果不填写size则读取全部内容(不推荐使用这种方式读取所有行)\n* `write(str)` : 将字符串直接写入文件中\n* `writelines(lines)`: 将字符串或者字符串列表写入文件中.\n* `close()`: 关闭文件操作\n\n我们可以使用for循环遍历整个文件\n```python\nfile = open(\"demo.txt\")\nfor line in file:\n\tprint(line)\n```\n\n### OS模块文件操作\n```python\nfd = os.open(filename, flag, [mode])\n```\nfilename和mode我们通过上面的描述都知道了,现在我们看一下flag属性值(文件打开方式)\n* os.O_CREAT : 创建文件\n* os.O_RDONLY : 只读方式打开\n* os.O_WRONLY : 只写方式打开\n* os.O_RDWR : 读写方式打开\n\n示例\n```python\nfd = os.open(\"test.txt\", os.O_CREAT | os.O_RDWR)\nos.write(fd, \"helloworld\")\n```\n\n### 中文乱码\n写入文件时,如果输出中文,我们经常会遇到乱码的问题.只需要在python文件顶部加上以下内容就可以了\n```python\n#-*- coding=utf-8 -*-\n```\n","slug":"python/python2文件操作","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0o009tvjs6ya8f0zkk"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 模块","_content":"\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n### 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n### 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n","source":"_posts/python/python2模块.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 模块\n---\n\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n### 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n### 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n","slug":"python/python2模块","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0r009vvjs6dtfa9wj7"},{"date":"2016-03-05T16:00:00.000Z","title":"PYTHON2 网络编程","_content":"\n## Socket服务器\n```python\nimport socket\n\nsock=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nsock.bind(('localhost',8089))\nsock.listen(5)\n\nprint('tcpServer listen at: %s:%s\\n\\r' %('localhost',8089))\n\nwhile True:\n    client_sock,client_addr=sock.accept()\n    print('%s:%s connect' %client_addr)\n    while True:\n        recv=client_sock.recv(4096)\n        if not recv:\n            client_sock.close()\n            break\n        print('[Client %s:%s said]:%s' % (client_addr[0],client_addr[1],recv))\n        client_sock.send('tcpServer has received your message')\n        sock.close()\n```\n\n## HttpServer\n```python\nimport BaseHTTPServer\nimport urlparse\nclass WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"\n        \"\"\"\n        print \"8090\"\n\nserver = BaseHTTPServer.HTTPServer(('0.0.0.0',8090), WebRequestHandler)\nserver.serve_forever()\n```\n\nself 还有如下参数\n* self.path\n* self.client_address\n* self.address_string()\n* self.command\n* self.path\n* self.request_version\n* self.server_version\n* self.sys_version\n* self.protocol_version\n* self.headers\n* self.send_response(200)\n* self.end_headers()\n\n## Socket客户端\n```python\nclient=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nclient.connect(('localhost',8880))\n\nclient.send('2')\nrecvData=client.recv(1024)\nprint recvData\n```","source":"_posts/python/python2网络编程.md","raw":"category: python2\ndate: 2016-03-06\ntitle: PYTHON2 网络编程\n---\n\n## Socket服务器\n```python\nimport socket\n\nsock=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nsock.bind(('localhost',8089))\nsock.listen(5)\n\nprint('tcpServer listen at: %s:%s\\n\\r' %('localhost',8089))\n\nwhile True:\n    client_sock,client_addr=sock.accept()\n    print('%s:%s connect' %client_addr)\n    while True:\n        recv=client_sock.recv(4096)\n        if not recv:\n            client_sock.close()\n            break\n        print('[Client %s:%s said]:%s' % (client_addr[0],client_addr[1],recv))\n        client_sock.send('tcpServer has received your message')\n        sock.close()\n```\n\n## HttpServer\n```python\nimport BaseHTTPServer\nimport urlparse\nclass WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n    def do_GET(self):\n        \"\"\"\n        \"\"\"\n        print \"8090\"\n\nserver = BaseHTTPServer.HTTPServer(('0.0.0.0',8090), WebRequestHandler)\nserver.serve_forever()\n```\n\nself 还有如下参数\n* self.path\n* self.client_address\n* self.address_string()\n* self.command\n* self.path\n* self.request_version\n* self.server_version\n* self.sys_version\n* self.protocol_version\n* self.headers\n* self.send_response(200)\n* self.end_headers()\n\n## Socket客户端\n```python\nclient=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\nclient.connect(('localhost',8880))\n\nclient.send('2')\nrecvData=client.recv(1024)\nprint recvData\n```","slug":"python/python2网络编程","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0v009yvjs62zdu4cqo"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2集合","_content":"\n### 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n### 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n### 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n### 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n### Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n### Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n","source":"_posts/python/python2集合.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2集合\n---\n\n### 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n### 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n### 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n### 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n### Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n### Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n","slug":"python/python2集合","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii0z00a0vjs6rq2j9928"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2 面向对象","_content":"\n### self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n### 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n### 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n#### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n#### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n### 变量\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n#### 权限控制\n对象的属性(变量和方法)如果名字以`__`开头则不能被外部访问,但是如果名称构成形式为`__xxx__`则被称为特殊属性,是可以被外界访问的.\n\n### 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n#### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n```\n\n\n \n","source":"_posts/python/python2面向对象.md","raw":"category: python2\ndate: 2015-08-08\ntitle: PYTHON2 面向对象\n---\n\n### self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n### 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n### 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n#### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n#### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n### 变量\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n#### 权限控制\n对象的属性(变量和方法)如果名字以`__`开头则不能被外部访问,但是如果名称构成形式为`__xxx__`则被称为特殊属性,是可以被外界访问的.\n\n### 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n#### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n```\n\n\n \n","slug":"python/python2面向对象","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1300a3vjs63zp12xmj"},{"date":"2016-04-25T16:00:00.000Z","title":"Spring 任务调度","_content":"[官方文档](https://spring.io/guides/gs/scheduling-tasks/)学习\n\n\n测试代码\n```java\nimport java.util.Date;\nimport java.util.concurrent.TimeUnit;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.scheduling.annotation.EnableScheduling;\nimport org.springframework.scheduling.annotation.Scheduled;\nimport org.springframework.stereotype.Component;\n\n@SpringBootApplication\n@EnableScheduling\npublic class TestScheduledTasks {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tSpringApplication.run(TestScheduledTasks.class);\n\t}\n}\n\n@Component\nclass ScheduledTasks {\n\t// 当任务完成之后, 再延迟fixedDelay毫秒后执行\n\t@Scheduled(fixedDelay = 3000)\n\tpublic void fixedDelay() throws InterruptedException {\n\t\tSystem.out.println(\"fixedDelay : \" + new Date());\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n\n\t// 每三秒钟执行一次\n\t@Scheduled(fixedRate = 3000)\n\tpublic void fixedRate() throws InterruptedException {\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tSystem.out.println(\"fixedRate : \" + new Date());\n\t}\n\n}\n```\n结果为\n```bash\nfixedRate : Tue Apr 26 15:59:15 CST 2016\nfixedDelay : Tue Apr 26 15:59:15 CST 2016\nfixedRate : Tue Apr 26 15:59:21 CST 2016\nfixedRate : Tue Apr 26 15:59:24 CST 2016\nfixedRate : Tue Apr 26 15:59:27 CST 2016\nfixedDelay : Tue Apr 26 15:59:27 CST 2016\n```\n`Scheduled`的注解还有\n* cron : 这个可以让我们使用cron表达式\n\n最后添加所需要的Maven依赖\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.springframework</groupId>\n    <artifactId>gs-scheduling-tasks</artifactId>\n    <version>0.1.0</version>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.3.RELEASE</version>\n    </parent>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```","source":"_posts/spring/Spring 任务调度.md","raw":"category: Spring\ndate: 2016-04-26\ntitle: Spring 任务调度\n---\n[官方文档](https://spring.io/guides/gs/scheduling-tasks/)学习\n\n\n测试代码\n```java\nimport java.util.Date;\nimport java.util.concurrent.TimeUnit;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.scheduling.annotation.EnableScheduling;\nimport org.springframework.scheduling.annotation.Scheduled;\nimport org.springframework.stereotype.Component;\n\n@SpringBootApplication\n@EnableScheduling\npublic class TestScheduledTasks {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tSpringApplication.run(TestScheduledTasks.class);\n\t}\n}\n\n@Component\nclass ScheduledTasks {\n\t// 当任务完成之后, 再延迟fixedDelay毫秒后执行\n\t@Scheduled(fixedDelay = 3000)\n\tpublic void fixedDelay() throws InterruptedException {\n\t\tSystem.out.println(\"fixedDelay : \" + new Date());\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n\n\t// 每三秒钟执行一次\n\t@Scheduled(fixedRate = 3000)\n\tpublic void fixedRate() throws InterruptedException {\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tSystem.out.println(\"fixedRate : \" + new Date());\n\t}\n\n}\n```\n结果为\n```bash\nfixedRate : Tue Apr 26 15:59:15 CST 2016\nfixedDelay : Tue Apr 26 15:59:15 CST 2016\nfixedRate : Tue Apr 26 15:59:21 CST 2016\nfixedRate : Tue Apr 26 15:59:24 CST 2016\nfixedRate : Tue Apr 26 15:59:27 CST 2016\nfixedDelay : Tue Apr 26 15:59:27 CST 2016\n```\n`Scheduled`的注解还有\n* cron : 这个可以让我们使用cron表达式\n\n最后添加所需要的Maven依赖\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.springframework</groupId>\n    <artifactId>gs-scheduling-tasks</artifactId>\n    <version>0.1.0</version>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.3.RELEASE</version>\n    </parent>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```","slug":"spring/Spring 任务调度","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1600a5vjs6bgbxmu0c"},{"date":"2016-04-21T16:00:00.000Z","title":"Spring 异步方法访问","_content":"[官方文档](https://spring.io/guides/gs/async-method/)学习\n\n\n官网的教程就是访问GitHub 的一个用户数据. 首先我们创建一个Model类\n```java\nimport com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n\n@JsonIgnoreProperties(ignoreUnknown=true)\npublic class User {\n\n    private String name;\n    private String blog;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getBlog() {\n        return blog;\n    }\n\n    public void setBlog(String blog) {\n        this.blog = blog;\n    }\n\n    @Override\n    public String toString() {\n        return \"User [name=\" + name + \", blog=\" + blog + \"]\";\n    }\n\n}\n```\n> Spring默认使用的是 Jackson JSON类库。 在这个例子中@JsonIgnoreProperties, 会忽略Github返回的不在User中的参数\n\n然后我们创建一个异步的服务\n```java\nimport java.util.concurrent.Future;\n\nimport org.springframework.scheduling.annotation.Async;\nimport org.springframework.scheduling.annotation.AsyncResult;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.client.RestTemplate;\n\n@Service\npublic class GitHubLookupService {\n\n    RestTemplate restTemplate = new RestTemplate();\n\n    @Async\n    public Future<User> findUser(String user) throws InterruptedException {\n        System.out.println(\"Looking up \" + user);\n        User results = restTemplate.getForObject(\"https://api.github.com/users/\" + user, User.class);\n        // Artificial delay of 1s for demonstration purposes\n        Thread.sleep(1000L);\n        return new AsyncResult<User>(results);\n    }\n\n}\n```\n我们创建的服务, 使用的是RestTemplate来创建一个Rest远程调用, 然后将结果转换为一个User实例.\n\n`@Async`注解会让Spring在一个单独的线程中执行该方法, 最后我们使用`AsyncResult`对调用的结果进行了一个异步的封装.\n\n> 需要注意的是, 如果创建一个本地实例并不会异步调用`findUser()`方法, 我们必须在`@Configuration`或者`@ComponentScan`注解中才行.\n\n下面我们创建Demo运行一下程序\n```java\nimport java.util.concurrent.Future;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.scheduling.annotation.EnableAsync;\n\n@SpringBootApplication\n@EnableAsync\npublic class Application implements CommandLineRunner {\n\n    @Autowired\n    GitHubLookupService gitHubLookupService;\n\n    @Override\n    public void run(String... args) throws Exception {\n        // Start the clock\n        long start = System.currentTimeMillis();\n\n        // Kick of multiple, asynchronous lookups\n        Future<User> page1 = gitHubLookupService.findUser(\"PivotalSoftware\");\n        Future<User> page2 = gitHubLookupService.findUser(\"CloudFoundry\");\n        Future<User> page3 = gitHubLookupService.findUser(\"Spring-Projects\");\n\n        // Wait until they are all done\n        while (!(page1.isDone() && page2.isDone() && page3.isDone())) {\n            Thread.sleep(10); //10-millisecond pause between each check\n        }\n\n        // Print results, including elapsed time\n        System.out.println(\"Elapsed time: \" + (System.currentTimeMillis() - start));\n        System.out.println(page1.get());\n        System.out.println(page2.get());\n        System.out.println(page3.get());\n    }\n\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n\n}\n```\n`@EnableAsync`注解, 会让`@Async`方法在一个线程池中执行\n\n> @SpringBootApplication会为我们做如下工作\n> * @Configuration\n> * @EnableAutoConfiguration\n> * @ComponentScan\n \n\n最后添加所需要的Maven依赖\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.springframework</groupId>\n    <artifactId>gs-async-method</artifactId>\n    <version>0.1.0</version>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.3.RELEASE</version>\n    </parent>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n        </dependency>\n    </dependencies>\n\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```","source":"_posts/spring/Spring 异步方法访问.md","raw":"category: Spring\ndate: 2016-04-22\ntitle: Spring 异步方法访问\n---\n[官方文档](https://spring.io/guides/gs/async-method/)学习\n\n\n官网的教程就是访问GitHub 的一个用户数据. 首先我们创建一个Model类\n```java\nimport com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n\n@JsonIgnoreProperties(ignoreUnknown=true)\npublic class User {\n\n    private String name;\n    private String blog;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getBlog() {\n        return blog;\n    }\n\n    public void setBlog(String blog) {\n        this.blog = blog;\n    }\n\n    @Override\n    public String toString() {\n        return \"User [name=\" + name + \", blog=\" + blog + \"]\";\n    }\n\n}\n```\n> Spring默认使用的是 Jackson JSON类库。 在这个例子中@JsonIgnoreProperties, 会忽略Github返回的不在User中的参数\n\n然后我们创建一个异步的服务\n```java\nimport java.util.concurrent.Future;\n\nimport org.springframework.scheduling.annotation.Async;\nimport org.springframework.scheduling.annotation.AsyncResult;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.client.RestTemplate;\n\n@Service\npublic class GitHubLookupService {\n\n    RestTemplate restTemplate = new RestTemplate();\n\n    @Async\n    public Future<User> findUser(String user) throws InterruptedException {\n        System.out.println(\"Looking up \" + user);\n        User results = restTemplate.getForObject(\"https://api.github.com/users/\" + user, User.class);\n        // Artificial delay of 1s for demonstration purposes\n        Thread.sleep(1000L);\n        return new AsyncResult<User>(results);\n    }\n\n}\n```\n我们创建的服务, 使用的是RestTemplate来创建一个Rest远程调用, 然后将结果转换为一个User实例.\n\n`@Async`注解会让Spring在一个单独的线程中执行该方法, 最后我们使用`AsyncResult`对调用的结果进行了一个异步的封装.\n\n> 需要注意的是, 如果创建一个本地实例并不会异步调用`findUser()`方法, 我们必须在`@Configuration`或者`@ComponentScan`注解中才行.\n\n下面我们创建Demo运行一下程序\n```java\nimport java.util.concurrent.Future;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.scheduling.annotation.EnableAsync;\n\n@SpringBootApplication\n@EnableAsync\npublic class Application implements CommandLineRunner {\n\n    @Autowired\n    GitHubLookupService gitHubLookupService;\n\n    @Override\n    public void run(String... args) throws Exception {\n        // Start the clock\n        long start = System.currentTimeMillis();\n\n        // Kick of multiple, asynchronous lookups\n        Future<User> page1 = gitHubLookupService.findUser(\"PivotalSoftware\");\n        Future<User> page2 = gitHubLookupService.findUser(\"CloudFoundry\");\n        Future<User> page3 = gitHubLookupService.findUser(\"Spring-Projects\");\n\n        // Wait until they are all done\n        while (!(page1.isDone() && page2.isDone() && page3.isDone())) {\n            Thread.sleep(10); //10-millisecond pause between each check\n        }\n\n        // Print results, including elapsed time\n        System.out.println(\"Elapsed time: \" + (System.currentTimeMillis() - start));\n        System.out.println(page1.get());\n        System.out.println(page2.get());\n        System.out.println(page3.get());\n    }\n\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n\n}\n```\n`@EnableAsync`注解, 会让`@Async`方法在一个线程池中执行\n\n> @SpringBootApplication会为我们做如下工作\n> * @Configuration\n> * @EnableAutoConfiguration\n> * @ComponentScan\n \n\n最后添加所需要的Maven依赖\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.springframework</groupId>\n    <artifactId>gs-async-method</artifactId>\n    <version>0.1.0</version>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>1.3.3.RELEASE</version>\n    </parent>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n        </dependency>\n    </dependencies>\n\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```","slug":"spring/Spring 异步方法访问","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1900a7vjs6y7zoi2ss"},{"date":"2015-04-08T16:00:00.000Z","title":"SpringBoot HTTP 服务","_content":"## 添加依赖\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-actuator</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n```\n\n## 构建应用\n```java\n@Controller\n// 告诉Spring Boot根据添加的jar依赖猜测如何配置Spring\n@EnableAutoConfiguration\t\n@ComponentScan\npublic class App {\n\n    public static void main(String[] args) {\n    \tSpringApplication.run(App.class, new String[0]);\n    }\n}\n\n@Component\n@RequestMapping(\"/\")\npublic class TestAction {\n\n\t// http://localhost:8080/h\n\t@RequestMapping(\"/h\")\n\t@ResponseBody\n\tString home() {\n\t\treturn \"home:Hello World!\";\n\t}\n}\n```\n上面给出了一个最简单的HTTP应用. 上面默认的就是一个GET请求, 我们还可以自己定义其他请求`@RequestMapping(value = \"post\", method = RequestMethod.POST)`.\n\n我们还可以指定路径参数\n```java\n// http://localhost:8080/pathVariable/a\n@RequestMapping(\"/pathVariable/{paramV}\")\n@ResponseBody\nString pathVariable(@PathVariable String paramV) {\n\treturn paramV;\n}\n```\n\n## Get路径参数\n```java\n// http://localhost:8080/requestParam?v=v&n=n\n@RequestMapping(\"/requestParam\")\n@ResponseBody\nString requestParam(@RequestParam String v) {\n\treturn v;\n}\n```\n常用来处理以下情况\n* 常用来处理简单类型的绑定,可以处理get 方式中queryString的值,也可以处理post方式中 body data的值;\n* 用来处理Content-Type: 为application/x-www-form-urlencoded编码的内容,提交方式GET、POST;\n* 该注解有两个属性： value、required; value用来指定要传入值的id名称,required用来指示参数是否必须绑定;\n\n\n## 完整路径\n该注解常用来处理Content-Type:\n* 不是application/x-www-form-urlencoded编码的内容,例如application/json, application/xml等;\n* 它是通过使用HandlerAdapter 配置的HttpMessageConverters来解析post data body,然后绑定到相应的bean上的.\n* 因为配置有FormHttpMessageConverter,所以也可以用来处理application/x-www-form-urlencoded的内容,处理完的结果放在一个MultiValueMap<String, String>里,这种情况在某些特殊需求下使用,详情查看FormHttpMessageConverter api;\n```java\n@RequestMapping(\"/requestBody\")\n@ResponseBody\nString requestBody(@RequestBody String v) {\n\treturn v;\n}\n```\n\n## 指定HEADER\n```java\n// http://localhost:8080/requestHeader\n@RequestMapping(\"/requestHeader\")\n@ResponseBody\nString requestHeader(@RequestHeader(\"Accept-Encoding\") String encoding) {\n\treturn \"Accept-Encoding : \" + encoding;\n}\n```\n\n## 设置Cookie\n```java\n@RequestMapping(\"/cookieValue\")\n@ResponseBody\nString cookieValue(@CookieValue(\"SESSION_ID\") String v) {\n\treturn v;\n}\n```\n\n## RestController\nSpring Boot官网还提供了一种更简单的配置\n```java\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RestController\npublic class HelloController {\n\n    @RequestMapping(\"/\")\n    public String index() {\n        return \"Greetings from Spring Boot!\";\n    }\n\n}\n```\n使用`RestController`表示HelloController要使用Spring MVC来处理web请求了. `RestController`内部聚合了`@Controller `和`@ResponseBody`注解. `RequestMapping`将`/`映射到`index()`方法. ","source":"_posts/spring/spring boot web.md","raw":"category: Spring\ndate: 2015-04-09\ntitle: SpringBoot HTTP 服务\n---\n## 添加依赖\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-actuator</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n```\n\n## 构建应用\n```java\n@Controller\n// 告诉Spring Boot根据添加的jar依赖猜测如何配置Spring\n@EnableAutoConfiguration\t\n@ComponentScan\npublic class App {\n\n    public static void main(String[] args) {\n    \tSpringApplication.run(App.class, new String[0]);\n    }\n}\n\n@Component\n@RequestMapping(\"/\")\npublic class TestAction {\n\n\t// http://localhost:8080/h\n\t@RequestMapping(\"/h\")\n\t@ResponseBody\n\tString home() {\n\t\treturn \"home:Hello World!\";\n\t}\n}\n```\n上面给出了一个最简单的HTTP应用. 上面默认的就是一个GET请求, 我们还可以自己定义其他请求`@RequestMapping(value = \"post\", method = RequestMethod.POST)`.\n\n我们还可以指定路径参数\n```java\n// http://localhost:8080/pathVariable/a\n@RequestMapping(\"/pathVariable/{paramV}\")\n@ResponseBody\nString pathVariable(@PathVariable String paramV) {\n\treturn paramV;\n}\n```\n\n## Get路径参数\n```java\n// http://localhost:8080/requestParam?v=v&n=n\n@RequestMapping(\"/requestParam\")\n@ResponseBody\nString requestParam(@RequestParam String v) {\n\treturn v;\n}\n```\n常用来处理以下情况\n* 常用来处理简单类型的绑定,可以处理get 方式中queryString的值,也可以处理post方式中 body data的值;\n* 用来处理Content-Type: 为application/x-www-form-urlencoded编码的内容,提交方式GET、POST;\n* 该注解有两个属性： value、required; value用来指定要传入值的id名称,required用来指示参数是否必须绑定;\n\n\n## 完整路径\n该注解常用来处理Content-Type:\n* 不是application/x-www-form-urlencoded编码的内容,例如application/json, application/xml等;\n* 它是通过使用HandlerAdapter 配置的HttpMessageConverters来解析post data body,然后绑定到相应的bean上的.\n* 因为配置有FormHttpMessageConverter,所以也可以用来处理application/x-www-form-urlencoded的内容,处理完的结果放在一个MultiValueMap<String, String>里,这种情况在某些特殊需求下使用,详情查看FormHttpMessageConverter api;\n```java\n@RequestMapping(\"/requestBody\")\n@ResponseBody\nString requestBody(@RequestBody String v) {\n\treturn v;\n}\n```\n\n## 指定HEADER\n```java\n// http://localhost:8080/requestHeader\n@RequestMapping(\"/requestHeader\")\n@ResponseBody\nString requestHeader(@RequestHeader(\"Accept-Encoding\") String encoding) {\n\treturn \"Accept-Encoding : \" + encoding;\n}\n```\n\n## 设置Cookie\n```java\n@RequestMapping(\"/cookieValue\")\n@ResponseBody\nString cookieValue(@CookieValue(\"SESSION_ID\") String v) {\n\treturn v;\n}\n```\n\n## RestController\nSpring Boot官网还提供了一种更简单的配置\n```java\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RestController\npublic class HelloController {\n\n    @RequestMapping(\"/\")\n    public String index() {\n        return \"Greetings from Spring Boot!\";\n    }\n\n}\n```\n使用`RestController`表示HelloController要使用Spring MVC来处理web请求了. `RestController`内部聚合了`@Controller `和`@ResponseBody`注解. `RequestMapping`将`/`映射到`index()`方法. ","slug":"spring/spring boot web","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1f00aavjs650dkab3i"},{"date":"2015-04-07T16:00:00.000Z","title":"SpringBoot","_content":"SpringBoot提供了一种快速构建应用的方式. 它会根据Classpath和beans上的现有配置来推测你缺少哪些配置, 从而将缺少的配置自动加载.\n\n```java\npackage hello;\n\nimport java.util.Arrays;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.ApplicationContext;\n\n@SpringBootApplication\npublic class Application {\n\n    public static void main(String[] args) {\n        ApplicationContext ctx = SpringApplication.run(Application.class, args);\n\n        System.out.println(\"Let's inspect the beans provided by Spring Boot:\");\n\n        String[] beanNames = ctx.getBeanDefinitionNames();\n        Arrays.sort(beanNames);\n        for (String beanName : beanNames) {\n            System.out.println(beanName);\n        }\n    }\n\n}\n```\n`@SpringBootApplication`聚合了以下注解\n* `@Configuration` 标记该class为应用上下文的bean资源.\n* `@EnableAutoConfiguration` 该注解是让Spring自动从classpath, 其他beans以及配置文件中加载bean.\n* `@EnableWebMvc` 开启Spring的MVN功能, 但是当Spring Boot 在classpath中发现SpringMVN依赖后会自动开启该模块(依赖了`@EnableAutoConfiguration`). 这注解会将当前应用作为一个web应用启动.\n* `@ComponentScan` Spring 会在指定包下搜索components, configurations, 和services. 在本例中, 它会在hello包中所搜, 以及找到一个`HelloController`.\n\n标记Bean的注解\n* `@Configuration` 注解类等价与XML中配置beans.\n* `@Bean` 标注方法等价于XML中配置bean\n* `@Import`\n* `@DependsOn`\n* `@Component` : 通用注解, 可以用于注解任何bean.\n* `@Repository` : `Component`的子注解, 一般用来注解DAO类\n* `@Service` : `Component`的子注解, 一般用来注解Service类\n* `@Controller` : `Component`的子注解, 一般用来注解控制层\n* `@Scope` : 指定bean的作用域\n> `@Component`可以作为元注解去注解我们自定义的注解, 然后我们自定义的注解注解到类的时候, 也会被自动加载到SpringContext中.\n\n注入bean值的注解\n* `Required` 适用于bean属性的setter方法.\n* `Autowired` : 注入值. 可以用于属性, 方法, 构造器等.\n","source":"_posts/spring/spring boot.md","raw":"category: Spring\ndate: 2015-04-08\ntitle: SpringBoot\n---\nSpringBoot提供了一种快速构建应用的方式. 它会根据Classpath和beans上的现有配置来推测你缺少哪些配置, 从而将缺少的配置自动加载.\n\n```java\npackage hello;\n\nimport java.util.Arrays;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.ApplicationContext;\n\n@SpringBootApplication\npublic class Application {\n\n    public static void main(String[] args) {\n        ApplicationContext ctx = SpringApplication.run(Application.class, args);\n\n        System.out.println(\"Let's inspect the beans provided by Spring Boot:\");\n\n        String[] beanNames = ctx.getBeanDefinitionNames();\n        Arrays.sort(beanNames);\n        for (String beanName : beanNames) {\n            System.out.println(beanName);\n        }\n    }\n\n}\n```\n`@SpringBootApplication`聚合了以下注解\n* `@Configuration` 标记该class为应用上下文的bean资源.\n* `@EnableAutoConfiguration` 该注解是让Spring自动从classpath, 其他beans以及配置文件中加载bean.\n* `@EnableWebMvc` 开启Spring的MVN功能, 但是当Spring Boot 在classpath中发现SpringMVN依赖后会自动开启该模块(依赖了`@EnableAutoConfiguration`). 这注解会将当前应用作为一个web应用启动.\n* `@ComponentScan` Spring 会在指定包下搜索components, configurations, 和services. 在本例中, 它会在hello包中所搜, 以及找到一个`HelloController`.\n\n标记Bean的注解\n* `@Configuration` 注解类等价与XML中配置beans.\n* `@Bean` 标注方法等价于XML中配置bean\n* `@Import`\n* `@DependsOn`\n* `@Component` : 通用注解, 可以用于注解任何bean.\n* `@Repository` : `Component`的子注解, 一般用来注解DAO类\n* `@Service` : `Component`的子注解, 一般用来注解Service类\n* `@Controller` : `Component`的子注解, 一般用来注解控制层\n* `@Scope` : 指定bean的作用域\n> `@Component`可以作为元注解去注解我们自定义的注解, 然后我们自定义的注解注解到类的时候, 也会被自动加载到SpringContext中.\n\n注入bean值的注解\n* `Required` 适用于bean属性的setter方法.\n* `Autowired` : 注入值. 可以用于属性, 方法, 构造器等.\n","slug":"spring/spring boot","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1j00acvjs6tm0a1spa"},{"date":"2016-04-25T16:00:00.000Z","title":"ZooKeeper Curator 事件监听","_content":"## 监测时检查出已有节点\n```java\npackage zk;\n\nimport java.util.Date;\nimport java.util.concurrent.TimeUnit;\n\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.framework.recipes.cache.ChildData;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCache;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.curator.utils.CloseableUtils;\nimport org.apache.curator.utils.ZKPaths;\nimport org.apache.zookeeper.CreateMode;\n\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\t\tTimeUnit.SECONDS.sleep(10);\n\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(5);\n\t\tzkClient1.closeAllService();\n\t\tzkClient2.closeAllService();\n\t\tzkClient3.closeAllService();\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache1\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n\t\tsetValue(client, servername, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n输出结果为\n```bash\nServer1 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:41:54\nServer1 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer1 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer3 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09\nServer2 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09\nServer3 Monitor Node removed: /ServersCache1/Server2. 2016-4-28 18:42:09\n```\n\n## 删除节点监测\n```java\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache5\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n\t\tsetValue(client, servername, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(3);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tremove(client, servername);\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n输出结果为\n```bash\nServer1 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:13\nServer1 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer2 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer3 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer3 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer2 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer3 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\nServer1 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\nServer2 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\n```\n\n## 客户端网络断开监测\n```java\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tzkClient1.closeCuratorFramework();\n\t\tTimeUnit.SECONDS.sleep(1);\n\t\tzkClient2.closeCuratorFramework();\n\t\tTimeUnit.SECONDS.sleep(1);\n\t\tzkClient3.closeCuratorFramework();\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tzkClient1.closePathChildrenCache();\n\t\tzkClient2.closePathChildrenCache();\n\t\tzkClient3.closePathChildrenCache();\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache4\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n//\t\tremove(client, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n结果输出为\n```bash\nServer1 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:32\nServer1 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35\nServer1 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer2 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer1 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer3 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer2 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39\nServer3 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39\nServer3 Monitor Node removed: /ServersCache4/Server3. 2016-4-28 19:27:40\n```","source":"_posts/zookeeper/ZooKeeper Curator 事件监听.md","raw":"category: ZooKeeper\ndate: 2016-04-26\ntitle: ZooKeeper Curator 事件监听\n---\n## 监测时检查出已有节点\n```java\npackage zk;\n\nimport java.util.Date;\nimport java.util.concurrent.TimeUnit;\n\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.framework.recipes.cache.ChildData;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCache;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;\nimport org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.curator.utils.CloseableUtils;\nimport org.apache.curator.utils.ZKPaths;\nimport org.apache.zookeeper.CreateMode;\n\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\t\tTimeUnit.SECONDS.sleep(10);\n\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(5);\n\t\tzkClient1.closeAllService();\n\t\tzkClient2.closeAllService();\n\t\tzkClient3.closeAllService();\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache1\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n\t\tsetValue(client, servername, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n输出结果为\n```bash\nServer1 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:41:54\nServer1 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer1 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer3 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04\nServer2 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04\nServer3 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09\nServer2 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09\nServer3 Monitor Node removed: /ServersCache1/Server2. 2016-4-28 18:42:09\n```\n\n## 删除节点监测\n```java\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache5\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n\t\tsetValue(client, servername, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(3);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tremove(client, servername);\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n输出结果为\n```bash\nServer1 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:13\nServer1 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer2 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16\nServer3 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16\nServer2 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer3 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16\nServer1 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer3 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer2 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19\nServer3 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\nServer1 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\nServer2 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19\n```\n\n## 客户端网络断开监测\n```java\npublic class PathCacheExample {\n\n\tpublic static void main(String[] args) throws InterruptedException {\n\n\t\tZKClient zkClient1 = register(\"Server1\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tZKClient zkClient2 = register(\"Server2\");\n\t\tZKClient zkClient3 = register(\"Server3\");\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tzkClient1.closeCuratorFramework();\n\t\tTimeUnit.SECONDS.sleep(1);\n\t\tzkClient2.closeCuratorFramework();\n\t\tTimeUnit.SECONDS.sleep(1);\n\t\tzkClient3.closeCuratorFramework();\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t\tzkClient1.closePathChildrenCache();\n\t\tzkClient2.closePathChildrenCache();\n\t\tzkClient3.closePathChildrenCache();\n\t}\n\n\tpublic static ZKClient register(String serverName) throws InterruptedException {\n\t\tZKClient zkClient = new ZKClient(serverName);\n\t\tThread thread = new Thread(zkClient);\n\t\tthread.start();\n\t\treturn zkClient;\n\t}\n}\n\nclass ZKClient implements Runnable {\n\tprivate static final String PATH = \"/ServersCache4\";\n\n\tprivate CuratorFramework client = null;\n\tprivate PathChildrenCache cache = null;\n\tprivate String servername = null;\n\n\tpublic void closeAllService() {\n\t\tcloseCuratorFramework();\n\t\tclosePathChildrenCache();\n\t}\n\n\tpublic void closeCuratorFramework() {\n\t\tCloseableUtils.closeQuietly(client);\n\t}\n\n\tpublic void closePathChildrenCache() {\n\t\tCloseableUtils.closeQuietly(cache);\n\t}\n\n\tpublic ZKClient(String serverName) {\n\t\tthis.servername = serverName;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\t\t\tcache = new PathChildrenCache(client, PATH, true);\n\t\t\tcache.start();\n\t\t\taddListener(cache);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\tcreate(client, servername, servername);\n//\t\tremove(client, servername);\n\t\ttry {\n\t\t\tTimeUnit.SECONDS.sleep(1);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void addListener(PathChildrenCache cache) {\n\t\tPathChildrenCacheListener listener = (client, event) -> {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase CHILD_ADDED: {\n\t\t\t\t\tprintNodeStateChange(\"added\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_UPDATED: {\n\t\t\t\t\tprintNodeStateChange(\"changed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase CHILD_REMOVED: {\n\t\t\t\t\tprintNodeStateChange(\"removed\", event.getData().getPath());\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tcache.getListenable().addListener(listener);\n\t}\n\n\tprivate void printNodeStateChange(String type, String path) {\n\t\tSystem.out.println(servername + \" Monitor Node \" + type + \": \" + path + \". \" + new Date().toLocaleString());\n\t}\n\n\tprivate static void remove(CuratorFramework client, String pathName) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void create(CuratorFramework client, String pathName, String data)  {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void setValue(CuratorFramework client, String pathName, String data) {\n\t\tString path = ZKPaths.makePath(PATH, pathName);\n\t\ttry {\n\t\t\tclient.setData().forPath(path, data.getBytes());\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n结果输出为\n```bash\nServer1 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:32\nServer1 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35\nServer1 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer3 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35\nServer2 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35\nServer2 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer1 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer3 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38\nServer2 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39\nServer3 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39\nServer3 Monitor Node removed: /ServersCache4/Server3. 2016-4-28 19:27:40\n```","slug":"zookeeper/ZooKeeper Curator 事件监听","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1m00aevjs6ddn7w27i"},{"date":"2016-04-26T16:00:00.000Z","title":"ZooKeeper Curator 基本操作","_content":"Curator的Framework API为我们操作Zookeeper提供了非常便捷的操作. 它在ZooKeeper API之上为我们增加里许多新的特性, 例如对ZooKeeper集群连接的管理以及重试操作等等. 下面就列举了一些特性:\n\n* 自动连接管理\n* Leader 选举\n* 共享锁\n* 路径缓存以及watch\n* 分布式队列(以及分布式Priority队列)\n\n\n我们根据下面的例子看一下Curator Framework的增删改查操作\n```java\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.curator.utils.CloseableUtils;\nimport org.apache.zookeeper.CreateMode;\n\npublic class TestCurator {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tCuratorFramework client = null;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\n\t\t\t// 创建一个临时节点, 如果父节点不存在, 则将父节点也创建出来\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(\"/Servers/LoginServer\");\n\n\t\t\t// 查看根节点下的所有节点, 但是不会对子节点进行递归查询\n\t\t\tclient.getChildren().forPath(\"/\").forEach(path -> System.out.println(\"Exist : \" + path));\n\n\t\t\t// 设置数据\n\t\t\tclient.setData().forPath(\"/Servers/LoginServer\", \"192.168.15.15\".getBytes());\n\n\t\t\t// 获取节点数据\n\t\t\tSystem.out.println(\"Data : \" + client.getData().forPath(\"/Servers/LoginServer\"));\n\n\t\t\t// 将子节点和父节点一起删除\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(\"/Servers\");\n\n\t\t\t// 验证最后还有哪些节点存在\n\t\t\tclient.getChildren().forPath(\"/\").forEach(path -> System.out.println(\"Exist : \" + path));\n\t\t} finally {\n\t\t\tCloseableUtils.closeQuietly(client);\n\t\t}\n\t}\n}\n```\n结果为\n```bash\nExist : Servers\nExist : zookeeper\nData : [B@63753b6d\n```\n\n> 如果要异步执行的话, 只需要调用相关逻辑的background方法就好了\n\n我们使用的是Curator2.x版本\n```xml\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-framework</artifactId>\n    <version>2.10.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-recipes</artifactId>\n    <version>2.10.0</version>\n</dependency>\n```\n我们应该使用curator-framework, 而不是使用curator-client\n```xml\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-client</artifactId>\n    <version>2.10.0</version>\n</dependency>\n```\ncurator-client是对Zookepper官方API的一个简单封装, 如果我们使用curator-client, 还需要自己处理一些底层问题, 例如失败重连等问题\n```java\nRetryLoop retryLoop = client.newRetryLoop();\nwhile ( retryLoop.shouldContinue() )\n{\n   try\n   {\n       // perform your work\n       ...\n       // it's important to re\\-get the ZK instance as there may have been an error and the instance was re\\-created\n       ZooKeeper      zk = client.getZookeeper();\n       retryLoop.markComplete();\n   }\n   catch ( Exception e )\n   {\n       retryLoop.takeException(e);\n   }\n}\n```\n或者\n```java\nRetryLoop.callWithRetry(client, new Callable<Void>()\n{\n      @Override\n      public Void call() throws Exception\n      {\n          // do your work here - it will get retried if needed\n          return null;\n      }\n});\n```\n","source":"_posts/zookeeper/ZooKeeper Curator 基本操作.md","raw":"category: ZooKeeper\ndate: 2016-04-27\ntitle: ZooKeeper Curator 基本操作\n---\nCurator的Framework API为我们操作Zookeeper提供了非常便捷的操作. 它在ZooKeeper API之上为我们增加里许多新的特性, 例如对ZooKeeper集群连接的管理以及重试操作等等. 下面就列举了一些特性:\n\n* 自动连接管理\n* Leader 选举\n* 共享锁\n* 路径缓存以及watch\n* 分布式队列(以及分布式Priority队列)\n\n\n我们根据下面的例子看一下Curator Framework的增删改查操作\n```java\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\nimport org.apache.curator.utils.CloseableUtils;\nimport org.apache.zookeeper.CreateMode;\n\npublic class TestCurator {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tCuratorFramework client = null;\n\t\ttry {\n\t\t\tclient = CuratorFrameworkFactory.newClient(\"0.0.0.0:2181\", new ExponentialBackoffRetry(1000, 3));\n\t\t\tclient.start();\n\n\t\t\t// 创建一个临时节点, 如果父节点不存在, 则将父节点也创建出来\n\t\t\tclient.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(\"/Servers/LoginServer\");\n\n\t\t\t// 查看根节点下的所有节点, 但是不会对子节点进行递归查询\n\t\t\tclient.getChildren().forPath(\"/\").forEach(path -> System.out.println(\"Exist : \" + path));\n\n\t\t\t// 设置数据\n\t\t\tclient.setData().forPath(\"/Servers/LoginServer\", \"192.168.15.15\".getBytes());\n\n\t\t\t// 获取节点数据\n\t\t\tSystem.out.println(\"Data : \" + client.getData().forPath(\"/Servers/LoginServer\"));\n\n\t\t\t// 将子节点和父节点一起删除\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(\"/Servers\");\n\n\t\t\t// 验证最后还有哪些节点存在\n\t\t\tclient.getChildren().forPath(\"/\").forEach(path -> System.out.println(\"Exist : \" + path));\n\t\t} finally {\n\t\t\tCloseableUtils.closeQuietly(client);\n\t\t}\n\t}\n}\n```\n结果为\n```bash\nExist : Servers\nExist : zookeeper\nData : [B@63753b6d\n```\n\n> 如果要异步执行的话, 只需要调用相关逻辑的background方法就好了\n\n我们使用的是Curator2.x版本\n```xml\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-framework</artifactId>\n    <version>2.10.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-recipes</artifactId>\n    <version>2.10.0</version>\n</dependency>\n```\n我们应该使用curator-framework, 而不是使用curator-client\n```xml\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-client</artifactId>\n    <version>2.10.0</version>\n</dependency>\n```\ncurator-client是对Zookepper官方API的一个简单封装, 如果我们使用curator-client, 还需要自己处理一些底层问题, 例如失败重连等问题\n```java\nRetryLoop retryLoop = client.newRetryLoop();\nwhile ( retryLoop.shouldContinue() )\n{\n   try\n   {\n       // perform your work\n       ...\n       // it's important to re\\-get the ZK instance as there may have been an error and the instance was re\\-created\n       ZooKeeper      zk = client.getZookeeper();\n       retryLoop.markComplete();\n   }\n   catch ( Exception e )\n   {\n       retryLoop.takeException(e);\n   }\n}\n```\n或者\n```java\nRetryLoop.callWithRetry(client, new Callable<Void>()\n{\n      @Override\n      public Void call() throws Exception\n      {\n          // do your work here - it will get retried if needed\n          return null;\n      }\n});\n```\n","slug":"zookeeper/ZooKeeper Curator 基本操作","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1p00ahvjs6wxk2uo7h"},{"date":"2013-11-19T16:00:00.000Z","title":"ZooKeeper Java客户端","_content":"我们使用ZooKeeper官方java客户端进行测试,另外可以使用curator.\n\n我们使用Maven添加相关依赖\n```xml\n<dependency>\n\t<groupId>org.apache.zookeeper</groupId>\n\t<artifactId>zookeeper</artifactId>\n\t<version>3.4.8</version>\n</dependency>\n```\n\n## 创建节点\n然后我们向zk服务器上添加俩个节点\n```java\nimport org.apache.zookeeper.CreateMode;\nimport org.apache.zookeeper.KeeperException;\nimport org.apache.zookeeper.ZooDefs;\nimport org.apache.zookeeper.ZooKeeper;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.concurrent.TimeUnit;\n\npublic class CreateNode {\n\tprivate static final String ROOT_PATH = \"/Servers\";\n\tprivate static ZooKeeper zooKeeper;\n\n\tpublic static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n\t\t// 连接ZooKeeper服务器\n\t\tzooKeeper = new ZooKeeper(\"localhost:2181\", 15000, event -> {\n\t\t\t// TODO\n\t\t});\n\n\t\t// 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1\n\t\tzooKeeper.create(ROOT_PATH, // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\t// TODO\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 创建子节点\n\t\tzooKeeper.create(ROOT_PATH + \"/server1\", // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\t// TODO\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 获取节点下的所有子节点\n\t\tList<String> children = zooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t// TODO\n\t\t});\n\n\t\tchildren.forEach(child -> System.out.println(child));\n\n\t\tTimeUnit.SECONDS.sleep(1);\n\t}\n}\n```\n\n## watch\n```java\nimport org.apache.zookeeper.*;\n\nimport java.io.IOException;\nimport java.util.Random;\nimport java.util.concurrent.TimeUnit;\n\npublic class CreateNode {\n\tprivate static final String ROOT_PATH = \"/Servers\" + new Random().nextInt(100000);\n\tprivate static ZooKeeper zooKeeper;\n\n\tpublic static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n\t\t// 连接ZooKeeper服务器\n\t\tzooKeeper = new ZooKeeper(\"localhost:2181\", 15000, event -> {\n\t\t\tSystem.out.println(\"事件变化 : \" + event.getPath() + \" -> \" + event.getType());\n\t\t});\n\n\t\t// 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1\n\t\tzooKeeper.create(ROOT_PATH, // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\ttry {\n\t\t\t\t\t\tSystem.out.println(\"Create Node OK!\");\n\t\t\t\t\t\tzooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t\t\t\t\tSystem.out.println(\"Watch : \" + event.getPath() + \" -> \" + event.getType());\n\t\t\t\t\t\t});\n\t\t\t\t\t} catch (final Exception e) {\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 在创建上个node的时候, 由于注册watch是异步执行的, 因此需要在这里等待一下\n\t\tTimeUnit.SECONDS.sleep(3);\n\n\t\tzooKeeper.create(ROOT_PATH + \"/server1\", // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\ttry {\n\t\t\t\t\t\tSystem.out.println(\"Create Node OK!\");\n\t\t\t\t\t\tzooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t\t\t\t\tSystem.out.println(\"Watch : \" + event.getPath() + \" -> \" + event.getType());\n\t\t\t\t\t\t});\n\t\t\t\t\t} catch (final Exception e) {\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}, ROOT_PATH);\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n}\n```\n输出结果为\n```xml\n事件变化 : null -> None\nCreate Node OK!\nWatch : /Servers53734 -> NodeChildrenChanged\nCreate Node OK!\n```\n","source":"_posts/zookeeper/ZooKeeper Java客户端.md","raw":"category: ZooKeeper\ndate: 2013-11-20\ntitle: ZooKeeper Java客户端\n---\n我们使用ZooKeeper官方java客户端进行测试,另外可以使用curator.\n\n我们使用Maven添加相关依赖\n```xml\n<dependency>\n\t<groupId>org.apache.zookeeper</groupId>\n\t<artifactId>zookeeper</artifactId>\n\t<version>3.4.8</version>\n</dependency>\n```\n\n## 创建节点\n然后我们向zk服务器上添加俩个节点\n```java\nimport org.apache.zookeeper.CreateMode;\nimport org.apache.zookeeper.KeeperException;\nimport org.apache.zookeeper.ZooDefs;\nimport org.apache.zookeeper.ZooKeeper;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.concurrent.TimeUnit;\n\npublic class CreateNode {\n\tprivate static final String ROOT_PATH = \"/Servers\";\n\tprivate static ZooKeeper zooKeeper;\n\n\tpublic static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n\t\t// 连接ZooKeeper服务器\n\t\tzooKeeper = new ZooKeeper(\"localhost:2181\", 15000, event -> {\n\t\t\t// TODO\n\t\t});\n\n\t\t// 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1\n\t\tzooKeeper.create(ROOT_PATH, // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\t// TODO\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 创建子节点\n\t\tzooKeeper.create(ROOT_PATH + \"/server1\", // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\t// TODO\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 获取节点下的所有子节点\n\t\tList<String> children = zooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t// TODO\n\t\t});\n\n\t\tchildren.forEach(child -> System.out.println(child));\n\n\t\tTimeUnit.SECONDS.sleep(1);\n\t}\n}\n```\n\n## watch\n```java\nimport org.apache.zookeeper.*;\n\nimport java.io.IOException;\nimport java.util.Random;\nimport java.util.concurrent.TimeUnit;\n\npublic class CreateNode {\n\tprivate static final String ROOT_PATH = \"/Servers\" + new Random().nextInt(100000);\n\tprivate static ZooKeeper zooKeeper;\n\n\tpublic static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n\t\t// 连接ZooKeeper服务器\n\t\tzooKeeper = new ZooKeeper(\"localhost:2181\", 15000, event -> {\n\t\t\tSystem.out.println(\"事件变化 : \" + event.getPath() + \" -> \" + event.getType());\n\t\t});\n\n\t\t// 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1\n\t\tzooKeeper.create(ROOT_PATH, // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\ttry {\n\t\t\t\t\t\tSystem.out.println(\"Create Node OK!\");\n\t\t\t\t\t\tzooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t\t\t\t\tSystem.out.println(\"Watch : \" + event.getPath() + \" -> \" + event.getType());\n\t\t\t\t\t\t});\n\t\t\t\t\t} catch (final Exception e) {\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}, ROOT_PATH);\n\n\t\t// 在创建上个node的时候, 由于注册watch是异步执行的, 因此需要在这里等待一下\n\t\tTimeUnit.SECONDS.sleep(3);\n\n\t\tzooKeeper.create(ROOT_PATH + \"/server1\", // 节点路径\n\t\t\t\t\"create\".getBytes(), // 节点数据\n\t\t\t\tZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制)\n\t\t\t\tCreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点)\n\t\t\t\t(rc, path, ctx, name) -> { // 节点创建成功之后的回调函数\n\t\t\t\t\ttry {\n\t\t\t\t\t\tSystem.out.println(\"Create Node OK!\");\n\t\t\t\t\t\tzooKeeper.getChildren(ROOT_PATH, event -> {\n\t\t\t\t\t\t\tSystem.out.println(\"Watch : \" + event.getPath() + \" -> \" + event.getType());\n\t\t\t\t\t\t});\n\t\t\t\t\t} catch (final Exception e) {\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}, ROOT_PATH);\n\n\t\tTimeUnit.SECONDS.sleep(3);\n\t}\n}\n```\n输出结果为\n```xml\n事件变化 : null -> None\nCreate Node OK!\nWatch : /Servers53734 -> NodeChildrenChanged\nCreate Node OK!\n```\n","slug":"zookeeper/ZooKeeper Java客户端","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii1v00ajvjs6yi6q7t4o"},{"date":"2013-09-12T16:00:00.000Z","title":"ZooKeeper 原理","_content":"\n## 数据结构\nZookeeper 会维护一个类似于标准的文件系统的数据结构\n![]()\n\n\n## 节点类型\n* PERSISTENT：持久化目录节点，这个目录节点存储的数据不会丢失；\n* PERSISTENT_SEQUENTIAL：顺序自动编号的目录节点，这种目录节点会根据当前已近存在的节点数自动加 1，然后返回给客户端已经成功创建的目录节点名；\n* EPHEMERAL：临时目录节点，一旦创建这个节点的客户端与服务器端口也就是 session 超时，这种节点会被自动删除；\n* EPHEMERAL_SEQUENTIAL：临时自动编号节点\n\n## 权限控制\n\n\n## 选举","source":"_posts/zookeeper/ZooKeeper 原理.md","raw":"category: ZooKeeper\ndate: 2013-09-13\ntitle: ZooKeeper 原理\n---\n\n## 数据结构\nZookeeper 会维护一个类似于标准的文件系统的数据结构\n![]()\n\n\n## 节点类型\n* PERSISTENT：持久化目录节点，这个目录节点存储的数据不会丢失；\n* PERSISTENT_SEQUENTIAL：顺序自动编号的目录节点，这种目录节点会根据当前已近存在的节点数自动加 1，然后返回给客户端已经成功创建的目录节点名；\n* EPHEMERAL：临时目录节点，一旦创建这个节点的客户端与服务器端口也就是 session 超时，这种节点会被自动删除；\n* EPHEMERAL_SEQUENTIAL：临时自动编号节点\n\n## 权限控制\n\n\n## 选举","slug":"zookeeper/ZooKeeper 原理","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2000amvjs6rwlkibck"},{"date":"2013-11-19T16:00:00.000Z","title":"ZooKeeper 命令行客户端","_content":"我们执行\n```shell\nbin/zkCli.cmd -server 127.0.0.1:2181\n```\n就连接上了刚才启动的服务器,进入shell\n```shell\nE:\\zookeeper-3.4.6\\bin>.\\zkCli.cmd -server 127.0.0.1:2181\nConnecting to 127.0.0.1:2181\n2015-11-09 16:04:51,367 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT\n...\n2015-11-09 16:04:51,374 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=C:\\Users\\Administrator\n2015-11-09 16:04:51,374 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=E:\\zookeeper-3.4.6\\bin\n2015-11-09 16:04:51,375 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@277050dc\nWelcome to ZooKeeper!\n2015-11-09 16:04:51,514 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@975] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n2015-11-09 16:04:51,516 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@852] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session\n2015-11-09 16:04:51,684 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x150eb438ceb0000, negotiated timeout = 30000\n\nWATCHER::\n\nWatchedEvent state:SyncConnected type:None path:null\nJLine support is enabled\n[zk: 127.0.0.1:2181(CONNECTED) 0]\n```\n\n进入到shell之后,我们可以敲人`help`命令，查看我们都能使用哪些命令：\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 1] help\nZooKeeper -server host:port cmd args\n\tstat path [watch]\n\tset path data [version]\n\tls path [watch]\n\tdelquota [-n|-b] path\n\tls2 path [watch]\n\tsetAcl path acl\n\tsetquota -n|-b val path\n\thistory\n\tredo cmdno\n\tprintwatches on|off\n\tdelete path [version]\n\tsync path\n\tlistquota path\n\trmr path\n\tget path [watch]\n\tcreate [-s] [-e] path data acl\n\taddauth scheme auth\n\tquit\n\tgetAcl path\n\tclose\n\tconnect host:port\n[zk: 127.0.0.1:2181(CONNECTED) 2]\n```\n看到了,我们能使用这么多命令，下来我们简单的接受几个命令.\n\n我们使用`create`命令创建一个`znode`(这个node里和字符串\"my_data\"关联起来了).\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 1] create /zk_test my_data\nCreated /zk_test\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /\n[zookeeper, zk_test]\n[zk: 127.0.0.1:2181(CONNECTED) 4]\n```\n但是实际上，这个node还没有被创建出来.\n\n下来我们使用`get`命令验证一下`zk_test`是不是真的和\"my_data\"关联起来了\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 4] get /zk_test\nmy_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x3\nmtime = Mon Nov 09 16:29:12 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 7\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 5]\n```\n\n我们还可以使用`set`命令将刚才那个node重新关联\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 5] set /zk_test new_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x4\nmtime = Mon Nov 09 16:35:11 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 8\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 7] get /zk_test\nnew_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x4\nmtime = Mon Nov 09 16:35:11 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 8\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 8]\n```\n\n最后，我们将这个node删掉\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 9] delete /zk_test\n[zk: 127.0.0.1:2181(CONNECTED) 10] ls /\n[zookeeper]\n[zk: 127.0.0.1:2181(CONNECTED) 11]\n```\n","source":"_posts/zookeeper/ZooKeeper 命令行客户端.md","raw":"category: ZooKeeper\ndate: 2013-11-20\ntitle: ZooKeeper 命令行客户端\n---\n我们执行\n```shell\nbin/zkCli.cmd -server 127.0.0.1:2181\n```\n就连接上了刚才启动的服务器,进入shell\n```shell\nE:\\zookeeper-3.4.6\\bin>.\\zkCli.cmd -server 127.0.0.1:2181\nConnecting to 127.0.0.1:2181\n2015-11-09 16:04:51,367 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT\n...\n2015-11-09 16:04:51,374 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=C:\\Users\\Administrator\n2015-11-09 16:04:51,374 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=E:\\zookeeper-3.4.6\\bin\n2015-11-09 16:04:51,375 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@277050dc\nWelcome to ZooKeeper!\n2015-11-09 16:04:51,514 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@975] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n2015-11-09 16:04:51,516 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@852] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session\n2015-11-09 16:04:51,684 [myid:] - INFO  [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x150eb438ceb0000, negotiated timeout = 30000\n\nWATCHER::\n\nWatchedEvent state:SyncConnected type:None path:null\nJLine support is enabled\n[zk: 127.0.0.1:2181(CONNECTED) 0]\n```\n\n进入到shell之后,我们可以敲人`help`命令，查看我们都能使用哪些命令：\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 1] help\nZooKeeper -server host:port cmd args\n\tstat path [watch]\n\tset path data [version]\n\tls path [watch]\n\tdelquota [-n|-b] path\n\tls2 path [watch]\n\tsetAcl path acl\n\tsetquota -n|-b val path\n\thistory\n\tredo cmdno\n\tprintwatches on|off\n\tdelete path [version]\n\tsync path\n\tlistquota path\n\trmr path\n\tget path [watch]\n\tcreate [-s] [-e] path data acl\n\taddauth scheme auth\n\tquit\n\tgetAcl path\n\tclose\n\tconnect host:port\n[zk: 127.0.0.1:2181(CONNECTED) 2]\n```\n看到了,我们能使用这么多命令，下来我们简单的接受几个命令.\n\n我们使用`create`命令创建一个`znode`(这个node里和字符串\"my_data\"关联起来了).\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 1] create /zk_test my_data\nCreated /zk_test\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /\n[zookeeper, zk_test]\n[zk: 127.0.0.1:2181(CONNECTED) 4]\n```\n但是实际上，这个node还没有被创建出来.\n\n下来我们使用`get`命令验证一下`zk_test`是不是真的和\"my_data\"关联起来了\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 4] get /zk_test\nmy_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x3\nmtime = Mon Nov 09 16:29:12 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 7\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 5]\n```\n\n我们还可以使用`set`命令将刚才那个node重新关联\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 5] set /zk_test new_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x4\nmtime = Mon Nov 09 16:35:11 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 8\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 7] get /zk_test\nnew_data\ncZxid = 0x3\nctime = Mon Nov 09 16:29:12 CST 2015\nmZxid = 0x4\nmtime = Mon Nov 09 16:35:11 CST 2015\npZxid = 0x3\ncversion = 0\ndataVersion = 1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 8\nnumChildren = 0\n[zk: 127.0.0.1:2181(CONNECTED) 8]\n```\n\n最后，我们将这个node删掉\n```shell\n[zk: 127.0.0.1:2181(CONNECTED) 9] delete /zk_test\n[zk: 127.0.0.1:2181(CONNECTED) 10] ls /\n[zookeeper]\n[zk: 127.0.0.1:2181(CONNECTED) 11]\n```\n","slug":"zookeeper/ZooKeeper 命令行客户端","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2400aovjs6yq1x3194"},{"date":"2013-09-12T16:00:00.000Z","title":"ZooKeeper 服务器","_content":"演示windows系统下快速使用`Zookeeper3.4.6`版本\n\n## 单机模式\n我们从Zookeeper官网下载下其最新的压缩包之后,然后解压得到下面的目录：\n```shell\n├───bin\n├───conf\n├───contrib\n├───datadir\n├───dist-maven\n├───docs\n├───lib\n├───recipes\n└───src\n```\n> `datadir`是我自己创建的,用于存放内存数据的快照文件。\n\n1. 进入到`conf`目录，将`zoo_sample.cfg`修改为`zoo.cfg`文件\n2. 修改`zoo.cfg`文件内容,`dataDir=E:/zookeeper-3.4.6/datadir`这个是我修改过的路径\n3. 进入到`bin`目录, 执行`.\\zkServer.cmd start` .最后见到` Established session 0x150eb438ceb0000 with negotiated timeout 30000 for client /127.0.0.1:54408`就启动成功了\n\n> 如果遇到`java.lang.NumberFormatException: For input string: \"E:\\zookeeper-3.4.6\\bin\\..\\conf\\zoo.cfg\"`这个提示,那就要去修改`bin/zkServer.cmd`文件, 将`%*`这个去掉就好了\n\n```xml\ncall %JAVA% \"-Dzookeeper.log.dir=%ZOO_LOG_DIR%\" \"-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\" -cp \"%CLASSPATH%\" %ZOOMAIN% \"%ZOOCFG%\" %*\n```\n修改成\n```xml\ncall %JAVA% \"-Dzookeeper.log.dir=%ZOO_LOG_DIR%\" \"-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\" -cp \"%CLASSPATH%\" %ZOOMAIN% \"%ZOOCFG%\"\n```\n\n## 集群模式\n","source":"_posts/zookeeper/ZooKeeper 服务器.md","raw":"category: ZooKeeper\ndate: 2013-09-13\ntitle: ZooKeeper 服务器\n---\n演示windows系统下快速使用`Zookeeper3.4.6`版本\n\n## 单机模式\n我们从Zookeeper官网下载下其最新的压缩包之后,然后解压得到下面的目录：\n```shell\n├───bin\n├───conf\n├───contrib\n├───datadir\n├───dist-maven\n├───docs\n├───lib\n├───recipes\n└───src\n```\n> `datadir`是我自己创建的,用于存放内存数据的快照文件。\n\n1. 进入到`conf`目录，将`zoo_sample.cfg`修改为`zoo.cfg`文件\n2. 修改`zoo.cfg`文件内容,`dataDir=E:/zookeeper-3.4.6/datadir`这个是我修改过的路径\n3. 进入到`bin`目录, 执行`.\\zkServer.cmd start` .最后见到` Established session 0x150eb438ceb0000 with negotiated timeout 30000 for client /127.0.0.1:54408`就启动成功了\n\n> 如果遇到`java.lang.NumberFormatException: For input string: \"E:\\zookeeper-3.4.6\\bin\\..\\conf\\zoo.cfg\"`这个提示,那就要去修改`bin/zkServer.cmd`文件, 将`%*`这个去掉就好了\n\n```xml\ncall %JAVA% \"-Dzookeeper.log.dir=%ZOO_LOG_DIR%\" \"-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\" -cp \"%CLASSPATH%\" %ZOOMAIN% \"%ZOOCFG%\" %*\n```\n修改成\n```xml\ncall %JAVA% \"-Dzookeeper.log.dir=%ZOO_LOG_DIR%\" \"-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%\" -cp \"%CLASSPATH%\" %ZOOMAIN% \"%ZOOCFG%\"\n```\n\n## 集群模式\n","slug":"zookeeper/ZooKeeper 服务器","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2800arvjs65nocmulr"},{"date":"2015-10-11T16:00:00.000Z","title":"双线程锁","_content":"所谓的双线程锁指的是这种锁适用于俩个线程运行的前提下. 下面我们依次给出了三种双线程锁解决方案：\n\n双线程算法遵循以下俩点约定:\n1. 线程标志为`0`或者`1`. 若当前线程调用者的标志为i,则另一方的调用者为1 - i\n2. 通过ThreadId.get()获取自己的标志\n\n* 互斥: 俩个线程的临界区是没有重叠的,那么我们撑这俩个临界区是互斥的.\n* 无死锁: 如果一个线程尝试获得一个锁,那么总会成功获得这个锁.\n* 无饥饿：每一个尝试获得锁的线程都能成功. 当线程调用一个锁方法的时候,这个方法立即返回,我们便称这个锁是无饥饿的.\n\n## LockOne\n```java\nclass LockOne {\n\tprivate volatile boolean[] flags = new boolean[2];\n\tpublic void lock() {\n\t\tint i = ThreadID.get();\n\t\tint j = 1- i;\n\t\tflag[i] = true;\n\t\twhile(flag[j]) {}\t\t\n\n\t}\n\n\tpublic void unlock() {\n\t\tint i = ThreadID.get();\n\t\tflag[i] = false;\n\t}\n}\n```\n\n假设线程A对应flag[0]标志,线程B对应flag[1]标志,那么我们得出下面这一个流程:\n1. `write_A(flag[0] = true) -> read_A(flag[1] == false) -> CS_A`这段话的意思是线程A将`flag[0]`的值置为true然后读取`flag[1]`的值,这个过程称为`CS_A`事件\n2. `write_B(flag[1] = true) -> read_B(flag[0] == false) -> CS_B`这段话的意思是线程B将`flag[1]`的值置为true然后读取`flag[0]`的值,这个过程称为`CS_B`事件\n\n> 我们验证一下LockOne算法是否满足互斥\n```java\n假设这个算法不是互斥的，也就是无法得到`CS_A -> CS_B`且`CS_B -> CS_A`.\n假设CS_A事件先于CS_B事件,那么有：\nwrite_A(flag[0] = true) -> read_A(flag[1] == false) -> write_B(flag[1] = true)\n=>\nread_A(flag[1] == false) -> write_B(flag[1] = true)\n可以看到这俩个事件是互斥的(它们的临界区是没有重叠的).\n```\nLockOne算法满足了互斥,但是如果俩个线程并发执行的话，就会进入死锁,同样我们来证明一下\n```java\n假设\nwrite_A(flag[0] = true) -> write_B(flag[1] = true) -> read_A(flag[1] == false) -> read_B(flag[0] == false)\n那么`flag[0]`和`flag[1]`就都成为true,也就是线程A和线程B进入了死锁.\n```\n\n至于说为什么要使用`volatile`关键字,这是为了保证`flags`变量的内存可见性,因为Java会将这段代码\n```java\nwhile(flag[j]) {}\n=>\nif(flag[j]) {\n\twhile(true) {\n\n\t}\n}\n```\n编译后的代码进行了提升优化,加上`volatile`关键字,就是告诉编译器,不要提升优化我的代码.\n\n## LockTwo\n```java\nclass LockTwo {\n\tprivate int lock;\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\twhile(lock == tid){}\n\t}\n\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\n\t}\n}\n```\n\n同样我们假设有俩个事件发生\n1. `write_A(lock = 1) -> read_A(lock == 1) -> CS_A`\n2. `write_B(lock = 2) -> read_B(lock == 2) -> CS_B`\n很明显任何线程调用加锁操作都会造成死循环. 但是,如果锁调用交叉调用的话\n```java\nwrite_A(lock = 1) -> write_B(lock = 2) -> read_A(lock == 2) -> read_B(lock == 2)\n```\n直到A线程释放锁,B线程就一直在阻塞着. 因此只要这俩个事件并发执行就能完成互斥要求.\n\n## Peterson\n算法实现\n```java\nclass Peterson {\n\tprivate voliate boolean[] flag = new boolean[2];\n\tprivate int lock;\n\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tint oid = 1 - tid;\n\t\tflag[oid] = true;\n\t\tlock = tid;\n\n\t\twhile(flag[tid] && lock == tid) {}\n\t}\n\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tflag[tid] = false;\n\t}\n}\n```\n同样的我们看看俩个线程依次调用锁过程(假设线程A对应flag[0]标志,线程B对应flag[1]标志)：\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> read_A(flag[0] == false) -> read_A(lock == 0) -> CS_A\nwrite_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> CS_B\n```\n好，首先我们看一下\n* `CS_A`先于`CS_B`事件执行的话,那么B线程会进入锁等待.\n\n`CS_A`和`CS_B`事件并发执行我们分俩种情况分析：\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_A(flag[1] == true) -> read_A(lock == 0) -> read_B(flag[1] == true) -> read_B(lock == 1)\n```\n同样的A线程事件先于B线程事件,我们看到A线程并没有进入锁等待,而是B线程进入了锁等待\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> read_A(flag[1] == true) -> read_A(lock == 0)\n```\n我们发现这个锁算法仍然是有问题的.\n","source":"_posts/并发编程/1_1_双线程锁.md","raw":"category: 并发编程\ndate: 2015-10-12\ntitle: 双线程锁\n---\n所谓的双线程锁指的是这种锁适用于俩个线程运行的前提下. 下面我们依次给出了三种双线程锁解决方案：\n\n双线程算法遵循以下俩点约定:\n1. 线程标志为`0`或者`1`. 若当前线程调用者的标志为i,则另一方的调用者为1 - i\n2. 通过ThreadId.get()获取自己的标志\n\n* 互斥: 俩个线程的临界区是没有重叠的,那么我们撑这俩个临界区是互斥的.\n* 无死锁: 如果一个线程尝试获得一个锁,那么总会成功获得这个锁.\n* 无饥饿：每一个尝试获得锁的线程都能成功. 当线程调用一个锁方法的时候,这个方法立即返回,我们便称这个锁是无饥饿的.\n\n## LockOne\n```java\nclass LockOne {\n\tprivate volatile boolean[] flags = new boolean[2];\n\tpublic void lock() {\n\t\tint i = ThreadID.get();\n\t\tint j = 1- i;\n\t\tflag[i] = true;\n\t\twhile(flag[j]) {}\t\t\n\n\t}\n\n\tpublic void unlock() {\n\t\tint i = ThreadID.get();\n\t\tflag[i] = false;\n\t}\n}\n```\n\n假设线程A对应flag[0]标志,线程B对应flag[1]标志,那么我们得出下面这一个流程:\n1. `write_A(flag[0] = true) -> read_A(flag[1] == false) -> CS_A`这段话的意思是线程A将`flag[0]`的值置为true然后读取`flag[1]`的值,这个过程称为`CS_A`事件\n2. `write_B(flag[1] = true) -> read_B(flag[0] == false) -> CS_B`这段话的意思是线程B将`flag[1]`的值置为true然后读取`flag[0]`的值,这个过程称为`CS_B`事件\n\n> 我们验证一下LockOne算法是否满足互斥\n```java\n假设这个算法不是互斥的，也就是无法得到`CS_A -> CS_B`且`CS_B -> CS_A`.\n假设CS_A事件先于CS_B事件,那么有：\nwrite_A(flag[0] = true) -> read_A(flag[1] == false) -> write_B(flag[1] = true)\n=>\nread_A(flag[1] == false) -> write_B(flag[1] = true)\n可以看到这俩个事件是互斥的(它们的临界区是没有重叠的).\n```\nLockOne算法满足了互斥,但是如果俩个线程并发执行的话，就会进入死锁,同样我们来证明一下\n```java\n假设\nwrite_A(flag[0] = true) -> write_B(flag[1] = true) -> read_A(flag[1] == false) -> read_B(flag[0] == false)\n那么`flag[0]`和`flag[1]`就都成为true,也就是线程A和线程B进入了死锁.\n```\n\n至于说为什么要使用`volatile`关键字,这是为了保证`flags`变量的内存可见性,因为Java会将这段代码\n```java\nwhile(flag[j]) {}\n=>\nif(flag[j]) {\n\twhile(true) {\n\n\t}\n}\n```\n编译后的代码进行了提升优化,加上`volatile`关键字,就是告诉编译器,不要提升优化我的代码.\n\n## LockTwo\n```java\nclass LockTwo {\n\tprivate int lock;\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\twhile(lock == tid){}\n\t}\n\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\n\t}\n}\n```\n\n同样我们假设有俩个事件发生\n1. `write_A(lock = 1) -> read_A(lock == 1) -> CS_A`\n2. `write_B(lock = 2) -> read_B(lock == 2) -> CS_B`\n很明显任何线程调用加锁操作都会造成死循环. 但是,如果锁调用交叉调用的话\n```java\nwrite_A(lock = 1) -> write_B(lock = 2) -> read_A(lock == 2) -> read_B(lock == 2)\n```\n直到A线程释放锁,B线程就一直在阻塞着. 因此只要这俩个事件并发执行就能完成互斥要求.\n\n## Peterson\n算法实现\n```java\nclass Peterson {\n\tprivate voliate boolean[] flag = new boolean[2];\n\tprivate int lock;\n\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tint oid = 1 - tid;\n\t\tflag[oid] = true;\n\t\tlock = tid;\n\n\t\twhile(flag[tid] && lock == tid) {}\n\t}\n\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tflag[tid] = false;\n\t}\n}\n```\n同样的我们看看俩个线程依次调用锁过程(假设线程A对应flag[0]标志,线程B对应flag[1]标志)：\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> read_A(flag[0] == false) -> read_A(lock == 0) -> CS_A\nwrite_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> CS_B\n```\n好，首先我们看一下\n* `CS_A`先于`CS_B`事件执行的话,那么B线程会进入锁等待.\n\n`CS_A`和`CS_B`事件并发执行我们分俩种情况分析：\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_A(flag[1] == true) -> read_A(lock == 0) -> read_B(flag[1] == true) -> read_B(lock == 1)\n```\n同样的A线程事件先于B线程事件,我们看到A线程并没有进入锁等待,而是B线程进入了锁等待\n```java\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> read_A(flag[1] == true) -> read_A(lock == 0)\n```\n我们发现这个锁算法仍然是有问题的.\n","slug":"并发编程/1_1_双线程锁","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2c00atvjs6qve6vovk"},{"date":"2015-09-07T16:00:00.000Z","title":"IO","_content":"\n## IO概念\nlinux内核将内分分成内核区和用户区俩个区域：\n1. 用户区进程A向内核发起一个读文件的系统调用(进程A阻塞)\n2. linux在内核区生成一个文件句柄fd(该文件句柄指向了一个内核缓冲区)\n3. linux通过驱动程序向磁盘读取指定文件\n4. 驱动程序将读取到的数据存储在内核区的缓冲区内\n5. 当内核缓冲区的大小大于进程A设置的读取文件的大小时发生读就绪,内核缓冲区的数据刷新到用户区内\n\n## IO类型\n\n### 阻塞IO\n在进程空间中调用recvfrom,其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回,期间一直在等待.我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的.\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n这种情况下用户空间的进程不断地向内核空间轮询是否有数据到达,如果没有达到不进入阻塞(睡眠)而是直接返回一个错误.\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n这种操作效率是及其低下的,因为它把密集型IO操作变成了IO密集和计算密集的操作.\n\n### SIGIO\n首先开启套接口信号驱动I/O功能,并通过系统调用sigaction安装一个信号处理函数(此系统调用立即返回,进程继续工作,它是非阻塞的).当数据报准备好被读时,就为该进程生成一个SIGIO信号.随即可以在信号处理程序中调用recvfrom来读数据报,井通知主循环数据已准备好被处理中.也可以通知主循环,让它来读数据报.\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### IO复用\n在`select/poll`上注册多个`fd`, 然后`select/poll`顺序轮询所有的`fd`,如果轮询到某个`fd`读就绪或者写就绪就取出该`fd`进行读写数据,但是由于`select/poll`支持的`fd`数量有限而且是顺序扫描的,因此它的性能仍然会达不到要求. 于是`epoll`出现了,它是基于事件驱动方式,而不是顺序扫描,当有fd就绪时,立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n### windows的IOCP\n告知内核启动某个操作,并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们.这种模型与信号驱动模型的主要区别是：\n* 信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；\n* 异步I/O模型：由内核通知我们I/O操作何时完成.\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝.可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上,数据无需流经应用程序.本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销,然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能.\n\n\n### 传统方法数据传输\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换.在内部,发出 `sys_read()`(或等效内容)以从文件中读取数据.直接内存存取(`direct memory access`,DMA)引擎执行了第一次拷贝,它从磁盘中读取文件内容,然后将它们存储到一个内核地址空间缓存区中.\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区,read() 调用返回.该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换).现在数据被储存在用户地址空间缓冲区.\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换.数据被第三次拷贝,并被再次放置在内核地址空间缓冲区.但是这一次放置的缓冲区不同,该缓冲区与目标套接字相关联.\n4. `send()` 系统调用返回,结果导致了第四次的上下文切换.DMA 引擎将数据从内核缓冲区传到协议引擎,第四次拷贝独立地、异步地发生 .\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下.但是之所以引入中间内核缓冲区的目的是想提高性能.在读取方面使用中间内核缓冲区,可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时,充当 “预读高速缓存(readahead cache)” 的角色.这在所需数据量小于内核缓冲区大小时极大地提高了性能.在写入方面的中间缓冲区则可以让写入过程异步完成.\n\n不幸的是,如果所需数据量远大于内核缓冲区大小的话,这个方法本身可能成为一个性能瓶颈.数据在被最终传入到应用程序前,在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次.零拷贝通过消除这些冗余的数据拷贝而提高了性能.\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区.然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区.\n\n2. 数据的第三次复制发生在DMA引擎将数据从内核套接字缓冲区传到协议引擎时.改进的地方：我们将上下文切换的次数从四次减少到了两次,将数据复制的次数从四次减少到了三次(其中只有一次涉及到了CPU).但是这个代码尚未达到我们的零拷贝要求.如果底层网络接口卡支持收集操作的话,那么我们就可以进一步减少内核的数据复制.在Linux内核2.4及后期版本中,套接字缓冲区描述符就做了相应调整,以满足该需求.这种方法不仅可以减少多个上下文切换,还可以消除需要涉及CPU的重复的数据拷贝.对于用户方面,用法还是一样的,但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区.\nB. 数据未被拷贝到套接字缓冲区.取而代之的是,只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区.DMA 引擎直接把数据从内核缓冲区传输到协议引擎,从而消除了剩下的最后一次 CPU 拷贝.\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n","source":"_posts/操作系统/io.md","raw":"category: 操作系统\ndate: 2015-09-08\ntitle: IO\n---\n\n## IO概念\nlinux内核将内分分成内核区和用户区俩个区域：\n1. 用户区进程A向内核发起一个读文件的系统调用(进程A阻塞)\n2. linux在内核区生成一个文件句柄fd(该文件句柄指向了一个内核缓冲区)\n3. linux通过驱动程序向磁盘读取指定文件\n4. 驱动程序将读取到的数据存储在内核区的缓冲区内\n5. 当内核缓冲区的大小大于进程A设置的读取文件的大小时发生读就绪,内核缓冲区的数据刷新到用户区内\n\n## IO类型\n\n### 阻塞IO\n在进程空间中调用recvfrom,其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回,期间一直在等待.我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的.\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n这种情况下用户空间的进程不断地向内核空间轮询是否有数据到达,如果没有达到不进入阻塞(睡眠)而是直接返回一个错误.\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n这种操作效率是及其低下的,因为它把密集型IO操作变成了IO密集和计算密集的操作.\n\n### SIGIO\n首先开启套接口信号驱动I/O功能,并通过系统调用sigaction安装一个信号处理函数(此系统调用立即返回,进程继续工作,它是非阻塞的).当数据报准备好被读时,就为该进程生成一个SIGIO信号.随即可以在信号处理程序中调用recvfrom来读数据报,井通知主循环数据已准备好被处理中.也可以通知主循环,让它来读数据报.\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### IO复用\n在`select/poll`上注册多个`fd`, 然后`select/poll`顺序轮询所有的`fd`,如果轮询到某个`fd`读就绪或者写就绪就取出该`fd`进行读写数据,但是由于`select/poll`支持的`fd`数量有限而且是顺序扫描的,因此它的性能仍然会达不到要求. 于是`epoll`出现了,它是基于事件驱动方式,而不是顺序扫描,当有fd就绪时,立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n### windows的IOCP\n告知内核启动某个操作,并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们.这种模型与信号驱动模型的主要区别是：\n* 信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；\n* 异步I/O模型：由内核通知我们I/O操作何时完成.\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝.可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上,数据无需流经应用程序.本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销,然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能.\n\n\n### 传统方法数据传输\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换.在内部,发出 `sys_read()`(或等效内容)以从文件中读取数据.直接内存存取(`direct memory access`,DMA)引擎执行了第一次拷贝,它从磁盘中读取文件内容,然后将它们存储到一个内核地址空间缓存区中.\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区,read() 调用返回.该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换).现在数据被储存在用户地址空间缓冲区.\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换.数据被第三次拷贝,并被再次放置在内核地址空间缓冲区.但是这一次放置的缓冲区不同,该缓冲区与目标套接字相关联.\n4. `send()` 系统调用返回,结果导致了第四次的上下文切换.DMA 引擎将数据从内核缓冲区传到协议引擎,第四次拷贝独立地、异步地发生 .\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下.但是之所以引入中间内核缓冲区的目的是想提高性能.在读取方面使用中间内核缓冲区,可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时,充当 “预读高速缓存(readahead cache)” 的角色.这在所需数据量小于内核缓冲区大小时极大地提高了性能.在写入方面的中间缓冲区则可以让写入过程异步完成.\n\n不幸的是,如果所需数据量远大于内核缓冲区大小的话,这个方法本身可能成为一个性能瓶颈.数据在被最终传入到应用程序前,在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次.零拷贝通过消除这些冗余的数据拷贝而提高了性能.\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区.然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区.\n\n2. 数据的第三次复制发生在DMA引擎将数据从内核套接字缓冲区传到协议引擎时.改进的地方：我们将上下文切换的次数从四次减少到了两次,将数据复制的次数从四次减少到了三次(其中只有一次涉及到了CPU).但是这个代码尚未达到我们的零拷贝要求.如果底层网络接口卡支持收集操作的话,那么我们就可以进一步减少内核的数据复制.在Linux内核2.4及后期版本中,套接字缓冲区描述符就做了相应调整,以满足该需求.这种方法不仅可以减少多个上下文切换,还可以消除需要涉及CPU的重复的数据拷贝.对于用户方面,用法还是一样的,但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区.\nB. 数据未被拷贝到套接字缓冲区.取而代之的是,只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区.DMA 引擎直接把数据从内核缓冲区传输到协议引擎,从而消除了剩下的最后一次 CPU 拷贝.\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n","slug":"操作系统/io","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2g00awvjs6wlrcc6ew"},{"date":"2015-10-14T16:00:00.000Z","title":"自旋锁","_content":"# 自旋锁spinlock\n自旋锁是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。\n自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。\nSimpleSpinLock里有一个owner属性持有锁当前拥有者的线程的引用，如果该引用为null，则表示锁未被占用，不为null则被占用。\n这里用AtomicReference是为了使用它的原子性的compareAndSet方法（CAS操作），\n解决了多线程并发操作导致数据不一致的问题，确保其他线程可以看到锁的真实状态。\n缺点\nCAS操作需要硬件的配合；\n保证各个CPU的缓存（L1、L2、L3、跨CPU Socket、主存）的数据一致性，通讯开销很大，在多处理器系统上更严重；\n没法保证公平性，不保证等待进程/线程按照FIFO顺序获得锁。\n\n```java\npublic class Spinlock {\n\tprivate AtomicReference<Thread> owner = new AtomicReference<Thread>();\n\n\tpublic void lock() {\n\t\tThread currentThread = Thread.currentThread();\n\n\t\t// 如果锁未被占用，则设置当前线程为锁的拥有者\n\t\twhile (owner.compareAndSet(null, currentThread)) {\n\t\t}\n\t}\n\n\tpublic void unlock() {\n\t\tThread currentThread = Thread.currentThread();\n\n\t\t// 只有锁的拥有者才能释放锁\n\t\towner.compareAndSet(currentThread, null);\n\t}\n}\n```\n\n\n# TicketSpinLock\n\nTicket Lock 是为了解决上面的公平性问题，类似于现实中银行柜台的排队叫号：\n锁拥有一个服务号，表示正在服务的线程，还有一个排队号；每个线程尝试获取锁之前先拿一个排队号，\n然后不断轮询锁的当前服务号是否是自己的排队号，如果是，则表示自己拥有了锁，不是则继续轮询。\n\n当线程释放锁时，将服务号加1，这样下一个线程看到这个变化，就退出自旋。\nTicket Lock 虽然解决了公平性的问题，但是多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，\n每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。\n\n```java\n\npublic class TicketSpinLock {\n   private AtomicInteger serviceNum = new AtomicInteger(); // 服务号\n   private AtomicInteger ticketNum = new AtomicInteger(); // 排队号\n\n   public int lock() {\n         // 首先原子性地获得一个排队号\n         int myTicketNum = ticketNum.getAndIncrement();\n\n              // 只要当前服务号不是自己的就不断轮询\n       while (serviceNum.get() != myTicketNum) {\n       }\n\n       return myTicketNum;\n    }\n\n    public void unlock(int myTicket) {\n        // 只有当前线程拥有者才能释放锁\n        int next = myTicket + 1;\n        serviceNum.compareAndSet(myTicket, next);\n    }\n}\n```\n# CLHSpinLock\n\nCLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，\n它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。\n *\n差异：\n *\n 从代码实现来看，CLH比MCS要简单得多。\n 从自旋的条件来看，CLH是在本地变量上自旋，MCS是自旋在其他对象的属性。\n 从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。\n CLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。\n 注意：这里实现的锁都是独占的，且不能重入的。\n\n ```java\n public class CLHSpinLock {\n\tpublic static class CLHNode {\n\t\tprivate boolean isLocked = true; // 默认是在等待锁\n\t}\n\n\t@SuppressWarnings(\"unused\")\n\tprivate volatile CLHNode tail;\n\tprivate static final AtomicReferenceFieldUpdater<CLHSpinLock, CLHNode> UPDATER = AtomicReferenceFieldUpdater\n\t\t\t.newUpdater(CLHSpinLock.class, CLHNode.class, \"tail\");\n\n\tpublic void lock(CLHNode currentThread) {\n\t\tCLHNode preNode = UPDATER.getAndSet(this, currentThread);\n\t\tif (preNode != null) {// 已有线程占用了锁，进入自旋\n\t\t\twhile (preNode.isLocked) {\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void unlock(CLHNode currentThread) {\n\t\t// 如果队列里只有当前线程，则释放对当前线程的引用（for GC）。\n\t\tif (!UPDATER.compareAndSet(this, currentThread, null)) {\n\t\t\t// 还有后续线程\n\t\t\tcurrentThread.isLocked = false;// 改变状态，让后续线程结束自旋\n\t\t}\n\t}\n}\n```\n# MCSSpinLock\n\nMCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。\n\n```java\npublic class MCSSpinLock {\n\tpublic static class MCSNode {\n\t\tvolatile MCSNode next;\n\t\tvolatile boolean isLocked = true; // 默认是在等待锁\n\t}\n\n\tvolatile MCSNode queue;// 指向最后一个申请锁的MCSNode\n\tprivate static final AtomicReferenceFieldUpdater<MCSSpinLock, MCSNode> UPDATER = AtomicReferenceFieldUpdater\n\t\t\t.newUpdater(MCSSpinLock.class, MCSNode.class, \"queue\");\n\n\tpublic void lock(MCSNode currentThread) {\n\t\tMCSNode predecessor = UPDATER.getAndSet(this, currentThread);// step 1\n\t\tif (predecessor != null) {\n\t\t\tpredecessor.next = currentThread;// step 2\n\n\t\t\twhile (currentThread.isLocked) {// step 3\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void unlock(MCSNode currentThread) {\n\t\tif (UPDATER.get(this) == currentThread) {// 锁拥有者进行释放锁才有意义\n\t\t\tif (currentThread.next == null) {// 检查是否有人排在自己后面\n\t\t\t\tif (UPDATER.compareAndSet(this, currentThread, null)) {// step 4\n\t\t\t\t\t// compareAndSet返回true表示确实没有人排在自己后面\n\t\t\t\t\treturn;\n\t\t\t\t} else {\n\t\t\t\t\t// 突然有人排在自己后面了，可能还不知道是谁，下面是等待后续者\n\t\t\t\t\t// 这里之所以要忙等是因为：step 1执行完后，step 2可能还没执行完\n\t\t\t\t\twhile (currentThread.next == null) { // step 5\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcurrentThread.next.isLocked = false;\n\t\t\tcurrentThread.next = null;// for GC\n\t\t}\n\t}\n}\n\n```\n\n","source":"_posts/并发编程/自旋锁.md","raw":"category: 并发编程\ndate: 2015-10-15\ntitle: 自旋锁\n---\n# 自旋锁spinlock\n自旋锁是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。\n自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。\nSimpleSpinLock里有一个owner属性持有锁当前拥有者的线程的引用，如果该引用为null，则表示锁未被占用，不为null则被占用。\n这里用AtomicReference是为了使用它的原子性的compareAndSet方法（CAS操作），\n解决了多线程并发操作导致数据不一致的问题，确保其他线程可以看到锁的真实状态。\n缺点\nCAS操作需要硬件的配合；\n保证各个CPU的缓存（L1、L2、L3、跨CPU Socket、主存）的数据一致性，通讯开销很大，在多处理器系统上更严重；\n没法保证公平性，不保证等待进程/线程按照FIFO顺序获得锁。\n\n```java\npublic class Spinlock {\n\tprivate AtomicReference<Thread> owner = new AtomicReference<Thread>();\n\n\tpublic void lock() {\n\t\tThread currentThread = Thread.currentThread();\n\n\t\t// 如果锁未被占用，则设置当前线程为锁的拥有者\n\t\twhile (owner.compareAndSet(null, currentThread)) {\n\t\t}\n\t}\n\n\tpublic void unlock() {\n\t\tThread currentThread = Thread.currentThread();\n\n\t\t// 只有锁的拥有者才能释放锁\n\t\towner.compareAndSet(currentThread, null);\n\t}\n}\n```\n\n\n# TicketSpinLock\n\nTicket Lock 是为了解决上面的公平性问题，类似于现实中银行柜台的排队叫号：\n锁拥有一个服务号，表示正在服务的线程，还有一个排队号；每个线程尝试获取锁之前先拿一个排队号，\n然后不断轮询锁的当前服务号是否是自己的排队号，如果是，则表示自己拥有了锁，不是则继续轮询。\n\n当线程释放锁时，将服务号加1，这样下一个线程看到这个变化，就退出自旋。\nTicket Lock 虽然解决了公平性的问题，但是多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，\n每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。\n\n```java\n\npublic class TicketSpinLock {\n   private AtomicInteger serviceNum = new AtomicInteger(); // 服务号\n   private AtomicInteger ticketNum = new AtomicInteger(); // 排队号\n\n   public int lock() {\n         // 首先原子性地获得一个排队号\n         int myTicketNum = ticketNum.getAndIncrement();\n\n              // 只要当前服务号不是自己的就不断轮询\n       while (serviceNum.get() != myTicketNum) {\n       }\n\n       return myTicketNum;\n    }\n\n    public void unlock(int myTicket) {\n        // 只有当前线程拥有者才能释放锁\n        int next = myTicket + 1;\n        serviceNum.compareAndSet(myTicket, next);\n    }\n}\n```\n# CLHSpinLock\n\nCLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，\n它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。\n *\n差异：\n *\n 从代码实现来看，CLH比MCS要简单得多。\n 从自旋的条件来看，CLH是在本地变量上自旋，MCS是自旋在其他对象的属性。\n 从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。\n CLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。\n 注意：这里实现的锁都是独占的，且不能重入的。\n\n ```java\n public class CLHSpinLock {\n\tpublic static class CLHNode {\n\t\tprivate boolean isLocked = true; // 默认是在等待锁\n\t}\n\n\t@SuppressWarnings(\"unused\")\n\tprivate volatile CLHNode tail;\n\tprivate static final AtomicReferenceFieldUpdater<CLHSpinLock, CLHNode> UPDATER = AtomicReferenceFieldUpdater\n\t\t\t.newUpdater(CLHSpinLock.class, CLHNode.class, \"tail\");\n\n\tpublic void lock(CLHNode currentThread) {\n\t\tCLHNode preNode = UPDATER.getAndSet(this, currentThread);\n\t\tif (preNode != null) {// 已有线程占用了锁，进入自旋\n\t\t\twhile (preNode.isLocked) {\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void unlock(CLHNode currentThread) {\n\t\t// 如果队列里只有当前线程，则释放对当前线程的引用（for GC）。\n\t\tif (!UPDATER.compareAndSet(this, currentThread, null)) {\n\t\t\t// 还有后续线程\n\t\t\tcurrentThread.isLocked = false;// 改变状态，让后续线程结束自旋\n\t\t}\n\t}\n}\n```\n# MCSSpinLock\n\nMCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。\n\n```java\npublic class MCSSpinLock {\n\tpublic static class MCSNode {\n\t\tvolatile MCSNode next;\n\t\tvolatile boolean isLocked = true; // 默认是在等待锁\n\t}\n\n\tvolatile MCSNode queue;// 指向最后一个申请锁的MCSNode\n\tprivate static final AtomicReferenceFieldUpdater<MCSSpinLock, MCSNode> UPDATER = AtomicReferenceFieldUpdater\n\t\t\t.newUpdater(MCSSpinLock.class, MCSNode.class, \"queue\");\n\n\tpublic void lock(MCSNode currentThread) {\n\t\tMCSNode predecessor = UPDATER.getAndSet(this, currentThread);// step 1\n\t\tif (predecessor != null) {\n\t\t\tpredecessor.next = currentThread;// step 2\n\n\t\t\twhile (currentThread.isLocked) {// step 3\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void unlock(MCSNode currentThread) {\n\t\tif (UPDATER.get(this) == currentThread) {// 锁拥有者进行释放锁才有意义\n\t\t\tif (currentThread.next == null) {// 检查是否有人排在自己后面\n\t\t\t\tif (UPDATER.compareAndSet(this, currentThread, null)) {// step 4\n\t\t\t\t\t// compareAndSet返回true表示确实没有人排在自己后面\n\t\t\t\t\treturn;\n\t\t\t\t} else {\n\t\t\t\t\t// 突然有人排在自己后面了，可能还不知道是谁，下面是等待后续者\n\t\t\t\t\t// 这里之所以要忙等是因为：step 1执行完后，step 2可能还没执行完\n\t\t\t\t\twhile (currentThread.next == null) { // step 5\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcurrentThread.next.isLocked = false;\n\t\t\tcurrentThread.next = null;// for GC\n\t\t}\n\t}\n}\n\n```\n\n","slug":"并发编程/自旋锁","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii2z00ayvjs64bj4quqs"},{"date":"2015-10-25T16:00:00.000Z","title":"NUMA和RDMA","_content":"\n## 支持NUMA的CPU\n\n英特尔系列的\n* Nehalem和Tukwila系列之后的处理器\n* Xeon\n* 至强处理器 E5-2690\n* i3、i5、i7\n\nHP系列的\n* Superdome\n* SGI的Altix 3000\n\nIBM的\n* p690\n* x440\n\nNEC\n* TX7\n\nAMD\n* Opteron\n\n\n## Linux中关于NUMA的命令\n* NUMACTL ：设定进程NUMA策略的命令行工具。\n* NUMASTAT ：获取NUMA内存访问统计信息的命令行工具\n\n开启NUMA\n```java\nnumactl --cpunodebind=0 --membind=0 myapp\n```\n\n\n# JAVA中的NUMA\n`-XX:+UseNUMA`启用Numa, 默认情况下,JVM所占内存会随机的分配到不同的NUMA节点上,当cpu运算时可能会到不同的NUMA节点的告诉缓存上进行数据查找,降低系统速度,可使用numactl工具将JVM进程绑定到特定的NUMA节点上,只让其访问自己所在节点的内存.\n\n# NUMA用于MySQL\n调优的时候，有哪些关键配置项，需要注意什么\n\n* `numactl --interleave=all`\n* 在MySQL进程启动前，使用`sysctl -q -w vm.drop_caches=3`清空文件缓存所占用的空间\n* Innodb在启动时，就完成整个`Innodb_buffer_pool_size`的内存分配\n\n# RDMA\nRDMA 技术需要怎样的硬件，寻找一篇RDMA用于数据库或者Java的文章，对其性能和用法做简单的阐述。\n\nRDMA是一种网卡技术,采用该技术可以使一台计算机直接将信息放入另一台计算机的内存中。RDMA通过在网卡上将可靠传输协议固化于硬件,以及支持绕过内核的零拷贝网络这两种途径来达到这一目标。绕过内核使应用程序不必执行内核调用就可以向网卡发出命令。当一个应用程序执行RDMA读/写请求时,系统并不执行数据拷贝动作。这就减少了处理 网络通信时在内核空间和用户空间上下文切换的次数。RDMA请求的完成,或者完全在用户空间中进行,或者在应用程序希望进入睡眠直到完成信号出现的情况下 通过内核进行。\n\nRDMA实现：\n* 利用传统的网络硬件,以TCP/IP及以太网络标准来建立因特网\n* InfiniBand网络和实现虚拟接口架构的网络支持RDMA.\n\n采用RDMA来获取高性能的协议包括\n* Sockets Direct Protocol\n* SCSI RDMA Protocol（SRP）\n* Direct Access File System（DAFS）\n\n## Java 7 SDP\n在Solaris系统上只要有物理InfiniBand网卡，Java 7 SDP就可以立即工作。\n\nLinux则通过Open Fabrics Enterprise Distribution（OFED）包支持SDP。\n> 确认Linux版本有没有配置OFED设备驱动器，`egrep \"^[ \\t]+ib\" /proc/net/dev`可以使用该命令测试.\n\nJava只通过`java.net.Socket、java.net.ServerSocket、java.net.Datagram`对传输层进行抽象,通过`Java.net.InetAddress`对网络层进行抽象.只需要将JVM和InfiniBand操作系统设备和库进行设定,java就可以通过传输层抽象直接与物理层进行访问,从而绕过了网络层和数据链路层.\n\nSDP也能让Java具备非常强大的“零拷贝”,这个零拷贝并不是指的是`java.nio.channels.FileChannel`的`transferTo()`实现的零拷贝.而是直接使用原生的InfiniBand零拷贝协议实现。现在CPU不用将一个内存区域的数据拷贝到另一个内存区域。CPU可以继续处理其他任务，数据拷贝则由机器的另一部分并行处理，这样就提升了性能。此外，零拷贝操作减少了在用户空间和内核空间之间切换所消耗的时间。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/net/javasdp.jpg)\n\n### 配置JVM7支持SDP\nSDP配置文件是个文本文件，JVM启动时会从本地文件系统读取该文件。我们有俩种规则来定义：\n1. bind规则：只要TCP套接字绑定到与规则匹配的地址和端口，就会使用SDP协议进行传输。\n2. connect规则：没有绑定的TCP套接字尝试连接匹配规则的地址和端口时，就会使用SDP协议进行传输。\n第一个关键字用来表明规则是bind还是connect。第二部分指定主机名或IP地址。当指定为IP地址时，你也可以指定表示IP地址范围的前缀。第三部分即最后一个部分是端口号或端口号范围。\n```java\n# 绑定到192.168.1.196主机所有端口使用SDP\nbind 192.168.1.196 *\n\n# 连接到192.168.2.*上的所有应用服务时都使用SDP\nconnect 192.168.2.0/24 1024-*\n```\n### 使用SDP的JVM7\n```java\njava \\\n-Dcom.sun.sdp.conf=sdp.conf \\\n-Djava.net.preferIPv4Stack=true \\\nApplication.class\n```\n> 注意要指定网络格式为`IPv4Stack`。尽管Java 7和InfiniBand都支持IPv6网络格式，但Solaris和Linux都不支持两者之间的映射。所以启动支持SDP的Java 7 VM时，还是要使用基础、可靠的IPv4网络格式。\n\n## IO性能度量\n\n### 全SSD硬盘的IO阀值\nSSD 硬盘传输速率取 500M/S\n```java\n0.1ms + 0 + 4K/500MB = 0.1 + 0 + 0.008 = 0.108\n\nIOPS = 1/0.108 ms = 9259 IOPS\n```\n吞吐率 = `9259 * 4K = 37M / 500M = 7.4%`\n\n\n### 1万转机械磁盘的IO阀值\n1 万转机械磁盘传输速率取 200M/S\n```java\n5ms + (60sec/10000RPM/2) + 4K/200MB = 5 + 3 + 0.02 = 8.02 IOPS = 1/8.02s ms = 125 IOPS\n```\n吞吐率 = `125 * 4K = 500K / 200M = 0.25%`\n","source":"_posts/操作系统/NUMA.md","raw":"category: 操作系统\ndate: 2015-10-26\ntitle: NUMA和RDMA\n---\n\n## 支持NUMA的CPU\n\n英特尔系列的\n* Nehalem和Tukwila系列之后的处理器\n* Xeon\n* 至强处理器 E5-2690\n* i3、i5、i7\n\nHP系列的\n* Superdome\n* SGI的Altix 3000\n\nIBM的\n* p690\n* x440\n\nNEC\n* TX7\n\nAMD\n* Opteron\n\n\n## Linux中关于NUMA的命令\n* NUMACTL ：设定进程NUMA策略的命令行工具。\n* NUMASTAT ：获取NUMA内存访问统计信息的命令行工具\n\n开启NUMA\n```java\nnumactl --cpunodebind=0 --membind=0 myapp\n```\n\n\n# JAVA中的NUMA\n`-XX:+UseNUMA`启用Numa, 默认情况下,JVM所占内存会随机的分配到不同的NUMA节点上,当cpu运算时可能会到不同的NUMA节点的告诉缓存上进行数据查找,降低系统速度,可使用numactl工具将JVM进程绑定到特定的NUMA节点上,只让其访问自己所在节点的内存.\n\n# NUMA用于MySQL\n调优的时候，有哪些关键配置项，需要注意什么\n\n* `numactl --interleave=all`\n* 在MySQL进程启动前，使用`sysctl -q -w vm.drop_caches=3`清空文件缓存所占用的空间\n* Innodb在启动时，就完成整个`Innodb_buffer_pool_size`的内存分配\n\n# RDMA\nRDMA 技术需要怎样的硬件，寻找一篇RDMA用于数据库或者Java的文章，对其性能和用法做简单的阐述。\n\nRDMA是一种网卡技术,采用该技术可以使一台计算机直接将信息放入另一台计算机的内存中。RDMA通过在网卡上将可靠传输协议固化于硬件,以及支持绕过内核的零拷贝网络这两种途径来达到这一目标。绕过内核使应用程序不必执行内核调用就可以向网卡发出命令。当一个应用程序执行RDMA读/写请求时,系统并不执行数据拷贝动作。这就减少了处理 网络通信时在内核空间和用户空间上下文切换的次数。RDMA请求的完成,或者完全在用户空间中进行,或者在应用程序希望进入睡眠直到完成信号出现的情况下 通过内核进行。\n\nRDMA实现：\n* 利用传统的网络硬件,以TCP/IP及以太网络标准来建立因特网\n* InfiniBand网络和实现虚拟接口架构的网络支持RDMA.\n\n采用RDMA来获取高性能的协议包括\n* Sockets Direct Protocol\n* SCSI RDMA Protocol（SRP）\n* Direct Access File System（DAFS）\n\n## Java 7 SDP\n在Solaris系统上只要有物理InfiniBand网卡，Java 7 SDP就可以立即工作。\n\nLinux则通过Open Fabrics Enterprise Distribution（OFED）包支持SDP。\n> 确认Linux版本有没有配置OFED设备驱动器，`egrep \"^[ \\t]+ib\" /proc/net/dev`可以使用该命令测试.\n\nJava只通过`java.net.Socket、java.net.ServerSocket、java.net.Datagram`对传输层进行抽象,通过`Java.net.InetAddress`对网络层进行抽象.只需要将JVM和InfiniBand操作系统设备和库进行设定,java就可以通过传输层抽象直接与物理层进行访问,从而绕过了网络层和数据链路层.\n\nSDP也能让Java具备非常强大的“零拷贝”,这个零拷贝并不是指的是`java.nio.channels.FileChannel`的`transferTo()`实现的零拷贝.而是直接使用原生的InfiniBand零拷贝协议实现。现在CPU不用将一个内存区域的数据拷贝到另一个内存区域。CPU可以继续处理其他任务，数据拷贝则由机器的另一部分并行处理，这样就提升了性能。此外，零拷贝操作减少了在用户空间和内核空间之间切换所消耗的时间。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/net/javasdp.jpg)\n\n### 配置JVM7支持SDP\nSDP配置文件是个文本文件，JVM启动时会从本地文件系统读取该文件。我们有俩种规则来定义：\n1. bind规则：只要TCP套接字绑定到与规则匹配的地址和端口，就会使用SDP协议进行传输。\n2. connect规则：没有绑定的TCP套接字尝试连接匹配规则的地址和端口时，就会使用SDP协议进行传输。\n第一个关键字用来表明规则是bind还是connect。第二部分指定主机名或IP地址。当指定为IP地址时，你也可以指定表示IP地址范围的前缀。第三部分即最后一个部分是端口号或端口号范围。\n```java\n# 绑定到192.168.1.196主机所有端口使用SDP\nbind 192.168.1.196 *\n\n# 连接到192.168.2.*上的所有应用服务时都使用SDP\nconnect 192.168.2.0/24 1024-*\n```\n### 使用SDP的JVM7\n```java\njava \\\n-Dcom.sun.sdp.conf=sdp.conf \\\n-Djava.net.preferIPv4Stack=true \\\nApplication.class\n```\n> 注意要指定网络格式为`IPv4Stack`。尽管Java 7和InfiniBand都支持IPv6网络格式，但Solaris和Linux都不支持两者之间的映射。所以启动支持SDP的Java 7 VM时，还是要使用基础、可靠的IPv4网络格式。\n\n## IO性能度量\n\n### 全SSD硬盘的IO阀值\nSSD 硬盘传输速率取 500M/S\n```java\n0.1ms + 0 + 4K/500MB = 0.1 + 0 + 0.008 = 0.108\n\nIOPS = 1/0.108 ms = 9259 IOPS\n```\n吞吐率 = `9259 * 4K = 37M / 500M = 7.4%`\n\n\n### 1万转机械磁盘的IO阀值\n1 万转机械磁盘传输速率取 200M/S\n```java\n5ms + (60sec/10000RPM/2) + 4K/200MB = 5 + 3 + 0.02 = 8.02 IOPS = 1/8.02s ms = 125 IOPS\n```\n吞吐率 = `125 * 4K = 500K / 200M = 0.25%`\n","slug":"操作系统/NUMA","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3200b1vjs6ed78a4jy"},{"date":"2015-11-23T16:00:00.000Z","title":"Mycat配置文件","_content":"[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n> 需要注意的一点是Mycat是支持分库,但是不支持分表的.\n\n* 启动Mycat `mycat.bat start`\n* 连接Mycat `mysql -hlocalhost -P8066 -utest -ptest`\n \n## schema.xml\n下面的例子实现一个分库,db1和db2各有一张idTable表\n```xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://org.opencloudb/\">\n\t<schema name=\"idDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t\t<table name=\"idTable\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"mod-long\" />\n\t</schema>\n\t<dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" />\n\t<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" />\n\t<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t\t<heartbeat>select user()</heartbeat>\n\t\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"root\" />\n\t</dataHost>\n</mycat:schema>\n```\n如果我们要实现分库的功能需要在`rule.xml`中指定分库逻辑\n\n### schema标签\n定义MyCat实例中的逻辑库,对于客户端来说,实际的数据库是不可见的,在sql中要使用逻辑库名称而不是实际的物理库的名称\n* `dataNode` : 对应实际的物理库(如果设置了这个属性,该逻辑库就不能实现分库功能了,但是该逻辑库就可以用作读写分离和主从切换). 它的值对应下面的dataNode标签.\n* `checkSQLschema` : 把schema字符去掉(在sql中将库名去掉)\n* `sqlMaxLimit` : 在分库中执行sql时,为sql添加`limit`字段\n* `name` : 逻辑库名称\n\n#### table标签\n定义MyCat中的逻辑表\n* `name` : 逻辑表表名\n* `dataNode` : 定义逻辑表所属的dataNode, 该属性值与schema标签dataNode属性值相对应\n* `rule` : 指定逻辑表要使用定义在rule.xml中的规则名字\n* `ruleRequired` : 指定表是否绑定分片规则(如果指定绑定但是在rule.xml中找不到则会报错)\n* `primaryKey` : 逻辑表对应真实表的主键\n* `type` : 逻辑表类型(可选值为global表示全局表,不设置的话为非全局表). 全局表就是每个分片内都保存一份全完相同的数据.\n* `autoIncrement` : 自增长主键,但是需要在Mysql中设置auto_increment属性\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n##### childTable标签\n用于定义E-R分片的子表\n* `name` : 子表名\n* `joinKey` : 插入子表的时候会使用这个列的值查找父表存储的数据节点\n* `parentKey` : \n* `primaryKey` : 逻辑表对应真实表的主键\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n### dataNode标签\n定义MyCat中的数据节点(也就是数据分片). \n* `name` : 数据节点名字\n* `dataHost` : 定义该分片属于哪个数据库实例\n* `database` : 分片属性哪个具体数据库实例上的具体库\n\n### dataHost标签\n定义了具体的数据库实例、读写分离配置和心跳语句。\n* `name` : dataHost标签名\n* `maxCon` : 每个读写实例连接池的最大连接\n* `minCon` : 每个读写实例连接池的最小连接，初始化连接池的大小。\n* `balance` : 负载均衡类型(`0`:所有读操作都发送到当前可用的writeHost上。'1`:所有读操作都随机的发送到readHost。`2`:所有读操作都随机的在writeHost、readhost上分发。)\n* `writeType` : 同balance属性\n* `dbType` : 后端连接的数据库类型(mysql,oracle等等)\n* `dbDriver` : 连接后端数据库使用的Driver，目前可选的值有native和JDBC\n\n#### heartbeat标签\n用于和后端数据库进行心跳检查的语句 \n\n#### writeHost, readHost\n用于实例化后端连接池.在一个dataHost内可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。另一方面，由于这个writeHost宕机系统会自动的检测到，并切换到备用的writeHost上去。\n* `host` : 标识不同实例\n* `url` : 后端实例连接地址\n* `password` : \n* `user` : 后端存储实例需要的用户名字\n* `password` :  后端存储实例需要的密码\n\n\n## server.xml\n保存mycat需要的系统配置信息.\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"defaultSqlParser\">druidparser</property>\n\t</system>\n\t<user name=\"test\">\n\t\t<property name=\"password\">test</property>\n\t\t<property name=\"schemas\">idDB</property>\n\t</user>\n</mycat:server>\n```\n\n### user标签\n定义登录mycat的用户和权限,它可以定义`property`子标签.`property`子标签的name值可以是：\n* `password` : 该用户的密码\n* `schemas` : 该用户可访问的schema(在schema.xml中定义的schema)\n* `readOnly` : 该用户的读写权限\n\n### system标签\n与系统配置有关.它同样使用`property`子标签.`property`子标签的name值可以是：\n* `defaultSqlParser` : 指定默认的解析器\n* `processors` : 指定系统可用的线程数.(主要影响processorBufferPool、processorBufferLocalPercent、processorExecutor属性)\n* `processorBufferChunk` : 这个属性指定每次分配Socket Direct Buffer的大小，默认是4096个字节。这个属性也影响buffer pool的长度。\n* `processorBufferPool` : 这个属性指定bufferPool计算 比例值.\n* `processorBufferLocalPercent` : 控制分配ThreadLocalPool的大小用的，但其也并不是一个准确的值，也是一个比例值。这个属性默认值为100。\n* `processorExecutor` : 指定NIOProcessor上共享的businessExecutor固定线程池大小\n* `sequnceHandlerType` : 指定使用Mycat全局序列的类型。0为本地文件方式，1为数据库方式。\n\n#### TCP连接相关属性\n* `frontSocketSoRcvbuf` : \n* `frontSocketSoSndbuf` : \n* `frontSocketNoDelay` : \n\n#### Mysql连接相关属性\n* `packetHeaderSize` : 指定Mysql协议中的报文头长度\n* `maxPacketSize` : 指定Mysql协议可以携带的数据最大长度\n* `idleTimeout` :  指定连接的空闲超时时间。某连接在发起空闲检查下，发现距离上次使用超过了空闲时间，那么这个连接会被回收，就是被直接的关闭掉。默认30分钟。\n* `charset` : 连接的初始化字符集。默认为utf8。\n* `txIsolation` : 前端连接的初始化事务隔离级别，只在初始化的时候使用，后续会根据客户端传递过来的属性对后端数据库连接进行同步。默认为REPEATED_READ。\n* `sqlExecuteTimeout` : SQL执行超时的时间，Mycat会检查连接上最后一次执行SQL的时间，若超过这个时间则会直接关闭这连接。默认时间为300秒。\n\n#### 周期间隔相关属性\n* `processorCheckPeriod` : \n* `dataNodeIdleCheckPeriod` : \n* `dataNodeHeartbeatPeriod` :\n \n#### 服务相关属性\n* `bindIp` :  mycat服务监听的IP地址，默认值为0.0.0.0。\n* `serverPort` : mycat的使用端口，默认值为8066。\n* `managerPort` : mycat的管理端口，默认值为9066。\n\n \n## rule.xml\n对表进行拆分所涉及到的规则定义\n```xml\n<tableRule name=\"rule2\">\n    <rule>\n      <columns>user_id</columns>\n      <algorithm>func1</algorithm>\n    </rule>\n</tableRule>\n```\n\n### tableRule标签\n定义表规则\n* `name` : 表规则名称\n\n#### rule标签\n指定对物理表中的哪一列进行拆分和使用什么路由算法。\n\n##### columns标签\n指定要拆分的列名字。\n\n##### algorithm标签\n使用function标签中的name属性。\n\n### function标签\n* `name` : 算法的名字\n* `class` : 制定路由算法具体的类名字\n\n#### property标签\n具体算法需要用到的一些属性\n* `name` : \n\n\n","source":"_posts/数据库/Mycat配置文件.md","raw":"category: 数据库 \ndate: 2015-11-24\ntitle: Mycat配置文件\n---\n[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n> 需要注意的一点是Mycat是支持分库,但是不支持分表的.\n\n* 启动Mycat `mycat.bat start`\n* 连接Mycat `mysql -hlocalhost -P8066 -utest -ptest`\n \n## schema.xml\n下面的例子实现一个分库,db1和db2各有一张idTable表\n```xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://org.opencloudb/\">\n\t<schema name=\"idDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t\t<table name=\"idTable\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"mod-long\" />\n\t</schema>\n\t<dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" />\n\t<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" />\n\t<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t\t<heartbeat>select user()</heartbeat>\n\t\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"root\" />\n\t</dataHost>\n</mycat:schema>\n```\n如果我们要实现分库的功能需要在`rule.xml`中指定分库逻辑\n\n### schema标签\n定义MyCat实例中的逻辑库,对于客户端来说,实际的数据库是不可见的,在sql中要使用逻辑库名称而不是实际的物理库的名称\n* `dataNode` : 对应实际的物理库(如果设置了这个属性,该逻辑库就不能实现分库功能了,但是该逻辑库就可以用作读写分离和主从切换). 它的值对应下面的dataNode标签.\n* `checkSQLschema` : 把schema字符去掉(在sql中将库名去掉)\n* `sqlMaxLimit` : 在分库中执行sql时,为sql添加`limit`字段\n* `name` : 逻辑库名称\n\n#### table标签\n定义MyCat中的逻辑表\n* `name` : 逻辑表表名\n* `dataNode` : 定义逻辑表所属的dataNode, 该属性值与schema标签dataNode属性值相对应\n* `rule` : 指定逻辑表要使用定义在rule.xml中的规则名字\n* `ruleRequired` : 指定表是否绑定分片规则(如果指定绑定但是在rule.xml中找不到则会报错)\n* `primaryKey` : 逻辑表对应真实表的主键\n* `type` : 逻辑表类型(可选值为global表示全局表,不设置的话为非全局表). 全局表就是每个分片内都保存一份全完相同的数据.\n* `autoIncrement` : 自增长主键,但是需要在Mysql中设置auto_increment属性\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n##### childTable标签\n用于定义E-R分片的子表\n* `name` : 子表名\n* `joinKey` : 插入子表的时候会使用这个列的值查找父表存储的数据节点\n* `parentKey` : \n* `primaryKey` : 逻辑表对应真实表的主键\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n### dataNode标签\n定义MyCat中的数据节点(也就是数据分片). \n* `name` : 数据节点名字\n* `dataHost` : 定义该分片属于哪个数据库实例\n* `database` : 分片属性哪个具体数据库实例上的具体库\n\n### dataHost标签\n定义了具体的数据库实例、读写分离配置和心跳语句。\n* `name` : dataHost标签名\n* `maxCon` : 每个读写实例连接池的最大连接\n* `minCon` : 每个读写实例连接池的最小连接，初始化连接池的大小。\n* `balance` : 负载均衡类型(`0`:所有读操作都发送到当前可用的writeHost上。'1`:所有读操作都随机的发送到readHost。`2`:所有读操作都随机的在writeHost、readhost上分发。)\n* `writeType` : 同balance属性\n* `dbType` : 后端连接的数据库类型(mysql,oracle等等)\n* `dbDriver` : 连接后端数据库使用的Driver，目前可选的值有native和JDBC\n\n#### heartbeat标签\n用于和后端数据库进行心跳检查的语句 \n\n#### writeHost, readHost\n用于实例化后端连接池.在一个dataHost内可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。另一方面，由于这个writeHost宕机系统会自动的检测到，并切换到备用的writeHost上去。\n* `host` : 标识不同实例\n* `url` : 后端实例连接地址\n* `password` : \n* `user` : 后端存储实例需要的用户名字\n* `password` :  后端存储实例需要的密码\n\n\n## server.xml\n保存mycat需要的系统配置信息.\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"defaultSqlParser\">druidparser</property>\n\t</system>\n\t<user name=\"test\">\n\t\t<property name=\"password\">test</property>\n\t\t<property name=\"schemas\">idDB</property>\n\t</user>\n</mycat:server>\n```\n\n### user标签\n定义登录mycat的用户和权限,它可以定义`property`子标签.`property`子标签的name值可以是：\n* `password` : 该用户的密码\n* `schemas` : 该用户可访问的schema(在schema.xml中定义的schema)\n* `readOnly` : 该用户的读写权限\n\n### system标签\n与系统配置有关.它同样使用`property`子标签.`property`子标签的name值可以是：\n* `defaultSqlParser` : 指定默认的解析器\n* `processors` : 指定系统可用的线程数.(主要影响processorBufferPool、processorBufferLocalPercent、processorExecutor属性)\n* `processorBufferChunk` : 这个属性指定每次分配Socket Direct Buffer的大小，默认是4096个字节。这个属性也影响buffer pool的长度。\n* `processorBufferPool` : 这个属性指定bufferPool计算 比例值.\n* `processorBufferLocalPercent` : 控制分配ThreadLocalPool的大小用的，但其也并不是一个准确的值，也是一个比例值。这个属性默认值为100。\n* `processorExecutor` : 指定NIOProcessor上共享的businessExecutor固定线程池大小\n* `sequnceHandlerType` : 指定使用Mycat全局序列的类型。0为本地文件方式，1为数据库方式。\n\n#### TCP连接相关属性\n* `frontSocketSoRcvbuf` : \n* `frontSocketSoSndbuf` : \n* `frontSocketNoDelay` : \n\n#### Mysql连接相关属性\n* `packetHeaderSize` : 指定Mysql协议中的报文头长度\n* `maxPacketSize` : 指定Mysql协议可以携带的数据最大长度\n* `idleTimeout` :  指定连接的空闲超时时间。某连接在发起空闲检查下，发现距离上次使用超过了空闲时间，那么这个连接会被回收，就是被直接的关闭掉。默认30分钟。\n* `charset` : 连接的初始化字符集。默认为utf8。\n* `txIsolation` : 前端连接的初始化事务隔离级别，只在初始化的时候使用，后续会根据客户端传递过来的属性对后端数据库连接进行同步。默认为REPEATED_READ。\n* `sqlExecuteTimeout` : SQL执行超时的时间，Mycat会检查连接上最后一次执行SQL的时间，若超过这个时间则会直接关闭这连接。默认时间为300秒。\n\n#### 周期间隔相关属性\n* `processorCheckPeriod` : \n* `dataNodeIdleCheckPeriod` : \n* `dataNodeHeartbeatPeriod` :\n \n#### 服务相关属性\n* `bindIp` :  mycat服务监听的IP地址，默认值为0.0.0.0。\n* `serverPort` : mycat的使用端口，默认值为8066。\n* `managerPort` : mycat的管理端口，默认值为9066。\n\n \n## rule.xml\n对表进行拆分所涉及到的规则定义\n```xml\n<tableRule name=\"rule2\">\n    <rule>\n      <columns>user_id</columns>\n      <algorithm>func1</algorithm>\n    </rule>\n</tableRule>\n```\n\n### tableRule标签\n定义表规则\n* `name` : 表规则名称\n\n#### rule标签\n指定对物理表中的哪一列进行拆分和使用什么路由算法。\n\n##### columns标签\n指定要拆分的列名字。\n\n##### algorithm标签\n使用function标签中的name属性。\n\n### function标签\n* `name` : 算法的名字\n* `class` : 制定路由算法具体的类名字\n\n#### property标签\n具体算法需要用到的一些属性\n* `name` : \n\n\n","slug":"数据库/Mycat配置文件","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3400b2vjs6y7fcftvn"},{"date":"2016-05-16T16:00:00.000Z","title":"Mysql JSON Data Type","_content":"[官方文档](http://dev.mysql.com/doc/refman/5.7/en/json.html)\n\n## Creating JSON Values\n在Mysql中, JSON是通过字符串进行存储的.\n\n下面的例子演示了创建JSON类型字段的表, 以及插入一个JSON串和插入一个非法的JSON串\n```sql\nmysql> CREATE TABLE t1 (jdoc JSON);\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> INSERT INTO t1 VALUES('{\"key1\": \"value1\", \"key2\": \"value2\"}');\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t1 VALUES('[1, 2,');\nERROR 3140 (22032) at line 2: Invalid JSON text: \"Invalid value.\" at position 6 in value (or column) '[1, 2,'.\n```\n> `at position N`是从0 开始计算的\n\n`JSON_TYPE()`方法接受一个JSON串, 然后尝试解析它, 最后返回该JSON的数据类型\n```sql\nmysql> SELECT JSON_TYPE('[\"a\", \"b\", 1]');\n+----------------------------+\n| JSON_TYPE('[\"a\", \"b\", 1]') |\n+----------------------------+\n| ARRAY                      |\n+----------------------------+\n\nmysql> SELECT JSON_TYPE('\"hello\"');\n+----------------------+\n| JSON_TYPE('\"hello\"') |\n+----------------------+\n| STRING               |\n+----------------------+\n\nmysql> SELECT JSON_TYPE('hello');\nERROR 3146 (22032): Invalid data type for JSON data in argument 1\nto function json_type; a JSON string or JSON type is required.\n```\nMySQL 使用`utf8mb4`编码和`utf8mb4_bin`集合处理JSON 字符串内容. 其他的编码会被转换成utf8mb4编码. (ascii 和 utf8 编码并不会进行转换, 因为这俩个字符集是utf8mb4的子集.)\n\n除了使用字面量JSON串之外, Mysql还提供了很多创建JSON串的方法. 例如JSON_ARRAY()`函数接受一个参数列表(个数大于等于0), 然后返回一个JSON字符串数组.\n```sql\nmysql> SELECT JSON_ARRAY('a', 1, NOW());\n+----------------------------------------+\n| JSON_ARRAY('a', 1, NOW())              |\n+----------------------------------------+\n| [\"a\", 1, \"2015-07-27 09:43:47.000000\"] |\n+----------------------------------------+\n```\n\n`JSON_OBJECT()`接受一个key/value形式的参数列表, 返回一个包含那些元素的JSON对象:\n```sql\nmysql> SELECT JSON_OBJECT('key1', 1, 'key2', 'abc');\n+---------------------------------------+\n| JSON_OBJECT('key1', 1, 'key2', 'abc') |\n+---------------------------------------+\n| {\"key1\": 1, \"key2\": \"abc\"}            |\n+---------------------------------------+\n```\n\n`JSON_MERGE()` 将多个JSON串组合到一起,然后返回一个总的JSON串:\n```sql\nmysql> SELECT JSON_MERGE('[\"a\", 1]', '{\"key\": \"value\"}');\n+--------------------------------------------+\n| JSON_MERGE('[\"a\", 1]', '{\"key\": \"value\"}') |\n+--------------------------------------------+\n| [\"a\", 1, {\"key\": \"value\"}]                 |\n+--------------------------------------------+\n```\n> 关于更多的合并规则,参考下面的 Normalization, Merging, and Autowrapping of JSON Values 章节.\n\n也可以将JSON赋给一个用户自定义的变量\n```sql\nmysql> SET @j = JSON_OBJECT('key', 'value');\nmysql> SELECT @j;\n+------------------+\n| @j               |\n+------------------+\n| {\"key\": \"value\"} |\n+------------------+\n```\n在上例中, 尽管`JSON_OBJECT()`方法会返回一个JSON类型对象, 但是当将其赋给一个变量(`@j`)时, 它就被自动转换成了一个字符串类型.\n\nJSON转换成的字符串, 它的编码是`utf8mb4`, 字符序为`utf8mb4_bin`:\n```sql\nmysql> SELECT CHARSET(@j), COLLATION(@j);\n+-------------+---------------+\n| CHARSET(@j) | COLLATION(@j) |\n+-------------+---------------+\n| utf8mb4     | utf8mb4_bin   |\n+-------------+---------------+\n```\n因为`utf8mb4_bin`是一种二进制的字符序, 因此在对比俩个JSON值是区分大小写的.\n```sql\nmysql> SELECT JSON_ARRAY('x') = JSON_ARRAY('X');\n+-----------------------------------+\n| JSON_ARRAY('x') = JSON_ARRAY('X') |\n+-----------------------------------+\n|                                 0 |\n+-----------------------------------+\n```\n区分大小写同样支持JSON的`null`, `true`, `false`等字面量. 因此在引用他们的时候一定要小写.\n```sql\nmysql> SELECT JSON_VALID('null'), JSON_VALID('Null'), JSON_VALID('NULL');\n+--------------------+--------------------+--------------------+\n| JSON_VALID('null') | JSON_VALID('Null') | JSON_VALID('NULL') |\n+--------------------+--------------------+--------------------+\n|                  1 |                  0 |                  0 |\n+--------------------+--------------------+--------------------+\n\nmysql> SELECT CAST('null' AS JSON);\n+----------------------+\n| CAST('null' AS JSON) |\n+----------------------+\n| null                 |\n+----------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT CAST('NULL' AS JSON);\nERROR 3141 (22032): Invalid JSON text in argument 1 to function cast_as_json:\n\"Invalid value.\" at position 0 in 'NULL'.\n```\nJSON字面量区分大小写与SQL中的不同. 在SQL中`NULL, TRUE, FALSE`等字面量可以写成由任意大小写组成:\n```sql\nmysql> SELECT ISNULL(null), ISNULL(Null), ISNULL(NULL);\n+--------------+--------------+--------------+\n| ISNULL(null) | ISNULL(Null) | ISNULL(NULL) |\n+--------------+--------------+--------------+\n|            1 |            1 |            1 |\n+--------------+--------------+--------------+\n```\n\n## Normalization, Merging, and Autowrapping of JSON Values\n当一个字符串可以解析成一个有效的JSON文档, 它同时也会进行归一化处理. 当JSON中出现重复的Key时, 只会保留最开始的那个Key/Value, 接下来重复出现的都会抛弃掉.\n```sql\nmysql> SELECT JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def');\n+------------------------------------------------------+\n| JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def') |\n+------------------------------------------------------+\n| {\"key1\": 1, \"key2\": \"abc\"}                           |\n+------------------------------------------------------+\n```\nMysql的归一化处理还会对JSON对象的key进行排序处理(以便查找时提供更好的性能). The result of this ordering is subject to change and not guaranteed to be consistent across releases. 另外, key或者value之间的空格会自动的被忽略掉.\n\n同样的, Mysql中创建JSON的方法同样也都做了归一化处理.\n\n当多个数组合并成一个数组时, 数组元素会依次存储进新的数组中, 如下面的`JSON_MERGE()`:\n```sql\nmysql> SELECT JSON_MERGE('[1, 2]', '[\"a\", \"b\"]', '[true, false]');\n+-----------------------------------------------------+\n| JSON_MERGE('[1, 2]', '[\"a\", \"b\"]', '[true, false]') |\n+-----------------------------------------------------+\n| [1, 2, \"a\", \"b\", true, false]                       |\n+-----------------------------------------------------+\n```\n\n多个对象合并到一个对象中的时候, 如果多个对象中都出现了相同的key, 那么相同的key对应的value值会被放到该key对应的数组中.\n```sql\nmysql> SELECT JSON_MERGE('{\"a\": 1, \"b\": 2}', '{\"c\": 3, \"a\": 4}');\n+----------------------------------------------------+\n| JSON_MERGE('{\"a\": 1, \"b\": 2}', '{\"c\": 3, \"a\": 4}') |\n+----------------------------------------------------+\n| {\"a\": [1, 4], \"b\": 2, \"c\": 3}                      |\n+----------------------------------------------------+\n```\n当非数组类型的数据出现在要求数组为参数的上下文中时, 非数组类型的数据会自动被包装成数组类型(会自动在数据俩侧添加`[]`将其括起来). 在下面的例子中, 每一个参数都会被自动包装成([1], [2]), 然后产生一个新的数组.\n```sql\nmysql> SELECT JSON_MERGE('1', '2');\n+----------------------+\n| JSON_MERGE('1', '2') |\n+----------------------+\n| [1, 2]               |\n+----------------------+\n```\n当对象和数组进行合并时, 对象会自动的包装成一个数组, 然后将这俩个数组进行合并\n```sql\nmysql> SELECT JSON_MERGE('[10, 20]', '{\"a\": \"x\", \"b\": \"y\"}');\n+------------------------------------------------+\n| JSON_MERGE('[10, 20]', '{\"a\": \"x\", \"b\": \"y\"}') |\n+------------------------------------------------+\n| [10, 20, {\"a\": \"x\", \"b\": \"y\"}]                 |\n+------------------------------------------------+\n```\n\n## Searching and Modifying JSON Values\n我们可以在JSON文档中通过指定path来搜索出一个值.\n\n在相关方法中使用表达式可以提取数据,或者修改JSON文档 以及进行其他的操作. 例如下面的操作就是从JSON文档中提取key为name的值.\n```sql\nmysql> SELECT JSON_EXTRACT('{\"id\": 14, \"name\": \"Aztalan\"}', '$.name');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"id\": 14, \"name\": \"Aztalan\"}', '$.name') |\n+---------------------------------------------------------+\n| \"Aztalan\"                                               |\n+---------------------------------------------------------+\n```\n在Mysql中, 可以使用`$`加后缀的方式表示一个JSON文档. `$`后可以跟一个选择符来索引到JSON文档中任意的位置元素:\n* `$\"key\"` 表示在JSON文档中, key所对应的值. 注意key必须使用`\"\"`括起来.\n* `[N]` 表示JSON数组文档中第N个位置的值(从0开始).\n* Paths 可以包含 `*`或者`**` 通配符.\n* `.[*]` 找到JSON对象中所有的成员值\n* `[*]` 找到JSON数组中所有的成员值\n* `prefix**suffix` 匹配所有的以prefix开头, 以suffix结尾的path.\n\n下面我们创建出三个元素的数组, 然后假设 `$` 指向这个数组:\n```json\n[3, {\"a\": [5, 6], \"b\": 10}, [99, 100]]\n```\n那么:\n* `$[0]` 求值为 3.\n* `$[1]` 求值为 {\"a\": [5, 6], \"b\": 10}.\n* `$[2]` 求值为[99, 100].\n* `$[3]` 求值为 NULL (指向一个不存在的元素).\n\n因为 $[1] 和 $[2] 是非标量的值, 因此我们可以进一步的使用path表达式求出它内嵌的值. 例如:\n* `$[1].a` 求值为 [5, 6].\n* `$[1].a[1]` 求值为 6.\n* `$[1].b` 求值为 10.\n* `$[2][0]` 求值为 99.\n\n刚才我们也提到了, path表达式的key必须被`\"\"`包含起来, 未被`\"\"`包含起来的key会被视为非法的.\n```json\n{\"a fish\": \"shark\", \"a bird\": \"sparrow\"}\n```\n这俩个key都包含了一个空格, 因此在path表达式中, 必须使用`\"\"`将key包含:\n\n* `$.\"a fish\"` 求值为 shark.\n* `$.\"a bird\"` 求值为 to sparrow.\n\n如果在对数组求值时, path中的通配符会求值出多个结果.\n```sql\nmysql> SELECT JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.*');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.*') |\n+---------------------------------------------------------+\n| [1, 2, [3, 4, 5]]                                       |\n+---------------------------------------------------------+\nmysql> SELECT JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.c[*]');\n+------------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.c[*]') |\n+------------------------------------------------------------+\n| [3, 4, 5]                                                  |\n+------------------------------------------------------------+\n```\n在下面的例子中, `$**.b`会在多个path($.a.b 和 $.c.b)中进行求值, 然后将求值结果放到一个数组中:\n```sql\nmysql> SELECT JSON_EXTRACT('{\"a\": {\"b\": 1}, \"c\": {\"b\": 2}}', '$**.b');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": {\"b\": 1}, \"c\": {\"b\": 2}}', '$**.b') |\n+---------------------------------------------------------+\n| [1, 2]                                                  |\n+---------------------------------------------------------+\n```\n在MySQL 5.7.9 和以后的版本中, 你可以使用`column->path`代替方法`JSON_EXTRACT(column, path)`.\n> 更多参考See Section 13.16.3, “Functions That Search JSON Values” 以及 Section 14.1.18.6, “Secondary Indexes and Generated Virtual Columns”.\n\n在一些方法中, 会接受一个JSON文档, 然后对该JSON文档进行一些处理. 例如\n* `JSON_SET()`\n* `JSON_INSERT()`\n* `JSON_REPLACE()`\n\n我们生成一个JSON文档, 然后在下面的操作中使用这个文档:\n```sql\nmysql> SET @j = '[\"a\", {\"b\": [true, false]}, [10, 20]]';\n```\n`JSON_SET()`会对已经存在的path替换, 不存在的进行添加:\n```sql\nmysql> SELECT JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+--------------------------------------------+\n| JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+--------------------------------------------+\n| [\"a\", {\"b\": [1, false]}, [10, 20, 2]]      |\n+--------------------------------------------+\n```\n在上例中`$[1].b[0]`选择了一个已经存在的value，然后它被替换成了1. 但是`$[2][2]` 并不存在, 所以就在`$[2][2]`插入了值2.\n\n`JSON_INSERT()`向JSON文档中插入新的值, 但是如果path已经存在, 则会归一化处理, 不会覆盖原有的值:\n```sql\nmysql> SELECT JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+-----------------------------------------------+\n| JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+-----------------------------------------------+\n| [\"a\", {\"b\": [true, false]}, [10, 20, 2]]      |\n+-----------------------------------------------+\n```\n`JSON_REPLACE()`执行替换操作, 但是如果path不存在的话, 不会进行插入操作:\n```sql\nmysql> SELECT JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+------------------------------------------------+\n| JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+------------------------------------------------+\n| [\"a\", {\"b\": [1, false]}, [10, 20]]             |\n+------------------------------------------------+\n```\n\n`JSON_REMOVE()` 接受一个 JSON 文档以及一个或者多个要删除的path.  The return value is the original document minus the values selected by paths that exist within the document:\n```sql\nmysql> SELECT JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]');\n+---------------------------------------------------+\n| JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]') |\n+---------------------------------------------------+\n| [\"a\", {\"b\": [true]}]                              |\n+---------------------------------------------------+\n```\n这三个path产生了如下的效果\n* `$[2]`找到匹配[10, 20]值, 然后将其删除掉.\n* 第一个`$[1].b[1]`匹配到了false值, 然后将其删除掉.\n* 第二个`$[1].b[1]`没有匹配到任何值, 因此该操作不会有任何结果.\n\n## Comparison and Ordering of JSON Values\n\nJSON文档里面的value可以通过如下操作符进行比较操作\n* =\n* <\n* <=\n* >\n* >=\n* <>\n* !=\n* <=>\n\n下面的比较操作符和方法并不支持JSON值\n* BETWEEN\n* IN()\n* GREATEST()\n* LEAST()\n\n刚才列出的比较操作符和方法会将JSON值转换成MySQL原生的numeric或者string类型, 因此他们有一个consistent non-JSON扩展类型.\n\nJSON值进行比较时会先根据JSON类型进行比较, 如果类型不同的话, 比较结果就决定于更高优先级的类型. 如果类型一样的话, 则会根据指定类型原则进行比较.\n\n下面列出了JSON类型的优先级, 从高到低进行排序. 我们可以通过`JSON_TYPE()`来获取某个值得类型.\n* BLOB\n* BIT\n* OPAQUE\n* DATETIME\n* TIME\n* DATE\n* BOOLEAN\n* ARRAY\n* OBJECT\n* STRING\n* INTEGER, DOUBLE\n* NULL\n如果JSON值拥有相同的优先级的话, 那么不同的类型或根据下面介绍的规则进行比较:\n\n### BLOB\n\nThe first N bytes of the two values are compared, where N is the number of bytes in the shorter value. If the first N bytes of the two values are identical, the shorter value is ordered before the longer value.\n\n### BIT\n\nSame rules as for BLOB.\n\n### OPAQUE\n\nSame rules as for BLOB. OPAQUE values are values that are not classified as one of the other types.\n\n### DATETIME\n\nA value that represents an earlier point in time is ordered before a value that represents a later point in time. If two values originally come from the MySQL DATETIME and TIMESTAMP types, respectively, they are equal if they represent the same point in time.\n\n### TIME\n\nThe smaller of two time values is ordered before the larger one.\n\n### DATE\n\nThe earlier date is ordered before the more recent date.\n\n### ARRAY\n\nTwo JSON arrays are equal if they have the same length and values in corresponding positions in the arrays are equal.\n\nIf the arrays are not equal, their order is determined by the elements in the first position where there is a difference. The array with the smaller value in that position is ordered first. If all values of the shorter array are equal to the corresponding values in the longer array, the shorter array is ordered first.\n\nExample:\n```json\n[] < [\"a\"] < [\"ab\"] < [\"ab\", \"cd\", \"ef\"] < [\"ab\", \"ef\"]\n```\n\n###BOOLEAN\n\nThe JSON false literal is less than the JSON true literal.\n\n### OBJECT\n\nTwo JSON objects are equal if they have the same set of keys, and each key has the same value in both objects.\n\nExample:\n```json\n{\"a\": 1, \"b\": 2} = {\"b\": 2, \"a\": 1}\n```\n\nThe order of two objects that are not equal is unspecified but deterministic.\n\n### STRING\n\nStrings are ordered lexically on the first N bytes of the utf8mb4 representation of the two strings being compared, where N is the length of the shorter string. If the first N bytes of the two strings are identical, the shorter string is considered smaller than the longer string.\n\nExample:\n\n\"a\" < \"ab\" < \"b\" < \"bc\"\nThis ordering is equivalent to the ordering of SQL strings with collation utf8mb4_bin. Because utf8mb4_bin is a binary collation, comparison of JSON values is case sensitive:\n\n\"A\" < \"a\"\n\n### INTEGER, DOUBLE\n\nJSON values can contain exact-value numbers and approximate-value numbers. For a general discussion of these types of numbers, see Section 10.1.2, “Number Literals”.\n\nThe rules for comparing native MySQL numeric types are discussed in Section 13.2, “Type Conversion in Expression Evaluation”, but the rules for comparing numbers within JSON values differ somewhat:\n\nIn a comparison between two columns that use the native MySQL INT and DOUBLE numeric types, respectively, it is known that all comparisons involve an integer and a double, so the integer is converted to double for all rows. That is, exact-value numbers are converted to approximate-value numbers.\n\nOn the other hand, if the query compares two JSON columns containing numbers, it cannot be known in advance whether numbers will be integer or double. To provide the most consistent behavior across all rows, MySQL converts approximate-value numbers to exact-value numbers. The resulting ordering is consistent and does not lose precision for the exact-value numbers. For example, given the scalars 9223372036854775805, 9223372036854775806, 9223372036854775807 and 9.223372036854776e18, the order is such as this:\n\n9223372036854775805 < 9223372036854775806 < 9223372036854775807\n< 9.223372036854776e18 = 9223372036854776000 < 9223372036854776001\nWere JSON comparisons to use the non-JSON numeric comparison rules, inconsistent ordering could occur. The usual MySQL comparison rules for numbers yield these orderings:\n\nInteger comparison:\n\n9223372036854775805 < 9223372036854775806 < 9223372036854775807\n(not defined for 9.223372036854776e18)\n\nDouble comparison:\n\n9223372036854775805 = 9223372036854775806 = 9223372036854775807 = 9.223372036854776e18\nFor comparison of any JSON value to SQL NULL, the result is UNKNOWN.\n\nFor comparison of JSON and non-JSON values, the non-JSON value is converted to JSON according to the rules in the following table, then the values compared as described previously.\n\nConverting between JSON and non-JSON values.  The following table provides a summary of the rules that MySQL follows when casting between JSON values and values of other types:\n\nConverting between JSON and non-JSON values.  The following table provides a summary of the rules that MySQL follows when casting between JSON values and values of other types:\n\nTable 12.1 JSON Conversion Rules\n\nother type\tCAST(other type AS JSON)\tCAST(JSON AS other type)\nJSON\tNo change\tNo change\nutf8 character type (utf8mb4, utf8, ascii)\tThe string is parsed into a JSON value.\tThe JSON value is serialized into a utf8mb4 string.\nOther character types\tOther character encodings are implicitly converted to utf8mb4 and treated as described for utf8 character type.\tThe JSON value is serialized into a utf8mb4 string, then cast to the other character encoding. The result may not be meaningful.\nNULL\tResults in a NULL value of type JSON.\tNot applicable.\nGeometry types\tThe geometry value is converted into a JSON document by calling ST_AsGeoJSON().\tIllegal operation. Workaround: Pass the result of CAST(json_val AS CHAR) to ST_GeomFromGeoJSON().\nAll other types\tResults in a JSON document consisting of a single scalar value.\tSucceeds if the JSON document consists of a single scalar value of the target type and that scalar value can be cast to the target type. Otherwise, returns NULL and produces a warning.\n\nORDER BY and GROUP BY for JSON values works according to these principles:\n\nOrdering of scalar JSON values uses the same rules as in the preceding discussion.\n\nFor ascending sorts, SQL NULL orders before all JSON values, including the JSON null literal; for descending sorts, SQL NULL orders after all JSON values, including the JSON null literal.\n\nSort keys for JSON values are bound by the value of the max_sort_length system variable, so keys that differ only after the first max_sort_length bytes compare as equal.\n\nSorting of nonscalar values is not currently supported and a warning occurs.\n\nFor sorting, it can be beneficial to cast a JSON scalar to some other native MySQL type. For example, if a column named jdoc contains JSON objects having a member consisting of an id key and a nonnegative value, use this expression to sort by id values:\n\nORDER BY CAST(JSON_EXTRACT(jdoc, '$.id') AS UNSIGNED)\nIf there happens to be a generated column defined to use the same expression as in the ORDER BY, the MySQL optimizer recognizes that and considers using the index for the query execution plan. See Section 9.3.9, “Optimizer Use of Generated Column Indexes”.\n","source":"_posts/数据库/Mysql JSON Data Type.md","raw":"category: 数据库\ndate: 2016-05-17\ntitle: Mysql JSON Data Type\n---\n[官方文档](http://dev.mysql.com/doc/refman/5.7/en/json.html)\n\n## Creating JSON Values\n在Mysql中, JSON是通过字符串进行存储的.\n\n下面的例子演示了创建JSON类型字段的表, 以及插入一个JSON串和插入一个非法的JSON串\n```sql\nmysql> CREATE TABLE t1 (jdoc JSON);\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> INSERT INTO t1 VALUES('{\"key1\": \"value1\", \"key2\": \"value2\"}');\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t1 VALUES('[1, 2,');\nERROR 3140 (22032) at line 2: Invalid JSON text: \"Invalid value.\" at position 6 in value (or column) '[1, 2,'.\n```\n> `at position N`是从0 开始计算的\n\n`JSON_TYPE()`方法接受一个JSON串, 然后尝试解析它, 最后返回该JSON的数据类型\n```sql\nmysql> SELECT JSON_TYPE('[\"a\", \"b\", 1]');\n+----------------------------+\n| JSON_TYPE('[\"a\", \"b\", 1]') |\n+----------------------------+\n| ARRAY                      |\n+----------------------------+\n\nmysql> SELECT JSON_TYPE('\"hello\"');\n+----------------------+\n| JSON_TYPE('\"hello\"') |\n+----------------------+\n| STRING               |\n+----------------------+\n\nmysql> SELECT JSON_TYPE('hello');\nERROR 3146 (22032): Invalid data type for JSON data in argument 1\nto function json_type; a JSON string or JSON type is required.\n```\nMySQL 使用`utf8mb4`编码和`utf8mb4_bin`集合处理JSON 字符串内容. 其他的编码会被转换成utf8mb4编码. (ascii 和 utf8 编码并不会进行转换, 因为这俩个字符集是utf8mb4的子集.)\n\n除了使用字面量JSON串之外, Mysql还提供了很多创建JSON串的方法. 例如JSON_ARRAY()`函数接受一个参数列表(个数大于等于0), 然后返回一个JSON字符串数组.\n```sql\nmysql> SELECT JSON_ARRAY('a', 1, NOW());\n+----------------------------------------+\n| JSON_ARRAY('a', 1, NOW())              |\n+----------------------------------------+\n| [\"a\", 1, \"2015-07-27 09:43:47.000000\"] |\n+----------------------------------------+\n```\n\n`JSON_OBJECT()`接受一个key/value形式的参数列表, 返回一个包含那些元素的JSON对象:\n```sql\nmysql> SELECT JSON_OBJECT('key1', 1, 'key2', 'abc');\n+---------------------------------------+\n| JSON_OBJECT('key1', 1, 'key2', 'abc') |\n+---------------------------------------+\n| {\"key1\": 1, \"key2\": \"abc\"}            |\n+---------------------------------------+\n```\n\n`JSON_MERGE()` 将多个JSON串组合到一起,然后返回一个总的JSON串:\n```sql\nmysql> SELECT JSON_MERGE('[\"a\", 1]', '{\"key\": \"value\"}');\n+--------------------------------------------+\n| JSON_MERGE('[\"a\", 1]', '{\"key\": \"value\"}') |\n+--------------------------------------------+\n| [\"a\", 1, {\"key\": \"value\"}]                 |\n+--------------------------------------------+\n```\n> 关于更多的合并规则,参考下面的 Normalization, Merging, and Autowrapping of JSON Values 章节.\n\n也可以将JSON赋给一个用户自定义的变量\n```sql\nmysql> SET @j = JSON_OBJECT('key', 'value');\nmysql> SELECT @j;\n+------------------+\n| @j               |\n+------------------+\n| {\"key\": \"value\"} |\n+------------------+\n```\n在上例中, 尽管`JSON_OBJECT()`方法会返回一个JSON类型对象, 但是当将其赋给一个变量(`@j`)时, 它就被自动转换成了一个字符串类型.\n\nJSON转换成的字符串, 它的编码是`utf8mb4`, 字符序为`utf8mb4_bin`:\n```sql\nmysql> SELECT CHARSET(@j), COLLATION(@j);\n+-------------+---------------+\n| CHARSET(@j) | COLLATION(@j) |\n+-------------+---------------+\n| utf8mb4     | utf8mb4_bin   |\n+-------------+---------------+\n```\n因为`utf8mb4_bin`是一种二进制的字符序, 因此在对比俩个JSON值是区分大小写的.\n```sql\nmysql> SELECT JSON_ARRAY('x') = JSON_ARRAY('X');\n+-----------------------------------+\n| JSON_ARRAY('x') = JSON_ARRAY('X') |\n+-----------------------------------+\n|                                 0 |\n+-----------------------------------+\n```\n区分大小写同样支持JSON的`null`, `true`, `false`等字面量. 因此在引用他们的时候一定要小写.\n```sql\nmysql> SELECT JSON_VALID('null'), JSON_VALID('Null'), JSON_VALID('NULL');\n+--------------------+--------------------+--------------------+\n| JSON_VALID('null') | JSON_VALID('Null') | JSON_VALID('NULL') |\n+--------------------+--------------------+--------------------+\n|                  1 |                  0 |                  0 |\n+--------------------+--------------------+--------------------+\n\nmysql> SELECT CAST('null' AS JSON);\n+----------------------+\n| CAST('null' AS JSON) |\n+----------------------+\n| null                 |\n+----------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT CAST('NULL' AS JSON);\nERROR 3141 (22032): Invalid JSON text in argument 1 to function cast_as_json:\n\"Invalid value.\" at position 0 in 'NULL'.\n```\nJSON字面量区分大小写与SQL中的不同. 在SQL中`NULL, TRUE, FALSE`等字面量可以写成由任意大小写组成:\n```sql\nmysql> SELECT ISNULL(null), ISNULL(Null), ISNULL(NULL);\n+--------------+--------------+--------------+\n| ISNULL(null) | ISNULL(Null) | ISNULL(NULL) |\n+--------------+--------------+--------------+\n|            1 |            1 |            1 |\n+--------------+--------------+--------------+\n```\n\n## Normalization, Merging, and Autowrapping of JSON Values\n当一个字符串可以解析成一个有效的JSON文档, 它同时也会进行归一化处理. 当JSON中出现重复的Key时, 只会保留最开始的那个Key/Value, 接下来重复出现的都会抛弃掉.\n```sql\nmysql> SELECT JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def');\n+------------------------------------------------------+\n| JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def') |\n+------------------------------------------------------+\n| {\"key1\": 1, \"key2\": \"abc\"}                           |\n+------------------------------------------------------+\n```\nMysql的归一化处理还会对JSON对象的key进行排序处理(以便查找时提供更好的性能). The result of this ordering is subject to change and not guaranteed to be consistent across releases. 另外, key或者value之间的空格会自动的被忽略掉.\n\n同样的, Mysql中创建JSON的方法同样也都做了归一化处理.\n\n当多个数组合并成一个数组时, 数组元素会依次存储进新的数组中, 如下面的`JSON_MERGE()`:\n```sql\nmysql> SELECT JSON_MERGE('[1, 2]', '[\"a\", \"b\"]', '[true, false]');\n+-----------------------------------------------------+\n| JSON_MERGE('[1, 2]', '[\"a\", \"b\"]', '[true, false]') |\n+-----------------------------------------------------+\n| [1, 2, \"a\", \"b\", true, false]                       |\n+-----------------------------------------------------+\n```\n\n多个对象合并到一个对象中的时候, 如果多个对象中都出现了相同的key, 那么相同的key对应的value值会被放到该key对应的数组中.\n```sql\nmysql> SELECT JSON_MERGE('{\"a\": 1, \"b\": 2}', '{\"c\": 3, \"a\": 4}');\n+----------------------------------------------------+\n| JSON_MERGE('{\"a\": 1, \"b\": 2}', '{\"c\": 3, \"a\": 4}') |\n+----------------------------------------------------+\n| {\"a\": [1, 4], \"b\": 2, \"c\": 3}                      |\n+----------------------------------------------------+\n```\n当非数组类型的数据出现在要求数组为参数的上下文中时, 非数组类型的数据会自动被包装成数组类型(会自动在数据俩侧添加`[]`将其括起来). 在下面的例子中, 每一个参数都会被自动包装成([1], [2]), 然后产生一个新的数组.\n```sql\nmysql> SELECT JSON_MERGE('1', '2');\n+----------------------+\n| JSON_MERGE('1', '2') |\n+----------------------+\n| [1, 2]               |\n+----------------------+\n```\n当对象和数组进行合并时, 对象会自动的包装成一个数组, 然后将这俩个数组进行合并\n```sql\nmysql> SELECT JSON_MERGE('[10, 20]', '{\"a\": \"x\", \"b\": \"y\"}');\n+------------------------------------------------+\n| JSON_MERGE('[10, 20]', '{\"a\": \"x\", \"b\": \"y\"}') |\n+------------------------------------------------+\n| [10, 20, {\"a\": \"x\", \"b\": \"y\"}]                 |\n+------------------------------------------------+\n```\n\n## Searching and Modifying JSON Values\n我们可以在JSON文档中通过指定path来搜索出一个值.\n\n在相关方法中使用表达式可以提取数据,或者修改JSON文档 以及进行其他的操作. 例如下面的操作就是从JSON文档中提取key为name的值.\n```sql\nmysql> SELECT JSON_EXTRACT('{\"id\": 14, \"name\": \"Aztalan\"}', '$.name');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"id\": 14, \"name\": \"Aztalan\"}', '$.name') |\n+---------------------------------------------------------+\n| \"Aztalan\"                                               |\n+---------------------------------------------------------+\n```\n在Mysql中, 可以使用`$`加后缀的方式表示一个JSON文档. `$`后可以跟一个选择符来索引到JSON文档中任意的位置元素:\n* `$\"key\"` 表示在JSON文档中, key所对应的值. 注意key必须使用`\"\"`括起来.\n* `[N]` 表示JSON数组文档中第N个位置的值(从0开始).\n* Paths 可以包含 `*`或者`**` 通配符.\n* `.[*]` 找到JSON对象中所有的成员值\n* `[*]` 找到JSON数组中所有的成员值\n* `prefix**suffix` 匹配所有的以prefix开头, 以suffix结尾的path.\n\n下面我们创建出三个元素的数组, 然后假设 `$` 指向这个数组:\n```json\n[3, {\"a\": [5, 6], \"b\": 10}, [99, 100]]\n```\n那么:\n* `$[0]` 求值为 3.\n* `$[1]` 求值为 {\"a\": [5, 6], \"b\": 10}.\n* `$[2]` 求值为[99, 100].\n* `$[3]` 求值为 NULL (指向一个不存在的元素).\n\n因为 $[1] 和 $[2] 是非标量的值, 因此我们可以进一步的使用path表达式求出它内嵌的值. 例如:\n* `$[1].a` 求值为 [5, 6].\n* `$[1].a[1]` 求值为 6.\n* `$[1].b` 求值为 10.\n* `$[2][0]` 求值为 99.\n\n刚才我们也提到了, path表达式的key必须被`\"\"`包含起来, 未被`\"\"`包含起来的key会被视为非法的.\n```json\n{\"a fish\": \"shark\", \"a bird\": \"sparrow\"}\n```\n这俩个key都包含了一个空格, 因此在path表达式中, 必须使用`\"\"`将key包含:\n\n* `$.\"a fish\"` 求值为 shark.\n* `$.\"a bird\"` 求值为 to sparrow.\n\n如果在对数组求值时, path中的通配符会求值出多个结果.\n```sql\nmysql> SELECT JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.*');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.*') |\n+---------------------------------------------------------+\n| [1, 2, [3, 4, 5]]                                       |\n+---------------------------------------------------------+\nmysql> SELECT JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.c[*]');\n+------------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": 1, \"b\": 2, \"c\": [3, 4, 5]}', '$.c[*]') |\n+------------------------------------------------------------+\n| [3, 4, 5]                                                  |\n+------------------------------------------------------------+\n```\n在下面的例子中, `$**.b`会在多个path($.a.b 和 $.c.b)中进行求值, 然后将求值结果放到一个数组中:\n```sql\nmysql> SELECT JSON_EXTRACT('{\"a\": {\"b\": 1}, \"c\": {\"b\": 2}}', '$**.b');\n+---------------------------------------------------------+\n| JSON_EXTRACT('{\"a\": {\"b\": 1}, \"c\": {\"b\": 2}}', '$**.b') |\n+---------------------------------------------------------+\n| [1, 2]                                                  |\n+---------------------------------------------------------+\n```\n在MySQL 5.7.9 和以后的版本中, 你可以使用`column->path`代替方法`JSON_EXTRACT(column, path)`.\n> 更多参考See Section 13.16.3, “Functions That Search JSON Values” 以及 Section 14.1.18.6, “Secondary Indexes and Generated Virtual Columns”.\n\n在一些方法中, 会接受一个JSON文档, 然后对该JSON文档进行一些处理. 例如\n* `JSON_SET()`\n* `JSON_INSERT()`\n* `JSON_REPLACE()`\n\n我们生成一个JSON文档, 然后在下面的操作中使用这个文档:\n```sql\nmysql> SET @j = '[\"a\", {\"b\": [true, false]}, [10, 20]]';\n```\n`JSON_SET()`会对已经存在的path替换, 不存在的进行添加:\n```sql\nmysql> SELECT JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+--------------------------------------------+\n| JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+--------------------------------------------+\n| [\"a\", {\"b\": [1, false]}, [10, 20, 2]]      |\n+--------------------------------------------+\n```\n在上例中`$[1].b[0]`选择了一个已经存在的value，然后它被替换成了1. 但是`$[2][2]` 并不存在, 所以就在`$[2][2]`插入了值2.\n\n`JSON_INSERT()`向JSON文档中插入新的值, 但是如果path已经存在, 则会归一化处理, 不会覆盖原有的值:\n```sql\nmysql> SELECT JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+-----------------------------------------------+\n| JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+-----------------------------------------------+\n| [\"a\", {\"b\": [true, false]}, [10, 20, 2]]      |\n+-----------------------------------------------+\n```\n`JSON_REPLACE()`执行替换操作, 但是如果path不存在的话, 不会进行插入操作:\n```sql\nmysql> SELECT JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2);\n+------------------------------------------------+\n| JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2) |\n+------------------------------------------------+\n| [\"a\", {\"b\": [1, false]}, [10, 20]]             |\n+------------------------------------------------+\n```\n\n`JSON_REMOVE()` 接受一个 JSON 文档以及一个或者多个要删除的path.  The return value is the original document minus the values selected by paths that exist within the document:\n```sql\nmysql> SELECT JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]');\n+---------------------------------------------------+\n| JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]') |\n+---------------------------------------------------+\n| [\"a\", {\"b\": [true]}]                              |\n+---------------------------------------------------+\n```\n这三个path产生了如下的效果\n* `$[2]`找到匹配[10, 20]值, 然后将其删除掉.\n* 第一个`$[1].b[1]`匹配到了false值, 然后将其删除掉.\n* 第二个`$[1].b[1]`没有匹配到任何值, 因此该操作不会有任何结果.\n\n## Comparison and Ordering of JSON Values\n\nJSON文档里面的value可以通过如下操作符进行比较操作\n* =\n* <\n* <=\n* >\n* >=\n* <>\n* !=\n* <=>\n\n下面的比较操作符和方法并不支持JSON值\n* BETWEEN\n* IN()\n* GREATEST()\n* LEAST()\n\n刚才列出的比较操作符和方法会将JSON值转换成MySQL原生的numeric或者string类型, 因此他们有一个consistent non-JSON扩展类型.\n\nJSON值进行比较时会先根据JSON类型进行比较, 如果类型不同的话, 比较结果就决定于更高优先级的类型. 如果类型一样的话, 则会根据指定类型原则进行比较.\n\n下面列出了JSON类型的优先级, 从高到低进行排序. 我们可以通过`JSON_TYPE()`来获取某个值得类型.\n* BLOB\n* BIT\n* OPAQUE\n* DATETIME\n* TIME\n* DATE\n* BOOLEAN\n* ARRAY\n* OBJECT\n* STRING\n* INTEGER, DOUBLE\n* NULL\n如果JSON值拥有相同的优先级的话, 那么不同的类型或根据下面介绍的规则进行比较:\n\n### BLOB\n\nThe first N bytes of the two values are compared, where N is the number of bytes in the shorter value. If the first N bytes of the two values are identical, the shorter value is ordered before the longer value.\n\n### BIT\n\nSame rules as for BLOB.\n\n### OPAQUE\n\nSame rules as for BLOB. OPAQUE values are values that are not classified as one of the other types.\n\n### DATETIME\n\nA value that represents an earlier point in time is ordered before a value that represents a later point in time. If two values originally come from the MySQL DATETIME and TIMESTAMP types, respectively, they are equal if they represent the same point in time.\n\n### TIME\n\nThe smaller of two time values is ordered before the larger one.\n\n### DATE\n\nThe earlier date is ordered before the more recent date.\n\n### ARRAY\n\nTwo JSON arrays are equal if they have the same length and values in corresponding positions in the arrays are equal.\n\nIf the arrays are not equal, their order is determined by the elements in the first position where there is a difference. The array with the smaller value in that position is ordered first. If all values of the shorter array are equal to the corresponding values in the longer array, the shorter array is ordered first.\n\nExample:\n```json\n[] < [\"a\"] < [\"ab\"] < [\"ab\", \"cd\", \"ef\"] < [\"ab\", \"ef\"]\n```\n\n###BOOLEAN\n\nThe JSON false literal is less than the JSON true literal.\n\n### OBJECT\n\nTwo JSON objects are equal if they have the same set of keys, and each key has the same value in both objects.\n\nExample:\n```json\n{\"a\": 1, \"b\": 2} = {\"b\": 2, \"a\": 1}\n```\n\nThe order of two objects that are not equal is unspecified but deterministic.\n\n### STRING\n\nStrings are ordered lexically on the first N bytes of the utf8mb4 representation of the two strings being compared, where N is the length of the shorter string. If the first N bytes of the two strings are identical, the shorter string is considered smaller than the longer string.\n\nExample:\n\n\"a\" < \"ab\" < \"b\" < \"bc\"\nThis ordering is equivalent to the ordering of SQL strings with collation utf8mb4_bin. Because utf8mb4_bin is a binary collation, comparison of JSON values is case sensitive:\n\n\"A\" < \"a\"\n\n### INTEGER, DOUBLE\n\nJSON values can contain exact-value numbers and approximate-value numbers. For a general discussion of these types of numbers, see Section 10.1.2, “Number Literals”.\n\nThe rules for comparing native MySQL numeric types are discussed in Section 13.2, “Type Conversion in Expression Evaluation”, but the rules for comparing numbers within JSON values differ somewhat:\n\nIn a comparison between two columns that use the native MySQL INT and DOUBLE numeric types, respectively, it is known that all comparisons involve an integer and a double, so the integer is converted to double for all rows. That is, exact-value numbers are converted to approximate-value numbers.\n\nOn the other hand, if the query compares two JSON columns containing numbers, it cannot be known in advance whether numbers will be integer or double. To provide the most consistent behavior across all rows, MySQL converts approximate-value numbers to exact-value numbers. The resulting ordering is consistent and does not lose precision for the exact-value numbers. For example, given the scalars 9223372036854775805, 9223372036854775806, 9223372036854775807 and 9.223372036854776e18, the order is such as this:\n\n9223372036854775805 < 9223372036854775806 < 9223372036854775807\n< 9.223372036854776e18 = 9223372036854776000 < 9223372036854776001\nWere JSON comparisons to use the non-JSON numeric comparison rules, inconsistent ordering could occur. The usual MySQL comparison rules for numbers yield these orderings:\n\nInteger comparison:\n\n9223372036854775805 < 9223372036854775806 < 9223372036854775807\n(not defined for 9.223372036854776e18)\n\nDouble comparison:\n\n9223372036854775805 = 9223372036854775806 = 9223372036854775807 = 9.223372036854776e18\nFor comparison of any JSON value to SQL NULL, the result is UNKNOWN.\n\nFor comparison of JSON and non-JSON values, the non-JSON value is converted to JSON according to the rules in the following table, then the values compared as described previously.\n\nConverting between JSON and non-JSON values.  The following table provides a summary of the rules that MySQL follows when casting between JSON values and values of other types:\n\nConverting between JSON and non-JSON values.  The following table provides a summary of the rules that MySQL follows when casting between JSON values and values of other types:\n\nTable 12.1 JSON Conversion Rules\n\nother type\tCAST(other type AS JSON)\tCAST(JSON AS other type)\nJSON\tNo change\tNo change\nutf8 character type (utf8mb4, utf8, ascii)\tThe string is parsed into a JSON value.\tThe JSON value is serialized into a utf8mb4 string.\nOther character types\tOther character encodings are implicitly converted to utf8mb4 and treated as described for utf8 character type.\tThe JSON value is serialized into a utf8mb4 string, then cast to the other character encoding. The result may not be meaningful.\nNULL\tResults in a NULL value of type JSON.\tNot applicable.\nGeometry types\tThe geometry value is converted into a JSON document by calling ST_AsGeoJSON().\tIllegal operation. Workaround: Pass the result of CAST(json_val AS CHAR) to ST_GeomFromGeoJSON().\nAll other types\tResults in a JSON document consisting of a single scalar value.\tSucceeds if the JSON document consists of a single scalar value of the target type and that scalar value can be cast to the target type. Otherwise, returns NULL and produces a warning.\n\nORDER BY and GROUP BY for JSON values works according to these principles:\n\nOrdering of scalar JSON values uses the same rules as in the preceding discussion.\n\nFor ascending sorts, SQL NULL orders before all JSON values, including the JSON null literal; for descending sorts, SQL NULL orders after all JSON values, including the JSON null literal.\n\nSort keys for JSON values are bound by the value of the max_sort_length system variable, so keys that differ only after the first max_sort_length bytes compare as equal.\n\nSorting of nonscalar values is not currently supported and a warning occurs.\n\nFor sorting, it can be beneficial to cast a JSON scalar to some other native MySQL type. For example, if a column named jdoc contains JSON objects having a member consisting of an id key and a nonnegative value, use this expression to sort by id values:\n\nORDER BY CAST(JSON_EXTRACT(jdoc, '$.id') AS UNSIGNED)\nIf there happens to be a generated column defined to use the same expression as in the ORDER BY, the MySQL optimizer recognizes that and considers using the index for the query execution plan. See Section 9.3.9, “Optimizer Use of Generated Column Indexes”.\n","slug":"数据库/Mysql JSON Data Type","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3700b5vjs6axo7pky5"},{"date":"2016-05-09T16:00:00.000Z","title":"Mysql Secondary Indexes and Generated Virtual Columns","_content":"[官方文档](http://dev.mysql.com/doc/refman/5.7/en/create-table-secondary-indexes-virtual-columns.html)\n\n## Generated Columns\ngenerated column是由普通column生成的列.\n```sql\nCREATE TABLE sum (\n  num1 int,\n  num2 int,\n  sum int AS (num1 + num2)\n);\nINSERT INTO sum (num1, num2) VALUES(1,1),(3,4);\nmysql> SELECT * FROM triangle;\n+-------+-------+--------------------+\n| num1  | num2  | sum                |\n+-------+-------+--------------------+\n|     1 |     1 |                  2 |\n|     3 |     4 |                  7 |\n+-------+-------+--------------------+\n```\n语法为\n```sql\ncol_name data_type [GENERATED ALWAYS] AS (expression)\n  [VIRTUAL | STORED] [UNIQUE [KEY]] [COMMENT comment]\n  [[NOT] NULL] [[PRIMARY] KEY]\n```\n* VIRTUAL: 不存储值到磁盘上\n* STORED : 将值存储到磁盘上\n\n## Secondary Indexes\n从MySQL5.7.8开始, InnoDB引擎基于自生成(generated virtual columns)的虚拟列支持辅助索引索引(secondary indexes, 并不支持其他索引, 例如簇索引等).\n\nsecondary indexe可以基于一个, 多个, 组合virtual columns或者非generated virtual columns生成。当基于virtual column的secondary index可以由`UNIQUE`进行定义.\n\n当基于generated virtual column创建的secondary index, generated column的值就体现在了这个secondary index的记录上. 如果这个索引是一个covering index, generated column值是从索引中已经生成的值进行索引, 而不是再自己计算一遍.\n> covering index 查询时检索所有的column.\n\n在执行`INSERT`和`UPDATE`这样的写操作时, 如果用到了基于virtual column的辅助索引时, 那么生成virtual column时会产生额外的性能消耗. 甚至当使用STORED generated columns时, 写操作会带来更多的性能消耗, 还有更多的内存和磁盘消耗. 如果secondary index不是基于virtual column, 当产生读操作时会带来更多的性能消耗, 这是因为virtual column的值每当该column的列被检查时都会计算一次.\n\n当发生回滚或者清除操作时, 被索引过的virtual column已经经过里MVCC-logged, 如此一来就可以以避免再计算一次. logged值的长度是由索引长度限制的, `COMPACT`和`REDUNDANT`是767字节, `DYNAMIC`和`COMPRESSED`是3072个字节.\n\n在virtual column 上增加或者删除secondary index是一个内置的操作.\n\nvirtual column 上的secondary index不能成为外键的索引. 同样secondary index的virtual column也不能指向外键, 而且也不能使用如下的语句定义\n* ON DELETE CASCADE\n* ON DELETE SET NULL\n* ON UPDATE CASCADE\n* ON UPDATE SET NULL.\n\n## Generated Virtual Column索引JSON Column上\nJSON columns是不能被直接索引的. 但是我们可以通过创建一个generated column来间接为JSON columns生成一个索引, 如下例:\n```sql\nmysql> CREATE TABLE jemp (\n    ->     c JSON,\n    ->     g INT GENERATED ALWAYS AS (JSON_EXTRACT(c, '$.id')),\n    ->     INDEX i (g)\n    -> );\nQuery OK, 0 rows affected (0.28 sec)\n\nmysql> INSERT INTO jemp (c) VALUES\n     >   ('{\"id\": \"1\", \"name\": \"Fred\"}'), ('{\"id\": \"2\", \"name\": \"Wilma\"}'),\n     >   ('{\"id\": \"3\", \"name\": \"Barney\"}'), ('{\"id\": \"4\", \"name\": \"Betty\"}');\nQuery OK, 4 rows affected (0.04 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> SELECT JSON_UNQUOTE(JSON_EXTRACT(c, '$.name')) AS name\n     >     FROM jemp WHERE g > 2;\n+--------+\n| name   |\n+--------+\n| Barney |\n| Betty  |\n+--------+\n2 rows in set (0.00 sec)\n\nmysql> EXPLAIN SELECT JSON_UNQUOTE(JSON_EXTRACT(c, '$.name')) AS name\n     >    FROM jemp WHERE g > 2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`,'$.name'))\nAS `name` from `test`.`jemp` where (`test`.`jemp`.`g` > 2)\n1 row in set (0.00 sec)\n```\n> 关于上例中创建表的更多信息参考 [Section 9.3.9, “Optimizer Use of Generated Column Indexes”]()\n\n在Mysql 5.7.9以后, 你可以使用`->`替代`JSON_EXTRACT()`作为path访问JSON列.\n\n当你使用`EXPLAIN`的语句中包含了一个或者多个`->`操作符时, 它们会被`JSON_EXTRACT()`进行替换.\n```sql\nmysql> EXPLAIN SELECT c->\"$.name\"\n     > FROM jemp WHERE g > 2\\G ORDER BY c->\"$.name\"\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where; Using filesort\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_extract(`test`.`jemp`.`c`,'$.name') AS\n`c->\"$.name\"` from `test`.`jemp` where (`test`.`jemp`.`g` > 2) order by\njson_extract(`test`.`jemp`.`c`,'$.name')  \n1 row in set (0.00 sec)\n```\n","source":"_posts/数据库/Mysql Secondary Indexes and Generated Virtual Columns.md","raw":"category: 数据库\ndate: 2016-05-10\ntitle: Mysql Secondary Indexes and Generated Virtual Columns\n---\n[官方文档](http://dev.mysql.com/doc/refman/5.7/en/create-table-secondary-indexes-virtual-columns.html)\n\n## Generated Columns\ngenerated column是由普通column生成的列.\n```sql\nCREATE TABLE sum (\n  num1 int,\n  num2 int,\n  sum int AS (num1 + num2)\n);\nINSERT INTO sum (num1, num2) VALUES(1,1),(3,4);\nmysql> SELECT * FROM triangle;\n+-------+-------+--------------------+\n| num1  | num2  | sum                |\n+-------+-------+--------------------+\n|     1 |     1 |                  2 |\n|     3 |     4 |                  7 |\n+-------+-------+--------------------+\n```\n语法为\n```sql\ncol_name data_type [GENERATED ALWAYS] AS (expression)\n  [VIRTUAL | STORED] [UNIQUE [KEY]] [COMMENT comment]\n  [[NOT] NULL] [[PRIMARY] KEY]\n```\n* VIRTUAL: 不存储值到磁盘上\n* STORED : 将值存储到磁盘上\n\n## Secondary Indexes\n从MySQL5.7.8开始, InnoDB引擎基于自生成(generated virtual columns)的虚拟列支持辅助索引索引(secondary indexes, 并不支持其他索引, 例如簇索引等).\n\nsecondary indexe可以基于一个, 多个, 组合virtual columns或者非generated virtual columns生成。当基于virtual column的secondary index可以由`UNIQUE`进行定义.\n\n当基于generated virtual column创建的secondary index, generated column的值就体现在了这个secondary index的记录上. 如果这个索引是一个covering index, generated column值是从索引中已经生成的值进行索引, 而不是再自己计算一遍.\n> covering index 查询时检索所有的column.\n\n在执行`INSERT`和`UPDATE`这样的写操作时, 如果用到了基于virtual column的辅助索引时, 那么生成virtual column时会产生额外的性能消耗. 甚至当使用STORED generated columns时, 写操作会带来更多的性能消耗, 还有更多的内存和磁盘消耗. 如果secondary index不是基于virtual column, 当产生读操作时会带来更多的性能消耗, 这是因为virtual column的值每当该column的列被检查时都会计算一次.\n\n当发生回滚或者清除操作时, 被索引过的virtual column已经经过里MVCC-logged, 如此一来就可以以避免再计算一次. logged值的长度是由索引长度限制的, `COMPACT`和`REDUNDANT`是767字节, `DYNAMIC`和`COMPRESSED`是3072个字节.\n\n在virtual column 上增加或者删除secondary index是一个内置的操作.\n\nvirtual column 上的secondary index不能成为外键的索引. 同样secondary index的virtual column也不能指向外键, 而且也不能使用如下的语句定义\n* ON DELETE CASCADE\n* ON DELETE SET NULL\n* ON UPDATE CASCADE\n* ON UPDATE SET NULL.\n\n## Generated Virtual Column索引JSON Column上\nJSON columns是不能被直接索引的. 但是我们可以通过创建一个generated column来间接为JSON columns生成一个索引, 如下例:\n```sql\nmysql> CREATE TABLE jemp (\n    ->     c JSON,\n    ->     g INT GENERATED ALWAYS AS (JSON_EXTRACT(c, '$.id')),\n    ->     INDEX i (g)\n    -> );\nQuery OK, 0 rows affected (0.28 sec)\n\nmysql> INSERT INTO jemp (c) VALUES\n     >   ('{\"id\": \"1\", \"name\": \"Fred\"}'), ('{\"id\": \"2\", \"name\": \"Wilma\"}'),\n     >   ('{\"id\": \"3\", \"name\": \"Barney\"}'), ('{\"id\": \"4\", \"name\": \"Betty\"}');\nQuery OK, 4 rows affected (0.04 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> SELECT JSON_UNQUOTE(JSON_EXTRACT(c, '$.name')) AS name\n     >     FROM jemp WHERE g > 2;\n+--------+\n| name   |\n+--------+\n| Barney |\n| Betty  |\n+--------+\n2 rows in set (0.00 sec)\n\nmysql> EXPLAIN SELECT JSON_UNQUOTE(JSON_EXTRACT(c, '$.name')) AS name\n     >    FROM jemp WHERE g > 2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`,'$.name'))\nAS `name` from `test`.`jemp` where (`test`.`jemp`.`g` > 2)\n1 row in set (0.00 sec)\n```\n> 关于上例中创建表的更多信息参考 [Section 9.3.9, “Optimizer Use of Generated Column Indexes”]()\n\n在Mysql 5.7.9以后, 你可以使用`->`替代`JSON_EXTRACT()`作为path访问JSON列.\n\n当你使用`EXPLAIN`的语句中包含了一个或者多个`->`操作符时, 它们会被`JSON_EXTRACT()`进行替换.\n```sql\nmysql> EXPLAIN SELECT c->\"$.name\"\n     > FROM jemp WHERE g > 2\\G ORDER BY c->\"$.name\"\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where; Using filesort\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_extract(`test`.`jemp`.`c`,'$.name') AS\n`c->\"$.name\"` from `test`.`jemp` where (`test`.`jemp`.`g` > 2) order by\njson_extract(`test`.`jemp`.`c`,'$.name')  \n1 row in set (0.00 sec)\n```\n","slug":"数据库/Mysql Secondary Indexes and Generated Virtual Columns","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3900b6vjs6wtb40pmv"},{"date":"2015-10-07T16:00:00.000Z","title":"Mysql 增删改查","_content":"## 连接数据库\n```\nmysql -h 主机地址 -u 用户名 －p 用户密码 （注:u与root可以不用加空格，其它也一样）\n```\n\n## 用户操作\n创建用户\n```\nCREATE USER 'username'@'host' IDENTIFIED BY 'password';\n```\n授权: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' \n```\n> privileges - 用户的操作权限,如SELECT,INSERT,UPDATE等.如果要授予所的权限则使用ALL;如果要授予该用户对所有数据库和表的相应操作权限则可用*表示, 如*.*. \n\n用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; \n```\n设置与更改用户密码 \n```\nSET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');\n```\n撤销用户权限 \n```\nREVOKE privilege ON databasename.tablename FROM 'username'@'host'; \n```\n删除用户 \n```\nDROP USER 'username'@'host';\n```\n\n## 数据库操作 \n* 显示数据库：`SHOW databases`; \n* 创建库：`CREATE DATABASE 库名`; \n* 删除库：`DROP DATABASE 库名`; \n* 使用库(选中库)：`USE 库名`; \n\n## 表操作\n* 显示数据表：`SHOW tables`\n* 显示表结构：`DESC 表名`\n* 删除表：`DROP TABLE 表名`; \n* 输入创建表的DDL语句 `SHOW CREATE TABLE 表名;`\n* 创建表：\n```sql\nCREATE TABLE  \n    USER  \n    (  \n        name VARCHAR(30) NOT NULL,  \n        id INT DEFAULT '0' NOT NULL,  \n        stu_id INT,  \n        phone VARCHAR(20),  \n        address VARCHAR(30) NOT NULL,  \n        age INT(4) NOT NULL,  \n        PRIMARY KEY (name),  \n        CONSTRAINT stu_id UNIQUE (stu_id)  \n    )  \n    ENGINE=InnoDB DEFAULT CHARSET=utf8;  \n```\n\n### 表数据操作\n* 清空表数据`truncate table 表名;`. truncate删除后不记录mysql日志，不可以恢复数据。相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。\n* 清空表数据`delete from 表名`. delete的效果有点像将mysql表中所有记录一条一条删除到删完\n\n### 修改表结构\n* 修改列名`alter table 表名称 change 字段名称 字段名称`\n* 修改表名`alter table 表名称 rename 表名称`\n* 修改某个表的字段类型及指定为空或非空`alter table 表名称 change 字段名称字段名称 字段类型 [null/not null];`\n* 修改某个表的字段名称及指定为空或非空`alter table 表名称 change 字段原名称字段新名称 字段类型 [null/not null];`\n* 增加一个字段(一列)`alter table table_name add column column_name type default value;` type指该字段的类型,value指该字段的默认值\n* 更改一个字段名字(也可以改变类型和默认值)`alter table table_name change sorce_col_name dest_col_name type defaultvalue;` source_col_name指原来的字段名称,dest_col_name指改后的字段名称\n* 改变一个字段的默认值`alter table table_name alter column_name set default value;`\n* 改变一个字段的数据类型`alter table table_name change column column_name column_name type;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 删除字段`alter table form1 drop column 列名;`\n\n\n### 复制表\n* 含有主键等信息的完整表结构 `CREATE table 新表名 LIKE book;`\n* 只有表结构，没有主键等信息 `create table 新表名 select * from books;\n* 将旧表中的数据灌入新表 `INSERT INTO 新表 SELECT * FROM 旧表；` 注：新表必须已经存在\n\n### 导入导出数据库\n* 数据库某表的备份,在命令行中输入:`mysqldump -u root -p database_name table_name > bak_file_name`\n* 导出数据`select_statment into outfile”dest_file”;`\n* 导入数据`load data infile”file_name” into table table_name;`\n* 将两个表里的数据拼接后插入到另一个表里`insert into tx select t1.com1,concat(t1.com2,t2.com1) from t1,t2;`\n\n### 查询表\nmysql查询的五种子句 \n\n#### where(条件查询)\n```sql\nSELECT * FROM t1 WHERE id > 100;\n```\n* 数值谓词:`>,=,<,<>,!=,!>,!<,=>,=<`\n* 字符串谓词：`=，like`\n* 日期谓词：`=` (`SELECT * from t1 WHERE create_time = '2011-04-08'`)\n\n\n#### having（筛选）\n```sql\n\n```\n\n#### group by（分组）\n```sql\nSELECT id FROM player GROUP BY vip;\n```\n\n#### order by（排序）\n```sql\nSELECT id FROM player ORDER BY id;\n```\n\n#### limit（限制结果数）\n查询前n条记录(默认从第0个开始)\n```sql\nSELECT id FROM player LIMIT 10;\n```\n从结果集中第1个开始查询, 查询10个\n```sql\nSELECT id FROM player LIMIT 1, 10;\n```\n\n## 执行顺序\nsql语句的执行顺序\n```sql\n(7)     SELECT \n(8)     DISTINCT <select_list>\n(1)     FROM <left_table>\n(3)     <join_type> JOIN <right_table>\n(2)     ON <join_condition>\n(4)     WHERE <where_condition>\n(5)     GROUP BY <group_by_list>\n(6)     HAVING <having_condition>\n(9)     ORDER BY <order_by_condition>\n(10)    LIMIT <limit_number>\n```\n也就是\n```\nFROM->ON->JOIN->WHERE->GROUP BY->HAVING->SELECT->DISTINCT->ORDER BY->LIMIT\n```","source":"_posts/数据库/Mysql 增删改查.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: Mysql 增删改查\n---\n## 连接数据库\n```\nmysql -h 主机地址 -u 用户名 －p 用户密码 （注:u与root可以不用加空格，其它也一样）\n```\n\n## 用户操作\n创建用户\n```\nCREATE USER 'username'@'host' IDENTIFIED BY 'password';\n```\n授权: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' \n```\n> privileges - 用户的操作权限,如SELECT,INSERT,UPDATE等.如果要授予所的权限则使用ALL;如果要授予该用户对所有数据库和表的相应操作权限则可用*表示, 如*.*. \n\n用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; \n```\n设置与更改用户密码 \n```\nSET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');\n```\n撤销用户权限 \n```\nREVOKE privilege ON databasename.tablename FROM 'username'@'host'; \n```\n删除用户 \n```\nDROP USER 'username'@'host';\n```\n\n## 数据库操作 \n* 显示数据库：`SHOW databases`; \n* 创建库：`CREATE DATABASE 库名`; \n* 删除库：`DROP DATABASE 库名`; \n* 使用库(选中库)：`USE 库名`; \n\n## 表操作\n* 显示数据表：`SHOW tables`\n* 显示表结构：`DESC 表名`\n* 删除表：`DROP TABLE 表名`; \n* 输入创建表的DDL语句 `SHOW CREATE TABLE 表名;`\n* 创建表：\n```sql\nCREATE TABLE  \n    USER  \n    (  \n        name VARCHAR(30) NOT NULL,  \n        id INT DEFAULT '0' NOT NULL,  \n        stu_id INT,  \n        phone VARCHAR(20),  \n        address VARCHAR(30) NOT NULL,  \n        age INT(4) NOT NULL,  \n        PRIMARY KEY (name),  \n        CONSTRAINT stu_id UNIQUE (stu_id)  \n    )  \n    ENGINE=InnoDB DEFAULT CHARSET=utf8;  \n```\n\n### 表数据操作\n* 清空表数据`truncate table 表名;`. truncate删除后不记录mysql日志，不可以恢复数据。相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。\n* 清空表数据`delete from 表名`. delete的效果有点像将mysql表中所有记录一条一条删除到删完\n\n### 修改表结构\n* 修改列名`alter table 表名称 change 字段名称 字段名称`\n* 修改表名`alter table 表名称 rename 表名称`\n* 修改某个表的字段类型及指定为空或非空`alter table 表名称 change 字段名称字段名称 字段类型 [null/not null];`\n* 修改某个表的字段名称及指定为空或非空`alter table 表名称 change 字段原名称字段新名称 字段类型 [null/not null];`\n* 增加一个字段(一列)`alter table table_name add column column_name type default value;` type指该字段的类型,value指该字段的默认值\n* 更改一个字段名字(也可以改变类型和默认值)`alter table table_name change sorce_col_name dest_col_name type defaultvalue;` source_col_name指原来的字段名称,dest_col_name指改后的字段名称\n* 改变一个字段的默认值`alter table table_name alter column_name set default value;`\n* 改变一个字段的数据类型`alter table table_name change column column_name column_name type;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 删除字段`alter table form1 drop column 列名;`\n\n\n### 复制表\n* 含有主键等信息的完整表结构 `CREATE table 新表名 LIKE book;`\n* 只有表结构，没有主键等信息 `create table 新表名 select * from books;\n* 将旧表中的数据灌入新表 `INSERT INTO 新表 SELECT * FROM 旧表；` 注：新表必须已经存在\n\n### 导入导出数据库\n* 数据库某表的备份,在命令行中输入:`mysqldump -u root -p database_name table_name > bak_file_name`\n* 导出数据`select_statment into outfile”dest_file”;`\n* 导入数据`load data infile”file_name” into table table_name;`\n* 将两个表里的数据拼接后插入到另一个表里`insert into tx select t1.com1,concat(t1.com2,t2.com1) from t1,t2;`\n\n### 查询表\nmysql查询的五种子句 \n\n#### where(条件查询)\n```sql\nSELECT * FROM t1 WHERE id > 100;\n```\n* 数值谓词:`>,=,<,<>,!=,!>,!<,=>,=<`\n* 字符串谓词：`=，like`\n* 日期谓词：`=` (`SELECT * from t1 WHERE create_time = '2011-04-08'`)\n\n\n#### having（筛选）\n```sql\n\n```\n\n#### group by（分组）\n```sql\nSELECT id FROM player GROUP BY vip;\n```\n\n#### order by（排序）\n```sql\nSELECT id FROM player ORDER BY id;\n```\n\n#### limit（限制结果数）\n查询前n条记录(默认从第0个开始)\n```sql\nSELECT id FROM player LIMIT 10;\n```\n从结果集中第1个开始查询, 查询10个\n```sql\nSELECT id FROM player LIMIT 1, 10;\n```\n\n## 执行顺序\nsql语句的执行顺序\n```sql\n(7)     SELECT \n(8)     DISTINCT <select_list>\n(1)     FROM <left_table>\n(3)     <join_type> JOIN <right_table>\n(2)     ON <join_condition>\n(4)     WHERE <where_condition>\n(5)     GROUP BY <group_by_list>\n(6)     HAVING <having_condition>\n(9)     ORDER BY <order_by_condition>\n(10)    LIMIT <limit_number>\n```\n也就是\n```\nFROM->ON->JOIN->WHERE->GROUP BY->HAVING->SELECT->DISTINCT->ORDER BY->LIMIT\n```","slug":"数据库/Mysql 增删改查","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3b00b9vjs6zx8g7ykl"},{"date":"2016-05-07T16:00:00.000Z","title":"Mysql 客户端","_content":"## mycli\n[MyCli](http://mycli.net/index) 是一个 MySQL 命令行工具，支持自动补全和语法高亮\n\n## dbv\n数据库版本控制系统 http://dbv.vizuina.com\n","source":"_posts/数据库/Mysql 客户端.md","raw":"category: 数据库\ndate: 2016-05-08\ntitle: Mysql 客户端\n---\n## mycli\n[MyCli](http://mycli.net/index) 是一个 MySQL 命令行工具，支持自动补全和语法高亮\n\n## dbv\n数据库版本控制系统 http://dbv.vizuina.com\n","slug":"数据库/Mysql 客户端","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3e00bavjs6pq8gc1f6"},{"date":"2015-10-07T16:00:00.000Z","title":"Mysql 数据类型","_content":"\n## varchar\nvarchar 字段是将实际内容单独存储在聚簇索引之外，内容开头用1到2个字节表示实际长度（长度超过255时需要2个字节），因此最大长度不能超过65535(2^16)。\n* 字符类型若为gbk，每个字符最多占2个字节，最大长度不能超过32766; \n* 字符类型若为utf8，每个字符最多占3个字节，最大长度不能超过21845。 \n* 对于英文比较多的论坛 ，使用GBK则每个字符占用2个字节，而使用UTF－8英文却只占一个字节。 \n* 若定义的时候超过上述限制，则varchar字段会被强行转为text类型，并产生warning。 ","source":"_posts/数据库/Mysql 数据类型.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: Mysql 数据类型\n---\n\n## varchar\nvarchar 字段是将实际内容单独存储在聚簇索引之外，内容开头用1到2个字节表示实际长度（长度超过255时需要2个字节），因此最大长度不能超过65535(2^16)。\n* 字符类型若为gbk，每个字符最多占2个字节，最大长度不能超过32766; \n* 字符类型若为utf8，每个字符最多占3个字节，最大长度不能超过21845。 \n* 对于英文比较多的论坛 ，使用GBK则每个字符占用2个字节，而使用UTF－8英文却只占一个字节。 \n* 若定义的时候超过上述限制，则varchar字段会被强行转为text类型，并产生warning。 ","slug":"数据库/Mysql 数据类型","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3m00bdvjs6ms2cccm9"},{"date":"2015-10-07T16:00:00.000Z","title":"Mysql 索引","_content":"一般我们在创建索引的时候都要指定它的索引名字. 当然这个不是必须的.\n\n### 普通索引\n```sql\nCREATE INDEX idxName ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  INDEX (id)\n)\n```\n\n### 唯一索引\n与普通索引相比值唯一, 可以有空值\n```sql\nCREATE UNIQUE INDEX id ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  UNIQUE (id)\n)\n```\n\n### 主键索引\n与普通索引相比值唯一, 不可以有空值\n```sql\nCREATE TABLE t1 (\n  id int NOT NULL,\n  PRIMARY KEY (id)\n)\n```\n\n### 组合索引\n下面我们创建了一个唯一组合索引.\n```sql\nCREATE TABLE `t1` (\n  `id` int(11) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  UNIQUE KEY `idx` (`id`,`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n### 索引注意事项\n* 如果索引上出现`NULL`值(包含组合索引),那么这一行就不会被索引\n* 我们要尽可能的使用短索引(指定一个前缀长度),例如对varchar类型进行索引,它的长度是16个字符,但是前6个字符是固定的,那么我们指定前缀长度为6就好了\n* 尽量不要对索引进行`like`操作\n* 不要在索引列上使用`NOT IN`和`<>`操作","source":"_posts/数据库/Mysql 索引.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: Mysql 索引\n---\n一般我们在创建索引的时候都要指定它的索引名字. 当然这个不是必须的.\n\n### 普通索引\n```sql\nCREATE INDEX idxName ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  INDEX (id)\n)\n```\n\n### 唯一索引\n与普通索引相比值唯一, 可以有空值\n```sql\nCREATE UNIQUE INDEX id ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  UNIQUE (id)\n)\n```\n\n### 主键索引\n与普通索引相比值唯一, 不可以有空值\n```sql\nCREATE TABLE t1 (\n  id int NOT NULL,\n  PRIMARY KEY (id)\n)\n```\n\n### 组合索引\n下面我们创建了一个唯一组合索引.\n```sql\nCREATE TABLE `t1` (\n  `id` int(11) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  UNIQUE KEY `idx` (`id`,`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n### 索引注意事项\n* 如果索引上出现`NULL`值(包含组合索引),那么这一行就不会被索引\n* 我们要尽可能的使用短索引(指定一个前缀长度),例如对varchar类型进行索引,它的长度是16个字符,但是前6个字符是固定的,那么我们指定前缀长度为6就好了\n* 尽量不要对索引进行`like`操作\n* 不要在索引列上使用`NOT IN`和`<>`操作","slug":"数据库/Mysql 索引","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3q00bevjs6z14wj1ub"},{"date":"2015-10-07T16:00:00.000Z","title":"Mycat全局序列号","_content":"[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\nMycat的全局序列号分为俩部分\n* 本地文件方式\n* 数据库方式\n\n因为本地文件方式当Mycat重启之后，里面记录的数据会被重置，所以我就只记录一下数据库方式.\n\n在`server.xml`文件中进行如下配置\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"sequnceHandlerType\">1</property>\n\t</system>\n</mycat:server>\n```\n接下来我们创建一张表,用于存放ID\n```sql\nDROP TABLE IF EXISTS MYCAT_SEQUENCE;\nCREATE TABLE db1.MYCAT_SEQUENCE\n(\n  name VARCHAR(10),\n  currentValue BIGINT DEFAULT 1 NOT NULL ,\n  increment INT DEFAULT 1 NOT NULL,\n  PRIMARY KEY(name)\n) ENGINE=InnoDB CHAR SET=utf8;\n```\n获取当前sequence的值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_currval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\n\tDECLARE retval VARCHAR(64);\n\tSET retval=\"-999999999,null\";\n\tSELECT CONCAT(CAST(current_value AS CHAR),\",\",CAST(increment AS CHAR))\n\t INTO retval\n\t FROM MYCAT_SEQUENCE\n\t WHERE NAME = seq_name;\n\t RETURN retval;\nEND\n$$\nDELIMITER ;\n```\n> 这里需要说明一点的是, 由于mysql默认分隔符为`;`,因此我们要先使用`DELIMITER $$`将分隔符置为`&&`,不然的话在函数里也使用到了`;`会影响到函数,最后再将分隔符置为`;`\n\n设置sequence值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_setval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),VALUE INTEGER) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\nUPDATE MYCAT_SEQUENCE\nSET current_value = VALUE\nWHERE NAME = seq_name;\nRETURN mycat_seq_currval(seq_name);\nEND\n$$\nDELIMITER ;\n```\n\n获取下一个sequence值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_nextval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\nUPDATE MYCAT_SEQUENCE\nSET current_value = current_value + increment WHERE NAME = seq_name;\nRETURN mycat_seq_currval(seq_name);\nEND\n$$\nDELIMITER ;\n```\n然后修改`sequence_db_conf.properties`这个配置文件\n```shell\n#sequence stored in datanode\nGLOBAL=dn1\nCOMPANY=dn1\nCUSTOMER=dn1\nORDERS=dn1\n```\n* `GLOBAL`\n* `COMPANY`\n* `CUSTOMER`\n* `ORDERS`\n","source":"_posts/数据库/mycat全局序列号.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: Mycat全局序列号\n---\n[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\nMycat的全局序列号分为俩部分\n* 本地文件方式\n* 数据库方式\n\n因为本地文件方式当Mycat重启之后，里面记录的数据会被重置，所以我就只记录一下数据库方式.\n\n在`server.xml`文件中进行如下配置\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"sequnceHandlerType\">1</property>\n\t</system>\n</mycat:server>\n```\n接下来我们创建一张表,用于存放ID\n```sql\nDROP TABLE IF EXISTS MYCAT_SEQUENCE;\nCREATE TABLE db1.MYCAT_SEQUENCE\n(\n  name VARCHAR(10),\n  currentValue BIGINT DEFAULT 1 NOT NULL ,\n  increment INT DEFAULT 1 NOT NULL,\n  PRIMARY KEY(name)\n) ENGINE=InnoDB CHAR SET=utf8;\n```\n获取当前sequence的值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_currval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\n\tDECLARE retval VARCHAR(64);\n\tSET retval=\"-999999999,null\";\n\tSELECT CONCAT(CAST(current_value AS CHAR),\",\",CAST(increment AS CHAR))\n\t INTO retval\n\t FROM MYCAT_SEQUENCE\n\t WHERE NAME = seq_name;\n\t RETURN retval;\nEND\n$$\nDELIMITER ;\n```\n> 这里需要说明一点的是, 由于mysql默认分隔符为`;`,因此我们要先使用`DELIMITER $$`将分隔符置为`&&`,不然的话在函数里也使用到了`;`会影响到函数,最后再将分隔符置为`;`\n\n设置sequence值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_setval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),VALUE INTEGER) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\nUPDATE MYCAT_SEQUENCE\nSET current_value = VALUE\nWHERE NAME = seq_name;\nRETURN mycat_seq_currval(seq_name);\nEND\n$$\nDELIMITER ;\n```\n\n获取下一个sequence值\n```sql\nDROP FUNCTION IF EXISTS mycat_seq_nextval;\nDELIMITER $$\nCREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS VARCHAR(64) CHARSET utf8\nDETERMINISTIC\nBEGIN\nUPDATE MYCAT_SEQUENCE\nSET current_value = current_value + increment WHERE NAME = seq_name;\nRETURN mycat_seq_currval(seq_name);\nEND\n$$\nDELIMITER ;\n```\n然后修改`sequence_db_conf.properties`这个配置文件\n```shell\n#sequence stored in datanode\nGLOBAL=dn1\nCOMPANY=dn1\nCUSTOMER=dn1\nORDERS=dn1\n```\n* `GLOBAL`\n* `COMPANY`\n* `CUSTOMER`\n* `ORDERS`\n","slug":"数据库/mycat全局序列号","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3s00bhvjs64b4ia6k9"},{"date":"2015-10-07T16:00:00.000Z","title":"Mycat分片","_content":"[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n由于分片规则主要定义在function里,因此下面的讲解中主要是针对function的讲解\n\n## 分片枚举\n```xml\n<function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n\t<property name=\"type\">0</property>\n\t<property name=\"defaultNode\">0</property>\n</function>\n```\n* mapFile: 配置文件名称\n* type: 0表示Integer，非零表示String\n* defaultNode: 枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点\n\n在partition-hash-int.txt文件中,采用`x=y`的形式, x是columns值. y是节点值. 所有的节点都是从0开始的.\n```shell\na=0\nb=1\nc=2\n```\n上面这个例子中,columns值为1的sql会路由到1的这个节点上. 节点在schema.xml中配置. 具体0对应哪个节点还需要探寻.\n\n## 范围约定\n```xml\n<function name=\"rang-long\" class=\"org.opencloudb.route.function.AutoPartitionByLong\">\n  <property name=\"mapFile\">autopartition-long.txt</property>\n  <property name=\"defaultNode\">0</property>\n</function>\n```\n这个规则是约定好,哪个范围的sql对应哪个节点,我们可以这样配置autopartition-long.txt\n```shell\n0-500=0\n500-1000=1\n1000-1500=2\n```\n这种范围的就只能适应,id分片的了\n\n## 求模\n```xml\n<function name=\"mod-long\" class=\"org.opencloudb.route.function.PartitionByMod\">\n <!-- how many data nodes  -->\n  <property name=\"count\">2</property>\n</function>\n```\n这个是根据column的十进制值进行求模分片.\n\n\n## 固定分片hash算法\n该算法是对columns的二进制的低十位进行取模运算.\n```xml\n<function name=\"partitionByLong\" class=\"org.opencloudb.route.function.PartitionByLong\">\n  <property name=\"partitionCount\">8, 1</property>\n  <property name=\"partitionLength\">128, 256</property>\n</function>\n```\n* partitionCount 分片个数列表\n* partitionLength 分片范围列表\n这来个参数的长度必须相等. 上面的例子的意思是, 在对低十位取模运算时, 128以内的sql要平均分配到8个分片上执行. 128 ~ 256的sql要到1个分片上执行\n","source":"_posts/数据库/mycat分片.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: Mycat分片\n---\n[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n由于分片规则主要定义在function里,因此下面的讲解中主要是针对function的讲解\n\n## 分片枚举\n```xml\n<function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n\t<property name=\"type\">0</property>\n\t<property name=\"defaultNode\">0</property>\n</function>\n```\n* mapFile: 配置文件名称\n* type: 0表示Integer，非零表示String\n* defaultNode: 枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点\n\n在partition-hash-int.txt文件中,采用`x=y`的形式, x是columns值. y是节点值. 所有的节点都是从0开始的.\n```shell\na=0\nb=1\nc=2\n```\n上面这个例子中,columns值为1的sql会路由到1的这个节点上. 节点在schema.xml中配置. 具体0对应哪个节点还需要探寻.\n\n## 范围约定\n```xml\n<function name=\"rang-long\" class=\"org.opencloudb.route.function.AutoPartitionByLong\">\n  <property name=\"mapFile\">autopartition-long.txt</property>\n  <property name=\"defaultNode\">0</property>\n</function>\n```\n这个规则是约定好,哪个范围的sql对应哪个节点,我们可以这样配置autopartition-long.txt\n```shell\n0-500=0\n500-1000=1\n1000-1500=2\n```\n这种范围的就只能适应,id分片的了\n\n## 求模\n```xml\n<function name=\"mod-long\" class=\"org.opencloudb.route.function.PartitionByMod\">\n <!-- how many data nodes  -->\n  <property name=\"count\">2</property>\n</function>\n```\n这个是根据column的十进制值进行求模分片.\n\n\n## 固定分片hash算法\n该算法是对columns的二进制的低十位进行取模运算.\n```xml\n<function name=\"partitionByLong\" class=\"org.opencloudb.route.function.PartitionByLong\">\n  <property name=\"partitionCount\">8, 1</property>\n  <property name=\"partitionLength\">128, 256</property>\n</function>\n```\n* partitionCount 分片个数列表\n* partitionLength 分片范围列表\n这来个参数的长度必须相等. 上面的例子的意思是, 在对低十位取模运算时, 128以内的sql要平均分配到8个分片上执行. 128 ~ 256的sql要到1个分片上执行\n","slug":"数据库/mycat分片","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3u00bivjs6b8qurlku"},{"date":"2016-03-15T16:00:00.000Z","title":"Mysql 数据压缩","_content":"我们在创建一个表的时候, 可以采用压缩技术\n```sql\nCREATE TABLE CUSTOMER (  \n…  \n) COMPRESS YES; \n```\n如果想要在中途停止表的压缩\n```sql\nALTER TABLE CUSTOMER COMPRESS NO;\n```\n但是停止之后并不会对已经存在的数据进行解压缩,如果想要对已经存在的数据解压缩的话, 我们可以使用\n```sql\nREORG TABLE CUSTOMER;\n```\n这个语句会根据当前表的压缩状态来重新整理表, 对数据进行压缩解压缩.\n\n如果我们只是想要对某个字符串字段(一般是针对Blob字段进行压缩)进行压缩的话, 那么我们可以使用压缩函数\n```sql\nCOMPRESS(string_to_compress) \n```\n然后再对其进行解压缩\n```sql\nUNCOMPRESS()\n```","source":"_posts/数据库/数据压缩.md","raw":"category: 数据库\ndate: 2016-03-16\ntitle: Mysql 数据压缩\n---\n我们在创建一个表的时候, 可以采用压缩技术\n```sql\nCREATE TABLE CUSTOMER (  \n…  \n) COMPRESS YES; \n```\n如果想要在中途停止表的压缩\n```sql\nALTER TABLE CUSTOMER COMPRESS NO;\n```\n但是停止之后并不会对已经存在的数据进行解压缩,如果想要对已经存在的数据解压缩的话, 我们可以使用\n```sql\nREORG TABLE CUSTOMER;\n```\n这个语句会根据当前表的压缩状态来重新整理表, 对数据进行压缩解压缩.\n\n如果我们只是想要对某个字符串字段(一般是针对Blob字段进行压缩)进行压缩的话, 那么我们可以使用压缩函数\n```sql\nCOMPRESS(string_to_compress) \n```\n然后再对其进行解压缩\n```sql\nUNCOMPRESS()\n```","slug":"数据库/数据压缩","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3w00blvjs6tetd0p7d"},{"date":"2015-10-07T16:00:00.000Z","title":"MySQL事务","_content":"## 事务\n事务（Transaction）是一个操作序列，它构成了并发执行的基本单元。事务的提出主要是为了解决并发情况下保持数据一致性。\n\n数据库事务具有ACID特性,即\n* 原子性： 原子性体现在对事务的修改,要么全部执行要么都不执行\n* 一致性： 保持数据的一致性,例如整数类型的数据大小不能溢出,字符型数据长度不能超过规定范围，保证数据的完整性.\n* 隔离性： 如果数据库并发执行A,B俩个事务,那么在A事务执行完之前对B事务是不可见的,也就是说,B事务是看不见A事务的中间状态的.\n* 持久性： 事务完成后,它对数据库的影响是永久的,即使数据库出现异常也是如此.\n\n\n隔离级别\n* `Read Uncommitted`: 读取未提交的数据,即其他事务已经提交修改但还未提交的数据(这是最低的隔离级别)\n* `Read Committed`: 读取已经提交的数据,但是在一个事务中,对同一个项,前后俩次读取的结果可能不同.\n* `Repetable Read`: 可重复读取,在一个事务中,对同一个项,确保前后俩次读取的结果一样\n* `Serializable`: 可序列话,即数据库的事务是可串行执行的,就像一个事务执行的时候没有别的事务同时在执行\n我们使用下面的语句来改变数据库的隔离级别\n```sql\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE\n```\n1. 不带`SESSION、GLOBAL`的SET命令,只对下一个事务有效\n2. `SET SESSION` 为当前会话设置隔离模式\n3. `SET GLOBAL`为以后新建的所有MYSQL连接设置隔离模式（当前连接不包括在内）\n\n读写异常\n* `Lost Update`: 俩个事务并发修改同一个数据,A事务提交成功,B事务提交失败回滚后,A事务的修改都可能会丢失\n* `Dirty Reads`: A事务读取了B事务更新却没有提交的数据\n* `Non-Repeatable Reads`: 一个事务对同一个数据项的多次读取可能得到不同的结果\n* `Second Lost Updates`:俩个事务并发修改同一个数据, B事务可能会覆盖掉A事务的修改\n* `Phantom Reads`: A事务进行前后俩次查询,但是在查询过程中出现了B事务向其中插入数据,那么A事务可能读取到未出现的数据\n\n隔离级别与读写异常的关系\n```\n    LU  DR  NRR  SLU  PR\nRU  N   Y   Y    Y    Y\nRC  N   N   Y    Y    Y\nRR  N   N   N   N     Y\nS   N   N   N   N     N\n```\n\n### 事务语句\n* 开始事物：`BEGIN TRANSACTION`\n* 提交事物：`COMMIT TRANSACTION`\n* 回滚事务：`ROLLBACK TRANSACTION`\n\n```sql\n# 开启一个事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(1);\n# 提交事务\nCOMMIT;\n\n# 开启事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(2);\n# 回滚刚才的事务\nROLLBACK;\n```\n\n\n\n### 并发控制\n\n#### 锁\n\n#### 写时复制\n\n#### 多版本并发控制\n\nMysql InnoDB存储引擎,InnoDB对每一行维护了俩个隐含的列,一列用于存储行被修改的时间,另一列存储每一行被删除的时间.\n> 这里的时间并不是绝对时间,而是与时间对应的数据库系统的版本号,每当一个事务开始时,InnoDB都会给这个事务分配一个递增的版本号,所以版本号也可以被任务是事务好.对于每一行的查询语句,InnoDB都会把这个查询语句的版本号同这个查询雨具遇到的行的版本号进行对比,然后结合不同的事务隔离级别来决定是否返回改行.\n\n下面以SELECT,DELETE,INSERT,UPDATE为例:\n##### SELECT\n只有同时满足下面俩个条件的行才能被返回:\n1. 行的版本号小于等于该事务的版本号\n2. 行的删除版本号要么没有定义,要么大于等于事务的版本号\n如果行的修改或者删除版本号大于事务号,说明行是被该食物后面启动的事务修改或者删除的 \n\n\n##### DELETE\nInnoDB直接把该行的删除版本号设置为当前的事务号,相当于标记为删除而不是物理删除\n\n##### INSERT\n对于新插入的行,行的修改版本号更新为该事务的事务号\n\n##### UPDATE\n更新行的时候,InnoDB会把原来的行复制一份,并把当前的事务号作为改行的修改版本号\n\n\n### 事务异常\n\n","source":"_posts/数据库/数据库事务.md","raw":"category: 数据库\ndate: 2015-10-08\ntitle: MySQL事务\n---\n## 事务\n事务（Transaction）是一个操作序列，它构成了并发执行的基本单元。事务的提出主要是为了解决并发情况下保持数据一致性。\n\n数据库事务具有ACID特性,即\n* 原子性： 原子性体现在对事务的修改,要么全部执行要么都不执行\n* 一致性： 保持数据的一致性,例如整数类型的数据大小不能溢出,字符型数据长度不能超过规定范围，保证数据的完整性.\n* 隔离性： 如果数据库并发执行A,B俩个事务,那么在A事务执行完之前对B事务是不可见的,也就是说,B事务是看不见A事务的中间状态的.\n* 持久性： 事务完成后,它对数据库的影响是永久的,即使数据库出现异常也是如此.\n\n\n隔离级别\n* `Read Uncommitted`: 读取未提交的数据,即其他事务已经提交修改但还未提交的数据(这是最低的隔离级别)\n* `Read Committed`: 读取已经提交的数据,但是在一个事务中,对同一个项,前后俩次读取的结果可能不同.\n* `Repetable Read`: 可重复读取,在一个事务中,对同一个项,确保前后俩次读取的结果一样\n* `Serializable`: 可序列话,即数据库的事务是可串行执行的,就像一个事务执行的时候没有别的事务同时在执行\n我们使用下面的语句来改变数据库的隔离级别\n```sql\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE\n```\n1. 不带`SESSION、GLOBAL`的SET命令,只对下一个事务有效\n2. `SET SESSION` 为当前会话设置隔离模式\n3. `SET GLOBAL`为以后新建的所有MYSQL连接设置隔离模式（当前连接不包括在内）\n\n读写异常\n* `Lost Update`: 俩个事务并发修改同一个数据,A事务提交成功,B事务提交失败回滚后,A事务的修改都可能会丢失\n* `Dirty Reads`: A事务读取了B事务更新却没有提交的数据\n* `Non-Repeatable Reads`: 一个事务对同一个数据项的多次读取可能得到不同的结果\n* `Second Lost Updates`:俩个事务并发修改同一个数据, B事务可能会覆盖掉A事务的修改\n* `Phantom Reads`: A事务进行前后俩次查询,但是在查询过程中出现了B事务向其中插入数据,那么A事务可能读取到未出现的数据\n\n隔离级别与读写异常的关系\n```\n    LU  DR  NRR  SLU  PR\nRU  N   Y   Y    Y    Y\nRC  N   N   Y    Y    Y\nRR  N   N   N   N     Y\nS   N   N   N   N     N\n```\n\n### 事务语句\n* 开始事物：`BEGIN TRANSACTION`\n* 提交事物：`COMMIT TRANSACTION`\n* 回滚事务：`ROLLBACK TRANSACTION`\n\n```sql\n# 开启一个事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(1);\n# 提交事务\nCOMMIT;\n\n# 开启事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(2);\n# 回滚刚才的事务\nROLLBACK;\n```\n\n\n\n### 并发控制\n\n#### 锁\n\n#### 写时复制\n\n#### 多版本并发控制\n\nMysql InnoDB存储引擎,InnoDB对每一行维护了俩个隐含的列,一列用于存储行被修改的时间,另一列存储每一行被删除的时间.\n> 这里的时间并不是绝对时间,而是与时间对应的数据库系统的版本号,每当一个事务开始时,InnoDB都会给这个事务分配一个递增的版本号,所以版本号也可以被任务是事务好.对于每一行的查询语句,InnoDB都会把这个查询语句的版本号同这个查询雨具遇到的行的版本号进行对比,然后结合不同的事务隔离级别来决定是否返回改行.\n\n下面以SELECT,DELETE,INSERT,UPDATE为例:\n##### SELECT\n只有同时满足下面俩个条件的行才能被返回:\n1. 行的版本号小于等于该事务的版本号\n2. 行的删除版本号要么没有定义,要么大于等于事务的版本号\n如果行的修改或者删除版本号大于事务号,说明行是被该食物后面启动的事务修改或者删除的 \n\n\n##### DELETE\nInnoDB直接把该行的删除版本号设置为当前的事务号,相当于标记为删除而不是物理删除\n\n##### INSERT\n对于新插入的行,行的修改版本号更新为该事务的事务号\n\n##### UPDATE\n更新行的时候,InnoDB会把原来的行复制一份,并把当前的事务号作为改行的修改版本号\n\n\n### 事务异常\n\n","slug":"数据库/数据库事务","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii3y00bmvjs6g6ewna4t"},{"date":"2015-11-17T16:00:00.000Z","title":"Elasticsearch 基本操作","_content":"\n使用Elasticsearch自带的客户端,添加maven依赖\n```xml\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>2.1.0</version>\n</dependency>\n```\n> 注意,依赖里的版本号要和Elasticsearch服务器的版本号一致\n\n\n## 节点客户端\n节点客户端以一个 无数据节点 的身份加入了一个集群。换句话说，它自身是没有任何数据的，但是他知道什么数据在集群中的哪一个节点上，然后就可以请求转发到正确的节点上并进行连接。\n```java\nSettings.Builder settings = Settings.settingsBuilder()\n\t\t.put(\"http.enabled\", false)\n\t\t.put(\"path.home\", \"D:\\\\log\\\\elasticsearch-1.7.1\")\n\t\t;\n\nNode node = nodeBuilder()\n\t\t.local(true)\n\t\t.settings(settings)\n\t\t.node();\n\nClient client = node.client();\n```\n\n## 传输客户端\n更加轻量的传输客户端可以被用来向远程集群发送请求。他并不加入集群本身，而是把请求转发到集群中的节点。\n```java\nSettings settings = Settings.settingsBuilder().build();\n\nClient client = TransportClient.builder().settings(settings).build()\n\t\t.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"localhost\"), 9300));\n```\n\n## 索引数据\n我们可以使用客户端提供的`prepareIndex()`方法索引数据,也就是向Elasticsearch添加数据\n```java\nIndexResponse indexResponse = client.prepareIndex(\"idx01\", \"type01\", \"01\").setSource(jsonObject.toJSONString()).execute().actionGet();\n\nSystem.out.println(\"IndexResponse : \" + indexResponse.getId());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getIndex());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getType());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getVersion());\n```\n结果输出为\n```java\nIndexResponse : 01\nIndexResponse : idx01\nIndexResponse : type01\nIndexResponse : 3\n```\nidx01为索引值, type01为类型值, 01为id. 当我们重复的使用这三个值向 Elasticsearch 索引数据时是合法的,但是我们会得不到不同的版本号，也就是最好的输出的那个值\n\n## 检索数据\n我们可以使用客户端提供的`prepareGet()`方法检索数据\n```java\nGetResponse getResponse = client.prepareGet(\"idx01\", \"type01\", \"01\")\n\t\t\t\t.setOperationThreaded(false)\n\t\t\t\t.get();\nSystem.out.println(\"GetResponse : \" + getResponse.getId());\nSystem.out.println(\"GetResponse : \" + getResponse.getIndex());\nSystem.out.println(\"GetResponse : \" + getResponse.getType());\nSystem.out.println(\"GetResponse : \" + getResponse.getVersion());\nSystem.out.println(\"GetResponse : \" + getResponse.getSourceAsString());\n```\n结果输出为\n```java\nGetResponse : 01\nGetResponse : idx01\nGetResponse : type01\nGetResponse : 4\nGetResponse : {\"age\":\"19\",\"name\":\"Tom\"}\n```\n\n> `setOperationThreaded()`这个方法是用来设置, 操作是否在其他的线程中执行, 设置为true就是在其他的线程中执行. 注意该操作仍然是异步执行的.\n\n#### 检索多个数据\n```java\nclient.prepareMultiGet()\n\t  .add(\"idx01\", \"type01\", \"01\")\n\t  .add(\"idx01\", \"type01\", \"02\")\n\t  .get()\n\t  .forEach(response -> System.out.println(JSON.toJSONString(response, true)));\n```\n\n## 删除数据\n```java\nDeleteResponse deleteResponse = client.prepareDelete(\"idx01\", \"type01\", \"01\").get();\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getId());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getIndex());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getType());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getVersion());\n```\n结果为\n```java\nDeleteResponse : 01\nDeleteResponse : idx01\nDeleteResponse : type01\nDeleteResponse : 6\n```\n如果我们再检索一边数据的话,会得到结果\n```java\nGetResponse : 01\nGetResponse : idx01\nGetResponse : type01\nGetResponse : -1\nGetResponse : null\n```\n说明那个文档已经被删除了\n\n## 更新数据\n我们可以使用`UpdateRequest`或者`prepareUpdate()`方法来对数据进行更新\n```java\nUpdateRequest updateRequest = new UpdateRequest();\nupdateRequest.index(\"idx01\");\nupdateRequest.type(\"type01\");\nupdateRequest.id(\"01\");\nupdateRequest.doc(jsonObject.toJSONString());\n\nclient.update(updateRequest).get();\n```\n当我们在通过`get`获取数据的时候,会发现数据已经发生了变化\n\n更新还有一个有用的功能,就是在更新的时候能实现如果有就更新,没有就插入\n```java\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx01\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.source(jsonObject.toJSONString());\n\nUpdateRequest updateRequest = new UpdateRequest()\n\t\t.index(\"idx01\")\n\t\t.type(\"type02\")\n\t\t.id(\"01\")\n\t\t.doc(jsonObject.toJSONString())\n\t\t.upsert(indexRequest);\n\nclient.update(updateRequest).get();\n```\n\n## 批处理\nelasticsearch内置的客户端中还有批处理功能,但是批处理只支持增删改, 不支持查询的功能\n```java\nBulkRequestBuilder bulkRequest = client.prepareBulk();\n\nJSONObject jsonObject = new JSONObject();\njsonObject.put(\"name\", \"Tom\");\njsonObject.put(\"age\", \"18\");\n\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.source(jsonObject.toJSONString());\nbulkRequest.add(indexRequest);\n\nUpdateRequest updateRequest = new UpdateRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.doc(jsonObject.toJSONString());\nbulkRequest.add(updateRequest);\n\nDeleteRequest deleteRequest = new DeleteRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\");\nbulkRequest.add(deleteRequest);\nBulkResponse bulkResponse = bulkRequest.get();\nbulkResponse.forEach(response -> System.out.println(response.getId()));\n\nGetResponse getResponse = client.prepareGet(\"idx02\", \"type01\", \"01\")\n\t\t.setOperationThreaded(false)\n\t\t.get();\nSystem.out.println(\"GetResponse : \" + getResponse.getId());\nSystem.out.println(\"GetResponse : \" + getResponse.getIndex());\nSystem.out.println(\"GetResponse : \" + getResponse.getType());\nSystem.out.println(\"GetResponse : \" + getResponse.getVersion());\nSystem.out.println(\"GetResponse : \" + getResponse.getSourceAsString());\n```\n","source":"_posts/日志工具/Elasticsearch 基本操作.md","raw":"category: 日志工具\ndate: 2015-11-18\ntitle: Elasticsearch 基本操作\n---\n\n使用Elasticsearch自带的客户端,添加maven依赖\n```xml\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>2.1.0</version>\n</dependency>\n```\n> 注意,依赖里的版本号要和Elasticsearch服务器的版本号一致\n\n\n## 节点客户端\n节点客户端以一个 无数据节点 的身份加入了一个集群。换句话说，它自身是没有任何数据的，但是他知道什么数据在集群中的哪一个节点上，然后就可以请求转发到正确的节点上并进行连接。\n```java\nSettings.Builder settings = Settings.settingsBuilder()\n\t\t.put(\"http.enabled\", false)\n\t\t.put(\"path.home\", \"D:\\\\log\\\\elasticsearch-1.7.1\")\n\t\t;\n\nNode node = nodeBuilder()\n\t\t.local(true)\n\t\t.settings(settings)\n\t\t.node();\n\nClient client = node.client();\n```\n\n## 传输客户端\n更加轻量的传输客户端可以被用来向远程集群发送请求。他并不加入集群本身，而是把请求转发到集群中的节点。\n```java\nSettings settings = Settings.settingsBuilder().build();\n\nClient client = TransportClient.builder().settings(settings).build()\n\t\t.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\"localhost\"), 9300));\n```\n\n## 索引数据\n我们可以使用客户端提供的`prepareIndex()`方法索引数据,也就是向Elasticsearch添加数据\n```java\nIndexResponse indexResponse = client.prepareIndex(\"idx01\", \"type01\", \"01\").setSource(jsonObject.toJSONString()).execute().actionGet();\n\nSystem.out.println(\"IndexResponse : \" + indexResponse.getId());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getIndex());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getType());\nSystem.out.println(\"IndexResponse : \" + indexResponse.getVersion());\n```\n结果输出为\n```java\nIndexResponse : 01\nIndexResponse : idx01\nIndexResponse : type01\nIndexResponse : 3\n```\nidx01为索引值, type01为类型值, 01为id. 当我们重复的使用这三个值向 Elasticsearch 索引数据时是合法的,但是我们会得不到不同的版本号，也就是最好的输出的那个值\n\n## 检索数据\n我们可以使用客户端提供的`prepareGet()`方法检索数据\n```java\nGetResponse getResponse = client.prepareGet(\"idx01\", \"type01\", \"01\")\n\t\t\t\t.setOperationThreaded(false)\n\t\t\t\t.get();\nSystem.out.println(\"GetResponse : \" + getResponse.getId());\nSystem.out.println(\"GetResponse : \" + getResponse.getIndex());\nSystem.out.println(\"GetResponse : \" + getResponse.getType());\nSystem.out.println(\"GetResponse : \" + getResponse.getVersion());\nSystem.out.println(\"GetResponse : \" + getResponse.getSourceAsString());\n```\n结果输出为\n```java\nGetResponse : 01\nGetResponse : idx01\nGetResponse : type01\nGetResponse : 4\nGetResponse : {\"age\":\"19\",\"name\":\"Tom\"}\n```\n\n> `setOperationThreaded()`这个方法是用来设置, 操作是否在其他的线程中执行, 设置为true就是在其他的线程中执行. 注意该操作仍然是异步执行的.\n\n#### 检索多个数据\n```java\nclient.prepareMultiGet()\n\t  .add(\"idx01\", \"type01\", \"01\")\n\t  .add(\"idx01\", \"type01\", \"02\")\n\t  .get()\n\t  .forEach(response -> System.out.println(JSON.toJSONString(response, true)));\n```\n\n## 删除数据\n```java\nDeleteResponse deleteResponse = client.prepareDelete(\"idx01\", \"type01\", \"01\").get();\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getId());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getIndex());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getType());\nSystem.out.println(\"DeleteResponse : \" + deleteResponse.getVersion());\n```\n结果为\n```java\nDeleteResponse : 01\nDeleteResponse : idx01\nDeleteResponse : type01\nDeleteResponse : 6\n```\n如果我们再检索一边数据的话,会得到结果\n```java\nGetResponse : 01\nGetResponse : idx01\nGetResponse : type01\nGetResponse : -1\nGetResponse : null\n```\n说明那个文档已经被删除了\n\n## 更新数据\n我们可以使用`UpdateRequest`或者`prepareUpdate()`方法来对数据进行更新\n```java\nUpdateRequest updateRequest = new UpdateRequest();\nupdateRequest.index(\"idx01\");\nupdateRequest.type(\"type01\");\nupdateRequest.id(\"01\");\nupdateRequest.doc(jsonObject.toJSONString());\n\nclient.update(updateRequest).get();\n```\n当我们在通过`get`获取数据的时候,会发现数据已经发生了变化\n\n更新还有一个有用的功能,就是在更新的时候能实现如果有就更新,没有就插入\n```java\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx01\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.source(jsonObject.toJSONString());\n\nUpdateRequest updateRequest = new UpdateRequest()\n\t\t.index(\"idx01\")\n\t\t.type(\"type02\")\n\t\t.id(\"01\")\n\t\t.doc(jsonObject.toJSONString())\n\t\t.upsert(indexRequest);\n\nclient.update(updateRequest).get();\n```\n\n## 批处理\nelasticsearch内置的客户端中还有批处理功能,但是批处理只支持增删改, 不支持查询的功能\n```java\nBulkRequestBuilder bulkRequest = client.prepareBulk();\n\nJSONObject jsonObject = new JSONObject();\njsonObject.put(\"name\", \"Tom\");\njsonObject.put(\"age\", \"18\");\n\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.source(jsonObject.toJSONString());\nbulkRequest.add(indexRequest);\n\nUpdateRequest updateRequest = new UpdateRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\")\n\t\t.doc(jsonObject.toJSONString());\nbulkRequest.add(updateRequest);\n\nDeleteRequest deleteRequest = new DeleteRequest()\n\t\t.index(\"idx02\")\n\t\t.type(\"type01\")\n\t\t.id(\"01\");\nbulkRequest.add(deleteRequest);\nBulkResponse bulkResponse = bulkRequest.get();\nbulkResponse.forEach(response -> System.out.println(response.getId()));\n\nGetResponse getResponse = client.prepareGet(\"idx02\", \"type01\", \"01\")\n\t\t.setOperationThreaded(false)\n\t\t.get();\nSystem.out.println(\"GetResponse : \" + getResponse.getId());\nSystem.out.println(\"GetResponse : \" + getResponse.getIndex());\nSystem.out.println(\"GetResponse : \" + getResponse.getType());\nSystem.out.println(\"GetResponse : \" + getResponse.getVersion());\nSystem.out.println(\"GetResponse : \" + getResponse.getSourceAsString());\n```\n","slug":"日志工具/Elasticsearch 基本操作","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4000bpvjs6h1dd3dpr"},{"date":"2015-11-17T16:00:00.000Z","title":"Elasticsearch 搜索","_content":"\n首先我们向库里准备一下数据\n```java\nJSONObject son = new JSONObject();\nson.put(\"name\", \"Jerry\");\nson.put(\"age\", \"18\");\nson.put(\"address\", \"baoding\");\nson.put(\"country\", \"china\");\n\nJSONObject jsonObject = new JSONObject();\njsonObject.put(\"name\", \"Tom\");\njsonObject.put(\"age\", \"48\");\njsonObject.put(\"address\", \"beijing\");\njsonObject.put(\"country\", \"china\");\njsonObject.put(\"age\", \"18\");\njsonObject.put(\"son\", son);\n\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx04\")\n\t\t.type(\"type02\")\n\t\t.id(\"02\")\n\t\t.source(jsonObject.toJSONString());\n\nclient.index(indexRequest).get();\n```\n\n* Leaf query clauses : 在指定的字段中搜索指定的值,例如使用`match`, `term` 或者 `range` 搜索时\n* Compound query clauses :\n\n首先我们来看一个简单的搜索案例\n```java\nSearchResponse response = client.prepareSearch(\"idx01\", \"idx02\")\n\t\t\t\t.setTypes(\"type01\", \"type02\")\n\t\t\t\t.setSearchType(SearchType.DFS_QUERY_THEN_FETCH)\n\t\t\t\t.setQuery(QueryBuilders.termQuery(\"multi\", \"test\"))                 // Query\n\t\t\t\t.setPostFilter(QueryBuilders.rangeQuery(\"age\").from(12).to(18))     // Filter\n\t\t\t\t.setFrom(0).setSize(60).setExplain(true)\n\t\t\t\t.execute()\n\t\t\t\t.actionGet();\n```\n\n\n\n### Match All Query\n最简单的搜索, 这个搜索将库中所有的文档都搜索出来\n```java\nQueryBuilder qb = matchAllQuery();\n```\n\n### 全文检索\n\n#### Match Query\n标准搜索, 包含模糊搜索, 短语搜索, 相近搜索\n```java\nQueryBuilder qb = matchQuery(\n\t\t\t\t\"age\",\t// 搜索的字段\n\t\t\t\t\"18\"\t// 搜索的字段值\n\t\t);\n\n\t\tSearchResponse searchResponse = client.prepareSearch(\"idx04\").setQuery(qb).execute().get();\n\t\tsearchResponse.getHits().forEach(hit -> {\n\t\t\tSystem.out.println(hit.getSourceAsString());\n\t\t});\n```\n结果为\n```json\n{\"address\":\"beijing\",\"age\":\"18\",\"country\":\"china\",\"name\":\"Tom\",\"son\":{\"address\":\"baoding\",\"age\":\"18\",\"country\":\"china\",\"name\":\"Jerry\"}}\n```\n\n\n#### Multi Match Query\n`match`搜索的多键版本, 会在多个指定字段中进行值匹配查找\n```java\nQueryBuilder qb = multiMatchQuery(\n\t\t\"baoding\",\t// 搜索值\n\t\t\"city\", \"country\"\t// 搜索的字段\n);\n\nSearchResponse searchResponse = client.prepareSearch(\"idx04\").setQuery(qb).execute().get();\nsearchResponse.getHits().forEach(hit -> {\n\tSystem.out.println(hit.getSourceAsString());\n});\n```\n\n\n#### Common Terms Query\n```java\nQueryBuilder qb = commonTermsQuery(\"name\", \"kimchy\");\n```\n\n\n#### Query String Query\n```java\nQueryBuilder qb = queryStringQuery(\"+kimchy -elasticsearch\");\n```\n\n\n#### Simple Query String Query\n```java\nQueryBuilder qb = simpleQueryStringQuery(\"+kimchy -elasticsearch\");\n```\n","source":"_posts/日志工具/Elasticsearch 搜索.md","raw":"category: 日志工具\ndate: 2015-11-18\ntitle: Elasticsearch 搜索\n---\n\n首先我们向库里准备一下数据\n```java\nJSONObject son = new JSONObject();\nson.put(\"name\", \"Jerry\");\nson.put(\"age\", \"18\");\nson.put(\"address\", \"baoding\");\nson.put(\"country\", \"china\");\n\nJSONObject jsonObject = new JSONObject();\njsonObject.put(\"name\", \"Tom\");\njsonObject.put(\"age\", \"48\");\njsonObject.put(\"address\", \"beijing\");\njsonObject.put(\"country\", \"china\");\njsonObject.put(\"age\", \"18\");\njsonObject.put(\"son\", son);\n\nIndexRequest indexRequest = new IndexRequest()\n\t\t.index(\"idx04\")\n\t\t.type(\"type02\")\n\t\t.id(\"02\")\n\t\t.source(jsonObject.toJSONString());\n\nclient.index(indexRequest).get();\n```\n\n* Leaf query clauses : 在指定的字段中搜索指定的值,例如使用`match`, `term` 或者 `range` 搜索时\n* Compound query clauses :\n\n首先我们来看一个简单的搜索案例\n```java\nSearchResponse response = client.prepareSearch(\"idx01\", \"idx02\")\n\t\t\t\t.setTypes(\"type01\", \"type02\")\n\t\t\t\t.setSearchType(SearchType.DFS_QUERY_THEN_FETCH)\n\t\t\t\t.setQuery(QueryBuilders.termQuery(\"multi\", \"test\"))                 // Query\n\t\t\t\t.setPostFilter(QueryBuilders.rangeQuery(\"age\").from(12).to(18))     // Filter\n\t\t\t\t.setFrom(0).setSize(60).setExplain(true)\n\t\t\t\t.execute()\n\t\t\t\t.actionGet();\n```\n\n\n\n### Match All Query\n最简单的搜索, 这个搜索将库中所有的文档都搜索出来\n```java\nQueryBuilder qb = matchAllQuery();\n```\n\n### 全文检索\n\n#### Match Query\n标准搜索, 包含模糊搜索, 短语搜索, 相近搜索\n```java\nQueryBuilder qb = matchQuery(\n\t\t\t\t\"age\",\t// 搜索的字段\n\t\t\t\t\"18\"\t// 搜索的字段值\n\t\t);\n\n\t\tSearchResponse searchResponse = client.prepareSearch(\"idx04\").setQuery(qb).execute().get();\n\t\tsearchResponse.getHits().forEach(hit -> {\n\t\t\tSystem.out.println(hit.getSourceAsString());\n\t\t});\n```\n结果为\n```json\n{\"address\":\"beijing\",\"age\":\"18\",\"country\":\"china\",\"name\":\"Tom\",\"son\":{\"address\":\"baoding\",\"age\":\"18\",\"country\":\"china\",\"name\":\"Jerry\"}}\n```\n\n\n#### Multi Match Query\n`match`搜索的多键版本, 会在多个指定字段中进行值匹配查找\n```java\nQueryBuilder qb = multiMatchQuery(\n\t\t\"baoding\",\t// 搜索值\n\t\t\"city\", \"country\"\t// 搜索的字段\n);\n\nSearchResponse searchResponse = client.prepareSearch(\"idx04\").setQuery(qb).execute().get();\nsearchResponse.getHits().forEach(hit -> {\n\tSystem.out.println(hit.getSourceAsString());\n});\n```\n\n\n#### Common Terms Query\n```java\nQueryBuilder qb = commonTermsQuery(\"name\", \"kimchy\");\n```\n\n\n#### Query String Query\n```java\nQueryBuilder qb = queryStringQuery(\"+kimchy -elasticsearch\");\n```\n\n\n#### Simple Query String Query\n```java\nQueryBuilder qb = simpleQueryStringQuery(\"+kimchy -elasticsearch\");\n```\n","slug":"日志工具/Elasticsearch 搜索","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4100bqvjs60i33vd2b"},{"date":"2015-12-14T16:00:00.000Z","title":"logstash编解码日志","_content":"我们可以在`input`或者`ouput`插件里使用`codec`插件, 正如logstash流程那样`input -> decode -> fliter -> encode -> output`\n\n## json\n当我们向文件输出日志的时候, 如果不指定编码的话\n```json\noutput {\n    file {\n        path => \"D:\\log\\generate\\%{+yyyy-MM-dd hh-MM}.log\"\n    }\n}\n```\n会将\n```java\nmoon3  2015-12-15 00:00:00,008 [ThreadPoolTaskExecutor-1] PlayerManagerImpl(506) ERROR ERROR update player error 2:1362104689008\n```\n输出为\n```json\n{\"message\":\"moon3  2015-12-15 00:00:00,008 [ThreadPoolTaskExecutor-1] PlayerManagerImpl(506) ERROR ERROR update player error 2:1362104689008\",\"@version\":\"1\",\"@timestamp\":\"2015-12-16T03:43:14.112Z\",\"host\":\"wangming-PC\",\"path\":\"D:/log/logs/moon-alert-2015-12-15.log\",\"type\":\"system\"}\n```\n\n而我们指定编码为json的话\n","source":"_posts/日志工具/logstash 编解码日志.md","raw":"category: 日志工具\ndate: 2015-12-15\ntitle: logstash编解码日志\n---\n我们可以在`input`或者`ouput`插件里使用`codec`插件, 正如logstash流程那样`input -> decode -> fliter -> encode -> output`\n\n## json\n当我们向文件输出日志的时候, 如果不指定编码的话\n```json\noutput {\n    file {\n        path => \"D:\\log\\generate\\%{+yyyy-MM-dd hh-MM}.log\"\n    }\n}\n```\n会将\n```java\nmoon3  2015-12-15 00:00:00,008 [ThreadPoolTaskExecutor-1] PlayerManagerImpl(506) ERROR ERROR update player error 2:1362104689008\n```\n输出为\n```json\n{\"message\":\"moon3  2015-12-15 00:00:00,008 [ThreadPoolTaskExecutor-1] PlayerManagerImpl(506) ERROR ERROR update player error 2:1362104689008\",\"@version\":\"1\",\"@timestamp\":\"2015-12-16T03:43:14.112Z\",\"host\":\"wangming-PC\",\"path\":\"D:/log/logs/moon-alert-2015-12-15.log\",\"type\":\"system\"}\n```\n\n而我们指定编码为json的话\n","slug":"日志工具/logstash 编解码日志","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4300btvjs6w7hog0x1"},{"date":"2015-08-07T16:00:00.000Z","title":"logstash 语法","_content":"一般我们将logstash的配置写到一个配置文件中. 然后在启动logstash时,加载这些配置.\n\n然后我们就可以在配置文件中写自己的插件配置. 常用的插件有`input`, `codec`, `filter`, `output`, 一般我们最少也要写一个`input`插件, 否则启动的时候会报错.\n\n插件的形式如下\n```json\ninput {\n    stdin {}\n    syslog {}\n}\n```\n`{}`称为区域, 我们可以在区域里定义新的插件. 我们还可以在区域内定义字段, 然后在其他的插件中引用这个字段, 例如\n```json\ninput {\n    stdin {\n\t\ttype => \"std\"\n\t}\n}\n```\n","source":"_posts/日志工具/logstash 语法.md","raw":"category: 日志工具\ndate: 2015-08-08\ntitle: logstash 语法\n---\n一般我们将logstash的配置写到一个配置文件中. 然后在启动logstash时,加载这些配置.\n\n然后我们就可以在配置文件中写自己的插件配置. 常用的插件有`input`, `codec`, `filter`, `output`, 一般我们最少也要写一个`input`插件, 否则启动的时候会报错.\n\n插件的形式如下\n```json\ninput {\n    stdin {}\n    syslog {}\n}\n```\n`{}`称为区域, 我们可以在区域里定义新的插件. 我们还可以在区域内定义字段, 然后在其他的插件中引用这个字段, 例如\n```json\ninput {\n    stdin {\n\t\ttype => \"std\"\n\t}\n}\n```\n","slug":"日志工具/logstash 语法","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4500buvjs6dlimumtm"},{"date":"2015-08-07T16:00:00.000Z","title":"logstash读取日志","_content":"启动logstash时,我们需要指定配置文件, 以便让logstash按照我们配置的方式进行工作, 例如`logstash -f ./logstash.conf`\n\n## 接受标准日志\n```json\nstdin {\n        add_field => {\"key\" => \"value\"}\n        tags => [\"add\"]\n        type => \"std\"\n }\n```\n\n## 从文件中读取\n```json\ninput {\n\t# 只支持文件的绝对路径,而且会不自动递归目录. /path/to/**/*.log,用 ** 来缩写表示递归全部子目录.\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件.默认值是 15 秒.\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去,这里跟 path 一样支持 glob 展开.\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新）,默认是 1 秒.\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据,默认是结束位置,也就是说 logstash 进程会以类似 tail -F 的形式运行\n    }\n}\n```\n\n## 接受rsysylog日志\n```json\ninput {\n\tsyslog {\n\t\tport => \"514\"\n\t}\n}\n```\n\n## 接受TCP日志\n```json\ninput {\n\ttcp {\n\t\tport => 8888\n\t\tmode => \"server\"\n\t\tssl_enable => false\n\t}\n}\n```\nlogstash可以直接接受tcp日志,但是由于logstash内部采用SizedQueue实现日志队列机制,它只能缓存20个日志事件,因此这个功能更多的是在测试时候使用,正式环境中应该采用其他更加高效地消息队列.\n\n\n```java\nSocket socket = new Socket();\nsocket.connect(new InetSocketAddress(\"localhost\", 8888));\nBufferedWriter writer = new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()));\nfor (int i = 0; i < 10000; i++) {\n\twriter.write(\"hello world\");\n}\nwriter.close();\nsocket.close();\n```\n","source":"_posts/日志工具/logstash 读取日志.md","raw":"category: 日志工具\ndate: 2015-08-08\ntitle: logstash读取日志\n---\n启动logstash时,我们需要指定配置文件, 以便让logstash按照我们配置的方式进行工作, 例如`logstash -f ./logstash.conf`\n\n## 接受标准日志\n```json\nstdin {\n        add_field => {\"key\" => \"value\"}\n        tags => [\"add\"]\n        type => \"std\"\n }\n```\n\n## 从文件中读取\n```json\ninput {\n\t# 只支持文件的绝对路径,而且会不自动递归目录. /path/to/**/*.log,用 ** 来缩写表示递归全部子目录.\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件.默认值是 15 秒.\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去,这里跟 path 一样支持 glob 展开.\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新）,默认是 1 秒.\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据,默认是结束位置,也就是说 logstash 进程会以类似 tail -F 的形式运行\n    }\n}\n```\n\n## 接受rsysylog日志\n```json\ninput {\n\tsyslog {\n\t\tport => \"514\"\n\t}\n}\n```\n\n## 接受TCP日志\n```json\ninput {\n\ttcp {\n\t\tport => 8888\n\t\tmode => \"server\"\n\t\tssl_enable => false\n\t}\n}\n```\nlogstash可以直接接受tcp日志,但是由于logstash内部采用SizedQueue实现日志队列机制,它只能缓存20个日志事件,因此这个功能更多的是在测试时候使用,正式环境中应该采用其他更加高效地消息队列.\n\n\n```java\nSocket socket = new Socket();\nsocket.connect(new InetSocketAddress(\"localhost\", 8888));\nBufferedWriter writer = new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()));\nfor (int i = 0; i < 10000; i++) {\n\twriter.write(\"hello world\");\n}\nwriter.close();\nsocket.close();\n```\n","slug":"日志工具/logstash 读取日志","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4600bwvjs6ozgfzllm"},{"date":"2015-12-14T16:00:00.000Z","title":"logstash输出日志","_content":"\n## 标准输出\n```json\noutput {\n    stdout {\n        codec => rubydebug\n        workers => 2\n    }\n}\n```\n使用`stdout`我们将能将接受到的日志输出到控制台里\n\n## 输出到文件\n```json\noutput {\n    file {\n        path => \"D:\\log\\generate\\%{+yyyy-MM-dd}.log\"\n    }\n}\n```\n采用这个插件日志就会输出到`D:\\log\\generate`目录下的2015-12-15.log文件中.\n\n在file插件里,除了path字段之外,我们还有俩个字段`message_format`和`gzip`\n* `message_format` ：选择要输出的内容,默认是输出整个event的JSON形式字符串, 我们可以将其设置为`%{message}`, 这样我们就只会输出日志内容了\n* `gzip` : 启用这个参数是采用gzip压缩.\n\n## 输出到elasticsearch\n将接受到的日志输出到 elasticsearch中\n```json\noutput {\n    elasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```\n","source":"_posts/日志工具/logstash 输出日志.md","raw":"category: 日志工具\ndate: 2015-12-15\ntitle: logstash输出日志\n---\n\n## 标准输出\n```json\noutput {\n    stdout {\n        codec => rubydebug\n        workers => 2\n    }\n}\n```\n使用`stdout`我们将能将接受到的日志输出到控制台里\n\n## 输出到文件\n```json\noutput {\n    file {\n        path => \"D:\\log\\generate\\%{+yyyy-MM-dd}.log\"\n    }\n}\n```\n采用这个插件日志就会输出到`D:\\log\\generate`目录下的2015-12-15.log文件中.\n\n在file插件里,除了path字段之外,我们还有俩个字段`message_format`和`gzip`\n* `message_format` ：选择要输出的内容,默认是输出整个event的JSON形式字符串, 我们可以将其设置为`%{message}`, 这样我们就只会输出日志内容了\n* `gzip` : 启用这个参数是采用gzip压缩.\n\n## 输出到elasticsearch\n将接受到的日志输出到 elasticsearch中\n```json\noutput {\n    elasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```\n","slug":"日志工具/logstash 输出日志","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4800byvjs6m8z5exjd"},{"date":"2015-12-14T16:00:00.000Z","title":"logstash过滤日志","_content":"### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n\n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\n}\n```\n","source":"_posts/日志工具/logstash 过滤日志.md","raw":"category: 日志工具\ndate: 2015-12-15\ntitle: logstash过滤日志\n---\n### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n\n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\n}\n```\n","slug":"日志工具/logstash 过滤日志","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4900c0vjs6yw1llz9x"},{"date":"2016-03-18T16:00:00.000Z","title":"二叉树","_content":"二叉树就是有一个根节点, 每个节点最多有俩个子节点的树形结构. 二叉树又分为三种状态\n* 满二叉树: 除了叶子节点之外, 所有的节点上都有俩个子节点的树\n* 完全二叉树 : 除了叶子结点之外, 其余的节点上要么有俩个子节点要么一个子节点的树\n* 非完全二叉树 : 除了叶子节点之外, 其余的节点上出现了只有一个子节点的树\n\n","source":"_posts/算法/二叉树.md","raw":"category: 算法\ndate: 2016-03-19\ntitle: 二叉树\n---\n二叉树就是有一个根节点, 每个节点最多有俩个子节点的树形结构. 二叉树又分为三种状态\n* 满二叉树: 除了叶子节点之外, 所有的节点上都有俩个子节点的树\n* 完全二叉树 : 除了叶子结点之外, 其余的节点上要么有俩个子节点要么一个子节点的树\n* 非完全二叉树 : 除了叶子节点之外, 其余的节点上出现了只有一个子节点的树\n\n","slug":"算法/二叉树","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4b00c2vjs6qig0ag3w"},{"date":"2016-06-08T16:00:00.000Z","title":"冒泡排序","_content":"\n```python\n#-*- coding=utf-8 -*-\n\ndata = [5, 4, 3, 2, 1]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        for j in range(i, 0, -1):\n            pre = j - 1\n            if data[j] < data[pre]:\n                tmp = data[pre]\n                data[pre] = data[j]\n                data[j] = tmp\n                print str(data[pre]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n\nsort()\n```\n结果为\n```\n[5, 4, 3, 2, 1]\n4 compore 5 -> [4, 5, 3, 2, 1]\n3 compore 5 -> [4, 3, 5, 2, 1]\n3 compore 4 -> [3, 4, 5, 2, 1]\n2 compore 5 -> [3, 4, 2, 5, 1]\n2 compore 4 -> [3, 2, 4, 5, 1]\n2 compore 3 -> [2, 3, 4, 5, 1]\n1 compore 5 -> [2, 3, 4, 1, 5]\n1 compore 4 -> [2, 3, 1, 4, 5]\n1 compore 3 -> [2, 1, 3, 4, 5]\n1 compore 2 -> [1, 2, 3, 4, 5]\n```\n\n","source":"_posts/算法/冒泡排序.md","raw":"category: 算法\ndate: 2016-06-09\ntitle: 冒泡排序\n---\n\n```python\n#-*- coding=utf-8 -*-\n\ndata = [5, 4, 3, 2, 1]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        for j in range(i, 0, -1):\n            pre = j - 1\n            if data[j] < data[pre]:\n                tmp = data[pre]\n                data[pre] = data[j]\n                data[j] = tmp\n                print str(data[pre]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n\nsort()\n```\n结果为\n```\n[5, 4, 3, 2, 1]\n4 compore 5 -> [4, 5, 3, 2, 1]\n3 compore 5 -> [4, 3, 5, 2, 1]\n3 compore 4 -> [3, 4, 5, 2, 1]\n2 compore 5 -> [3, 4, 2, 5, 1]\n2 compore 4 -> [3, 2, 4, 5, 1]\n2 compore 3 -> [2, 3, 4, 5, 1]\n1 compore 5 -> [2, 3, 4, 1, 5]\n1 compore 4 -> [2, 3, 1, 4, 5]\n1 compore 3 -> [2, 1, 3, 4, 5]\n1 compore 2 -> [1, 2, 3, 4, 5]\n```\n\n","slug":"算法/冒泡排序","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4c00c4vjs60cinj282"},{"date":"2016-06-09T16:00:00.000Z","title":"希尔排序","_content":"希尔排序是一种基于插入排序的算法.\n\n插入排序的递增序列是1, 每次向前插入的时候都是和相邻的数组元素比较. 而希尔排序的递增是不固定的, 一般我们是选择一个算法, 算出递增. 希尔排序的思想是在间隔任意值h之间的数字是有序的, 这样的数组称为h有序数组. h有序数组是由h个互相独立的有序数组组成的一个大数组.\n\n```python\n#-*- coding=utf-8 -*-\n\ndata = [8, 7, 6, 5, 4, 3, 2, 1]\nprint data\n\nh = 1\nwhile h < len(data)/3:\n    h = 3*h + 1\n\ndef sort():\n    global h\n    while h > 0:\n        for i in range(0, len(data)):\n            for j in range(i, 0, -h):\n                pre = j - h\n                if data[j] < data[pre]:\n                    tmp = data[pre]\n                    data[pre] = data[j]\n                    data[j] = tmp\n\n                print str(h) + \":   \" + str(data[j - h]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n        h = h / 3\nsort()\n```\n运算结果为\n```bash\n[8, 7, 6, 5, 4, 3, 2, 1]\n4:   3 compore 7 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   2 compore 6 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   1 compore 5 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   4 compore 8 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   3 compore 7 -> [4, 3, 6, 5, 8, 7, 2, 1]\n4:   3 compore 7 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   2 compore 6 -> [4, 7, 2, 5, 8, 3, 6, 1]\n4:   2 compore 6 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   1 compore 5 -> [4, 7, 6, 1, 8, 3, 2, 5]\n4:   1 compore 5 -> [4, 7, 6, 5, 8, 3, 2, 1]\n1:   4 compore 7 -> [4, 7, 6, 5, 8, 3, 2, 1]\n1:   6 compore 7 -> [4, 6, 7, 5, 8, 3, 2, 1]\n1:   4 compore 6 -> [4, 6, 7, 5, 8, 3, 2, 1]\n1:   5 compore 7 -> [4, 6, 5, 7, 8, 3, 2, 1]\n1:   5 compore 6 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   4 compore 5 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   7 compore 8 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   6 compore 7 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   5 compore 6 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   4 compore 5 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   3 compore 8 -> [4, 5, 6, 7, 3, 8, 2, 1]\n1:   3 compore 7 -> [4, 5, 6, 3, 7, 8, 2, 1]\n1:   3 compore 6 -> [4, 5, 3, 6, 7, 8, 2, 1]\n1:   3 compore 5 -> [4, 3, 5, 6, 7, 8, 2, 1]\n1:   3 compore 4 -> [3, 4, 5, 6, 7, 8, 2, 1]\n1:   2 compore 8 -> [3, 4, 5, 6, 7, 2, 8, 1]\n1:   2 compore 7 -> [3, 4, 5, 6, 2, 7, 8, 1]\n1:   2 compore 6 -> [3, 4, 5, 2, 6, 7, 8, 1]\n1:   2 compore 5 -> [3, 4, 2, 5, 6, 7, 8, 1]\n1:   2 compore 4 -> [3, 2, 4, 5, 6, 7, 8, 1]\n1:   2 compore 3 -> [2, 3, 4, 5, 6, 7, 8, 1]\n1:   1 compore 8 -> [2, 3, 4, 5, 6, 7, 1, 8]\n1:   1 compore 7 -> [2, 3, 4, 5, 6, 1, 7, 8]\n1:   1 compore 6 -> [2, 3, 4, 5, 1, 6, 7, 8]\n1:   1 compore 5 -> [2, 3, 4, 1, 5, 6, 7, 8]\n1:   1 compore 4 -> [2, 3, 1, 4, 5, 6, 7, 8]\n1:   1 compore 3 -> [2, 1, 3, 4, 5, 6, 7, 8]\n1:   1 compore 2 -> [1, 2, 3, 4, 5, 6, 7, 8]\n```","source":"_posts/算法/希尔排序.md","raw":"category: 算法\ndate: 2016-06-10\ntitle: 希尔排序\n---\n希尔排序是一种基于插入排序的算法.\n\n插入排序的递增序列是1, 每次向前插入的时候都是和相邻的数组元素比较. 而希尔排序的递增是不固定的, 一般我们是选择一个算法, 算出递增. 希尔排序的思想是在间隔任意值h之间的数字是有序的, 这样的数组称为h有序数组. h有序数组是由h个互相独立的有序数组组成的一个大数组.\n\n```python\n#-*- coding=utf-8 -*-\n\ndata = [8, 7, 6, 5, 4, 3, 2, 1]\nprint data\n\nh = 1\nwhile h < len(data)/3:\n    h = 3*h + 1\n\ndef sort():\n    global h\n    while h > 0:\n        for i in range(0, len(data)):\n            for j in range(i, 0, -h):\n                pre = j - h\n                if data[j] < data[pre]:\n                    tmp = data[pre]\n                    data[pre] = data[j]\n                    data[j] = tmp\n\n                print str(h) + \":   \" + str(data[j - h]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n        h = h / 3\nsort()\n```\n运算结果为\n```bash\n[8, 7, 6, 5, 4, 3, 2, 1]\n4:   3 compore 7 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   2 compore 6 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   1 compore 5 -> [8, 7, 6, 5, 4, 3, 2, 1]\n4:   4 compore 8 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   3 compore 7 -> [4, 3, 6, 5, 8, 7, 2, 1]\n4:   3 compore 7 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   2 compore 6 -> [4, 7, 2, 5, 8, 3, 6, 1]\n4:   2 compore 6 -> [4, 7, 6, 5, 8, 3, 2, 1]\n4:   1 compore 5 -> [4, 7, 6, 1, 8, 3, 2, 5]\n4:   1 compore 5 -> [4, 7, 6, 5, 8, 3, 2, 1]\n1:   4 compore 7 -> [4, 7, 6, 5, 8, 3, 2, 1]\n1:   6 compore 7 -> [4, 6, 7, 5, 8, 3, 2, 1]\n1:   4 compore 6 -> [4, 6, 7, 5, 8, 3, 2, 1]\n1:   5 compore 7 -> [4, 6, 5, 7, 8, 3, 2, 1]\n1:   5 compore 6 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   4 compore 5 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   7 compore 8 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   6 compore 7 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   5 compore 6 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   4 compore 5 -> [4, 5, 6, 7, 8, 3, 2, 1]\n1:   3 compore 8 -> [4, 5, 6, 7, 3, 8, 2, 1]\n1:   3 compore 7 -> [4, 5, 6, 3, 7, 8, 2, 1]\n1:   3 compore 6 -> [4, 5, 3, 6, 7, 8, 2, 1]\n1:   3 compore 5 -> [4, 3, 5, 6, 7, 8, 2, 1]\n1:   3 compore 4 -> [3, 4, 5, 6, 7, 8, 2, 1]\n1:   2 compore 8 -> [3, 4, 5, 6, 7, 2, 8, 1]\n1:   2 compore 7 -> [3, 4, 5, 6, 2, 7, 8, 1]\n1:   2 compore 6 -> [3, 4, 5, 2, 6, 7, 8, 1]\n1:   2 compore 5 -> [3, 4, 2, 5, 6, 7, 8, 1]\n1:   2 compore 4 -> [3, 2, 4, 5, 6, 7, 8, 1]\n1:   2 compore 3 -> [2, 3, 4, 5, 6, 7, 8, 1]\n1:   1 compore 8 -> [2, 3, 4, 5, 6, 7, 1, 8]\n1:   1 compore 7 -> [2, 3, 4, 5, 6, 1, 7, 8]\n1:   1 compore 6 -> [2, 3, 4, 5, 1, 6, 7, 8]\n1:   1 compore 5 -> [2, 3, 4, 1, 5, 6, 7, 8]\n1:   1 compore 4 -> [2, 3, 1, 4, 5, 6, 7, 8]\n1:   1 compore 3 -> [2, 1, 3, 4, 5, 6, 7, 8]\n1:   1 compore 2 -> [1, 2, 3, 4, 5, 6, 7, 8]\n```","slug":"算法/希尔排序","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4e00c6vjs64tcb3nal"},{"date":"2016-06-08T16:00:00.000Z","title":"插入排序","_content":"插入排序和选择排序类似, 也是在每个数组元素左边的数据都是有序的, 但是不确定他们的最终位置在哪里. 都是排序完的结果都是升序, 但是选择排序是将每个数据向后比较, 上次的比较和交换结果对下次的比较交换并没有什么影响. 而插入排序就不一样了, 插入排序是向前比较, 而它前面的数据是已经排序好了的. 因此插入排序的结果是受数据输入的影响的.如果输入的数据是一个已经排序好的数组, 那么插入排序的时间复杂度仅仅是`O(N)`. 更多关于性能方面的介绍我会在最后给出, 下面我们看一个实现, 以及对一组简单数据排序后的结果:\n\n```python\n#-*- coding=utf-8 -*-\n\ndata = [10, 2, 5, 3, 6, 4]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        for j in range(i, 0, -1):\n            if data[j] < data[j - 1]:\n                tmp = data[j - 1]\n                data[j - 1] = data[j]\n                data[j] = tmp\n                \n            \n\nsort()\n```\n结果为\n```\n[10, 2, 5, 3, 6, 4]\n2 compore 10 -> [2, 10, 5, 3, 6, 4]\n5 compore 10 -> [2, 5, 10, 3, 6, 4]\n2 compore 5 -> [2, 5, 10, 3, 6, 4]\n3 compore 10 -> [2, 5, 3, 10, 6, 4]\n3 compore 5 -> [2, 3, 5, 10, 6, 4]\n2 compore 3 -> [2, 3, 5, 10, 6, 4]\n6 compore 10 -> [2, 3, 5, 6, 10, 4]\n5 compore 6 -> [2, 3, 5, 6, 10, 4]\n3 compore 5 -> [2, 3, 5, 6, 10, 4]\n2 compore 3 -> [2, 3, 5, 6, 10, 4]\n4 compore 10 -> [2, 3, 5, 6, 4, 10]\n4 compore 6 -> [2, 3, 5, 4, 6, 10]\n4 compore 5 -> [2, 3, 4, 5, 6, 10]\n3 compore 4 -> [2, 3, 4, 5, 6, 10]\n2 compore 3 -> [2, 3, 4, 5, 6, 10]\n```\n\n","source":"_posts/算法/插入排序.md","raw":"category: 算法\ndate: 2016-06-09\ntitle: 插入排序\n---\n插入排序和选择排序类似, 也是在每个数组元素左边的数据都是有序的, 但是不确定他们的最终位置在哪里. 都是排序完的结果都是升序, 但是选择排序是将每个数据向后比较, 上次的比较和交换结果对下次的比较交换并没有什么影响. 而插入排序就不一样了, 插入排序是向前比较, 而它前面的数据是已经排序好了的. 因此插入排序的结果是受数据输入的影响的.如果输入的数据是一个已经排序好的数组, 那么插入排序的时间复杂度仅仅是`O(N)`. 更多关于性能方面的介绍我会在最后给出, 下面我们看一个实现, 以及对一组简单数据排序后的结果:\n\n```python\n#-*- coding=utf-8 -*-\n\ndata = [10, 2, 5, 3, 6, 4]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        for j in range(i, 0, -1):\n            if data[j] < data[j - 1]:\n                tmp = data[j - 1]\n                data[j - 1] = data[j]\n                data[j] = tmp\n                \n            \n\nsort()\n```\n结果为\n```\n[10, 2, 5, 3, 6, 4]\n2 compore 10 -> [2, 10, 5, 3, 6, 4]\n5 compore 10 -> [2, 5, 10, 3, 6, 4]\n2 compore 5 -> [2, 5, 10, 3, 6, 4]\n3 compore 10 -> [2, 5, 3, 10, 6, 4]\n3 compore 5 -> [2, 3, 5, 10, 6, 4]\n2 compore 3 -> [2, 3, 5, 10, 6, 4]\n6 compore 10 -> [2, 3, 5, 6, 10, 4]\n5 compore 6 -> [2, 3, 5, 6, 10, 4]\n3 compore 5 -> [2, 3, 5, 6, 10, 4]\n2 compore 3 -> [2, 3, 5, 6, 10, 4]\n4 compore 10 -> [2, 3, 5, 6, 4, 10]\n4 compore 6 -> [2, 3, 5, 4, 6, 10]\n4 compore 5 -> [2, 3, 4, 5, 6, 10]\n3 compore 4 -> [2, 3, 4, 5, 6, 10]\n2 compore 3 -> [2, 3, 4, 5, 6, 10]\n```\n\n","slug":"算法/插入排序","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4h00c8vjs6e9098hmh"},{"date":"2016-03-11T16:00:00.000Z","title":"环形队列","_content":"```python\n#-*- coding=utf-8 -*-\n\n# 环形队列实现\nclass CircleQueue:\n    # 队列头\n    queueHead = 0\n    # 队列尾\n    queueTail = 0\n    # 队列容量\n    queueCacity = 0\n    # 队列当前长度\n    queueLength = 0\n    # 队列容器\n    queue = []\n\n    def __init__(self, capacity):\n        self.queueCacity = capacity\n        self.queue = [0] * capacity\n\n    # 入列\n    def enqueue(self, obj):\n        if(self.isFull()):\n            raise RuntimeError(\"Queue is Full\")\n\n        self.queue[self.queueTail] = obj\n        self.queueTail += 1\n        # 为了让队列头一直在环形队列中进行变化, 因此进行取余操作,\n        # 当队列头达到最大容量时,再增长就回到初始队列头的位置\n        self.queueTail = self.queueTail % self.queueCacity\n        self.queueLength += 1\n\n        return self.queueLength\n\n    # 出列\n    def dequeue(self):\n        if(self.isEmpoty()):\n            raise RuntimeError(\"Queue is Empoty\")\n        obj = self.queue[self.queueHead]\n        self.queueHead += 1\n        self.queueHead = self.queueHead % self.queueCacity\n        self.queueLength -= 1\n        return obj\n\n    # 判断队列是否为空\n    def isEmpoty(self):\n        return self.queueLength == 0\n\n    # 判断队列是否已满\n    def isFull(self):\n        return self.queueLength == self.queueCacity\n\n\n# 测试\ncircleQueue = CircleQueue(5)\n\n# 入列5个元素\nassert circleQueue.enqueue(1) == 1\nassert circleQueue.enqueue(2) == 2\nassert circleQueue.enqueue(3) == 3\nassert circleQueue.enqueue(4) == 4\nassert circleQueue.enqueue(5) == 5\n\n# 现在队列的长度为5, 且队列尾已经和队列头重合了\nassert circleQueue.queueLength == 5\nassert circleQueue.queueTail == 0\nassert circleQueue.queueHead == 0\n\nassert circleQueue.dequeue() == 1\nassert circleQueue.dequeue() == 2\nassert circleQueue.dequeue() == 3\nassert circleQueue.dequeue() == 4\nassert circleQueue.dequeue() == 5\n\nassert circleQueue.queueTail == 0\nassert circleQueue.queueHead == 0\n\n# 再入列一个数据,当前长度为1,且队列头为0,队列尾为1\nassert circleQueue.enqueue(6) == 1\n\nassert circleQueue.queueTail == 1\nassert circleQueue.queueHead == 0\n\n```\n环形队列的关键是能让头索引和尾索引能够在整个环形队列中自己循环\n","source":"_posts/算法/环形队列.md","raw":"category: 算法\ndate: 2016-03-12\ntitle: 环形队列\n---\n```python\n#-*- coding=utf-8 -*-\n\n# 环形队列实现\nclass CircleQueue:\n    # 队列头\n    queueHead = 0\n    # 队列尾\n    queueTail = 0\n    # 队列容量\n    queueCacity = 0\n    # 队列当前长度\n    queueLength = 0\n    # 队列容器\n    queue = []\n\n    def __init__(self, capacity):\n        self.queueCacity = capacity\n        self.queue = [0] * capacity\n\n    # 入列\n    def enqueue(self, obj):\n        if(self.isFull()):\n            raise RuntimeError(\"Queue is Full\")\n\n        self.queue[self.queueTail] = obj\n        self.queueTail += 1\n        # 为了让队列头一直在环形队列中进行变化, 因此进行取余操作,\n        # 当队列头达到最大容量时,再增长就回到初始队列头的位置\n        self.queueTail = self.queueTail % self.queueCacity\n        self.queueLength += 1\n\n        return self.queueLength\n\n    # 出列\n    def dequeue(self):\n        if(self.isEmpoty()):\n            raise RuntimeError(\"Queue is Empoty\")\n        obj = self.queue[self.queueHead]\n        self.queueHead += 1\n        self.queueHead = self.queueHead % self.queueCacity\n        self.queueLength -= 1\n        return obj\n\n    # 判断队列是否为空\n    def isEmpoty(self):\n        return self.queueLength == 0\n\n    # 判断队列是否已满\n    def isFull(self):\n        return self.queueLength == self.queueCacity\n\n\n# 测试\ncircleQueue = CircleQueue(5)\n\n# 入列5个元素\nassert circleQueue.enqueue(1) == 1\nassert circleQueue.enqueue(2) == 2\nassert circleQueue.enqueue(3) == 3\nassert circleQueue.enqueue(4) == 4\nassert circleQueue.enqueue(5) == 5\n\n# 现在队列的长度为5, 且队列尾已经和队列头重合了\nassert circleQueue.queueLength == 5\nassert circleQueue.queueTail == 0\nassert circleQueue.queueHead == 0\n\nassert circleQueue.dequeue() == 1\nassert circleQueue.dequeue() == 2\nassert circleQueue.dequeue() == 3\nassert circleQueue.dequeue() == 4\nassert circleQueue.dequeue() == 5\n\nassert circleQueue.queueTail == 0\nassert circleQueue.queueHead == 0\n\n# 再入列一个数据,当前长度为1,且队列头为0,队列尾为1\nassert circleQueue.enqueue(6) == 1\n\nassert circleQueue.queueTail == 1\nassert circleQueue.queueHead == 0\n\n```\n环形队列的关键是能让头索引和尾索引能够在整个环形队列中自己循环\n","slug":"算法/环形队列","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4j00cavjs6q95q5k3s"},{"date":"2016-03-30T16:00:00.000Z","title":"计算二维数组索引","_content":"假设我们有这样的一个二维数组\n```java\n(X,Y)\t0\t1\t2\n0\t\t0\t1\t2\n1\t\t3\t4\t5\n2\t\t6\t7\t8\n```\n* (0, 0) -> 0\n* (1, 0) -> 1\n* (2, 0) -> 2\n* (0, 1) -> 3\n* (1, 1) -> 4\n* (2, 1) -> 5\n* (0, 2) -> 6\n* (1, 2) -> 7\n* (2, 2) -> 8\n下面我们实现这个算法\n```java\npublic class Test {\n\n    public static void main(String[] args) {\n        int width = 3;\n        int length = 3;\n        for (int x = 0; x < width; x++) {\n            for (int y = 0; y < length; y++) {\n                System.out.println(\"(\" + x + \", \" + y + \")\" + (x + y * length));\n            }\n        }\n    }\n}\n```\n我们可以这样想象: 将这个二维数组串行, 就是以`0, 1 , 2, 3, 4, 5, 6`, 当计算(1, 1)这个坐标的时候就是用x加上 y在x上移动的倍数","source":"_posts/算法/计算二维数组索引.md","raw":"category: 算法\ndate: 2016-03-31\ntitle: 计算二维数组索引\n---\n假设我们有这样的一个二维数组\n```java\n(X,Y)\t0\t1\t2\n0\t\t0\t1\t2\n1\t\t3\t4\t5\n2\t\t6\t7\t8\n```\n* (0, 0) -> 0\n* (1, 0) -> 1\n* (2, 0) -> 2\n* (0, 1) -> 3\n* (1, 1) -> 4\n* (2, 1) -> 5\n* (0, 2) -> 6\n* (1, 2) -> 7\n* (2, 2) -> 8\n下面我们实现这个算法\n```java\npublic class Test {\n\n    public static void main(String[] args) {\n        int width = 3;\n        int length = 3;\n        for (int x = 0; x < width; x++) {\n            for (int y = 0; y < length; y++) {\n                System.out.println(\"(\" + x + \", \" + y + \")\" + (x + y * length));\n            }\n        }\n    }\n}\n```\n我们可以这样想象: 将这个二维数组串行, 就是以`0, 1 , 2, 3, 4, 5, 6`, 当计算(1, 1)这个坐标的时候就是用x加上 y在x上移动的倍数","slug":"算法/计算二维数组索引","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4l00ccvjs6a0ihzphc"},{"date":"2016-06-09T16:00:00.000Z","title":"选择排序","_content":"假设我们有这样的一个数组 [10, 2, 5, 3, 6, 4]. 在选择排序算法时, 会进行如下操作\n1. 10 与 2, 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第一轮排序之后结果为 [2, 10, 5, 3, 6, 4]\n2. 10 与 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 5, 10, 6, 4]\n3. 5 与 10, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 4, 10, 6, 5]\n4. ...以此类推\n\n我们看一下选择排序的实现\n```python\n#-*- coding=utf-8 -*-\n\ndata = [5, 4, 3, 2, 1]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        min  = i\n        for j in range(i, len(data)):\n            if data[j] < data[min]:\n                min = j\n\n        tmp = data[i]\n        data[i] = data[min]\n        data[min] = tmp\n        print str(data[i]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n\nsort()\n```\n结果为\n```bash\n[5, 4, 3, 2, 1]\n1 compore 5 -> [1, 4, 3, 2, 5]\n2 compore 5 -> [1, 2, 3, 4, 5]\n3 compore 5 -> [1, 2, 3, 4, 5]\n4 compore 5 -> [1, 2, 3, 4, 5]\n5 compore 5 -> [1, 2, 3, 4, 5]\n```\n\n选择排序的运行时间和输入没有关系. 因为在排序的过程中, 每一个位置的数字都会跟后边的数字比较一遍.所以哪怕数组是排序好的, 仍然会进行比较.\n\n那么选择排序会比较多少次呢? 答案是`(N + (N - 1) + (N - 2) ... 1) = N^2/2`.\n\n相关网站\n* [visualgo](http://visualgo.net)\n* [Sorting Algorithm](http://www.sorting-algorithms.com/)","source":"_posts/算法/选择排序.md","raw":"category: 算法\ndate: 2016-06-10\ntitle: 选择排序\n---\n假设我们有这样的一个数组 [10, 2, 5, 3, 6, 4]. 在选择排序算法时, 会进行如下操作\n1. 10 与 2, 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第一轮排序之后结果为 [2, 10, 5, 3, 6, 4]\n2. 10 与 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 5, 10, 6, 4]\n3. 5 与 10, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 4, 10, 6, 5]\n4. ...以此类推\n\n我们看一下选择排序的实现\n```python\n#-*- coding=utf-8 -*-\n\ndata = [5, 4, 3, 2, 1]\nprint data\n\ndef sort():\n    for i in range(0, len(data)):\n        min  = i\n        for j in range(i, len(data)):\n            if data[j] < data[min]:\n                min = j\n\n        tmp = data[i]\n        data[i] = data[min]\n        data[min] = tmp\n        print str(data[i]) + \" compore \" + str(data[j]) + \" -> \" + str(data)\n\nsort()\n```\n结果为\n```bash\n[5, 4, 3, 2, 1]\n1 compore 5 -> [1, 4, 3, 2, 5]\n2 compore 5 -> [1, 2, 3, 4, 5]\n3 compore 5 -> [1, 2, 3, 4, 5]\n4 compore 5 -> [1, 2, 3, 4, 5]\n5 compore 5 -> [1, 2, 3, 4, 5]\n```\n\n选择排序的运行时间和输入没有关系. 因为在排序的过程中, 每一个位置的数字都会跟后边的数字比较一遍.所以哪怕数组是排序好的, 仍然会进行比较.\n\n那么选择排序会比较多少次呢? 答案是`(N + (N - 1) + (N - 2) ... 1) = N^2/2`.\n\n相关网站\n* [visualgo](http://visualgo.net)\n* [Sorting Algorithm](http://www.sorting-algorithms.com/)","slug":"算法/选择排序","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4n00cevjs68bbe7uw7"},{"date":"2014-04-16T16:00:00.000Z","title":"Groovy ANT","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","source":"_posts/编程语言/Groovy ANT.md","raw":"category: 编程语言\ndate: 2014-04-17\ntitle: Groovy ANT\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","slug":"编程语言/Groovy ANT","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4p00cgvjs68guwhrol"},{"date":"2014-04-08T16:00:00.000Z","title":"Groovy IO","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n### 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n### 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n### 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n### 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n### 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n","source":"_posts/编程语言/Groovy IO.md","raw":"category: 编程语言\ndate: 2014-04-09\ntitle: Groovy IO\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n### 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n### 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n### 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n### 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n### 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n","slug":"编程语言/Groovy IO","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4r00civjs6vec18l4r"},{"date":"2014-04-17T16:00:00.000Z","title":"Groovy JSON","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n## JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n### Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n### JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串.\n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型.\n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```groovy\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n","source":"_posts/编程语言/Groovy JSON.md","raw":"category: 编程语言\ndate: 2014-04-18\ntitle: Groovy JSON\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n## JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n### Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n### JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串.\n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型.\n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```groovy\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n","slug":"编程语言/Groovy JSON","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4s00ckvjs6ptzdhflz"},{"date":"2014-04-15T16:00:00.000Z","title":"Groovy 字符串","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n### 单引号字符\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n### 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n### 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n#### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n#### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n### 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\n当双引号字符串内没有插值(`${}`)的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n#### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n#### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5. With a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6. But with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\n\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n#### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n#### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n### Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n### Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n### Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n### Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n","source":"_posts/编程语言/Groovy 字符串.md","raw":"category: 编程语言\ndate: 2014-04-16\ntitle: Groovy 字符串\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n### 单引号字符\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n### 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n### 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n#### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n#### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n### 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\n当双引号字符串内没有插值(`${}`)的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n#### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n#### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5. With a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6. But with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\n\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n#### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n#### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n### Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n### Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n### Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n### Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n","slug":"编程语言/Groovy 字符串","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4u00cmvjs6rohaxc54"},{"date":"2014-04-14T16:00:00.000Z","title":"Groovy 数字","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n### Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n#### Alternative non-base 10 representations\n\n##### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n##### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n##### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n### Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n### Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n### Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n### Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n#### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n##### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n##### 如果exponent为整数类型\n```groovy\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n##### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n## Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n","source":"_posts/编程语言/Groovy 数字.md","raw":"category: 编程语言\ndate: 2014-04-15\ntitle: Groovy 数字\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n### Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n#### Alternative non-base 10 representations\n\n##### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n##### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n##### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n### Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n### Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n### Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n### Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n#### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n##### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n##### 如果exponent为整数类型\n```groovy\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n##### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n## Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n","slug":"编程语言/Groovy 数字","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4w00covjs6v3n6j70k"},{"date":"2014-04-10T16:00:00.000Z","title":"Groovy 集合","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n\n### Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n#### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n#### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n#### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n#### Manipulating lists\n\n##### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n##### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n##### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n##### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n##### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n### Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n### Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n#### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n#### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n#### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n#### Manipulating maps\n\n##### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n##### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n##### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n##### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n### Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n","source":"_posts/编程语言/Groovy 集合.md","raw":"category: 编程语言\ndate: 2014-04-11\ntitle: Groovy 集合\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n\n### Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n#### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n#### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n#### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n#### Manipulating lists\n\n##### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n##### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n##### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n##### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n##### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n### Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n### Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n#### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n#### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n#### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n#### Manipulating maps\n\n##### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n##### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n##### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n##### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n### Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n","slug":"编程语言/Groovy 集合","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii4z00cqvjs6wsw0514f"},{"date":"2014-04-07T16:00:00.000Z","title":"Groovy 注释和标识符","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n## 注释\n### 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n### 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n#### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n### Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n## 标识符\n\n### 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n### 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n","source":"_posts/编程语言/Groovy.md","raw":"category: 编程语言\ndate: 2014-04-08\ntitle: Groovy 注释和标识符\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n## 注释\n### 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n### 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n#### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n### Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n## 标识符\n\n### 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n### 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n","slug":"编程语言/Groovy","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5000csvjs69pip327d"},{"date":"2015-09-07T16:00:00.000Z","title":"JavaScript变量和流程控制","_content":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n## 数据类型\n\n### 数字\nJavaScript只有一个数字类型,它在内部被表示为64位的浮点数. 它没有分离出整数类型,因此1和1.0的值是相同的\n\nNaN是一个数值，它表示一个不能产生正常结果的运算结果。`NaN`不等于任何值，包括它自己。可以使用函数`isNaN`来检测`NaN`。\n\n### 字符串\n字符串可以由一对单引号或者一对双引号构成，可以包含0到多个字符。`\\`是转义字符。JavaScript采用Unicode16作为字符集，因此所有的字符都是16位的。\n\n字符串有一个length属性，可以获得字符串长度。\n\n字符串同样也是不可变的。一旦字符串被创建出来就无法改变它。我们同+链接其他字符串创建一个新的字符串。俩个包含着相同字符且字符顺序也相同的字符被认为是同一个字符串。`===`进行字符串判断。\n\n## 变量\n我们通过 `var`关键字来声明一个变量\n\n### 函数私有变量\nJavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部可用，而在函数外面不可用。\n\n### 全局变量\n每个JavaScript环境有一个全局对象，当你在任意的函数外面使用this的时候可以访问到。你创建的每一个全局变量都成了这个全局对象的属性。\n\n## 控制流程\n\n我们可以通过条件语句(if和switch),循环语句（while，for和do）强制跳转语句（break,return，throw）和函数调用来改变执行序列。\n\n### if\n进行if判断时，下列值被作为假：\n* false\n* null\n* 空字符串 `''`\n* 数字0\n* 数字NaN\n\n### switch\n其表达式的值和case条件进行匹配。表达式可以是字符串或者数字。case表达式不一定必须是常量\n```javascript\nswitch (num)\n{\n\tcase 1:\n\t  x=\"输入正确\";\n\t  break;\n\tdefault:\n\t  x=\"输入错误\";\n}\n```\n\n### while\n```javascript\nwhile (i<5)\n{\n\tsum += i;\n}\n```\n\n### for\n```javascript\nfor (var i = 0; i<5; i++)\n{\n\tsum += i;\n}\n```\nfor...in\n```javascript\nvar array = [1, 2]\nfor (i in array)\n{\n\tsum += i;\n}\n```\n","source":"_posts/编程语言/JavaScript.md","raw":"category: 编程语言\ndate: 2015-09-08\ntitle: JavaScript变量和流程控制\n---\nJavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n## 数据类型\n\n### 数字\nJavaScript只有一个数字类型,它在内部被表示为64位的浮点数. 它没有分离出整数类型,因此1和1.0的值是相同的\n\nNaN是一个数值，它表示一个不能产生正常结果的运算结果。`NaN`不等于任何值，包括它自己。可以使用函数`isNaN`来检测`NaN`。\n\n### 字符串\n字符串可以由一对单引号或者一对双引号构成，可以包含0到多个字符。`\\`是转义字符。JavaScript采用Unicode16作为字符集，因此所有的字符都是16位的。\n\n字符串有一个length属性，可以获得字符串长度。\n\n字符串同样也是不可变的。一旦字符串被创建出来就无法改变它。我们同+链接其他字符串创建一个新的字符串。俩个包含着相同字符且字符顺序也相同的字符被认为是同一个字符串。`===`进行字符串判断。\n\n## 变量\n我们通过 `var`关键字来声明一个变量\n\n### 函数私有变量\nJavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部可用，而在函数外面不可用。\n\n### 全局变量\n每个JavaScript环境有一个全局对象，当你在任意的函数外面使用this的时候可以访问到。你创建的每一个全局变量都成了这个全局对象的属性。\n\n## 控制流程\n\n我们可以通过条件语句(if和switch),循环语句（while，for和do）强制跳转语句（break,return，throw）和函数调用来改变执行序列。\n\n### if\n进行if判断时，下列值被作为假：\n* false\n* null\n* 空字符串 `''`\n* 数字0\n* 数字NaN\n\n### switch\n其表达式的值和case条件进行匹配。表达式可以是字符串或者数字。case表达式不一定必须是常量\n```javascript\nswitch (num)\n{\n\tcase 1:\n\t  x=\"输入正确\";\n\t  break;\n\tdefault:\n\t  x=\"输入错误\";\n}\n```\n\n### while\n```javascript\nwhile (i<5)\n{\n\tsum += i;\n}\n```\n\n### for\n```javascript\nfor (var i = 0; i<5; i++)\n{\n\tsum += i;\n}\n```\nfor...in\n```javascript\nvar array = [1, 2]\nfor (i in array)\n{\n\tsum += i;\n}\n```\n","slug":"编程语言/JavaScript","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5200cuvjs6jwx9eume"},{"date":"2015-09-07T16:00:00.000Z","title":"JavaScript函数","_content":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\nJavaScript中函数就是对象。函数对象连接到Function.prototype(该原型连接到Object.prototype).\n* 每个函数对象在创建时也随配一个prototype属性,它的值是一个拥有constructor属性且值为该函数的对象（这和连接到Function.prototype全完不同）.\n* 因为函数是对象,所以函数可以保存在变量,对象和数组中. 函数可以当做参数传递给其他函数,函数也可以再返回给函数.而且因为函数是对象,函数还可以拥有方法\n* 一个函数总会有一个返回值,如果没有指定返回值则返回undefined(如果函数调用前加上了new前缀,且返回的不是一个对象,则返回this)\n\n### 函数字面量\n我们定义一个函数字面量\n```JavaScript\nvar add = function(a, b) {\n\treturn a + b;\n}\n```\n上面这个函数字面量是通过将一个匿名函数赋值给一个变量.\n\n函数字面量可以出现在任何允许表达式出现的地方. 函数可以被定义在其他函数中. 可以作为函数参数或者函数返回值出现。函数甚至拥有自己的作用域(就像变量有自己的作用域一样)\n\n每声明一个函数实际是创建了一个Function 实例,上面的函数等价于\n```javascript\nvar Add = new Function(\"a\",\"b\",\"a + b;\");\n\nvar add = new Add(1, 2);\n```\n\n### 闭包\n内部函数可以访问自己内部的参数和变量还可以访问嵌套在父函数的参数和变量。通过函数字面量创建的函数对象包含了一个连接到外部上下文的连接，这杯称为闭包(每个函数在创建时会附加俩个隐藏属性：函数的上下文和实现函数行为的代码).\n\n\n### 函数调用\n当调用函数时除了显示地向其传递的参数,每个函数还会接受俩个附加参数`this`, `arguments`. 当实际参数大于形式参数时,多余的参数会被忽略,而当实际参数小于形式,参数时缺少的参数会被赋值为undefined.\n\n下面会介绍四种调用模式,每种调用模式对`this`参数的初始化是不一样的.\n\n#### 方法调用模式\n当一个函数作为一个对象的属性时,我们称其为方法.方法里的this参数被被绑定到该对象上.\n```javascript\nvar obj = {\n\tvalue : 1;\n\taddOne : function() {\n\t\tthis.value += 1;\n\t}\n};\n\nobj.addOne();\n```\n\n#### 函数调用模式\n当一个函数并非一个对象属性时,那么它就被当做是一个函数来调用\n```javascript\nfunction add(a, b) {\n\treturn a + b;\n}\n\nc = add(1, 2);\n```\n这种模式下this被绑定到全局对象上\n\n#### 构造器调用模式\n\n\n一个函数如果创建的目的就是希望集合new关键字来使用,那么它就是构造器函数\n\n如果在一个函数前面带上一个new来调用,实际上会创建一个连接到该函数prototype成员的新对象,同时this也会绑定到那个新对象上.\n```javascript\nvar Quo = function(string) {\n\tthis.status = string;\n}\n\nQuo.prototype.get_status = function() {\n\treturn this.status;\n}\n\nvar myQuo = new Quo(\"hello\");\n```\n\n#### Apply调用模式\nJavaScript的函数可以拥有方法,apply方法可以让我们构建一个参数数组传递给调用函数. apply方法接受俩个参数`this`和参数数组.\n```javascript\nvar add = function(a, b) {\n\treturn a + b;\n}\n\nvar argus = [3, 4];\nvar sum = add.apply(null, argus);\n```\n\n### arguments数组\n在函数内部我们可以通过arguments数组变量访问所有的实际参数\n```javascript\nvar add = function () {\n\tvar sum = 0;\n\tfor(i = 0; i < arguments.length; i += 1) {\n\t\tsum += argements[i];\n\t}\n};\n\nvar sum = add(1, 2, 3, 4, 5);\n```\n\n### 异常\nthrow语句中断函数的执行,它应该抛出一个exception对象,这个对象包含一个`name`和`message`属性(你也可以添加额外的属性).\n\n我们使用try catch来捕获异常 \n```javascript\nvar add = function(a, b) {\n\tif(arguments.length < 2) {\n\t\tthrow {\n\t\t\t\tname: \"arguments error\",\n\t\t\t\tmessage: \"need more arguments\"\n\t\t\t}\n\t}\n}\n\nvar tryAdd = function(a, b) {\n\ttry {\n\t\treturn add(a, b);\n\t} catch(e) {\n\n\t}\n}\n\ntryAdd(1, 2, 3);\n```\n\n### 作用域\n代码块是包在一对花括号中的一组语句，JavaScript中的代码块不会创建新的作用域.但是函数确实是有其自己的作用域的,但是在函数内部定义的变量在整个函数体的任意位置都是可见的,因此变量应该被定义在函数的头部。\n\n作用域的好处是内部函数可以访问定义在他们的外部函数的参数和变量(除了this和arguments)\n\n### 闭包\n当我们在函数A中定义了函数B,函数B引用了函数A中的变量I,当函数A执行完毕,函数B作为返回值继续被执行时,函数A的变量I是仍然可以被访问的,这就是闭包.\n```javascript\nvar f1 = function() {\n\tvar id = 1132;\n\treturn {\n\t\tadd: function() {\n\t\t\treturn id += 1;\n\t\t}\n\n\t}\n}\n\nvar if1 = fi();\nvar id = if1.add(); // 结果是1133\n```\n简而言之呢,闭包的特性是保存了创建它时的上下文信息.\n\n### 模块\n我们可以使用函数和闭包来构造模块. 模块是一个提供接口却隐藏状态与实现的函数或者对象.\n\n模块的一般形式是：一个定义了私有变量和函数的函数,利用闭包创建可以访问私有变量和函数的特权函数,最后返回这个特权函数,或者将他们保存到一个可访问到的地方.\n\n\n\n### 柯里化\n函数也是值,我们可以像往常操作值那样去操作函数, 将函数作为一个变量.\n```javascript\nvar f = function(a, b, c) {\n\n}\n\nvar f1 = function() {\n\treturn p(1);\n} \n\nvar c = f1();\n```\n上面就实现了函数的柯里化\n\n\n\n### 普通函数\n\n```JavaScript\nfunction add(a, b) {\n\treturn a + b;\n}\n```\n","source":"_posts/编程语言/JavaScript函数.md","raw":"category: 编程语言\ndate: 2015-09-08\ntitle: JavaScript函数\n---\nJavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\nJavaScript中函数就是对象。函数对象连接到Function.prototype(该原型连接到Object.prototype).\n* 每个函数对象在创建时也随配一个prototype属性,它的值是一个拥有constructor属性且值为该函数的对象（这和连接到Function.prototype全完不同）.\n* 因为函数是对象,所以函数可以保存在变量,对象和数组中. 函数可以当做参数传递给其他函数,函数也可以再返回给函数.而且因为函数是对象,函数还可以拥有方法\n* 一个函数总会有一个返回值,如果没有指定返回值则返回undefined(如果函数调用前加上了new前缀,且返回的不是一个对象,则返回this)\n\n### 函数字面量\n我们定义一个函数字面量\n```JavaScript\nvar add = function(a, b) {\n\treturn a + b;\n}\n```\n上面这个函数字面量是通过将一个匿名函数赋值给一个变量.\n\n函数字面量可以出现在任何允许表达式出现的地方. 函数可以被定义在其他函数中. 可以作为函数参数或者函数返回值出现。函数甚至拥有自己的作用域(就像变量有自己的作用域一样)\n\n每声明一个函数实际是创建了一个Function 实例,上面的函数等价于\n```javascript\nvar Add = new Function(\"a\",\"b\",\"a + b;\");\n\nvar add = new Add(1, 2);\n```\n\n### 闭包\n内部函数可以访问自己内部的参数和变量还可以访问嵌套在父函数的参数和变量。通过函数字面量创建的函数对象包含了一个连接到外部上下文的连接，这杯称为闭包(每个函数在创建时会附加俩个隐藏属性：函数的上下文和实现函数行为的代码).\n\n\n### 函数调用\n当调用函数时除了显示地向其传递的参数,每个函数还会接受俩个附加参数`this`, `arguments`. 当实际参数大于形式参数时,多余的参数会被忽略,而当实际参数小于形式,参数时缺少的参数会被赋值为undefined.\n\n下面会介绍四种调用模式,每种调用模式对`this`参数的初始化是不一样的.\n\n#### 方法调用模式\n当一个函数作为一个对象的属性时,我们称其为方法.方法里的this参数被被绑定到该对象上.\n```javascript\nvar obj = {\n\tvalue : 1;\n\taddOne : function() {\n\t\tthis.value += 1;\n\t}\n};\n\nobj.addOne();\n```\n\n#### 函数调用模式\n当一个函数并非一个对象属性时,那么它就被当做是一个函数来调用\n```javascript\nfunction add(a, b) {\n\treturn a + b;\n}\n\nc = add(1, 2);\n```\n这种模式下this被绑定到全局对象上\n\n#### 构造器调用模式\n\n\n一个函数如果创建的目的就是希望集合new关键字来使用,那么它就是构造器函数\n\n如果在一个函数前面带上一个new来调用,实际上会创建一个连接到该函数prototype成员的新对象,同时this也会绑定到那个新对象上.\n```javascript\nvar Quo = function(string) {\n\tthis.status = string;\n}\n\nQuo.prototype.get_status = function() {\n\treturn this.status;\n}\n\nvar myQuo = new Quo(\"hello\");\n```\n\n#### Apply调用模式\nJavaScript的函数可以拥有方法,apply方法可以让我们构建一个参数数组传递给调用函数. apply方法接受俩个参数`this`和参数数组.\n```javascript\nvar add = function(a, b) {\n\treturn a + b;\n}\n\nvar argus = [3, 4];\nvar sum = add.apply(null, argus);\n```\n\n### arguments数组\n在函数内部我们可以通过arguments数组变量访问所有的实际参数\n```javascript\nvar add = function () {\n\tvar sum = 0;\n\tfor(i = 0; i < arguments.length; i += 1) {\n\t\tsum += argements[i];\n\t}\n};\n\nvar sum = add(1, 2, 3, 4, 5);\n```\n\n### 异常\nthrow语句中断函数的执行,它应该抛出一个exception对象,这个对象包含一个`name`和`message`属性(你也可以添加额外的属性).\n\n我们使用try catch来捕获异常 \n```javascript\nvar add = function(a, b) {\n\tif(arguments.length < 2) {\n\t\tthrow {\n\t\t\t\tname: \"arguments error\",\n\t\t\t\tmessage: \"need more arguments\"\n\t\t\t}\n\t}\n}\n\nvar tryAdd = function(a, b) {\n\ttry {\n\t\treturn add(a, b);\n\t} catch(e) {\n\n\t}\n}\n\ntryAdd(1, 2, 3);\n```\n\n### 作用域\n代码块是包在一对花括号中的一组语句，JavaScript中的代码块不会创建新的作用域.但是函数确实是有其自己的作用域的,但是在函数内部定义的变量在整个函数体的任意位置都是可见的,因此变量应该被定义在函数的头部。\n\n作用域的好处是内部函数可以访问定义在他们的外部函数的参数和变量(除了this和arguments)\n\n### 闭包\n当我们在函数A中定义了函数B,函数B引用了函数A中的变量I,当函数A执行完毕,函数B作为返回值继续被执行时,函数A的变量I是仍然可以被访问的,这就是闭包.\n```javascript\nvar f1 = function() {\n\tvar id = 1132;\n\treturn {\n\t\tadd: function() {\n\t\t\treturn id += 1;\n\t\t}\n\n\t}\n}\n\nvar if1 = fi();\nvar id = if1.add(); // 结果是1133\n```\n简而言之呢,闭包的特性是保存了创建它时的上下文信息.\n\n### 模块\n我们可以使用函数和闭包来构造模块. 模块是一个提供接口却隐藏状态与实现的函数或者对象.\n\n模块的一般形式是：一个定义了私有变量和函数的函数,利用闭包创建可以访问私有变量和函数的特权函数,最后返回这个特权函数,或者将他们保存到一个可访问到的地方.\n\n\n\n### 柯里化\n函数也是值,我们可以像往常操作值那样去操作函数, 将函数作为一个变量.\n```javascript\nvar f = function(a, b, c) {\n\n}\n\nvar f1 = function() {\n\treturn p(1);\n} \n\nvar c = f1();\n```\n上面就实现了函数的柯里化\n\n\n\n### 普通函数\n\n```JavaScript\nfunction add(a, b) {\n\treturn a + b;\n}\n```\n","slug":"编程语言/JavaScript函数","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5300cwvjs6jivwf3zf"},{"date":"2015-09-07T16:00:00.000Z","title":"JavaScript面向对象和原型链","_content":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n## 对象\nJavaScript的简单数据类型包括数字，字符串，布尔值，null值和undefined值，其他值都是对象(数组，函数都是对象)。 数字，字符串和布尔值虽然拥有方法，但他们是不可变的，因此不能称他们为对象。JavaScript中的对象是可变的键控集合。\n\n对象是属性的容器，每个属性都有名字和值。\n* 属性名：包括空串在内的任意字符串。如果字符串不是JavaScript保留的关键字切是合法的标识符则可以不必使用双引号。\n* 属性值：包括undefined值之外的任何值\n\n但是JavaScript里的对象是无类型的。\n\nJavaScript包含一种原型链特性,允许对象继承另一个对象的属性.正确的使用它能减少对象初始化时小号的时间和内存.\n\n### 对象字面量\n包围在一对花括号中的0~N个键值对即为对象字面量。\n```javascript\nvar empoty = {};\n\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n}\n```\n对象字面量还可以嵌套使用\n\n```javascript\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n\tchengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n}\n```\n\n### 检索对象里的值\n我们可以使用`[]`括住一个字符串表达式来索引某个值\n```javascript\nxiaoming[\"name\"]\n```\n如果该字符串是一个合法的标识符且不是保留关键字，那么也可以使用`.`进行索引\n```javascript\nxiaoming.name\n```\n如果我们索引`hair`这个属性的话,会得到一个`undefined`值,因此我们也可以使用`||`指定一个默认值\n```javascript\nxiaoming.hair || \"red\"\n```\n这样我们获得的结果就是`red`这个字符串,可是如果我们向一个`undefined`值继续索引的话会得到一个`TypeError`异常,我们可以使用`&&`来避免\n```javascript\nxiaoming.cars && xiaoming.cars.changcheng\n```\n我们通过这种方式获得小明拥有的汽车中长城汽车的属性值.\n\n### 更新对象的值\n我们可以通过`=`对对象进行赋值.\n```javascript\nxiaoming.name = \"zhangxiaoming\"\n\n// 或者赋值某个新的对象\nxiaoming.chengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n```\n\n### 引用对象\n对象通过引用来传递\n\n```javascript\nvar chengji = xiaoming.chengji\n```\n\n### 创建对象\n\n#### Object 模式\n```javascript\nvar o1 = {};//字面量的表现形式\nvar o2 = new Object;\nvar o3 = new Object();\nvar o4 = new Object(null);\nvar o5 = new Object(undefined);\nvar o6 = Object.create(Object.prototype);//等价于 var o = {};//即以 Object.prototype 对象为一个原型模板,新建一个以这个原型模板为原型的对象\n// 区别\nvar o7 = Object.create(null);//创建一个原型为 null 的对象\n```\n\n#### 构造器模式\n```javascript\nfunction Car(sColor){\n    this.color = sColor;      \n}\n\nvar car = new Car(\"red\");\n```\n\n\n### 原型链\n每个对象都会连接到一个原型对象,并且从中继承属性. 对象字面量会连接到`Object.prototype`\n\n需要指出的是原型连接在对象更新时是不起作用的(如果我们对某个对象做出改变是不会触及该对象的原型).原型连接只有在索引值的时候才会被用到.\n\n#### 委托\n如果我们尝试去索引某个对象A的值,但该对象没有此属性名,那么JavaScript会试着从A的原型B中进行查找,如果B中也没有的话,会继续向B的原型C中查找,一直找到`Object.prototype`,如果都没有找到那么值就是`undefined`.\n\n#### 指定对象的原型\n```javascript\n\n```\n\n### 反射\n我们可以使用typeof来观察我们的对象中是否包含某个属性\n```javascript\ntypeof xiaoming.name  // 值为string\ntypeof xiaoming.address  // 值为undefined\n```\n这样我们可以通过`undefined`来判断某个对象中是否包含某个值,但是有一点需要说明的是`typeof`也会在原型链进行索引判断。\n\n那么我们可以使用`hasOwnProperty`方法进行判断，它不对原型链进行检查同时它的返回值只有布尔值\n```javascript\nxiaoming.hasOwnProperty(\"address\")  // 值为false\n```\n\n### 删除\ndelete运算符可以用来删除对象的属性.它不会触及原型链中的任何对象. 如果我们自定义的对象属性覆盖了原型中的属性,我们可以通过删除对象的属性而让原型中的属性显露出来\n\n","source":"_posts/编程语言/JavaScript面向对象.md","raw":"category: 编程语言\ndate: 2015-09-08\ntitle: JavaScript面向对象和原型链\n---\nJavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n## 对象\nJavaScript的简单数据类型包括数字，字符串，布尔值，null值和undefined值，其他值都是对象(数组，函数都是对象)。 数字，字符串和布尔值虽然拥有方法，但他们是不可变的，因此不能称他们为对象。JavaScript中的对象是可变的键控集合。\n\n对象是属性的容器，每个属性都有名字和值。\n* 属性名：包括空串在内的任意字符串。如果字符串不是JavaScript保留的关键字切是合法的标识符则可以不必使用双引号。\n* 属性值：包括undefined值之外的任何值\n\n但是JavaScript里的对象是无类型的。\n\nJavaScript包含一种原型链特性,允许对象继承另一个对象的属性.正确的使用它能减少对象初始化时小号的时间和内存.\n\n### 对象字面量\n包围在一对花括号中的0~N个键值对即为对象字面量。\n```javascript\nvar empoty = {};\n\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n}\n```\n对象字面量还可以嵌套使用\n\n```javascript\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n\tchengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n}\n```\n\n### 检索对象里的值\n我们可以使用`[]`括住一个字符串表达式来索引某个值\n```javascript\nxiaoming[\"name\"]\n```\n如果该字符串是一个合法的标识符且不是保留关键字，那么也可以使用`.`进行索引\n```javascript\nxiaoming.name\n```\n如果我们索引`hair`这个属性的话,会得到一个`undefined`值,因此我们也可以使用`||`指定一个默认值\n```javascript\nxiaoming.hair || \"red\"\n```\n这样我们获得的结果就是`red`这个字符串,可是如果我们向一个`undefined`值继续索引的话会得到一个`TypeError`异常,我们可以使用`&&`来避免\n```javascript\nxiaoming.cars && xiaoming.cars.changcheng\n```\n我们通过这种方式获得小明拥有的汽车中长城汽车的属性值.\n\n### 更新对象的值\n我们可以通过`=`对对象进行赋值.\n```javascript\nxiaoming.name = \"zhangxiaoming\"\n\n// 或者赋值某个新的对象\nxiaoming.chengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n```\n\n### 引用对象\n对象通过引用来传递\n\n```javascript\nvar chengji = xiaoming.chengji\n```\n\n### 创建对象\n\n#### Object 模式\n```javascript\nvar o1 = {};//字面量的表现形式\nvar o2 = new Object;\nvar o3 = new Object();\nvar o4 = new Object(null);\nvar o5 = new Object(undefined);\nvar o6 = Object.create(Object.prototype);//等价于 var o = {};//即以 Object.prototype 对象为一个原型模板,新建一个以这个原型模板为原型的对象\n// 区别\nvar o7 = Object.create(null);//创建一个原型为 null 的对象\n```\n\n#### 构造器模式\n```javascript\nfunction Car(sColor){\n    this.color = sColor;      \n}\n\nvar car = new Car(\"red\");\n```\n\n\n### 原型链\n每个对象都会连接到一个原型对象,并且从中继承属性. 对象字面量会连接到`Object.prototype`\n\n需要指出的是原型连接在对象更新时是不起作用的(如果我们对某个对象做出改变是不会触及该对象的原型).原型连接只有在索引值的时候才会被用到.\n\n#### 委托\n如果我们尝试去索引某个对象A的值,但该对象没有此属性名,那么JavaScript会试着从A的原型B中进行查找,如果B中也没有的话,会继续向B的原型C中查找,一直找到`Object.prototype`,如果都没有找到那么值就是`undefined`.\n\n#### 指定对象的原型\n```javascript\n\n```\n\n### 反射\n我们可以使用typeof来观察我们的对象中是否包含某个属性\n```javascript\ntypeof xiaoming.name  // 值为string\ntypeof xiaoming.address  // 值为undefined\n```\n这样我们可以通过`undefined`来判断某个对象中是否包含某个值,但是有一点需要说明的是`typeof`也会在原型链进行索引判断。\n\n那么我们可以使用`hasOwnProperty`方法进行判断，它不对原型链进行检查同时它的返回值只有布尔值\n```javascript\nxiaoming.hasOwnProperty(\"address\")  // 值为false\n```\n\n### 删除\ndelete运算符可以用来删除对象的属性.它不会触及原型链中的任何对象. 如果我们自定义的对象属性覆盖了原型中的属性,我们可以通过删除对象的属性而让原型中的属性显露出来\n\n","slug":"编程语言/JavaScript面向对象","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5500cyvjs6ktle2rcp"},{"date":"2015-12-15T16:00:00.000Z","title":"PHP 语法初探","_content":"PHP 脚本以 `<?php 开头，以 ?>` 结尾：\n```php\n<?php\n// 此处是 PHP 代码\n?>\n```\n\n## 变量\n```php\n<?php\n// 定义一个变量\n$x=5;\n// 调用echo函数输出变量x的值\necho $x;\n?>\n```\n\nPHP 有三种不同的变量作用域：\n* local : 函数里定义的变量,只能在函数内部访问,函数外部不可访问\n* global: 函数外部定义的变量,只能在函数外部访问,函数内部不可访问\n* static: 当变量脱离它的作用域之后,并不会被删除掉,而是缓存起来\n\n\n```php\n<?php\n$x=5; // 全局作用域\n\nfunction socpePrint() {\n  $y=10; // 局部作用域\n  echo $y;\n  echo $x;\n} \n\nmyTest();\n\necho $y;\necho $x;\n?>\n```\n\n刚才我们只是介绍了`global`这个作用域,其实还有`global`关键字,这个关键字是在函数内部定义一个全局变量,让函数外访问函数内部的变量\n```php\n<?php\nfunction socpePrint() {\n  global $x=10;\n}\n\nsocpePrint();\necho $x;\n?>\n```\n\nphp里有如下的数据类型\n* 字符串\n* 整数\n* 浮点数\n* 逻辑\n* 数组\n* 对象\n* NULL\n```php\n<?php\n$stringVar=\"this is a string\";\t// 定义一个字符串\n$numVar=10;\t// 定义一个整数\n$floatVar=1.0;\t// 定义一个浮点数\n$boolVar=true;\t\t// 定义一个布尔值\n$arrayVar=array(1,2);\t// 定义一个数组\n?>\n```\n\n数组相关操作\n```php\n<?php\n$arrayVar=array(1,2);\t// 定义一个数组\n$ele1=$arrayVar[0];\t// 访问数组第一个元素\n$arrayCount=count($arrayVar);\t// 求数组长度\n$arrayVar[2]=3;\t\t// 向数组中追加元素\n?>\n```\n\n## 函数\n\n下面我们定义了一个求和函数, 这个函数定义了俩个参数`x, y`, 其中y是一个默认参数,它有一个默认值, 最后我们还定义了一个函数返回值. \n```php\n<?php\nfunction sum($x,$y=5) {\n  $z=$x+$y;\n  return $z;\n}\n\necho sum(5,10);\n?>\n```\n\n### 常量函数\n在php中,我们如果想要定义一个常量,则必须使用常量函数`define()`\n```php\n<?php\ndefine(\"constant\", \"I am constant\", true);\necho CONSTANT;\n?>\n```\n最后一个参数是一个可选参数,如果设置为true,则说明访问常量的时候是不区分大小写的. 访问常量则不需要`$`符号\n\n### 日期函数\n我们使用`date(format,timestamp)`函数来获得系统的时间, 第二个参数是可选的,如果不填则是当前时间. 第一个参数则是格式化时间戳的格式, 有如下选项\n* `d` - 表示月里的某天（01-31）\n* `m` - 表示月（01-12）\n* `Y` - 表示年（四位数）\n* `1` - 表示周里的某天\n* `h` - 带有首位零的 12 小时小时格式\n* `i` - 带有首位零的分钟\n* `s` - 带有首位零的秒（00 -59）\n* `a` - 小写的午前和午后（am 或 pm）\n```php\n\n<?php \n$now = date(\"Y-m-d h:i:sa\");\necho $now;\n?>\n```\n\n## 流程控制\n\n### if else\n```php\n<?php\ndefine(\"TEN\", 10);\n\nif (TEN<\"20\") {\n    echo \"10 < 20\";\n} else {\n\techo \"ERROR\";\n}\n?>\n```\n如果还有其他条件的话我们可以采用\n```php\n<?php\ndefine(\"TEN\", 10);\n\nif (TEN<20) {\n    echo \"10 < 20\";\n} elseif (TEN==20) {\n  echo \"ERROR\";\n} else {\n\techo \"ERROR\";\n}\n?>\n```\n\n### switch\n```php\n<?php\nswitch ($x)\n{\ncase 1:\n  echo \"Number 1\";\n  break;\ncase 2:\n  echo \"Number 2\";\n  break;\ndefault:\n  echo \"No number between 1 and 3\";\n}\n?>\n```\n\n### while\n```php\n<?php \n$x=1; \nwhile($x<=5) {\n  echo \"这个数字是：$x <br>\";\n  $x++;\n} \n?>\n```\n\n### for\n```php\n<?php \nfor ($x=0; $x<=10; $x++) {\n  echo $x;\n} \n?>\n```\n\n另外还有一种适用于数组的foreach\n```php\n<?php \n$colors = array(\"red\",\"green\",\"blue\",\"yellow\"); \n\nforeach ($colors as $value) {\n  echo \"$value\";\n}\n?>\n```\n如果我们遍历数组的时候,数组的元素是一个键值对的话, 我们可以这样处理\n<?php \n$colors = array(\"red:555\",\"green:123\",\"blue:856\"); \n\nforeach ($colors as $colerKey => $colorValue) {\n  echo \"$colerKey  is $colorValue\";\n}\n?>\n```\n`=>`就表示一个键值对\n\n## 文件\n我们使用`fopen(fileName, openMode)`函数打开文件, 第一个参数是文件名, 第二个参数打开模式\n* `r`:\t打开文件为只读。文件指针在文件的开头开始。\n* `w`:\t打开文件为只写。删除文件的内容或创建一个新的文件，如果它不存在。文件指针在文件的开头开始。\n* `a`:\t打开文件为只写。文件中的现有数据会被保留。文件指针在文件结尾开始。创建新的文件，如果文件不存在。\n* `x`:\t创建新文件为只写。返回 FALSE 和错误，如果文件已存在。\n* `r+`:\t打开文件为读/写、文件指针在文件开头开始。\n* `w+`:\t打开文件为读/写。删除文件内容或创建新文件，如果它不存在。文件指针在文件开头开始。\n* `a+`:\t打开文件为读/写。文件中已有的数据会被保留。文件指针在文件结尾开始。创建新文件，如果它不存在。\n* `x+`:\t创建新文件为读/写。返回 FALSE 和错误，如果文件已存在。\n```php\n<?php\n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\n?>\n```\n\n读取文件内容, `fread()`函数会读取整个文件内容\n```php\n<?php \n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\nfread($demofile,filesize(\"demo.txt\"));\n?>\n```\n按行读取\n```php\n<?php\n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\nwhile(!feof($demofile)) {\t// 如果文件没有到达结尾的话,则继续读取\n  echo fgets($demofile);\t// 读取一行\n}\nfclose($myfile);\t\t// 关闭文件\n?>\n```\n\n向文件中写入数据\n```php\n<?php \n$demofile = fopen(\"demo.txt\", \"w\") or die(\"Unable to open file!\");\nfwrite($demofile, \"hello world\");\nfclose($myfile);\n?>\n```\n\n## mysql\n建立连接\n```php\n<?php \n// 建立mysql连接\n$con = mysql_connect(\"localhost\",\"root\",\"root\");\nif (!$con) {\n  die('Could not connect: ' . mysql_error());\n}\n\n// 选择数据库\nmysql_select_db(\"my_db\", $con);\n\n// 执行sql语句\n$result = mysql_query(\"SELECT * FROM Persons\");\n\n// 遍历结果\nwhile($row = mysql_fetch_array($result)) {\n\t// 输出某个列元素\n  echo $row['FirstName'];\n}\n\n// 关闭连接\nmysql_close($con);\n?>\n```\n","source":"_posts/编程语言/PHP 语法初探.md","raw":"category: 编程语言\ndate: 2015-12-16\ntitle: PHP 语法初探\n---\nPHP 脚本以 `<?php 开头，以 ?>` 结尾：\n```php\n<?php\n// 此处是 PHP 代码\n?>\n```\n\n## 变量\n```php\n<?php\n// 定义一个变量\n$x=5;\n// 调用echo函数输出变量x的值\necho $x;\n?>\n```\n\nPHP 有三种不同的变量作用域：\n* local : 函数里定义的变量,只能在函数内部访问,函数外部不可访问\n* global: 函数外部定义的变量,只能在函数外部访问,函数内部不可访问\n* static: 当变量脱离它的作用域之后,并不会被删除掉,而是缓存起来\n\n\n```php\n<?php\n$x=5; // 全局作用域\n\nfunction socpePrint() {\n  $y=10; // 局部作用域\n  echo $y;\n  echo $x;\n} \n\nmyTest();\n\necho $y;\necho $x;\n?>\n```\n\n刚才我们只是介绍了`global`这个作用域,其实还有`global`关键字,这个关键字是在函数内部定义一个全局变量,让函数外访问函数内部的变量\n```php\n<?php\nfunction socpePrint() {\n  global $x=10;\n}\n\nsocpePrint();\necho $x;\n?>\n```\n\nphp里有如下的数据类型\n* 字符串\n* 整数\n* 浮点数\n* 逻辑\n* 数组\n* 对象\n* NULL\n```php\n<?php\n$stringVar=\"this is a string\";\t// 定义一个字符串\n$numVar=10;\t// 定义一个整数\n$floatVar=1.0;\t// 定义一个浮点数\n$boolVar=true;\t\t// 定义一个布尔值\n$arrayVar=array(1,2);\t// 定义一个数组\n?>\n```\n\n数组相关操作\n```php\n<?php\n$arrayVar=array(1,2);\t// 定义一个数组\n$ele1=$arrayVar[0];\t// 访问数组第一个元素\n$arrayCount=count($arrayVar);\t// 求数组长度\n$arrayVar[2]=3;\t\t// 向数组中追加元素\n?>\n```\n\n## 函数\n\n下面我们定义了一个求和函数, 这个函数定义了俩个参数`x, y`, 其中y是一个默认参数,它有一个默认值, 最后我们还定义了一个函数返回值. \n```php\n<?php\nfunction sum($x,$y=5) {\n  $z=$x+$y;\n  return $z;\n}\n\necho sum(5,10);\n?>\n```\n\n### 常量函数\n在php中,我们如果想要定义一个常量,则必须使用常量函数`define()`\n```php\n<?php\ndefine(\"constant\", \"I am constant\", true);\necho CONSTANT;\n?>\n```\n最后一个参数是一个可选参数,如果设置为true,则说明访问常量的时候是不区分大小写的. 访问常量则不需要`$`符号\n\n### 日期函数\n我们使用`date(format,timestamp)`函数来获得系统的时间, 第二个参数是可选的,如果不填则是当前时间. 第一个参数则是格式化时间戳的格式, 有如下选项\n* `d` - 表示月里的某天（01-31）\n* `m` - 表示月（01-12）\n* `Y` - 表示年（四位数）\n* `1` - 表示周里的某天\n* `h` - 带有首位零的 12 小时小时格式\n* `i` - 带有首位零的分钟\n* `s` - 带有首位零的秒（00 -59）\n* `a` - 小写的午前和午后（am 或 pm）\n```php\n\n<?php \n$now = date(\"Y-m-d h:i:sa\");\necho $now;\n?>\n```\n\n## 流程控制\n\n### if else\n```php\n<?php\ndefine(\"TEN\", 10);\n\nif (TEN<\"20\") {\n    echo \"10 < 20\";\n} else {\n\techo \"ERROR\";\n}\n?>\n```\n如果还有其他条件的话我们可以采用\n```php\n<?php\ndefine(\"TEN\", 10);\n\nif (TEN<20) {\n    echo \"10 < 20\";\n} elseif (TEN==20) {\n  echo \"ERROR\";\n} else {\n\techo \"ERROR\";\n}\n?>\n```\n\n### switch\n```php\n<?php\nswitch ($x)\n{\ncase 1:\n  echo \"Number 1\";\n  break;\ncase 2:\n  echo \"Number 2\";\n  break;\ndefault:\n  echo \"No number between 1 and 3\";\n}\n?>\n```\n\n### while\n```php\n<?php \n$x=1; \nwhile($x<=5) {\n  echo \"这个数字是：$x <br>\";\n  $x++;\n} \n?>\n```\n\n### for\n```php\n<?php \nfor ($x=0; $x<=10; $x++) {\n  echo $x;\n} \n?>\n```\n\n另外还有一种适用于数组的foreach\n```php\n<?php \n$colors = array(\"red\",\"green\",\"blue\",\"yellow\"); \n\nforeach ($colors as $value) {\n  echo \"$value\";\n}\n?>\n```\n如果我们遍历数组的时候,数组的元素是一个键值对的话, 我们可以这样处理\n<?php \n$colors = array(\"red:555\",\"green:123\",\"blue:856\"); \n\nforeach ($colors as $colerKey => $colorValue) {\n  echo \"$colerKey  is $colorValue\";\n}\n?>\n```\n`=>`就表示一个键值对\n\n## 文件\n我们使用`fopen(fileName, openMode)`函数打开文件, 第一个参数是文件名, 第二个参数打开模式\n* `r`:\t打开文件为只读。文件指针在文件的开头开始。\n* `w`:\t打开文件为只写。删除文件的内容或创建一个新的文件，如果它不存在。文件指针在文件的开头开始。\n* `a`:\t打开文件为只写。文件中的现有数据会被保留。文件指针在文件结尾开始。创建新的文件，如果文件不存在。\n* `x`:\t创建新文件为只写。返回 FALSE 和错误，如果文件已存在。\n* `r+`:\t打开文件为读/写、文件指针在文件开头开始。\n* `w+`:\t打开文件为读/写。删除文件内容或创建新文件，如果它不存在。文件指针在文件开头开始。\n* `a+`:\t打开文件为读/写。文件中已有的数据会被保留。文件指针在文件结尾开始。创建新文件，如果它不存在。\n* `x+`:\t创建新文件为读/写。返回 FALSE 和错误，如果文件已存在。\n```php\n<?php\n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\n?>\n```\n\n读取文件内容, `fread()`函数会读取整个文件内容\n```php\n<?php \n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\nfread($demofile,filesize(\"demo.txt\"));\n?>\n```\n按行读取\n```php\n<?php\n$demofile = fopen(\"demo.txt\", \"r\") or die(\"Unable to open file!\");\nwhile(!feof($demofile)) {\t// 如果文件没有到达结尾的话,则继续读取\n  echo fgets($demofile);\t// 读取一行\n}\nfclose($myfile);\t\t// 关闭文件\n?>\n```\n\n向文件中写入数据\n```php\n<?php \n$demofile = fopen(\"demo.txt\", \"w\") or die(\"Unable to open file!\");\nfwrite($demofile, \"hello world\");\nfclose($myfile);\n?>\n```\n\n## mysql\n建立连接\n```php\n<?php \n// 建立mysql连接\n$con = mysql_connect(\"localhost\",\"root\",\"root\");\nif (!$con) {\n  die('Could not connect: ' . mysql_error());\n}\n\n// 选择数据库\nmysql_select_db(\"my_db\", $con);\n\n// 执行sql语句\n$result = mysql_query(\"SELECT * FROM Persons\");\n\n// 遍历结果\nwhile($row = mysql_fetch_array($result)) {\n\t// 输出某个列元素\n  echo $row['FirstName'];\n}\n\n// 关闭连接\nmysql_close($con);\n?>\n```\n","slug":"编程语言/PHP 语法初探","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5700d0vjs6jc8ztg2e"},{"date":"2015-04-07T16:00:00.000Z","title":"haskell类型系统","_content":"\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```haskell\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```haskell\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\nHaskell提供了以下的类型类\n* Eq\n* Ord\n* Enum\n* Bounded\n* Num\n* Show\n\n## 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n","source":"_posts/编程语言/haskell.md","raw":"category: 编程语言\ndate: 2015-04-08\ntitle: haskell类型系统\n---\n\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```haskell\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```haskell\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\nHaskell提供了以下的类型类\n* Eq\n* Ord\n* Enum\n* Bounded\n* Num\n* Show\n\n## 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n","slug":"编程语言/haskell","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5800d2vjs6tfvdpdc3"},{"date":"2015-04-07T16:00:00.000Z","title":"haskell函数","_content":"我们采用如下格式定义一个函数\n```haskell\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n## 参数绑定\n\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n\n#### 替换函数\n* where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n```haskell\n\n```\n\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n","source":"_posts/编程语言/haskell函数.md","raw":"category: 编程语言\ndate: 2015-04-08\ntitle: haskell函数\n---\n我们采用如下格式定义一个函数\n```haskell\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n## 参数绑定\n\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n\n#### 替换函数\n* where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n```haskell\n\n```\n\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n","slug":"编程语言/haskell函数","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5a00d4vjs6zz7att0d"},{"date":"2015-04-07T16:00:00.000Z","title":"haskell表达式","_content":"\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```haskell\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n","source":"_posts/编程语言/haskell表达式.md","raw":"category: 编程语言\ndate: 2015-04-08\ntitle: haskell表达式\n---\n\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```haskell\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n","slug":"编程语言/haskell表达式","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5b00d6vjs664qb1ntc"},{"date":"2016-04-05T16:00:00.000Z","title":"IP地址","_content":"今天遇到一个比较奇葩的问题, 在一个JDBC程序连接数据库的时候, 使用IPV4地址就无法访问, 使用localhost就成功, 现在就对这个问题一探究竟\n```java\njdbc:mysql://localhost:3306/c2x?autoReconnect=true\n```\n\n首先要说明一下localhost, 127.0.0.1和ipv4之间的关系\n* localhost : 首先这不是一个地址, 而是一个域名, 类似于www.baidu.com这种东西\n* 127.0.0.1 : 127开头的网段默认都是属于loopback接口, 用于测试本机TCP/IP协议栈. 它被分配在了一个虚拟网卡上\n* ipv4 : 是一个真实网卡上的ip地址.\n\n首先我们看一下win7系统上的C:\\Windows\\System32\\drivers\\etc的host配置文件\n```xml\n# localhost name resolution is handled within DNS itself.\n#\t127.0.0.1       localhost\n#\t::1             localhost\n```\n我们看到127.0.0.1就映射到了localhost, ::1是在ipv6的前提下分配到的localhost. 通过这个配置文件我们就看到了localhost和 127.0.0.1这二者之间的关系.\n\n下面我们再使用`ipconfig/all`这个命令看一下Windows的网卡配置\n```xml\nWindows IP 配置\n\n   主机名  . . . . . . . . . . . . . : OA1503P0256\n   主 DNS 后缀 . . . . . . . . . . . : xxx(lol)\n   节点类型  . . . . . . . . . . . . : 混合\n   IP 路由已启用 . . . . . . . . . . : 否\n   WINS 代理已启用 . . . . . . . . . : 否\n   DNS 后缀搜索列表  . . . . . . . . : xxx(lol)\n\n以太网适配器 本地连接:\n\n   连接特定的 DNS 后缀 . . . . . . . : xxx(lol)\n   描述. . . . . . . . . . . . . . . : Realtek PCIe GBE Family Controller\n   物理地址. . . . . . . . . . . . . : F0-79-59-64-74-71\n   DHCP 已启用 . . . . . . . . . . . : 是\n   自动配置已启用. . . . . . . . . . : 是\n   本地链接 IPv6 地址. . . . . . . . : fe80::1d00:63da:2b98:8c05%11(首选) \n   IPv4 地址 . . . . . . . . . . . . : 192.168.10.220(首选) \n   子网掩码  . . . . . . . . . . . . : 255.255.255.0\n   获得租约的时间  . . . . . . . . . : 2016年3月29日 10:05:04\n   租约过期的时间  . . . . . . . . . : 2016年4月6日 16:32:42\n   默认网关. . . . . . . . . . . . . : 192.168.10.254\n   DHCP 服务器 . . . . . . . . . . . : 192.168.10.202\n   DHCPv6 IAID . . . . . . . . . . . : 235430502\n   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-1C-AE-A2-19-F0-79-59-64-74-71\n   DNS 服务器  . . . . . . . . . . . : 192.168.10.12\n                                       192.168.15.3\n   TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n\n隧道适配器 isatap.xxx(lol):\n\n   媒体状态  . . . . . . . . . . . . : 媒体已断开\n   连接特定的 DNS 后缀 . . . . . . . : xxx(lol)\n   描述. . . . . . . . . . . . . . . : Microsoft ISATAP Adapter\n   物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0\n   DHCP 已启用 . . . . . . . . . . . : 否\n   自动配置已启用. . . . . . . . . . : 是\n\n隧道适配器 Teredo Tunneling Pseudo-Interface:\n\n   媒体状态  . . . . . . . . . . . . : 媒体已断开\n   连接特定的 DNS 后缀 . . . . . . . : \n   描述. . . . . . . . . . . . . . . : Teredo Tunneling Pseudo-Interface\n   物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0\n   DHCP 已启用 . . . . . . . . . . . : 否\n   自动配置已启用. . . . . . . . . . : 是\n\n```\n\n好了, 最后验证一下刚开始谈到的那个数据库的问题. 当我分别使用`192.168.10.20`和`localhost`通过SQLyog连接时, 果真看到的是俩个不一样的数据库....\n\n然后我又写了一个测试程序\n```java\npublic class TestLocalhost {\n\n    public static void main(String[] args) throws IOException, InterruptedException {\n        ServerSocket serverSocket = new ServerSocket();\n        serverSocket.bind(new InetSocketAddress(\"192.168.10.220\", 9051));\n//        serverSocket.bind(new InetSocketAddress(\"localhost\", 9051));\n        serverSocket.accept();\n        System.out.println(\"connected!!!\");\n    }\n}\n```\n然后使用http请求测试\n* `http://localhost:9051/` 不可连接成功\n* `http://192.168.10.220:9051/`  连接成功\n说明`192.168.10.20`和`localhost`本身是不能互通的.\n\n接下来我改进一下这个程序\n```java\npublic class TestLocalhost {\n\n    public static void main(String[] args) throws InterruptedException {\n        SocketAcceptor socketAcceptor1 = new SocketAcceptor(\"192.168.10.220\");\n        SocketAcceptor socketAcceptor2 = new SocketAcceptor(\"localhost\");\n        socketAcceptor1.start();\n        socketAcceptor2.start();\n\n        TimeUnit.SECONDS.sleep(100);\n    }\n\n    public static class SocketAcceptor extends Thread {\n\n        public final String ip;\n        public SocketAcceptor(String ip) {\n            this.ip = ip;\n        }\n\n        @Override\n        public void run() {\n            try {\n                ServerSocket serverSocket1 = new ServerSocket();\n                serverSocket1.bind(new InetSocketAddress(ip, 9051));\n                serverSocket1.accept();\n                System.out.println(ip + \" accepted\");\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n然后继续使用上面俩个地址进行访问, 发现最后都进行了输出\n```xml\n192.168.10.220 accepted\nlocalhost accepted\n```\n这个例子也说明了不同的网卡可以绑定不同的端口, 即使是虚拟网卡也有一套自己端口","source":"_posts/网络/IP地址.md","raw":"category: 网络\ndate: 2016-04-06\ntitle: IP地址\n---\n今天遇到一个比较奇葩的问题, 在一个JDBC程序连接数据库的时候, 使用IPV4地址就无法访问, 使用localhost就成功, 现在就对这个问题一探究竟\n```java\njdbc:mysql://localhost:3306/c2x?autoReconnect=true\n```\n\n首先要说明一下localhost, 127.0.0.1和ipv4之间的关系\n* localhost : 首先这不是一个地址, 而是一个域名, 类似于www.baidu.com这种东西\n* 127.0.0.1 : 127开头的网段默认都是属于loopback接口, 用于测试本机TCP/IP协议栈. 它被分配在了一个虚拟网卡上\n* ipv4 : 是一个真实网卡上的ip地址.\n\n首先我们看一下win7系统上的C:\\Windows\\System32\\drivers\\etc的host配置文件\n```xml\n# localhost name resolution is handled within DNS itself.\n#\t127.0.0.1       localhost\n#\t::1             localhost\n```\n我们看到127.0.0.1就映射到了localhost, ::1是在ipv6的前提下分配到的localhost. 通过这个配置文件我们就看到了localhost和 127.0.0.1这二者之间的关系.\n\n下面我们再使用`ipconfig/all`这个命令看一下Windows的网卡配置\n```xml\nWindows IP 配置\n\n   主机名  . . . . . . . . . . . . . : OA1503P0256\n   主 DNS 后缀 . . . . . . . . . . . : xxx(lol)\n   节点类型  . . . . . . . . . . . . : 混合\n   IP 路由已启用 . . . . . . . . . . : 否\n   WINS 代理已启用 . . . . . . . . . : 否\n   DNS 后缀搜索列表  . . . . . . . . : xxx(lol)\n\n以太网适配器 本地连接:\n\n   连接特定的 DNS 后缀 . . . . . . . : xxx(lol)\n   描述. . . . . . . . . . . . . . . : Realtek PCIe GBE Family Controller\n   物理地址. . . . . . . . . . . . . : F0-79-59-64-74-71\n   DHCP 已启用 . . . . . . . . . . . : 是\n   自动配置已启用. . . . . . . . . . : 是\n   本地链接 IPv6 地址. . . . . . . . : fe80::1d00:63da:2b98:8c05%11(首选) \n   IPv4 地址 . . . . . . . . . . . . : 192.168.10.220(首选) \n   子网掩码  . . . . . . . . . . . . : 255.255.255.0\n   获得租约的时间  . . . . . . . . . : 2016年3月29日 10:05:04\n   租约过期的时间  . . . . . . . . . : 2016年4月6日 16:32:42\n   默认网关. . . . . . . . . . . . . : 192.168.10.254\n   DHCP 服务器 . . . . . . . . . . . : 192.168.10.202\n   DHCPv6 IAID . . . . . . . . . . . : 235430502\n   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-1C-AE-A2-19-F0-79-59-64-74-71\n   DNS 服务器  . . . . . . . . . . . : 192.168.10.12\n                                       192.168.15.3\n   TCPIP 上的 NetBIOS  . . . . . . . : 已启用\n\n隧道适配器 isatap.xxx(lol):\n\n   媒体状态  . . . . . . . . . . . . : 媒体已断开\n   连接特定的 DNS 后缀 . . . . . . . : xxx(lol)\n   描述. . . . . . . . . . . . . . . : Microsoft ISATAP Adapter\n   物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0\n   DHCP 已启用 . . . . . . . . . . . : 否\n   自动配置已启用. . . . . . . . . . : 是\n\n隧道适配器 Teredo Tunneling Pseudo-Interface:\n\n   媒体状态  . . . . . . . . . . . . : 媒体已断开\n   连接特定的 DNS 后缀 . . . . . . . : \n   描述. . . . . . . . . . . . . . . : Teredo Tunneling Pseudo-Interface\n   物理地址. . . . . . . . . . . . . : 00-00-00-00-00-00-00-E0\n   DHCP 已启用 . . . . . . . . . . . : 否\n   自动配置已启用. . . . . . . . . . : 是\n\n```\n\n好了, 最后验证一下刚开始谈到的那个数据库的问题. 当我分别使用`192.168.10.20`和`localhost`通过SQLyog连接时, 果真看到的是俩个不一样的数据库....\n\n然后我又写了一个测试程序\n```java\npublic class TestLocalhost {\n\n    public static void main(String[] args) throws IOException, InterruptedException {\n        ServerSocket serverSocket = new ServerSocket();\n        serverSocket.bind(new InetSocketAddress(\"192.168.10.220\", 9051));\n//        serverSocket.bind(new InetSocketAddress(\"localhost\", 9051));\n        serverSocket.accept();\n        System.out.println(\"connected!!!\");\n    }\n}\n```\n然后使用http请求测试\n* `http://localhost:9051/` 不可连接成功\n* `http://192.168.10.220:9051/`  连接成功\n说明`192.168.10.20`和`localhost`本身是不能互通的.\n\n接下来我改进一下这个程序\n```java\npublic class TestLocalhost {\n\n    public static void main(String[] args) throws InterruptedException {\n        SocketAcceptor socketAcceptor1 = new SocketAcceptor(\"192.168.10.220\");\n        SocketAcceptor socketAcceptor2 = new SocketAcceptor(\"localhost\");\n        socketAcceptor1.start();\n        socketAcceptor2.start();\n\n        TimeUnit.SECONDS.sleep(100);\n    }\n\n    public static class SocketAcceptor extends Thread {\n\n        public final String ip;\n        public SocketAcceptor(String ip) {\n            this.ip = ip;\n        }\n\n        @Override\n        public void run() {\n            try {\n                ServerSocket serverSocket1 = new ServerSocket();\n                serverSocket1.bind(new InetSocketAddress(ip, 9051));\n                serverSocket1.accept();\n                System.out.println(ip + \" accepted\");\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n然后继续使用上面俩个地址进行访问, 发现最后都进行了输出\n```xml\n192.168.10.220 accepted\nlocalhost accepted\n```\n这个例子也说明了不同的网卡可以绑定不同的端口, 即使是虚拟网卡也有一套自己端口","slug":"网络/IP地址","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5d00d7vjs67l8d8r7r"},{"date":"2015-11-01T16:00:00.000Z","title":"OSI参考模型","_content":"\nOSI参考模型:\n* 应用层: 为应用程序提供服务,并规定应用程序中通信相关的细节.\n* 表示层: 将应用处理的信息转换为适合网络传输的格式或者将下一层的数据转换为上层能够处理的格式\n* 会话层: 负责建立和断开通信连接,以及数据的分割等数据传输相关的管理\n* 传输层: 管理俩个节点的数据传输\n* 网络层: 负责寻址和路由选择.\n* 数据链路层: 负责物理层面上互联的,节点之间的通信传输.\n* 物理层: 负责0,1比特流与电压的高低,光的闪灭之间的互换\n\n> 表示层: 表示层担当着\"统一的网络数据格式\"与应用特定数据格式转换的功能. 实际上也就是将应用层的数据按照指定的格式进行编码,然后在数据首部添加首部信息.\n\n\n\n\n\n\n\n\n\n","source":"_posts/网络/OSI参考模型.md","raw":"category: 网络\ndate: 2015-11-02\ntitle: OSI参考模型\n---\n\nOSI参考模型:\n* 应用层: 为应用程序提供服务,并规定应用程序中通信相关的细节.\n* 表示层: 将应用处理的信息转换为适合网络传输的格式或者将下一层的数据转换为上层能够处理的格式\n* 会话层: 负责建立和断开通信连接,以及数据的分割等数据传输相关的管理\n* 传输层: 管理俩个节点的数据传输\n* 网络层: 负责寻址和路由选择.\n* 数据链路层: 负责物理层面上互联的,节点之间的通信传输.\n* 物理层: 负责0,1比特流与电压的高低,光的闪灭之间的互换\n\n> 表示层: 表示层担当着\"统一的网络数据格式\"与应用特定数据格式转换的功能. 实际上也就是将应用层的数据按照指定的格式进行编码,然后在数据首部添加首部信息.\n\n\n\n\n\n\n\n\n\n","slug":"网络/OSI参考模型","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5e00davjs66meurn51"},{"date":"2015-09-07T16:00:00.000Z","title":"HTTP","_content":"# HTTP报文\n用于HTTP协议交互的信息称为HTTP报文. HTTP报文一般被空行(`CR+LF`)分割成报文首部和报文主体俩部分.\n\n## 请求报文\n* 请求行\t\n* 请求首部字段\n* 通用首部字段\n* 实体首部字段\n\n\n## 响应报文\n* 响应行\t\n* 响应首部字段\n* 通用首部字段\n* 实体首部字段\n\n## HTTP状态码\n\n### 2XX\n\n* 200 ok\n* 204 No Content. \n* ","source":"_posts/网络/http.md","raw":"category: 网络\ndate: 2015-09-08\ntitle: HTTP\n---\n# HTTP报文\n用于HTTP协议交互的信息称为HTTP报文. HTTP报文一般被空行(`CR+LF`)分割成报文首部和报文主体俩部分.\n\n## 请求报文\n* 请求行\t\n* 请求首部字段\n* 通用首部字段\n* 实体首部字段\n\n\n## 响应报文\n* 响应行\t\n* 响应首部字段\n* 通用首部字段\n* 实体首部字段\n\n## HTTP状态码\n\n### 2XX\n\n* 200 ok\n* 204 No Content. \n* ","slug":"网络/http","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5f00dbvjs60wnxjvri"},{"date":"2015-11-07T16:00:00.000Z","title":"会话层","_content":"\n这一层负责连接如何建立,如何断开,以及保持多长时间.但是该层并不具有实际的传输数据的功能.\n\n它会在表示层前边添加会话层首部.\n\n例如,主机A向主机B发送5条消息,那么会话层就决定着是每个消息都进行一次连接建立断开,还是五条消息在同一个连接中建立断开.","source":"_posts/网络/会话层.md","raw":"category: 网络\ndate: 2015-11-08\ntitle: 会话层\n---\n\n这一层负责连接如何建立,如何断开,以及保持多长时间.但是该层并不具有实际的传输数据的功能.\n\n它会在表示层前边添加会话层首部.\n\n例如,主机A向主机B发送5条消息,那么会话层就决定着是每个消息都进行一次连接建立断开,还是五条消息在同一个连接中建立断开.","slug":"网络/会话层","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5i00devjs6li4bnzsi"},{"date":"2015-11-07T16:00:00.000Z","title":"传输层","_content":"\n在俩个主机之间创建逻辑上的通信连接.同时还要确保所传输的数据是可达的,如果不可达在负责重发.\n\n包含的协议:\n* TCP\n* UDP\n* SCTP\n* DCCP\nTCP模块负责建立,发送数据以及断开连接. 当传输层接收到应用层传递过来的数据,由TCP模块处理时,TCP模块会在应用层数据前部添加一个TCP首部,其包含:\n* 源端口号\n* 目标端口号\n* 序号(识别包中哪些是应用层数据)\n* 校验和(判断数据是否被破坏)\n\n## 连接管理\n\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/net/TCP_STATE2.jpg)\n## 三次握手\n* 第一次握手：建立连接时，客户端首先向服务端发送一个 SYN 包和一个随机序列号 A，客户端进入SYN_SENT状态，等待服务器确认；\n* 第二次握手：服务端收到后会回复客户端一个 SYN-ACK 包以及一个确认号（用于确认收到 SYN）A+1，同时再发送一个随机序列号 B，此时服务器进入SYN_RECV状态；\n* 第三次握手：客户端收到后会发送一个 ACK 包以及确认号（用于确认收到 SYN-ACK）B+1 和序列号 A+1 给服务端，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。\n\n### 四次挥手\n1. 客户端执行`CLOSE`主动关闭,向服务器发送`FIN`数据报. 客户端进入`FIN WAIT1`状态\n2. 服务器收到客户端发送过来的`FIN`数据包执行被动关闭,同时向客户端响应`ACK`数据包,服务器进入`CLOSE WAIT`状态. 客户端收到服务端发送过来的`ACK`包后, 客户端进入`FIN WAIT2`状态.\n3. 紧接着服务器再发送一个`ACK`包,服务器进入`LAST ACK`状态. 服务器端就关闭了.\n4. 客户端收到`ACK`包后进入`TIME_WAIT`状态. 当客户端超时后也就执行关闭了.\n\n\n\nTCP端口状态：\n1. LISTENING状态: FTP服务启动后首先处于侦听（LISTENING）状态。\n2. ESTABLISHED状态: ESTABLISHED的意思是建立连接。表示两台机器正在通信。\n3. CLOSE_WAIT: 对方主动关闭连接或者网络异常导致连接中断，这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭\n4. TIME_WAIT: 我方主动调用close()断开连接，收到对方确认后状态变为TIME_WAIT。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放，所以作为服务器，在可能的情况下，尽量不要主动断开连接，以减少TIME_WAIT状态造成的资源浪费。目前有一种避免TIME_WAIT资源浪费的方法，就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的，在某些情况下这个操作可能会带来错误。\n5. SYN_SENT状态:SYN_SENT状态表示请求连接，当你要访问其它的计算机的服务时首先要发个同步信号给该端口，此时状态为SYN_SENT，如果连接成功了就变为ESTABLISHED，此时SYN_SENT状态非常短暂。但如果发现SYN_SENT非常多且在向不同的机器发出，那你的机器可能中了冲击波或震荡波之类的病毒了。这类病毒为了感染别的计算机，它就要扫描别的计算机，在扫描的过程中对每个要扫描的计算机都要发出了同步请求，这也是出现许多SYN_SENT的原因。\n\n\n","source":"_posts/网络/传输层.md","raw":"category: 网络\ndate: 2015-11-08\ntitle: 传输层\n---\n\n在俩个主机之间创建逻辑上的通信连接.同时还要确保所传输的数据是可达的,如果不可达在负责重发.\n\n包含的协议:\n* TCP\n* UDP\n* SCTP\n* DCCP\nTCP模块负责建立,发送数据以及断开连接. 当传输层接收到应用层传递过来的数据,由TCP模块处理时,TCP模块会在应用层数据前部添加一个TCP首部,其包含:\n* 源端口号\n* 目标端口号\n* 序号(识别包中哪些是应用层数据)\n* 校验和(判断数据是否被破坏)\n\n## 连接管理\n\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/net/TCP_STATE2.jpg)\n## 三次握手\n* 第一次握手：建立连接时，客户端首先向服务端发送一个 SYN 包和一个随机序列号 A，客户端进入SYN_SENT状态，等待服务器确认；\n* 第二次握手：服务端收到后会回复客户端一个 SYN-ACK 包以及一个确认号（用于确认收到 SYN）A+1，同时再发送一个随机序列号 B，此时服务器进入SYN_RECV状态；\n* 第三次握手：客户端收到后会发送一个 ACK 包以及确认号（用于确认收到 SYN-ACK）B+1 和序列号 A+1 给服务端，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。\n\n### 四次挥手\n1. 客户端执行`CLOSE`主动关闭,向服务器发送`FIN`数据报. 客户端进入`FIN WAIT1`状态\n2. 服务器收到客户端发送过来的`FIN`数据包执行被动关闭,同时向客户端响应`ACK`数据包,服务器进入`CLOSE WAIT`状态. 客户端收到服务端发送过来的`ACK`包后, 客户端进入`FIN WAIT2`状态.\n3. 紧接着服务器再发送一个`ACK`包,服务器进入`LAST ACK`状态. 服务器端就关闭了.\n4. 客户端收到`ACK`包后进入`TIME_WAIT`状态. 当客户端超时后也就执行关闭了.\n\n\n\nTCP端口状态：\n1. LISTENING状态: FTP服务启动后首先处于侦听（LISTENING）状态。\n2. ESTABLISHED状态: ESTABLISHED的意思是建立连接。表示两台机器正在通信。\n3. CLOSE_WAIT: 对方主动关闭连接或者网络异常导致连接中断，这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭\n4. TIME_WAIT: 我方主动调用close()断开连接，收到对方确认后状态变为TIME_WAIT。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放，所以作为服务器，在可能的情况下，尽量不要主动断开连接，以减少TIME_WAIT状态造成的资源浪费。目前有一种避免TIME_WAIT资源浪费的方法，就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的，在某些情况下这个操作可能会带来错误。\n5. SYN_SENT状态:SYN_SENT状态表示请求连接，当你要访问其它的计算机的服务时首先要发个同步信号给该端口，此时状态为SYN_SENT，如果连接成功了就变为ESTABLISHED，此时SYN_SENT状态非常短暂。但如果发现SYN_SENT非常多且在向不同的机器发出，那你的机器可能中了冲击波或震荡波之类的病毒了。这类病毒为了感染别的计算机，它就要扫描别的计算机，在扫描的过程中对每个要扫描的计算机都要发出了同步请求，这也是出现许多SYN_SENT的原因。\n\n\n","slug":"网络/传输层","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5k00dfvjs66xdw5kee"},{"date":"2015-11-07T16:00:00.000Z","title":"数据链路层","_content":"\n物理层负责将实际设备过程中的电压的高低,光的闪灭,电波的强弱新号等与二进制0,1进行转换. 而数据链路层则负责将0,1数据集合成帧块后进行传输.\n\n* 数据链路段： 数据链路段是指一个被分割的网络.\n\n网络拓扑： 网络的连接与构成的形态被称为网络拓扑，有以下分类\n* [总线型]()\n* [环形]()\n* [星形]()\n* [混合型]()\n\n### MAC地址\nMAC地址用于识别数据链路中的互联的节点. 不论哪种数据链路的网络(以太网,FDDI,ATM,无线LAN),他们彼此的MAC地址都是唯一的.MAC地址总长46位,一般用16进制表示.\n* 第一位:单播地址(0)/多播地址(1)\n* 第2位: 全局地址(0)/本地地址(1)\n* 第3-24位:由IEEE管理并保证各厂家不重复\n* 第25-48位:由厂商管理并保证产品之间不重复\n\n### 通信介质\n从通信介质的使用方法来看,网络可以分为共享型介质和非共享型介质:\n\n共享介质型网络：是指多个设备共享一个通信介质的网络.在这种方式下多个设备使用同一个载波信道进行发送和接受,基本上采用半双工通信.\n* 半双工: 在数据链路上同时只发送或者只接受的通信方式\n* 全双工: 在数据链路上同时即可以发送也可以接受数据的通信方式\n\n共享介质型网络有俩种访问控制方式:\n* 争用方式:\n* 令牌传递方式:\n\n非共享介质:\n\n### 分组交换\n目前网络通信方式大致分为俩种：\n* 电路交换：这种交换技术主要应用于过去的电话网. 在这种交换中,交换机主要负责数据的中转处理. 计算机之间的连接是通过交换机连接上的,当俩个计算机通信之后,他们俩者就一直占用着这条线路\n* 分组交换：由于电路交换, 俩台计算机会一直占用某条线路,当有新的计算机连接到这条线路上想要通信时,就只能等当前通信的计算机断开连接,于是噩梦就这样产生了.\n\n在这种情况下,人们提出了分组交换. 即将数据进行分组成多个数据包,每个分组首部已经写入了发送端和接收端地址,然后当分组交换机(路由器)接收到分组数据之后,会将其缓存到自己的缓冲区中,然后再按照先进先出的规则将数据转发出去. 这样在同一条线路上也可以为多个计算机服务.\n\n![分组交换](https://raw.githubusercontent.com/ming15/blog-website/images/net/%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2.jpg)\n\n\n### VLAN\n\n\n\n\n### 网桥\n网桥交换机在数据链路层上连接俩个网络设备. 它使用物理地址(MAC地址)进行处理.\n\n网桥能够识别数据链路中的数据帧,并将其缓存起来重新生成新的数据帧发送给另一个网段. 得益于网桥的缓存功能,使得网桥能够连接传输速率完全不同的数据链路,并且不限制连接网段的个数.\n\n\n##  物理层\n\n### 中继器\n由电缆传过来的电信号或者光信号经由中继器的波形调整和放大再传给另一个电缆\n\n一般中继器俩段连接的是相同的媒介,但有的中继器也可以连接不同的媒介. 例如同轴电缆与光缆之间的信号调整,但是即使在这种情况下,TA也只是单纯的负责信号在0和1比特流之间的替换,并不判断数据是否有错误. 同时它只负责将电信号转换为光信号,因此不能在不同的媒介之间进行转发.\n","source":"_posts/网络/数据链路层.md","raw":"category: 网络\ndate: 2015-11-08\ntitle: 数据链路层\n---\n\n物理层负责将实际设备过程中的电压的高低,光的闪灭,电波的强弱新号等与二进制0,1进行转换. 而数据链路层则负责将0,1数据集合成帧块后进行传输.\n\n* 数据链路段： 数据链路段是指一个被分割的网络.\n\n网络拓扑： 网络的连接与构成的形态被称为网络拓扑，有以下分类\n* [总线型]()\n* [环形]()\n* [星形]()\n* [混合型]()\n\n### MAC地址\nMAC地址用于识别数据链路中的互联的节点. 不论哪种数据链路的网络(以太网,FDDI,ATM,无线LAN),他们彼此的MAC地址都是唯一的.MAC地址总长46位,一般用16进制表示.\n* 第一位:单播地址(0)/多播地址(1)\n* 第2位: 全局地址(0)/本地地址(1)\n* 第3-24位:由IEEE管理并保证各厂家不重复\n* 第25-48位:由厂商管理并保证产品之间不重复\n\n### 通信介质\n从通信介质的使用方法来看,网络可以分为共享型介质和非共享型介质:\n\n共享介质型网络：是指多个设备共享一个通信介质的网络.在这种方式下多个设备使用同一个载波信道进行发送和接受,基本上采用半双工通信.\n* 半双工: 在数据链路上同时只发送或者只接受的通信方式\n* 全双工: 在数据链路上同时即可以发送也可以接受数据的通信方式\n\n共享介质型网络有俩种访问控制方式:\n* 争用方式:\n* 令牌传递方式:\n\n非共享介质:\n\n### 分组交换\n目前网络通信方式大致分为俩种：\n* 电路交换：这种交换技术主要应用于过去的电话网. 在这种交换中,交换机主要负责数据的中转处理. 计算机之间的连接是通过交换机连接上的,当俩个计算机通信之后,他们俩者就一直占用着这条线路\n* 分组交换：由于电路交换, 俩台计算机会一直占用某条线路,当有新的计算机连接到这条线路上想要通信时,就只能等当前通信的计算机断开连接,于是噩梦就这样产生了.\n\n在这种情况下,人们提出了分组交换. 即将数据进行分组成多个数据包,每个分组首部已经写入了发送端和接收端地址,然后当分组交换机(路由器)接收到分组数据之后,会将其缓存到自己的缓冲区中,然后再按照先进先出的规则将数据转发出去. 这样在同一条线路上也可以为多个计算机服务.\n\n![分组交换](https://raw.githubusercontent.com/ming15/blog-website/images/net/%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2.jpg)\n\n\n### VLAN\n\n\n\n\n### 网桥\n网桥交换机在数据链路层上连接俩个网络设备. 它使用物理地址(MAC地址)进行处理.\n\n网桥能够识别数据链路中的数据帧,并将其缓存起来重新生成新的数据帧发送给另一个网段. 得益于网桥的缓存功能,使得网桥能够连接传输速率完全不同的数据链路,并且不限制连接网段的个数.\n\n\n##  物理层\n\n### 中继器\n由电缆传过来的电信号或者光信号经由中继器的波形调整和放大再传给另一个电缆\n\n一般中继器俩段连接的是相同的媒介,但有的中继器也可以连接不同的媒介. 例如同轴电缆与光缆之间的信号调整,但是即使在这种情况下,TA也只是单纯的负责信号在0和1比特流之间的替换,并不判断数据是否有错误. 同时它只负责将电信号转换为光信号,因此不能在不同的媒介之间进行转发.\n","slug":"网络/数据链路层","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5m00divjs6mzy9o1lm"},{"date":"2015-11-07T16:00:00.000Z","title":"网络层","_content":"\n网络层通过地址将数据从众多链路中传送到最终地址上.它实现的是终端节点之间的通信. 相比于数据链路层的只能在同一种数据链路中进行数据传输,网络层可以跨数据链路进行数据传输(这一点是通过下面介绍的路由器实现的).说的更加通俗一点是:数据链路层只是负责俩个设备之间的通信,但是如果想要跨多个设备通信的话,就只能借助网络层了.\n\n> 至于为什么需要网络层呢?是这样的,数据链路只能在同一种介质中进行通信,如果无线想要和以太网进行数据传输的话,单靠数据链路层是没办法完成这个需求的,此时就需要借助网络层的路由器了.\n\n网络层相关协议:\n* ARP\n* IP\n* ICMP\n\n### IP\nIP的作用分作三部分:\n* IP寻址\n* 路由\n* IP分包,组包\n我们知道MAC地址是用来在同一链路中识别不同计算机的,那么IP地址就是在连接到网络中的所有主机相互识别用的. 因此在连接到网络的所有的主机和路由器必须都设置上自己的IP地址.我们必须时刻记住IP地址只在网络层有效,网络层只是将主机的IP地址放到了数据包的IP首部位置,IP包在网桥或者中继器或者数据链路层是不会被使用到的,在硬件部分只是将IP包转化成一个个的0,1的数据流,在链路层只是对数据连绝真的数据部分进行转发.\n\n由于不同的数据链路的MTU值(Maximum Transmission Unit,最大传输单位)是不一样的,比如以太网的MTU为1500bytes,而FDDI则是4352Bytes,ATM则为9180bytes.IP包的长度有可能大于或者小于这些长度,于是就出现了IP包的分片处理. 网络层会将IP包分成一个个相等的较小的包,由链路层发送出去,到了终端网络层再组装起来.\n\n当IP包生成之后,会根据接收端IP从路由表里边查找接受该数据包的路由或者主机. 然后IP包会被发送给连接路由器或者NIC的驱动程序,实现真正的数据传输.\n\n网络层接受到传输层发送过来的数据(如:TCP首部+应用层数据),如果由UP模块处理,IP模块就会在数据首部再添加IP首部:\n* 接收端IP\n* 发送端IP\n* 判断传输层数据是TCP还是UDP数据的信息\n \n#### IP地址\nIPV4地址由32位正整数(0/1)表示,每8位一组,分成4组,每一组用`.`分隔.每一组的最大值是2的8次方也就是255,最小值是0. \n\n理论上2的32次方,大概是43亿,那么每个NIC都配置一个IP的话(NIC最少可以配置一个IP)那么就会有43亿的计算机可以连接到网络上(但实际上,能连接到网络上的计算机远远达不到这个数量).\n\n实际上IP地址是由网络和主机俩部分标志组成的.\n\n### 路由器\n路由器在网络层上连接网络,并对分组报文进行转发. 路由器使用IP地址进行进行处理. 路由器可以连接不同的数据链路,例如连接以太网和一个FDDI.\n\n### ARP\n当我们在写网络程序的时候,无论是HTTP协议还是TCP协议,我们只需要知道对方的IP地址就可以向其发送消息,但是在数据链路层在实际通信时,必须知道对方的MAC地址.\n\n我们就是通过ARP协议来通过IP地址找到对方的MAC地址的. 当主机A要向主机B发送一个消息时,主机A会尝试从自己的ARP表中查找目标IP的MAC地址. 如果找到了目标MAC地址,就直接向该MAC地址发送消息. 如果找不到MAC地址,主机A就向链路中发送ARP请求,链路中的所有主机和路由器都会对其进行解析. 当主机B与主机A在同一链路中,此时主机B会发送主机A发出的ARP请求与自己的IP地址一致,主机B就会回应一个ARP响应,响应中包含着主机B的MAC地址. 主机A接收到主机B的ARP响应后,会将主机B的MAC地址和IP地址的对应关系,缓存到自己的ARP表中.\n> ARP是为了提高性能而设计的. 如果每次IP通信都需要进行一次ARP请求,会造成非常大的网络流量\n\n上面我们只是阐述了,在同一链路中找到了目标主机,但是如果找不到呢?\n\n> 其实还有一种RARP协议,这个协议是将MAC地址定位IP地址的协议,与ARP协议恰恰相反. 平常我们在电脑里设置IP地址时,可以通过设置为自动获取IP地址(通过DHCP实现),但是使用嵌入式设备,我们可能就没有办法通过DHCP来获取IP地址了,那么,我们就需要架设一台RARP服务器,从而在这个设备上注册设备的MAC地址及其IP地址.\n\n## NAT\n网络地址转换(NAT,Network Address Translation)是用于在本地网络中使用私有地址,在连接互联网时转而使用全局IP地址的技术.NAT技术的踢出是为了解决IPV4地址日益枯竭的问题,即可以使用网关来完成NAT也可以使用NAT路由器来完成.\n\n首先我们来说说NAT路由器,NAT路由器内部有一张自动生成的用来转换地址的表. 例如在TCP情况下,建立TCP连接首次握手时的SYN包一旦发出,就会在路由器内部生成这个表. 随后收到关闭连接发出FIN包的确认应答时又从表中将其删除.\n\n> 说到这里,我们要谈一下,IPV4和IPV6之间通信的问题. IPV6的主机是没办法直接与IPV4的主机进行通信的,我們首先要使用NAT-PT技術將IPV6首部替換為IPV4首部,這樣他們二者才能進行通信. NAT-PT技術有很多實現方式,例如結合DNS和IP首部替換的DNS-ALG技術.\n\nNAT有俩种实现方式：\n* NAT: 将内网的IP地址替换为网关的IP地址，但是将内网的端口与网关端口进行绑定,也就是公网见到的端口是内网的端口,但是见到的IP是网关的地址.\n* NAPT：\t使用网关的IP，但端口会选择一个和临时会话对应的临时端口. 这种公网见到的IP地址和端口都是网关设定的.\n\n由于内网可能会跟公网建立俩个连接都采用不同的端口,因此NAPT针对这种情况又分为了俩种类型(需要说明的是不管是那种类型只要建立一个连接就会在网关中建立一个session)\n* Symmetric NAT型 (对称型): 来自同一个内网的ip俩个seesion会在网关上分配到俩个不同的端口.\n* Cone NAT型（圆锥型）:来自同一个内网的ip俩个seesion会在网关上分配同一个端口\n\nCone NAT又分了3种类型：\n* Full Cone NAT（完全圆锥型）：这种NAT，网关会根据session信息将公网发送过来的数据报都都发送到某个内网主机上.\n* Address Restricted Cone NAT （地址限制圆锥型）：这种NAT上的内网不会主动接受陌生公网主机的数据报,只有内网向公网主机发送过请求,才会接受那个公网的数据报.\n* Port Restricted Cone NAT（端口限制圆锥型）：和第二种NAT类似同样是不会主动接受陌生公网主机的数据报,但是这种NAT更加严苛的是还有端口限制,也就是说它只会接受向某个公网端口发送给请求的数据报.\n\nLinux的NAT是对称NAT，而不是锥形NAT. 且完全依赖ip_conntrack.\n\nNAT還有很多潛在的問題:\n1. 無法從NAT的外部向NAT內部直接建立連接.\n2. 轉換表的生成和轉換操作都有一定的开销.\n3. 通信过程中一旦NAT遇到异常需要重新启动时,所有的TCP连接都将被重置\n4. 即使准备俩台NAT做容灾备份,TCP连接还是会被断开.\n\n## 路由\n我们知道网络其实就是由一个个路由组成的. IP包就是在这一个个的路由间传输,每当路过一个路由的时候我们就说IP数据包经过了一跳. 每当IP包完成一跳时,当前路由器就会指定下一个路由器或者主机.\n> 一跳(Hop)的范围就是从一个主机或者一个路由器的网卡到另一个主机或者路由器网卡之间的区间.\n\n每个主机中都有一个路由控制表,这个表记录着IP数据包在下一步发给哪个路由器.IP包根据这个路由器在各个链路上进行传输.\n","source":"_posts/网络/网络层.md","raw":"category: 网络\ndate: 2015-11-08\ntitle: 网络层\n---\n\n网络层通过地址将数据从众多链路中传送到最终地址上.它实现的是终端节点之间的通信. 相比于数据链路层的只能在同一种数据链路中进行数据传输,网络层可以跨数据链路进行数据传输(这一点是通过下面介绍的路由器实现的).说的更加通俗一点是:数据链路层只是负责俩个设备之间的通信,但是如果想要跨多个设备通信的话,就只能借助网络层了.\n\n> 至于为什么需要网络层呢?是这样的,数据链路只能在同一种介质中进行通信,如果无线想要和以太网进行数据传输的话,单靠数据链路层是没办法完成这个需求的,此时就需要借助网络层的路由器了.\n\n网络层相关协议:\n* ARP\n* IP\n* ICMP\n\n### IP\nIP的作用分作三部分:\n* IP寻址\n* 路由\n* IP分包,组包\n我们知道MAC地址是用来在同一链路中识别不同计算机的,那么IP地址就是在连接到网络中的所有主机相互识别用的. 因此在连接到网络的所有的主机和路由器必须都设置上自己的IP地址.我们必须时刻记住IP地址只在网络层有效,网络层只是将主机的IP地址放到了数据包的IP首部位置,IP包在网桥或者中继器或者数据链路层是不会被使用到的,在硬件部分只是将IP包转化成一个个的0,1的数据流,在链路层只是对数据连绝真的数据部分进行转发.\n\n由于不同的数据链路的MTU值(Maximum Transmission Unit,最大传输单位)是不一样的,比如以太网的MTU为1500bytes,而FDDI则是4352Bytes,ATM则为9180bytes.IP包的长度有可能大于或者小于这些长度,于是就出现了IP包的分片处理. 网络层会将IP包分成一个个相等的较小的包,由链路层发送出去,到了终端网络层再组装起来.\n\n当IP包生成之后,会根据接收端IP从路由表里边查找接受该数据包的路由或者主机. 然后IP包会被发送给连接路由器或者NIC的驱动程序,实现真正的数据传输.\n\n网络层接受到传输层发送过来的数据(如:TCP首部+应用层数据),如果由UP模块处理,IP模块就会在数据首部再添加IP首部:\n* 接收端IP\n* 发送端IP\n* 判断传输层数据是TCP还是UDP数据的信息\n \n#### IP地址\nIPV4地址由32位正整数(0/1)表示,每8位一组,分成4组,每一组用`.`分隔.每一组的最大值是2的8次方也就是255,最小值是0. \n\n理论上2的32次方,大概是43亿,那么每个NIC都配置一个IP的话(NIC最少可以配置一个IP)那么就会有43亿的计算机可以连接到网络上(但实际上,能连接到网络上的计算机远远达不到这个数量).\n\n实际上IP地址是由网络和主机俩部分标志组成的.\n\n### 路由器\n路由器在网络层上连接网络,并对分组报文进行转发. 路由器使用IP地址进行进行处理. 路由器可以连接不同的数据链路,例如连接以太网和一个FDDI.\n\n### ARP\n当我们在写网络程序的时候,无论是HTTP协议还是TCP协议,我们只需要知道对方的IP地址就可以向其发送消息,但是在数据链路层在实际通信时,必须知道对方的MAC地址.\n\n我们就是通过ARP协议来通过IP地址找到对方的MAC地址的. 当主机A要向主机B发送一个消息时,主机A会尝试从自己的ARP表中查找目标IP的MAC地址. 如果找到了目标MAC地址,就直接向该MAC地址发送消息. 如果找不到MAC地址,主机A就向链路中发送ARP请求,链路中的所有主机和路由器都会对其进行解析. 当主机B与主机A在同一链路中,此时主机B会发送主机A发出的ARP请求与自己的IP地址一致,主机B就会回应一个ARP响应,响应中包含着主机B的MAC地址. 主机A接收到主机B的ARP响应后,会将主机B的MAC地址和IP地址的对应关系,缓存到自己的ARP表中.\n> ARP是为了提高性能而设计的. 如果每次IP通信都需要进行一次ARP请求,会造成非常大的网络流量\n\n上面我们只是阐述了,在同一链路中找到了目标主机,但是如果找不到呢?\n\n> 其实还有一种RARP协议,这个协议是将MAC地址定位IP地址的协议,与ARP协议恰恰相反. 平常我们在电脑里设置IP地址时,可以通过设置为自动获取IP地址(通过DHCP实现),但是使用嵌入式设备,我们可能就没有办法通过DHCP来获取IP地址了,那么,我们就需要架设一台RARP服务器,从而在这个设备上注册设备的MAC地址及其IP地址.\n\n## NAT\n网络地址转换(NAT,Network Address Translation)是用于在本地网络中使用私有地址,在连接互联网时转而使用全局IP地址的技术.NAT技术的踢出是为了解决IPV4地址日益枯竭的问题,即可以使用网关来完成NAT也可以使用NAT路由器来完成.\n\n首先我们来说说NAT路由器,NAT路由器内部有一张自动生成的用来转换地址的表. 例如在TCP情况下,建立TCP连接首次握手时的SYN包一旦发出,就会在路由器内部生成这个表. 随后收到关闭连接发出FIN包的确认应答时又从表中将其删除.\n\n> 说到这里,我们要谈一下,IPV4和IPV6之间通信的问题. IPV6的主机是没办法直接与IPV4的主机进行通信的,我們首先要使用NAT-PT技術將IPV6首部替換為IPV4首部,這樣他們二者才能進行通信. NAT-PT技術有很多實現方式,例如結合DNS和IP首部替換的DNS-ALG技術.\n\nNAT有俩种实现方式：\n* NAT: 将内网的IP地址替换为网关的IP地址，但是将内网的端口与网关端口进行绑定,也就是公网见到的端口是内网的端口,但是见到的IP是网关的地址.\n* NAPT：\t使用网关的IP，但端口会选择一个和临时会话对应的临时端口. 这种公网见到的IP地址和端口都是网关设定的.\n\n由于内网可能会跟公网建立俩个连接都采用不同的端口,因此NAPT针对这种情况又分为了俩种类型(需要说明的是不管是那种类型只要建立一个连接就会在网关中建立一个session)\n* Symmetric NAT型 (对称型): 来自同一个内网的ip俩个seesion会在网关上分配到俩个不同的端口.\n* Cone NAT型（圆锥型）:来自同一个内网的ip俩个seesion会在网关上分配同一个端口\n\nCone NAT又分了3种类型：\n* Full Cone NAT（完全圆锥型）：这种NAT，网关会根据session信息将公网发送过来的数据报都都发送到某个内网主机上.\n* Address Restricted Cone NAT （地址限制圆锥型）：这种NAT上的内网不会主动接受陌生公网主机的数据报,只有内网向公网主机发送过请求,才会接受那个公网的数据报.\n* Port Restricted Cone NAT（端口限制圆锥型）：和第二种NAT类似同样是不会主动接受陌生公网主机的数据报,但是这种NAT更加严苛的是还有端口限制,也就是说它只会接受向某个公网端口发送给请求的数据报.\n\nLinux的NAT是对称NAT，而不是锥形NAT. 且完全依赖ip_conntrack.\n\nNAT還有很多潛在的問題:\n1. 無法從NAT的外部向NAT內部直接建立連接.\n2. 轉換表的生成和轉換操作都有一定的开销.\n3. 通信过程中一旦NAT遇到异常需要重新启动时,所有的TCP连接都将被重置\n4. 即使准备俩台NAT做容灾备份,TCP连接还是会被断开.\n\n## 路由\n我们知道网络其实就是由一个个路由组成的. IP包就是在这一个个的路由间传输,每当路过一个路由的时候我们就说IP数据包经过了一跳. 每当IP包完成一跳时,当前路由器就会指定下一个路由器或者主机.\n> 一跳(Hop)的范围就是从一个主机或者一个路由器的网卡到另一个主机或者路由器网卡之间的区间.\n\n每个主机中都有一个路由控制表,这个表记录着IP数据包在下一步发给哪个路由器.IP包根据这个路由器在各个链路上进行传输.\n","slug":"网络/网络层","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii5q00djvjs6krrf2nkb"},{"date":"2014-11-27T16:00:00.000Z","title":"JVM 日志输出","_content":"本文主要列举了JVM中常用的日志输出参数\n\n## GC 输出\n###  PrintGC\n在jvm选项上添加上这个参数,只要遇上GC就会输出GC日志. 我们写一个测试程序\n```java\npublic class TestPrintGCDetails {\n    public static void main(String[] args) {\n        for (int i = 0; i < 3; i++) {\n            byte[] bytes = new byte[1024 * 924 * 7];\n            System.out.println(\"Allocate \" + i);\n        }\n    }\n}\n```\n我们采用虚拟机参数`-XX:+PrintGC -Xmx10M -Xms10M`看一下结果\n```xml\nAllocate 0\n[GC (Allocation Failure)  8003K->7116K(9728K), 0.0013420 secs]\n[Full GC (Ergonomics)  7116K->624K(9728K), 0.0063270 secs]\nAllocate 1\n[Full GC (Ergonomics)  7191K->592K(9728K), 0.0068230 secs]\nAllocate 2\n```\n我们看到一共进行里3次GC(1次新生代GC, 俩次Full GC)\n1. GC前, 堆使用内存为8003K, GC后堆内存使用为7116K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0013420秒\n2. GC前, 堆使用内存为7116K, GC后堆内存使用为624K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0063270秒\n3. GC前, 堆使用内存为7191K, GC后堆内存使用为592K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0068230秒\n\n###  PrintGCDetails\n这个参数相比于PrintGC,会输出更加详细的信息. 同样使用上面的测试程序, 然后使用虚拟机参数`-XX:+PrintGCDetails -Xmx10M -Xms10M`, 然后看一下输出\n```xml\nAllocate 0\n[GC (Allocation Failure) [PSYoungGen: 1535K->512K(2560K)] 8003K->7136K(9728K), 0.0020620 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\n[Full GC (Ergonomics) [PSYoungGen: 512K->0K(2560K)] [ParOldGen: 6624K->623K(7168K)] 7136K->623K(9728K), [Metaspace: 3089K->3089K(1056768K)], 0.0067020 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAllocate 1\n[Full GC (Ergonomics) [PSYoungGen: 77K->0K(2560K)] [ParOldGen: 7091K->592K(7168K)] 7168K->592K(9728K), [Metaspace: 3092K->3092K(1056768K)], 0.0070690 secs] [Times: user=0.02 sys=0.00, real=0.00 secs]\nAllocate 2\nHeap\n PSYoungGen      total 2560K, used 78K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 3% used [0x00000007bfd00000,0x00000007bfd138e0,0x00000007bff00000)\n  from space 512K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007bff80000)\n  to   space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n ParOldGen       total 7168K, used 7060K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 98% used [0x00000007bf600000,0x00000007bfce5308,0x00000007bfd00000)\n Metaspace       used 3099K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 340K, capacity 386K, committed 512K, reserved 1048576K\n```\nGC过程为\n1. 新生代GC, 新生代已用内存从1535K变为512K, 新生代可用内存为2560K. 整个堆内存从8003K变为7136K,整个堆可用内存为9728K, 耗时为0.0020620 秒.\n2. Full GC, 新生代将已用内存512k清空, 可用内存为2560K. 老年代已用内存从7091K变成592K, 整个老年代可用内存为7168K. 整个堆内存已用内存从7136K变成623K, 整个堆可用内存为9728K. Metaspace区(Java8里的方法区)没有回收, 整个Full GC耗时0.0067020 秒.\n\n最后还输出了虚拟机退出时, 整个虚拟机的内存分布情况\n1. 新生代总共有2560K的内存, 使用了78K\n2. 新生代eden区为2048K, 使用了3%\n3. 新生代survivor区(from部分)为512k, 没有使用\n4. 新生代survivor区(to部分)为512k, 没有使用\n5. 老年代(ParOld垃圾回收器) 总共内存为7168K, 使用里7060K.\n\n###  PrintHeapAtGC\n这个参数会在GC前后打印出堆内信息\n```java\npublic class TestPrintGCDetails {\n    public static void main(String[] args) {\n        for (int i = 0; i < 2; i++) {\n            byte[] bytes = new byte[1024 * 924 * 7];\n            System.out.println(\"Allocate \" + i);\n        }\n    }\n}\n```\n我们使用虚拟机参数`-XX:+PrintHeapAtGC -Xmx10M -Xms10M`运行程序输出结果\n```xml\nAllocate 0\n{Heap before GC invocations=1 (full 0):\n PSYoungGen      total 2560K, used 1535K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 74% used [0x00000007bfd00000,0x00000007bfe7fe40,0x00000007bff00000)\n  from space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n  to   space 512K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007bff80000)\n ParOldGen       total 7168K, used 6468K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 90% used [0x00000007bf600000,0x00000007bfc51010,0x00000007bfd00000)\n Metaspace       used 3097K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 339K, capacity 386K, committed 512K, reserved 1048576K\nHeap after GC invocations=1 (full 0):\n PSYoungGen      total 2560K, used 512K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 0% used [0x00000007bfd00000,0x00000007bfd00000,0x00000007bff00000)\n  from space 512K, 100% used [0x00000007bff00000,0x00000007bff80000,0x00000007bff80000)\n  to   space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n ParOldGen       total 7168K, used 6616K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 92% used [0x00000007bf600000,0x00000007bfc763a8,0x00000007bfd00000)\n Metaspace       used 3097K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 339K, capacity 386K, committed 512K, reserved 1048576K\n}\n{Heap before GC invocations=2 (full 1):\n ...\n}\nAllocate 1\n```\n限于篇幅, 我只输出了一次的GC日志. 大部分的内容解释我们都可以在`PrintGCDetails`例子解释中找到答案. 需要特别指出的是\n* invocations=1 : 代表这是第一次GC\n* (full 0) : 表示虚拟机进行的Full GC的次数\n\n###  PrintGCTimeStamps\n这个参数会在每次GC的时候,输出GC发生的时间. \u0010们还是使用上面的测试程序, 指定虚拟机参数`-XX:+PrintGC -XX:+PrintGCTimeStamps -Xmx10M -Xms10M`看一下输出结果\n```xml\nAllocate 0\n0.285: [GC (Allocation Failure)  8003K->7124K(9728K), 0.0015210 secs]\n0.286: [Full GC (Ergonomics)  7124K->622K(9728K), 0.0072690 secs]\nAllocate 1\n```\n1. 第一次GC发生在JVM启动0.285秒时进行的\n2. 第二次GC发生在JVM启动0.286秒时进行的\n\n###  PrintGCApplicationConcurrentTime\n打印应用程序的执行时间. 我们使用`-XX:+PrintGC -XX:+PrintGCApplicationConcurrentTime -Xmx10M -Xms10M`虚拟机参数运行一下上面的程序, 看一下输出结果为\n```xml\nAllocate 0\nApplication time: 0.1094100 seconds\n[GC (Allocation Failure)  8003K->7136K(9728K), 0.0018960 secs]\n[Full GC (Ergonomics)  7136K->623K(9728K), 0.0080650 secs]\nAllocate 1\nApplication time: 0.0026340 seconds\n```\n\n###  PrintGCApplicationStoppedTime\n打印程序因为GC停顿的时间. 同样使用虚拟机参数`-XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -Xmx10M -Xms10M`, 运行一下上面的程序\n```xml\nAllocate 0\n[GC (Allocation Failure)  8003K->7120K(9728K), 0.0014070 secs]\n[Full GC (Ergonomics)  7120K->623K(9728K), 0.0073180 secs]\nTotal time for which application threads were stopped: 0.0089770 seconds\nAllocate 1\n```\n我们看到整个应用在Full GC时, 停顿了 0.0089770 秒.\n\n###  PrintGCDateStamps\n仍然使用上面的测试程序, 然后使用JVM参数`-XX:+PrintGC -Xmx10M -Xms10M -XX:+PrintGCDateStamps`. 结果为\n```bash\n2016-05-18T17:28:34.689+0800: [GC (Allocation Failure)  2028K->1006K(9728K), 0.0076949 secs]\n2016-05-18T17:28:34.741+0800: [GC (Allocation Failure)  3052K->1565K(9728K), 0.0191430 secs]\n2016-05-18T17:28:34.772+0800: [GC (Allocation Failure)  1750K->1597K(9728K), 0.0088998 secs]\n2016-05-18T17:28:34.781+0800: [GC (Allocation Failure)  1597K->1603K(9728K), 0.0371759 secs]\n2016-05-18T17:28:34.818+0800: [Full GC (Allocation Failure)  1603K->1068K(9728K), 0.0078928 secs]\n2016-05-18T17:28:34.826+0800: [GC (Allocation Failure)  1068K->1068K(9728K), 0.0185343 secs]\n2016-05-18T17:28:34.844+0800: [Full GC (Allocation Failure)  1068K->1041K(9728K), 0.0176116 secs]\n```\n这个时间输出比PrintGCTimeStamps可读性更好, 因为它输出的是系统时间\n\n###  PrintTenuringDistribution\n打印GC后新生代各个年龄对象的大小。 我们使用最开始的测试程序, 然后指定JVM参数`-XX:+PrintGC -Xmx10M -Xms10M -XX:+PrintTenuringDistribution`, 看一下结果\n```bash\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 2028K->1025K(9728K), 0.0150981 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 3071K->1579K(9728K), 0.0141280 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 1743K->1635K(9728K), 0.0125040 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 1635K->1619K(9728K), 0.0136705 secs]\n[Full GC (Allocation Failure)  1619K->1401K(9728K), 0.0138036 secs]\n[GC (Allocation Failure)\nDesired survivor size 1048576 bytes, new threshold 6 (max 15)\n 1401K->1401K(9728K), 0.0018372 secs]\n[Full GC (Allocation Failure)  1401K->1374K(9728K), 0.0294141 secs]\n```\n\n### GC日志文件\n* UseGCLogFileRotation : 开启GC日志文件切分功能,前置选项-Xloggc, `-XX:+UseGCLogFileRotation`\n* NumberOfGCLogFiles : 设置Gc日志文件的数量(必须大于1), `-XX:NumberOfGCLogFiles=10`\n* GCLogFileSize : gc日志文件大小(必须>=8K), `-XX:GCLogFileSize=8K`\n* Xloggc : `-Xloggc:<filename>`gc日志文件\n我们使用测试程序\n```java\n\n```\n然后指定虚拟机参数`-XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:NumberOfGCLogFiles=3 -XX:GCLogFileSize=10K -XX:+UseGCLogFileRotation -Xloggc:gc.log`来运行一下. 最后我们会看到三个文件\n* gc.log.1 (11,016 字节)\n* gc.log.2 (11,755 字节)\n* gc.log.0.current (780 字节)\n我们看到使用这四个参数已经成功将日志输出到三个文件中.\n> 注意每次生成日志的时候都会将上次运行JVM的日志覆盖掉. 因此每次关服重启时, 最好将日志文件备份一下.\n\n## 异常输出\n\n###  HeapDumpOnOutOfMemoryError\n在发生内存溢出异常时是否生成堆转储快照,关闭则不生成`-XX:+HeapDumpOnOutOfMemoryError`\n\n> `-XX:HeapDumpPath=./java_pid<pid>.hprof`:堆内存溢出存放日志目录.\n\n###  OnOutOfMemoryError\n当虚拟机抛出内存溢出异常时,执行指令的命令`-XX:+OnOutOfMemoryError`\n\n###  OnError\n当虚拟机抛出ERROR异常时,执行指令的命令`-XX:+OnError`\n\n> `-XX:ErrorFile=./hs_err_pid<pid>.log`:如果有Error发生,则将Error输入到该日志.\n\n## 运行时状态\n\n###  PrintReferenceGC\n追踪系统内的软引用,弱引用,虚引用和Finallize队列的话可以使用`PrintReferenceGC`.\n\n###  verbose:class\n* `-verbose:class` : 跟踪类的加载和卸载\n* `-XX:+TraceClassLoading` : 追踪类的加载\n* `-XX:+TraceClassUnloading` : 追踪类的卸载\n我们运行最开始的那个测试程序, 看一下JVM启动时加载的类`-verbose:class`\n```bash\n[Opened /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/rt.jar]\n[Loaded java.lang.Object from /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/rt.jar]\n```\n这个特性用在使用ASM动态生成类的应用中特别有用, 因为这些类是由逻辑代码控制的, 加载这些类的行为具有一定的隐蔽性, 因此我们可以在虚拟机启动时, 加上这个参数做日志分析用.\n\n###  CITime\n`-XX:+CITime`:打印`JITCompiler`的耗时\n\n###  PrintConcurrentLocks\n打印J.U.C中的状态`-XX:+PrintConcurrentLocks`\n\n###  PrintCompilation\n显示所有可设置的参数及它们的值(从JDK6update21开始才可以用)`-XX:+`\n\n###  PrintInlining\n打印方法内联信息`-XX:+PrintInlining`\n\n###  PrintAssembly\n打印即时编译后的二进制信息\n\n###  PrintAdaptiveSizePolicy\n`-XX:-PrintAdaptiveSizePolicy` :打印JVM自动划分新生代和老生代大小信息.\n> 这个选项最好和-XX:+PrintGCDetails以及-XX:+PrintGCDateStamps或者-XX:+PrintGCTimeStamps一起使用.以GCAdaptiveSizePolicy开头的一些额外信息输出来了，survived标签表明“to” survivor空间的对象字节数。在这个例子中，survivor空间占用量是224408984字节，但是移动到old代的字节数却有10904856字节。overflow表明young代是否有对象溢出到old代，换句话说，就是表明了“to” survivor是否有足够的空间来容纳从eden空间和“from”survivor空间移动而来的对象。为了更好的吞吐量，期望在应用处于稳定运行状态下，survivor空间不要溢出。\n\n## 系统相关\n\n###  PrintVMOptions\n输出程序启动时, 虚拟机接收到命令行指定的参数. 我们指定虚拟机参数`-XX:+PrintVMOptions -Xmx10M -Xms10M`, 输出结果为\n```bash\nVM option '+PrintVMOptions'\n```\n> TODO 为什么输出只有PrintVMOptions, 而没有-Xmx10M -Xms10M呢?\n\n###  PrintCommandLineFlags\n打印启动虚拟机时输入的非稳定参数`-XX:+PrintCommandLineFlags`\n```xml\n-XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC\n```\n\n###  PrintFlagsFinal\n输出所有的系统的参数的值, 我们使用-XX:+PrintFlagsFinal`, 看一下结果\n```bash\n[Global flags]\n    uintx AdaptiveSizeDecrementScaleFactor          = 4               {product}\n    uintx AdaptiveSizeMajorGCDecayTimeScale         = 10              {product}\n    uintx AdaptiveSizePausePolicy                   = 0               {product}\n    uintx AdaptiveSizePolicyCollectionCostMargin    = 50              {product}\n    uintx AdaptiveSizePolicyInitializingSteps       = 20              {product}\n    uintx AdaptiveSizePolicyOutputInterval          = 0               {product}\n    uintx AdaptiveSizePolicyWeight                  = 10              {product}\n    uintx AdaptiveSizeThroughPutPolicy              = 0               {product}\n    uintx AdaptiveTimeWeight                        = 25              {product}\n     bool AdjustConcurrency                         = false           {product}\n     bool AggressiveOpts                            = false           {product}\n     intx AliasLevel                                = 3               {C2 product}\n     bool AlignVector                               = false           {C2 product}\n     intx AllocateInstancePrefetchLines             = 1               {product}\n     intx AllocatePrefetchDistance                  = 192             {product}\n     intx AllocatePrefetchInstr                     = 0               {product}\n     intx AllocatePrefetchLines                     = 4               {product}\n     intx AllocatePrefetchStepSize                  = 64              {product}\n     intx AllocatePrefetchStyle                     = 1               {product}\n     bool AllowJNIEnvProxy                          = false           {product}\n     bool AllowNonVirtualCalls                      = false           {product}\n     bool AllowParallelDefineClass                  = false           {product}\n     bool AllowUserSignalHandlers                   = false           {product}\n     bool AlwaysActAsServerClassMachine             = false           {product}\n     bool AlwaysCompileLoopMethods                  = false           {product}\n     bool AlwaysLockClassLoader                     = false           {product}\n     bool AlwaysPreTouch                            = false           {product}\n     bool AlwaysRestoreFPU                          = false           {product}\n     bool AlwaysTenure                              = false           {product}\n     bool AssertOnSuspendWaitFailure                = false           {product}\n     bool AssumeMP                                  = false           {product}\n     intx AutoBoxCacheMax                           = 128             {C2 product}\n    uintx AutoGCSelectPauseMillis                   = 5000            {product}\n     intx BCEATraceLevel                            = 0               {product}\n     intx BackEdgeThreshold                         = 100000          {pd product}\n     bool BackgroundCompilation                     = true            {pd product}\n    uintx BaseFootPrintEstimate                     = 268435456       {product}\n     intx BiasedLockingBulkRebiasThreshold          = 20              {product}\n     intx BiasedLockingBulkRevokeThreshold          = 40              {product}\n     intx BiasedLockingDecayTime                    = 25000           {product}\n     intx BiasedLockingStartupDelay                 = 4000            {product}\n     bool BindGCTaskThreadsToCPUs                   = false           {product}\n     bool BlockLayoutByFrequency                    = true            {C2 product}\n     intx BlockLayoutMinDiamondPercentage           = 20              {C2 product}\n     bool BlockLayoutRotateLoops                    = true            {C2 product}\n     bool BranchOnRegister                          = false           {C2 product}\n     bool BytecodeVerificationLocal                 = false           {product}\n     bool BytecodeVerificationRemote                = true            {product}\n     bool C1OptimizeVirtualCallProfiling            = true            {C1 product}\n     bool C1ProfileBranches                         = true            {C1 product}\n     bool C1ProfileCalls                            = true            {C1 product}\n     bool C1ProfileCheckcasts                       = true            {C1 product}\n     bool C1ProfileInlinedCalls                     = true            {C1 product}\n     bool C1ProfileVirtualCalls                     = true            {C1 product}\n     bool C1UpdateMethodData                        = true            {C1 product}\n     intx CICompilerCount                           = 2               {product}\n     bool CICompilerCountPerCPU                     = true            {product}\n     bool CITime                                    = false           {product}\n     bool CMSAbortSemantics                         = false           {product}\n    uintx CMSAbortablePrecleanMinWorkPerIteration   = 100             {product}\n     intx CMSAbortablePrecleanWaitMillis            = 100             {manageable}\n    uintx CMSBitMapYieldQuantum                     = 10485760        {product}\n    uintx CMSBootstrapOccupancy                     = 50              {product}\n     bool CMSClassUnloadingEnabled                  = true            {product}\n    uintx CMSClassUnloadingMaxInterval              = 0               {product}\n     bool CMSCleanOnEnter                           = true            {product}\n     bool CMSCompactWhenClearAllSoftRefs            = true            {product}\n    uintx CMSConcMarkMultiple                       = 32              {product}\n     bool CMSConcurrentMTEnabled                    = true            {product}\n    uintx CMSCoordinatorYieldSleepCount             = 10              {product}\n     bool CMSDumpAtPromotionFailure                 = false           {product}\n     bool CMSEdenChunksRecordAlways                 = true            {product}\n    uintx CMSExpAvgFactor                           = 50              {product}\n     bool CMSExtrapolateSweep                       = false           {product}\n    uintx CMSFullGCsBeforeCompaction                = 0               {product}\n    uintx CMSIncrementalDutyCycle                   = 10              {product}\n    uintx CMSIncrementalDutyCycleMin                = 0               {product}\n     bool CMSIncrementalMode                        = false           {product}\n    uintx CMSIncrementalOffset                      = 0               {product}\n     bool CMSIncrementalPacing                      = true            {product}\n    uintx CMSIncrementalSafetyFactor                = 10              {product}\n    uintx CMSIndexedFreeListReplenish               = 4               {product}\n     intx CMSInitiatingOccupancyFraction            = -1              {product}\n    uintx CMSIsTooFullPercentage                    = 98              {product}\n   double CMSLargeCoalSurplusPercent                = 0.950000        {product}\n   double CMSLargeSplitSurplusPercent               = 1.000000        {product}\n     bool CMSLoopWarn                               = false           {product}\n    uintx CMSMaxAbortablePrecleanLoops              = 0               {product}\n     intx CMSMaxAbortablePrecleanTime               = 5000            {product}\n    uintx CMSOldPLABMax                             = 1024            {product}\n    uintx CMSOldPLABMin                             = 16              {product}\n    uintx CMSOldPLABNumRefills                      = 4               {product}\n    uintx CMSOldPLABReactivityFactor                = 2               {product}\n     bool CMSOldPLABResizeQuicker                   = false           {product}\n    uintx CMSOldPLABToleranceFactor                 = 4               {product}\n     bool CMSPLABRecordAlways                       = true            {product}\n    uintx CMSParPromoteBlocksToClaim                = 16              {product}\n     bool CMSParallelInitialMarkEnabled             = true            {product}\n     bool CMSParallelRemarkEnabled                  = true            {product}\n     bool CMSParallelSurvivorRemarkEnabled          = true            {product}\n    uintx CMSPrecleanDenominator                    = 3               {product}\n    uintx CMSPrecleanIter                           = 3               {product}\n    uintx CMSPrecleanNumerator                      = 2               {product}\n     bool CMSPrecleanRefLists1                      = true            {product}\n     bool CMSPrecleanRefLists2                      = false           {product}\n     bool CMSPrecleanSurvivors1                     = false           {product}\n     bool CMSPrecleanSurvivors2                     = true            {product}\n    uintx CMSPrecleanThreshold                      = 1000            {product}\n     bool CMSPrecleaningEnabled                     = true            {product}\n     bool CMSPrintChunksInDump                      = false           {product}\n     bool CMSPrintEdenSurvivorChunks                = false           {product}\n     bool CMSPrintObjectsInDump                     = false           {product}\n    uintx CMSRemarkVerifyVariant                    = 1               {product}\n     bool CMSReplenishIntermediate                  = true            {product}\n    uintx CMSRescanMultiple                         = 32              {product}\n    uintx CMSSamplingGrain                          = 16384           {product}\n     bool CMSScavengeBeforeRemark                   = false           {product}\n    uintx CMSScheduleRemarkEdenPenetration          = 50              {product}\n    uintx CMSScheduleRemarkEdenSizeThreshold        = 2097152         {product}\n    uintx CMSScheduleRemarkSamplingRatio            = 5               {product}\n   double CMSSmallCoalSurplusPercent                = 1.050000        {product}\n   double CMSSmallSplitSurplusPercent               = 1.100000        {product}\n     bool CMSSplitIndexedFreeListBlocks             = true            {product}\n    uintx CMSTriggerRatio                           = 80              {product}\n     intx CMSWaitDuration                           = 2000            {manageable}\n    uintx CMSWorkQueueDrainThreshold                = 10              {product}\n     bool CMSYield                                  = true            {product}\n    uintx CMSYieldSleepCount                        = 0               {product}\n    uintx CMSYoungGenPerWorker                      = 67108864        {pd product}\n    uintx CMS_FLSPadding                            = 1               {product}\n    uintx CMS_FLSWeight                             = 75              {product}\n    uintx CMS_SweepPadding                          = 1               {product}\n    uintx CMS_SweepTimerThresholdMillis             = 10              {product}\n    uintx CMS_SweepWeight                           = 75              {product}\n     bool CheckJNICalls                             = false           {product}\n     bool ClassUnloading                            = true            {product}\n     intx ClearFPUAtPark                            = 0               {product}\n     bool ClipInlining                              = true            {product}\n    uintx CodeCacheExpansionSize                    = 65536           {pd product}\n    uintx CodeCacheMinimumFreeSpace                 = 512000          {product}\n     bool CollectGen0First                          = false           {product}\n     bool CompactFields                             = true            {product}\n     intx CompilationPolicyChoice                   = 3               {product}\n     intx CompilationRepeat                         = 0               {C1 product}\nccstrlist CompileCommand                            =                 {product}\n    ccstr CompileCommandFile                        =                 {product}\nccstrlist CompileOnly                               =                 {product}\n     intx CompileThreshold                          = 10000           {pd product}\n     bool CompilerThreadHintNoPreempt               = true            {product}\n     intx CompilerThreadPriority                    = -1              {product}\n     intx CompilerThreadStackSize                   = 0               {pd product}\n    uintx CompressedClassSpaceSize                  = 1073741824      {product}\n    uintx ConcGCThreads                             = 0               {product}\n     intx ConditionalMoveLimit                      = 3               {C2 pd product}\n     intx ContendedPaddingWidth                     = 128             {product}\n     bool ConvertSleepToYield                       = true            {pd product}\n     bool ConvertYieldToSleep                       = false           {product}\n     bool CreateMinidumpOnCrash                     = false           {product}\n     bool CriticalJNINatives                        = true            {product}\n     bool DTraceAllocProbes                         = false           {product}\n     bool DTraceMethodProbes                        = false           {product}\n     bool DTraceMonitorProbes                       = false           {product}\n     bool Debugging                                 = false           {product}\n    uintx DefaultMaxRAMFraction                     = 4               {product}\n     intx DefaultThreadPriority                     = -1              {product}\n     intx DeferPollingPageLoopCount                 = -1              {product}\n     intx DeferThrSuspendLoopCount                  = 4000            {product}\n     bool DeoptimizeRandom                          = false           {product}\n     bool DisableAttachMechanism                    = false           {product}\n     bool DisableExplicitGC                         = false           {product}\n     bool DisplayVMOutputToStderr                   = false           {product}\n     bool DisplayVMOutputToStdout                   = false           {product}\n     bool DoEscapeAnalysis                          = true            {C2 product}\n     bool DontCompileHugeMethods                    = true            {product}\n     bool DontYieldALot                             = false           {pd product}\n     bool DumpReplayDataOnError                     = true            {product}\n     bool DumpSharedSpaces                          = false           {product}\n     bool EagerXrunInit                             = false           {product}\n     intx EliminateAllocationArraySizeLimit         = 64              {C2 product}\n     bool EliminateAllocations                      = true            {C2 product}\n     bool EliminateAutoBox                          = false           {C2 product}\n     bool EliminateLocks                            = true            {C2 product}\n     bool EliminateNestedLocks                      = true            {C2 product}\n     intx EmitSync                                  = 0               {product}\n     bool EnableContended                           = true            {product}\n     bool EnableTracing                             = false           {product}\n    uintx ErgoHeapSizeLimit                         = 0               {product}\n    ccstr ErrorFile                                 =                 {product}\n    ccstr ErrorReportServer                         =                 {product}\n     bool EstimateArgEscape                         = true            {product}\n     bool ExplicitGCInvokesConcurrent               = false           {product}\n     bool ExplicitGCInvokesConcurrentAndUnloadsClasses  = false           {product}\n     bool ExtendedDTraceProbes                      = false           {product}\n     bool FLSAlwaysCoalesceLarge                    = false           {product}\n    uintx FLSCoalescePolicy                         = 2               {product}\n   double FLSLargestBlockCoalesceProximity          = 0.990000        {product}\n     bool FailOverToOldVerifier                     = true            {product}\n     bool FastTLABRefill                            = true            {product}\n     intx FenceInstruction                          = 0               {ARCH product}\n     intx FieldsAllocationStyle                     = 1               {product}\n     bool FilterSpuriousWakeups                     = true            {product}\n     bool ForceNUMA                                 = false           {product}\n     bool ForceTimeHighResolution                   = false           {product}\n     intx FreqInlineSize                            = 325             {pd product}\n   double G1ConcMarkStepDurationMillis              = 10.000000       {product}\n    uintx G1ConcRSHotCardLimit                      = 4               {product}\n    uintx G1ConcRSLogCacheSize                      = 10              {product}\n     intx G1ConcRefinementGreenZone                 = 0               {product}\n     intx G1ConcRefinementRedZone                   = 0               {product}\n     intx G1ConcRefinementServiceIntervalMillis     = 300             {product}\n    uintx G1ConcRefinementThreads                   = 0               {product}\n     intx G1ConcRefinementThresholdStep             = 0               {product}\n     intx G1ConcRefinementYellowZone                = 0               {product}\n    uintx G1ConfidencePercent                       = 50              {product}\n    uintx G1HeapRegionSize                          = 0               {product}\n    uintx G1HeapWastePercent                        = 10              {product}\n    uintx G1MixedGCCountTarget                      = 8               {product}\n     intx G1RSetRegionEntries                       = 0               {product}\n    uintx G1RSetScanBlockSize                       = 64              {product}\n     intx G1RSetSparseRegionEntries                 = 0               {product}\n     intx G1RSetUpdatingPauseTimePercent            = 10              {product}\n     intx G1RefProcDrainInterval                    = 10              {product}\n    uintx G1ReservePercent                          = 10              {product}\n    uintx G1SATBBufferEnqueueingThresholdPercent    = 60              {product}\n     intx G1SATBBufferSize                          = 1024            {product}\n     intx G1UpdateBufferSize                        = 256             {product}\n     bool G1UseAdaptiveConcRefinement               = true            {product}\n    uintx GCDrainStackTargetSize                    = 64              {product}\n    uintx GCHeapFreeLimit                           = 2               {product}\n    uintx GCLockerEdenExpansionPercent              = 5               {product}\n     bool GCLockerInvokesConcurrent                 = false           {product}\n    uintx GCLogFileSize                             = 0               {product}\n    uintx GCPauseIntervalMillis                     = 0               {product}\n    uintx GCTaskTimeStampEntries                    = 200             {product}\n    uintx GCTimeLimit                               = 98              {product}\n    uintx GCTimeRatio                               = 99              {product}\n    uintx HeapBaseMinAddress                        = 2147483648      {pd product}\n     bool HeapDumpAfterFullGC                       = false           {manageable}\n     bool HeapDumpBeforeFullGC                      = false           {manageable}\n     bool HeapDumpOnOutOfMemoryError                = false           {manageable}\n    ccstr HeapDumpPath                              =                 {manageable}\n    uintx HeapFirstMaximumCompactionCount           = 3               {product}\n    uintx HeapMaximumCompactionInterval             = 20              {product}\n    uintx HeapSizePerGCThread                       = 87241520        {product}\n     bool IgnoreUnrecognizedVMOptions               = false           {product}\n    uintx IncreaseFirstTierCompileThresholdAt       = 50              {product}\n     bool IncrementalInline                         = true            {C2 product}\n    uintx InitialBootClassLoaderMetaspaceSize       = 4194304         {product}\n    uintx InitialCodeCacheSize                      = 2555904         {pd product}\n    uintx InitialHeapSize                          := 10485760        {product}\n    uintx InitialRAMFraction                        = 64              {product}\n    uintx InitialSurvivorRatio                      = 8               {product}\n    uintx InitialTenuringThreshold                  = 7               {product}\n    uintx InitiatingHeapOccupancyPercent            = 45              {product}\n     bool Inline                                    = true            {product}\n     intx InlineSmallCode                           = 2000            {pd product}\n     bool InlineSynchronizedMethods                 = true            {C1 product}\n     bool InsertMemBarAfterArraycopy                = true            {C2 product}\n     intx InteriorEntryAlignment                    = 16              {C2 pd product}\n     intx InterpreterProfilePercentage              = 33              {product}\n     bool JNIDetachReleasesMonitors                 = true            {product}\n     bool JavaMonitorsInStackTrace                  = true            {product}\n     intx JavaPriority10_To_OSPriority              = -1              {product}\n     intx JavaPriority1_To_OSPriority               = -1              {product}\n     intx JavaPriority2_To_OSPriority               = -1              {product}\n     intx JavaPriority3_To_OSPriority               = -1              {product}\n     intx JavaPriority4_To_OSPriority               = -1              {product}\n     intx JavaPriority5_To_OSPriority               = -1              {product}\n     intx JavaPriority6_To_OSPriority               = -1              {product}\n     intx JavaPriority7_To_OSPriority               = -1              {product}\n     intx JavaPriority8_To_OSPriority               = -1              {product}\n     intx JavaPriority9_To_OSPriority               = -1              {product}\n     bool LIRFillDelaySlots                         = false           {C1 pd product}\n    uintx LargePageHeapSizeThreshold                = 134217728       {product}\n    uintx LargePageSizeInBytes                      = 0               {product}\n     bool LazyBootClassLoader                       = true            {product}\n     intx LiveNodeCountInliningCutoff               = 20000           {C2 product}\n     bool LogCommercialFeatures                     = false           {product}\n     intx LoopMaxUnroll                             = 16              {C2 product}\n     intx LoopOptsCount                             = 43              {C2 product}\n     intx LoopUnrollLimit                           = 60              {C2 pd product}\n     intx LoopUnrollMin                             = 4               {C2 product}\n     bool LoopUnswitching                           = true            {C2 product}\n     bool ManagementServer                          = false           {product}\n    uintx MarkStackSize                             = 4194304         {product}\n    uintx MarkStackSizeMax                          = 536870912       {product}\n    uintx MarkSweepAlwaysCompactCount               = 4               {product}\n    uintx MarkSweepDeadRatio                        = 1               {product}\n     intx MaxBCEAEstimateLevel                      = 5               {product}\n     intx MaxBCEAEstimateSize                       = 150             {product}\n    uintx MaxDirectMemorySize                       = 0               {product}\n     bool MaxFDLimit                                = true            {product}\n    uintx MaxGCMinorPauseMillis                     = 18446744073709551615{product}\n    uintx MaxGCPauseMillis                          = 18446744073709551615{product}\n    uintx MaxHeapFreeRatio                          = 70              {product}\n    uintx MaxHeapSize                              := 10485760        {product}\n     intx MaxInlineLevel                            = 9               {product}\n     intx MaxInlineSize                             = 35              {product}\n     intx MaxJavaStackTraceDepth                    = 1024            {product}\n     intx MaxJumpTableSize                          = 65000           {C2 product}\n     intx MaxJumpTableSparseness                    = 5               {C2 product}\n     intx MaxLabelRootDepth                         = 1100            {C2 product}\n     intx MaxLoopPad                                = 11              {C2 product}\n    uintx MaxMetaspaceExpansion                     = 5451776         {product}\n    uintx MaxMetaspaceFreeRatio                     = 70              {product}\n    uintx MaxMetaspaceSize                          = 18446744073709547520{product}\n    uintx MaxNewSize                               := 3145728         {product}\n     intx MaxNodeLimit                              = 75000           {C2 product}\n uint64_t MaxRAM                                    = 137438953472    {pd product}\n    uintx MaxRAMFraction                            = 4               {product}\n     intx MaxRecursiveInlineLevel                   = 1               {product}\n    uintx MaxTenuringThreshold                      = 15              {product}\n     intx MaxTrivialSize                            = 6               {product}\n     intx MaxVectorSize                             = 16              {C2 product}\n    uintx MetaspaceSize                             = 21807104        {pd product}\n     bool MethodFlushing                            = true            {product}\n    uintx MinHeapDeltaBytes                        := 524288          {product}\n    uintx MinHeapFreeRatio                          = 40              {product}\n     intx MinInliningThreshold                      = 250             {product}\n     intx MinJumpTableSize                          = 10              {C2 pd product}\n    uintx MinMetaspaceExpansion                     = 339968          {product}\n    uintx MinMetaspaceFreeRatio                     = 40              {product}\n    uintx MinRAMFraction                            = 2               {product}\n    uintx MinSurvivorRatio                          = 3               {product}\n    uintx MinTLABSize                               = 2048            {product}\n     intx MonitorBound                              = 0               {product}\n     bool MonitorInUseLists                         = false           {product}\n     intx MultiArrayExpandLimit                     = 6               {C2 product}\n     bool MustCallLoadClassInternal                 = false           {product}\n    uintx NUMAChunkResizeWeight                     = 20              {product}\n    uintx NUMAInterleaveGranularity                 = 2097152         {product}\n    uintx NUMAPageScanRate                          = 256             {product}\n    uintx NUMASpaceResizeRate                       = 1073741824      {product}\n     bool NUMAStats                                 = false           {product}\n    ccstr NativeMemoryTracking                      = off             {product}\n     intx NativeMonitorFlags                        = 0               {product}\n     intx NativeMonitorSpinLimit                    = 20              {product}\n     intx NativeMonitorTimeout                      = -1              {product}\n     bool NeedsDeoptSuspend                         = false           {pd product}\n     bool NeverActAsServerClassMachine              = false           {pd product}\n     bool NeverTenure                               = false           {product}\n    uintx NewRatio                                  = 2               {product}\n    uintx NewSize                                  := 3145728         {product}\n    uintx NewSizeThreadIncrease                     = 5320            {pd product}\n     intx NmethodSweepActivity                      = 10              {product}\n     intx NmethodSweepCheckInterval                 = 5               {product}\n     intx NmethodSweepFraction                      = 16              {product}\n     intx NodeLimitFudgeFactor                      = 2000            {C2 product}\n    uintx NumberOfGCLogFiles                        = 0               {product}\n     intx NumberOfLoopInstrToAlign                  = 4               {C2 product}\n     intx ObjectAlignmentInBytes                    = 8               {lp64_product}\n    uintx OldPLABSize                               = 1024            {product}\n    uintx OldPLABWeight                             = 50              {product}\n    uintx OldSize                                  := 7340032         {product}\n     bool OmitStackTraceInFastThrow                 = true            {product}\nccstrlist OnError                                   =                 {product}\nccstrlist OnOutOfMemoryError                        =                 {product}\n     intx OnStackReplacePercentage                  = 140             {pd product}\n     bool OptimizeFill                              = true            {C2 product}\n     bool OptimizePtrCompare                        = true            {C2 product}\n     bool OptimizeStringConcat                      = true            {C2 product}\n     bool OptoBundling                              = false           {C2 pd product}\n     intx OptoLoopAlignment                         = 16              {pd product}\n     bool OptoScheduling                            = false           {C2 pd product}\n    uintx PLABWeight                                = 75              {product}\n     bool PSChunkLargeArrays                        = true            {product}\n     intx ParGCArrayScanChunk                       = 50              {product}\n    uintx ParGCDesiredObjsFromOverflowList          = 20              {product}\n     bool ParGCTrimOverflow                         = true            {product}\n     bool ParGCUseLocalOverflow                     = false           {product}\n    uintx ParallelGCBufferWastePct                  = 10              {product}\n    uintx ParallelGCThreads                         = 4               {product}\n     bool ParallelGCVerbose                         = false           {product}\n    uintx ParallelOldDeadWoodLimiterMean            = 50              {product}\n    uintx ParallelOldDeadWoodLimiterStdDev          = 80              {product}\n     bool ParallelRefProcBalancingEnabled           = true            {product}\n     bool ParallelRefProcEnabled                    = false           {product}\n     bool PartialPeelAtUnsignedTests                = true            {C2 product}\n     bool PartialPeelLoop                           = true            {C2 product}\n     intx PartialPeelNewPhiDelta                    = 0               {C2 product}\n    uintx PausePadding                              = 1               {product}\n     intx PerBytecodeRecompilationCutoff            = 200             {product}\n     intx PerBytecodeTrapLimit                      = 4               {product}\n     intx PerMethodRecompilationCutoff              = 400             {product}\n     intx PerMethodTrapLimit                        = 100             {product}\n     bool PerfAllowAtExitRegistration               = false           {product}\n     bool PerfBypassFileSystemCheck                 = false           {product}\n     intx PerfDataMemorySize                        = 32768           {product}\n     intx PerfDataSamplingInterval                  = 50              {product}\n    ccstr PerfDataSaveFile                          =                 {product}\n     bool PerfDataSaveToFile                        = false           {product}\n     bool PerfDisableSharedMem                      = false           {product}\n     intx PerfMaxStringConstLength                  = 1024            {product}\n     intx PreInflateSpin                            = 10              {pd product}\n     bool PreferInterpreterNativeStubs              = false           {pd product}\n     intx PrefetchCopyIntervalInBytes               = 576             {product}\n     intx PrefetchFieldsAhead                       = 1               {product}\n     intx PrefetchScanIntervalInBytes               = 576             {product}\n     bool PreserveAllAnnotations                    = false           {product}\n    uintx PretenureSizeThreshold                    = 0               {product}\n     bool PrintAdaptiveSizePolicy                   = false           {product}\n     bool PrintCMSInitiationStatistics              = false           {product}\n     intx PrintCMSStatistics                        = 0               {product}\n     bool PrintClassHistogram                       = false           {manageable}\n     bool PrintClassHistogramAfterFullGC            = false           {manageable}\n     bool PrintClassHistogramBeforeFullGC           = false           {manageable}\n     bool PrintCodeCache                            = false           {product}\n     bool PrintCodeCacheOnCompilation               = false           {product}\n     bool PrintCommandLineFlags                     = false           {product}\n     bool PrintCompilation                          = false           {product}\n     bool PrintConcurrentLocks                      = false           {manageable}\n     intx PrintFLSCensus                            = 0               {product}\n     intx PrintFLSStatistics                        = 0               {product}\n     bool PrintFlagsFinal                          := true            {product}\n     bool PrintFlagsInitial                         = false           {product}\n     bool PrintGC                                   = false           {manageable}\n     bool PrintGCApplicationConcurrentTime          = false           {product}\n     bool PrintGCApplicationStoppedTime             = false           {product}\n     bool PrintGCCause                              = true            {product}\n     bool PrintGCDateStamps                         = false           {manageable}\n     bool PrintGCDetails                            = false           {manageable}\n     bool PrintGCTaskTimeStamps                     = false           {product}\n     bool PrintGCTimeStamps                         = false           {manageable}\n     bool PrintHeapAtGC                             = false           {product rw}\n     bool PrintHeapAtGCExtended                     = false           {product rw}\n     bool PrintHeapAtSIGBREAK                       = true            {product}\n     bool PrintJNIGCStalls                          = false           {product}\n     bool PrintJNIResolving                         = false           {product}\n     bool PrintOldPLAB                              = false           {product}\n     bool PrintOopAddress                           = false           {product}\n     bool PrintPLAB                                 = false           {product}\n     bool PrintParallelOldGCPhaseTimes              = false           {product}\n     bool PrintPromotionFailure                     = false           {product}\n     bool PrintReferenceGC                          = false           {product}\n     bool PrintSafepointStatistics                  = false           {product}\n     intx PrintSafepointStatisticsCount             = 300             {product}\n     intx PrintSafepointStatisticsTimeout           = -1              {product}\n     bool PrintSharedSpaces                         = false           {product}\n     bool PrintStringTableStatistics                = false           {product}\n     bool PrintTLAB                                 = false           {product}\n     bool PrintTenuringDistribution                 = false           {product}\n     bool PrintTieredEvents                         = false           {product}\n     bool PrintVMOptions                            = false           {product}\n     bool PrintVMQWaitTime                          = false           {product}\n     bool PrintWarnings                             = true            {product}\n    uintx ProcessDistributionStride                 = 4               {product}\n     bool ProfileInterpreter                        = true            {pd product}\n     bool ProfileIntervals                          = false           {product}\n     intx ProfileIntervalsTicks                     = 100             {product}\n     intx ProfileMaturityPercentage                 = 20              {product}\n     bool ProfileVM                                 = false           {product}\n     bool ProfilerPrintByteCodeStatistics           = false           {product}\n     bool ProfilerRecordPC                          = false           {product}\n    uintx PromotedPadding                           = 3               {product}\n    uintx QueuedAllocationWarningCount              = 0               {product}\n     bool RangeCheckElimination                     = true            {product}\n     intx ReadPrefetchInstr                         = 0               {ARCH product}\n     bool ReassociateInvariants                     = true            {C2 product}\n     bool ReduceBulkZeroing                         = true            {C2 product}\n     bool ReduceFieldZeroing                        = true            {C2 product}\n     bool ReduceInitialCardMarks                    = true            {C2 product}\n     bool ReduceSignalUsage                         = false           {product}\n     intx RefDiscoveryPolicy                        = 0               {product}\n     bool ReflectionWrapResolutionErrors            = true            {product}\n     bool RegisterFinalizersAtInit                  = true            {product}\n     bool RelaxAccessControlCheck                   = false           {product}\n    ccstr ReplayDataFile                            =                 {product}\n     bool RequireSharedSpaces                       = false           {product}\n    uintx ReservedCodeCacheSize                     = 251658240       {pd product}\n     bool ResizeOldPLAB                             = true            {product}\n     bool ResizePLAB                                = true            {product}\n     bool ResizeTLAB                                = true            {pd product}\n     bool RestoreMXCSROnJNICalls                    = false           {product}\n     bool RestrictContended                         = true            {product}\n     bool RewriteBytecodes                          = true            {pd product}\n     bool RewriteFrequentPairs                      = true            {pd product}\n     intx SafepointPollOffset                       = 256             {C1 pd product}\n     intx SafepointSpinBeforeYield                  = 2000            {product}\n     bool SafepointTimeout                          = false           {product}\n     intx SafepointTimeoutDelay                     = 10000           {product}\n     bool ScavengeBeforeFullGC                      = true            {product}\n     intx SelfDestructTimer                         = 0               {product}\n    uintx SharedBaseAddress                         = 34359738368     {product}\n    uintx SharedMiscCodeSize                        = 122880          {product}\n    uintx SharedMiscDataSize                        = 4194304         {product}\n    uintx SharedReadOnlySize                        = 16777216        {product}\n    uintx SharedReadWriteSize                       = 16777216        {product}\n     bool ShowMessageBoxOnError                     = false           {product}\n     intx SoftRefLRUPolicyMSPerMB                   = 1000            {product}\n     bool SpecialEncodeISOArray                     = true            {C2 product}\n     bool SplitIfBlocks                             = true            {C2 product}\n     intx StackRedPages                             = 1               {pd product}\n     intx StackShadowPages                          = 20              {pd product}\n     bool StackTraceInThrowable                     = true            {product}\n     intx StackYellowPages                          = 2               {pd product}\n     bool StartAttachListener                       = false           {product}\n     intx StarvationMonitorInterval                 = 200             {product}\n     bool StressLdcRewrite                          = false           {product}\n    uintx StringTableSize                           = 60013           {product}\n     bool SuppressFatalErrorMessage                 = false           {product}\n    uintx SurvivorPadding                           = 3               {product}\n    uintx SurvivorRatio                             = 8               {product}\n     intx SuspendRetryCount                         = 50              {product}\n     intx SuspendRetryDelay                         = 5               {product}\n     intx SyncFlags                                 = 0               {product}\n    ccstr SyncKnobs                                 =                 {product}\n     intx SyncVerbose                               = 0               {product}\n    uintx TLABAllocationWeight                      = 35              {product}\n    uintx TLABRefillWasteFraction                   = 64              {product}\n    uintx TLABSize                                  = 0               {product}\n     bool TLABStats                                 = true            {product}\n    uintx TLABWasteIncrement                        = 4               {product}\n    uintx TLABWasteTargetPercent                    = 1               {product}\n    uintx TargetPLABWastePct                        = 10              {product}\n    uintx TargetSurvivorRatio                       = 50              {product}\n    uintx TenuredGenerationSizeIncrement            = 20              {product}\n    uintx TenuredGenerationSizeSupplement           = 80              {product}\n    uintx TenuredGenerationSizeSupplementDecay      = 2               {product}\n     intx ThreadPriorityPolicy                      = 0               {product}\n     bool ThreadPriorityVerbose                     = false           {product}\n    uintx ThreadSafetyMargin                        = 52428800        {product}\n     intx ThreadStackSize                           = 1024            {pd product}\n    uintx ThresholdTolerance                        = 10              {product}\n     intx Tier0BackedgeNotifyFreqLog                = 10              {product}\n     intx Tier0InvokeNotifyFreqLog                  = 7               {product}\n     intx Tier0ProfilingStartPercentage             = 200             {product}\n     intx Tier23InlineeNotifyFreqLog                = 20              {product}\n     intx Tier2BackEdgeThreshold                    = 0               {product}\n     intx Tier2BackedgeNotifyFreqLog                = 14              {product}\n     intx Tier2CompileThreshold                     = 0               {product}\n     intx Tier2InvokeNotifyFreqLog                  = 11              {product}\n     intx Tier3BackEdgeThreshold                    = 60000           {product}\n     intx Tier3BackedgeNotifyFreqLog                = 13              {product}\n     intx Tier3CompileThreshold                     = 2000            {product}\n     intx Tier3DelayOff                             = 2               {product}\n     intx Tier3DelayOn                              = 5               {product}\n     intx Tier3InvocationThreshold                  = 200             {product}\n     intx Tier3InvokeNotifyFreqLog                  = 10              {product}\n     intx Tier3LoadFeedback                         = 5               {product}\n     intx Tier3MinInvocationThreshold               = 100             {product}\n     intx Tier4BackEdgeThreshold                    = 40000           {product}\n     intx Tier4CompileThreshold                     = 15000           {product}\n     intx Tier4InvocationThreshold                  = 5000            {product}\n     intx Tier4LoadFeedback                         = 3               {product}\n     intx Tier4MinInvocationThreshold               = 600             {product}\n     bool TieredCompilation                         = true            {pd product}\n     intx TieredCompileTaskTimeout                  = 50              {product}\n     intx TieredRateUpdateMaxTime                   = 25              {product}\n     intx TieredRateUpdateMinTime                   = 1               {product}\n     intx TieredStopAtLevel                         = 4               {product}\n     bool TimeLinearScan                            = false           {C1 product}\n     bool TraceBiasedLocking                        = false           {product}\n     bool TraceClassLoading                         = false           {product rw}\n     bool TraceClassLoadingPreorder                 = false           {product}\n     bool TraceClassResolution                      = false           {product}\n     bool TraceClassUnloading                       = false           {product rw}\n     bool TraceDynamicGCThreads                     = false           {product}\n     bool TraceGen0Time                             = false           {product}\n     bool TraceGen1Time                             = false           {product}\n    ccstr TraceJVMTI                                =                 {product}\n     bool TraceLoaderConstraints                    = false           {product rw}\n     bool TraceMetadataHumongousAllocation          = false           {product}\n     bool TraceMonitorInflation                     = false           {product}\n     bool TraceParallelOldGCTasks                   = false           {product}\n     intx TraceRedefineClasses                      = 0               {product}\n     bool TraceSafepointCleanupTime                 = false           {product}\n     bool TraceSuspendWaitFailures                  = false           {product}\n     intx TrackedInitializationLimit                = 50              {C2 product}\n     bool TransmitErrorReport                       = false           {product}\n     intx TypeProfileArgsLimit                      = 2               {product}\n    uintx TypeProfileLevel                          = 0               {pd product}\n     intx TypeProfileMajorReceiverPercent           = 90              {C2 product}\n     intx TypeProfileParmsLimit                     = 2               {product}\n     intx TypeProfileWidth                          = 2               {product}\n     intx UnguardOnExecutionViolation               = 0               {product}\n     bool UnlinkSymbolsALot                         = false           {product}\n     bool Use486InstrsOnly                          = false           {ARCH product}\n     bool UseAES                                    = true            {product}\n     bool UseAESIntrinsics                          = true            {product}\n     intx UseAVX                                    = 1               {ARCH product}\n     bool UseAdaptiveGCBoundary                     = false           {product}\n     bool UseAdaptiveGenerationSizePolicyAtMajorCollection  = true            {product}\n     bool UseAdaptiveGenerationSizePolicyAtMinorCollection  = true            {product}\n     bool UseAdaptiveNUMAChunkSizing                = true            {product}\n     bool UseAdaptiveSizeDecayMajorGCCost           = true            {product}\n     bool UseAdaptiveSizePolicy                     = true            {product}\n     bool UseAdaptiveSizePolicyFootprintGoal        = true            {product}\n     bool UseAdaptiveSizePolicyWithSystemGC         = false           {product}\n     bool UseAddressNop                             = true            {ARCH product}\n     bool UseAltSigs                                = false           {product}\n     bool UseAutoGCSelectPolicy                     = false           {product}\n     bool UseBiasedLocking                          = true            {product}\n     bool UseBimorphicInlining                      = true            {C2 product}\n     bool UseBoundThreads                           = true            {product}\n     bool UseBsdPosixThreadCPUClocks                = true            {product}\n     bool UseCLMUL                                  = true            {ARCH product}\n     bool UseCMSBestFit                             = true            {product}\n     bool UseCMSCollectionPassing                   = true            {product}\n     bool UseCMSCompactAtFullCollection             = true            {product}\n     bool UseCMSInitiatingOccupancyOnly             = false           {product}\n     bool UseCRC32Intrinsics                        = true            {product}\n     bool UseCodeCacheFlushing                      = true            {product}\n     bool UseCompiler                               = true            {product}\n     bool UseCompilerSafepoints                     = true            {product}\n     bool UseCompressedClassPointers               := true            {lp64_product}\n     bool UseCompressedOops                        := true            {lp64_product}\n     bool UseConcMarkSweepGC                        = false           {product}\n     bool UseCondCardMark                           = false           {C2 product}\n     bool UseCountLeadingZerosInstruction           = false           {ARCH product}\n     bool UseCounterDecay                           = true            {product}\n     bool UseDivMod                                 = true            {C2 product}\n     bool UseDynamicNumberOfGCThreads               = false           {product}\n     bool UseFPUForSpilling                         = false           {C2 product}\n     bool UseFastAccessorMethods                    = false           {product}\n     bool UseFastEmptyMethods                       = false           {product}\n     bool UseFastJNIAccessors                       = true            {product}\n     bool UseFastStosb                              = true            {ARCH product}\n     bool UseG1GC                                   = false           {product}\n     bool UseGCLogFileRotation                      = false           {product}\n     bool UseGCOverheadLimit                        = true            {product}\n     bool UseGCTaskAffinity                         = false           {product}\n     bool UseHeavyMonitors                          = false           {product}\n     bool UseHugeTLBFS                              = false           {product}\n     bool UseInlineCaches                           = true            {product}\n     bool UseInterpreter                            = true            {product}\n     bool UseJumpTables                             = true            {C2 product}\n     bool UseLWPSynchronization                     = true            {product}\n     bool UseLargePages                             = false           {pd product}\n     bool UseLargePagesInMetaspace                  = false           {product}\n     bool UseLargePagesIndividualAllocation         = false           {pd product}\n     bool UseLockedTracing                          = false           {product}\n     bool UseLoopCounter                            = true            {product}\n     bool UseLoopInvariantCodeMotion                = true            {C1 product}\n     bool UseLoopPredicate                          = true            {C2 product}\n     bool UseMaximumCompactionOnSystemGC            = true            {product}\n     bool UseMembar                                 = true            {pd product}\n     bool UseNUMA                                   = false           {product}\n     bool UseNUMAInterleaving                       = false           {product}\n     bool UseNewLongLShift                          = false           {ARCH product}\n     bool UseOSErrorReporting                       = false           {pd product}\n     bool UseOldInlining                            = true            {C2 product}\n     bool UseOnStackReplacement                     = true            {pd product}\n     bool UseOnlyInlinedBimorphic                   = true            {C2 product}\n     bool UseOprofile                               = false           {product}\n     bool UseOptoBiasInlining                       = true            {C2 product}\n     bool UsePPCLWSYNC                              = true            {product}\n     bool UsePSAdaptiveSurvivorSizePolicy           = true            {product}\n     bool UseParNewGC                               = false           {product}\n     bool UseParallelGC                            := true            {product}\n     bool UseParallelOldGC                          = true            {product}\n     bool UsePerfData                               = true            {product}\n     bool UsePopCountInstruction                    = true            {product}\n     bool UseRDPCForConstantTableBase               = false           {C2 product}\n     bool UseSHM                                    = false           {product}\n     intx UseSSE                                    = 4               {product}\n     bool UseSSE42Intrinsics                        = true            {product}\n     bool UseSerialGC                               = false           {product}\n     bool UseSharedSpaces                           = false           {product}\n     bool UseSignalChaining                         = true            {product}\n     bool UseStoreImmI16                            = false           {ARCH product}\n     bool UseSuperWord                              = true            {C2 product}\n     bool UseTLAB                                   = true            {pd product}\n     bool UseThreadPriorities                       = true            {pd product}\n     bool UseTypeProfile                            = true            {product}\n     bool UseUnalignedLoadStores                    = true            {ARCH product}\n     bool UseVMInterruptibleIO                      = false           {product}\n     bool UseXMMForArrayCopy                        = true            {product}\n     bool UseXmmI2D                                 = false           {ARCH product}\n     bool UseXmmI2F                                 = false           {ARCH product}\n     bool UseXmmLoadAndClearUpper                   = true            {ARCH product}\n     bool UseXmmRegToRegMoveAll                     = true            {ARCH product}\n     bool VMThreadHintNoPreempt                     = false           {product}\n     intx VMThreadPriority                          = -1              {product}\n     intx VMThreadStackSize                         = 1024            {pd product}\n     intx ValueMapInitialSize                       = 11              {C1 product}\n     intx ValueMapMaxLoopSize                       = 8               {C1 product}\n     intx ValueSearchLimit                          = 1000            {C2 product}\n     bool VerifyMergedCPBytecodes                   = true            {product}\n     intx WorkAroundNPTLTimedWaitHang               = 1               {product}\n    uintx YoungGenerationSizeIncrement              = 20              {product}\n    uintx YoungGenerationSizeSupplement             = 80              {product}\n    uintx YoungGenerationSizeSupplementDecay        = 8               {product}\n    uintx YoungPLABSize                             = 4096            {product}\n     bool ZeroTLAB                                  = false           {product}\n     intx hashCode                                  = 5               {product}\n```\n即时编译参数\n* `CompileThreshold`:触发即时编译的阈值\n* `OnStackReplacePercentage`:OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`:即时编译器编译的代码缓存使得最大值\n\n类型加载参数\n* `UseSplitVerifier`:使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`:当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`:在校验阶段放松对类型访问性的限制\n\n多线程相关参数\n* `UseSpinning`:开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`:使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`:使用本地线程优先级\n* `UseBiaseLocking`:是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`:当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n性能参数\n* `AggressiveOpts`:使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`:如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`:使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`:是否使用字符串缓存,开启则使用\n\n*给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=$debug_port\n```\n* suspend:这个参数是用来当JVM启动之后等待debug客户端连接,如果没有debug客户端连接,那么虚拟机就会一直等待，造成假死的现象\n* `-XX:+UseVMInterruptibleIO`:线程中断前或是EINTR在OS_INTRPT中对于I/O操作的结果\n* `-XX:+FailOverToOldVerifier`:当新的类型检测器失败时切换到旧的认证器\n* `-XX:-AllowUserSignalHandlers`:允许为java进程安装信号处理器（限于Linux和Solaris,默认关闭）\n* `-XX:AllocatePrefetchStyle=1`:预取指令的产生代码风格：0-没有预取指令,1-每一次分配内存就执行预取指令,2-当执行预取代码指令时,用TLAB分配水印指针指向门\n* `-XX:AllocatePrefetchLines=1`:在使用JIT生成的预读取指令分配对象后读取的缓存行数.如果上次分配的对象是一个实例则默认值是1,如果是一个数组则是3\n* `-XX:+OptimizeStringConcat`:对字符串拼接进行优化\n* `-XX:+UseCompressedStrings`:如果可以表示为纯ASCII的话,则用byte[]代替字符串.\n* `-XX:+UseBiasedLocking`:使用偏锁.\n* `-XX:LoopUnrollLimit=n`:代表节点数目小于给定值时打开循环体.\n* `-XX:+PerfDataSaveToFile`:Jvm退出时保存jvmstat的二进制数据.\n* `-XX:+AlwaysPreTouch`:当JVM初始化时预先对Java堆进行预先摸底(堆中每个页归零处理).\n* `-XX:InlineSmallCode=n`:当编译的代码小于指定的值时,内联编译的代码.\n* `-XX:InitialTenuringThreshold=7`:设置初始的对象在新生代中最大存活次数.\n* `-XX:+UseCompressedOops`:使用compressedpointers.这个参数默认在64bit的环境下默认启动,但是如果JVM的内存达到32G后,这个参数就会默认为不启动,因为32G内存后,压缩就没有多大必要了,要管理那么大的内存指针也需要很大的宽度了\n* `-XX:AllocatePrefetchDistance=n`:为对象分配设置预取距离.\n* `-XX:MaxInlineSize=35`:内联函数最大的字节码大小.\n* `-XX:-TraceClassResolution`:追踪常量池resolutions.\n* `-XX:FreqInlineSize=n`:经常执行方法内联的最大字节大小\n* `-XX:-TraceLoaderConstraints`:跟踪加载器的限制记录.\n","source":"_posts/jvm/JVM日志输出.md","raw":"category: JVM\ndate: 2014-11-28\ntitle: JVM 日志输出\n---\n本文主要列举了JVM中常用的日志输出参数\n\n## GC 输出\n###  PrintGC\n在jvm选项上添加上这个参数,只要遇上GC就会输出GC日志. 我们写一个测试程序\n```java\npublic class TestPrintGCDetails {\n    public static void main(String[] args) {\n        for (int i = 0; i < 3; i++) {\n            byte[] bytes = new byte[1024 * 924 * 7];\n            System.out.println(\"Allocate \" + i);\n        }\n    }\n}\n```\n我们采用虚拟机参数`-XX:+PrintGC -Xmx10M -Xms10M`看一下结果\n```xml\nAllocate 0\n[GC (Allocation Failure)  8003K->7116K(9728K), 0.0013420 secs]\n[Full GC (Ergonomics)  7116K->624K(9728K), 0.0063270 secs]\nAllocate 1\n[Full GC (Ergonomics)  7191K->592K(9728K), 0.0068230 secs]\nAllocate 2\n```\n我们看到一共进行里3次GC(1次新生代GC, 俩次Full GC)\n1. GC前, 堆使用内存为8003K, GC后堆内存使用为7116K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0013420秒\n2. GC前, 堆使用内存为7116K, GC后堆内存使用为624K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0063270秒\n3. GC前, 堆使用内存为7191K, GC后堆内存使用为592K, 当前堆可用的堆内存为9728K, 本次GC耗时0.0068230秒\n\n###  PrintGCDetails\n这个参数相比于PrintGC,会输出更加详细的信息. 同样使用上面的测试程序, 然后使用虚拟机参数`-XX:+PrintGCDetails -Xmx10M -Xms10M`, 然后看一下输出\n```xml\nAllocate 0\n[GC (Allocation Failure) [PSYoungGen: 1535K->512K(2560K)] 8003K->7136K(9728K), 0.0020620 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\n[Full GC (Ergonomics) [PSYoungGen: 512K->0K(2560K)] [ParOldGen: 6624K->623K(7168K)] 7136K->623K(9728K), [Metaspace: 3089K->3089K(1056768K)], 0.0067020 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAllocate 1\n[Full GC (Ergonomics) [PSYoungGen: 77K->0K(2560K)] [ParOldGen: 7091K->592K(7168K)] 7168K->592K(9728K), [Metaspace: 3092K->3092K(1056768K)], 0.0070690 secs] [Times: user=0.02 sys=0.00, real=0.00 secs]\nAllocate 2\nHeap\n PSYoungGen      total 2560K, used 78K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 3% used [0x00000007bfd00000,0x00000007bfd138e0,0x00000007bff00000)\n  from space 512K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007bff80000)\n  to   space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n ParOldGen       total 7168K, used 7060K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 98% used [0x00000007bf600000,0x00000007bfce5308,0x00000007bfd00000)\n Metaspace       used 3099K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 340K, capacity 386K, committed 512K, reserved 1048576K\n```\nGC过程为\n1. 新生代GC, 新生代已用内存从1535K变为512K, 新生代可用内存为2560K. 整个堆内存从8003K变为7136K,整个堆可用内存为9728K, 耗时为0.0020620 秒.\n2. Full GC, 新生代将已用内存512k清空, 可用内存为2560K. 老年代已用内存从7091K变成592K, 整个老年代可用内存为7168K. 整个堆内存已用内存从7136K变成623K, 整个堆可用内存为9728K. Metaspace区(Java8里的方法区)没有回收, 整个Full GC耗时0.0067020 秒.\n\n最后还输出了虚拟机退出时, 整个虚拟机的内存分布情况\n1. 新生代总共有2560K的内存, 使用了78K\n2. 新生代eden区为2048K, 使用了3%\n3. 新生代survivor区(from部分)为512k, 没有使用\n4. 新生代survivor区(to部分)为512k, 没有使用\n5. 老年代(ParOld垃圾回收器) 总共内存为7168K, 使用里7060K.\n\n###  PrintHeapAtGC\n这个参数会在GC前后打印出堆内信息\n```java\npublic class TestPrintGCDetails {\n    public static void main(String[] args) {\n        for (int i = 0; i < 2; i++) {\n            byte[] bytes = new byte[1024 * 924 * 7];\n            System.out.println(\"Allocate \" + i);\n        }\n    }\n}\n```\n我们使用虚拟机参数`-XX:+PrintHeapAtGC -Xmx10M -Xms10M`运行程序输出结果\n```xml\nAllocate 0\n{Heap before GC invocations=1 (full 0):\n PSYoungGen      total 2560K, used 1535K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 74% used [0x00000007bfd00000,0x00000007bfe7fe40,0x00000007bff00000)\n  from space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n  to   space 512K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007bff80000)\n ParOldGen       total 7168K, used 6468K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 90% used [0x00000007bf600000,0x00000007bfc51010,0x00000007bfd00000)\n Metaspace       used 3097K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 339K, capacity 386K, committed 512K, reserved 1048576K\nHeap after GC invocations=1 (full 0):\n PSYoungGen      total 2560K, used 512K [0x00000007bfd00000, 0x00000007c0000000, 0x00000007c0000000)\n  eden space 2048K, 0% used [0x00000007bfd00000,0x00000007bfd00000,0x00000007bff00000)\n  from space 512K, 100% used [0x00000007bff00000,0x00000007bff80000,0x00000007bff80000)\n  to   space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000)\n ParOldGen       total 7168K, used 6616K [0x00000007bf600000, 0x00000007bfd00000, 0x00000007bfd00000)\n  object space 7168K, 92% used [0x00000007bf600000,0x00000007bfc763a8,0x00000007bfd00000)\n Metaspace       used 3097K, capacity 4494K, committed 4864K, reserved 1056768K\n  class space    used 339K, capacity 386K, committed 512K, reserved 1048576K\n}\n{Heap before GC invocations=2 (full 1):\n ...\n}\nAllocate 1\n```\n限于篇幅, 我只输出了一次的GC日志. 大部分的内容解释我们都可以在`PrintGCDetails`例子解释中找到答案. 需要特别指出的是\n* invocations=1 : 代表这是第一次GC\n* (full 0) : 表示虚拟机进行的Full GC的次数\n\n###  PrintGCTimeStamps\n这个参数会在每次GC的时候,输出GC发生的时间. \u0010们还是使用上面的测试程序, 指定虚拟机参数`-XX:+PrintGC -XX:+PrintGCTimeStamps -Xmx10M -Xms10M`看一下输出结果\n```xml\nAllocate 0\n0.285: [GC (Allocation Failure)  8003K->7124K(9728K), 0.0015210 secs]\n0.286: [Full GC (Ergonomics)  7124K->622K(9728K), 0.0072690 secs]\nAllocate 1\n```\n1. 第一次GC发生在JVM启动0.285秒时进行的\n2. 第二次GC发生在JVM启动0.286秒时进行的\n\n###  PrintGCApplicationConcurrentTime\n打印应用程序的执行时间. 我们使用`-XX:+PrintGC -XX:+PrintGCApplicationConcurrentTime -Xmx10M -Xms10M`虚拟机参数运行一下上面的程序, 看一下输出结果为\n```xml\nAllocate 0\nApplication time: 0.1094100 seconds\n[GC (Allocation Failure)  8003K->7136K(9728K), 0.0018960 secs]\n[Full GC (Ergonomics)  7136K->623K(9728K), 0.0080650 secs]\nAllocate 1\nApplication time: 0.0026340 seconds\n```\n\n###  PrintGCApplicationStoppedTime\n打印程序因为GC停顿的时间. 同样使用虚拟机参数`-XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -Xmx10M -Xms10M`, 运行一下上面的程序\n```xml\nAllocate 0\n[GC (Allocation Failure)  8003K->7120K(9728K), 0.0014070 secs]\n[Full GC (Ergonomics)  7120K->623K(9728K), 0.0073180 secs]\nTotal time for which application threads were stopped: 0.0089770 seconds\nAllocate 1\n```\n我们看到整个应用在Full GC时, 停顿了 0.0089770 秒.\n\n###  PrintGCDateStamps\n仍然使用上面的测试程序, 然后使用JVM参数`-XX:+PrintGC -Xmx10M -Xms10M -XX:+PrintGCDateStamps`. 结果为\n```bash\n2016-05-18T17:28:34.689+0800: [GC (Allocation Failure)  2028K->1006K(9728K), 0.0076949 secs]\n2016-05-18T17:28:34.741+0800: [GC (Allocation Failure)  3052K->1565K(9728K), 0.0191430 secs]\n2016-05-18T17:28:34.772+0800: [GC (Allocation Failure)  1750K->1597K(9728K), 0.0088998 secs]\n2016-05-18T17:28:34.781+0800: [GC (Allocation Failure)  1597K->1603K(9728K), 0.0371759 secs]\n2016-05-18T17:28:34.818+0800: [Full GC (Allocation Failure)  1603K->1068K(9728K), 0.0078928 secs]\n2016-05-18T17:28:34.826+0800: [GC (Allocation Failure)  1068K->1068K(9728K), 0.0185343 secs]\n2016-05-18T17:28:34.844+0800: [Full GC (Allocation Failure)  1068K->1041K(9728K), 0.0176116 secs]\n```\n这个时间输出比PrintGCTimeStamps可读性更好, 因为它输出的是系统时间\n\n###  PrintTenuringDistribution\n打印GC后新生代各个年龄对象的大小。 我们使用最开始的测试程序, 然后指定JVM参数`-XX:+PrintGC -Xmx10M -Xms10M -XX:+PrintTenuringDistribution`, 看一下结果\n```bash\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 2028K->1025K(9728K), 0.0150981 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 3071K->1579K(9728K), 0.0141280 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 1743K->1635K(9728K), 0.0125040 secs]\n[GC (Allocation Failure)\nDesired survivor size 524288 bytes, new threshold 7 (max 15)\n 1635K->1619K(9728K), 0.0136705 secs]\n[Full GC (Allocation Failure)  1619K->1401K(9728K), 0.0138036 secs]\n[GC (Allocation Failure)\nDesired survivor size 1048576 bytes, new threshold 6 (max 15)\n 1401K->1401K(9728K), 0.0018372 secs]\n[Full GC (Allocation Failure)  1401K->1374K(9728K), 0.0294141 secs]\n```\n\n### GC日志文件\n* UseGCLogFileRotation : 开启GC日志文件切分功能,前置选项-Xloggc, `-XX:+UseGCLogFileRotation`\n* NumberOfGCLogFiles : 设置Gc日志文件的数量(必须大于1), `-XX:NumberOfGCLogFiles=10`\n* GCLogFileSize : gc日志文件大小(必须>=8K), `-XX:GCLogFileSize=8K`\n* Xloggc : `-Xloggc:<filename>`gc日志文件\n我们使用测试程序\n```java\n\n```\n然后指定虚拟机参数`-XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:NumberOfGCLogFiles=3 -XX:GCLogFileSize=10K -XX:+UseGCLogFileRotation -Xloggc:gc.log`来运行一下. 最后我们会看到三个文件\n* gc.log.1 (11,016 字节)\n* gc.log.2 (11,755 字节)\n* gc.log.0.current (780 字节)\n我们看到使用这四个参数已经成功将日志输出到三个文件中.\n> 注意每次生成日志的时候都会将上次运行JVM的日志覆盖掉. 因此每次关服重启时, 最好将日志文件备份一下.\n\n## 异常输出\n\n###  HeapDumpOnOutOfMemoryError\n在发生内存溢出异常时是否生成堆转储快照,关闭则不生成`-XX:+HeapDumpOnOutOfMemoryError`\n\n> `-XX:HeapDumpPath=./java_pid<pid>.hprof`:堆内存溢出存放日志目录.\n\n###  OnOutOfMemoryError\n当虚拟机抛出内存溢出异常时,执行指令的命令`-XX:+OnOutOfMemoryError`\n\n###  OnError\n当虚拟机抛出ERROR异常时,执行指令的命令`-XX:+OnError`\n\n> `-XX:ErrorFile=./hs_err_pid<pid>.log`:如果有Error发生,则将Error输入到该日志.\n\n## 运行时状态\n\n###  PrintReferenceGC\n追踪系统内的软引用,弱引用,虚引用和Finallize队列的话可以使用`PrintReferenceGC`.\n\n###  verbose:class\n* `-verbose:class` : 跟踪类的加载和卸载\n* `-XX:+TraceClassLoading` : 追踪类的加载\n* `-XX:+TraceClassUnloading` : 追踪类的卸载\n我们运行最开始的那个测试程序, 看一下JVM启动时加载的类`-verbose:class`\n```bash\n[Opened /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/rt.jar]\n[Loaded java.lang.Object from /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/jre/lib/rt.jar]\n```\n这个特性用在使用ASM动态生成类的应用中特别有用, 因为这些类是由逻辑代码控制的, 加载这些类的行为具有一定的隐蔽性, 因此我们可以在虚拟机启动时, 加上这个参数做日志分析用.\n\n###  CITime\n`-XX:+CITime`:打印`JITCompiler`的耗时\n\n###  PrintConcurrentLocks\n打印J.U.C中的状态`-XX:+PrintConcurrentLocks`\n\n###  PrintCompilation\n显示所有可设置的参数及它们的值(从JDK6update21开始才可以用)`-XX:+`\n\n###  PrintInlining\n打印方法内联信息`-XX:+PrintInlining`\n\n###  PrintAssembly\n打印即时编译后的二进制信息\n\n###  PrintAdaptiveSizePolicy\n`-XX:-PrintAdaptiveSizePolicy` :打印JVM自动划分新生代和老生代大小信息.\n> 这个选项最好和-XX:+PrintGCDetails以及-XX:+PrintGCDateStamps或者-XX:+PrintGCTimeStamps一起使用.以GCAdaptiveSizePolicy开头的一些额外信息输出来了，survived标签表明“to” survivor空间的对象字节数。在这个例子中，survivor空间占用量是224408984字节，但是移动到old代的字节数却有10904856字节。overflow表明young代是否有对象溢出到old代，换句话说，就是表明了“to” survivor是否有足够的空间来容纳从eden空间和“from”survivor空间移动而来的对象。为了更好的吞吐量，期望在应用处于稳定运行状态下，survivor空间不要溢出。\n\n## 系统相关\n\n###  PrintVMOptions\n输出程序启动时, 虚拟机接收到命令行指定的参数. 我们指定虚拟机参数`-XX:+PrintVMOptions -Xmx10M -Xms10M`, 输出结果为\n```bash\nVM option '+PrintVMOptions'\n```\n> TODO 为什么输出只有PrintVMOptions, 而没有-Xmx10M -Xms10M呢?\n\n###  PrintCommandLineFlags\n打印启动虚拟机时输入的非稳定参数`-XX:+PrintCommandLineFlags`\n```xml\n-XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC\n```\n\n###  PrintFlagsFinal\n输出所有的系统的参数的值, 我们使用-XX:+PrintFlagsFinal`, 看一下结果\n```bash\n[Global flags]\n    uintx AdaptiveSizeDecrementScaleFactor          = 4               {product}\n    uintx AdaptiveSizeMajorGCDecayTimeScale         = 10              {product}\n    uintx AdaptiveSizePausePolicy                   = 0               {product}\n    uintx AdaptiveSizePolicyCollectionCostMargin    = 50              {product}\n    uintx AdaptiveSizePolicyInitializingSteps       = 20              {product}\n    uintx AdaptiveSizePolicyOutputInterval          = 0               {product}\n    uintx AdaptiveSizePolicyWeight                  = 10              {product}\n    uintx AdaptiveSizeThroughPutPolicy              = 0               {product}\n    uintx AdaptiveTimeWeight                        = 25              {product}\n     bool AdjustConcurrency                         = false           {product}\n     bool AggressiveOpts                            = false           {product}\n     intx AliasLevel                                = 3               {C2 product}\n     bool AlignVector                               = false           {C2 product}\n     intx AllocateInstancePrefetchLines             = 1               {product}\n     intx AllocatePrefetchDistance                  = 192             {product}\n     intx AllocatePrefetchInstr                     = 0               {product}\n     intx AllocatePrefetchLines                     = 4               {product}\n     intx AllocatePrefetchStepSize                  = 64              {product}\n     intx AllocatePrefetchStyle                     = 1               {product}\n     bool AllowJNIEnvProxy                          = false           {product}\n     bool AllowNonVirtualCalls                      = false           {product}\n     bool AllowParallelDefineClass                  = false           {product}\n     bool AllowUserSignalHandlers                   = false           {product}\n     bool AlwaysActAsServerClassMachine             = false           {product}\n     bool AlwaysCompileLoopMethods                  = false           {product}\n     bool AlwaysLockClassLoader                     = false           {product}\n     bool AlwaysPreTouch                            = false           {product}\n     bool AlwaysRestoreFPU                          = false           {product}\n     bool AlwaysTenure                              = false           {product}\n     bool AssertOnSuspendWaitFailure                = false           {product}\n     bool AssumeMP                                  = false           {product}\n     intx AutoBoxCacheMax                           = 128             {C2 product}\n    uintx AutoGCSelectPauseMillis                   = 5000            {product}\n     intx BCEATraceLevel                            = 0               {product}\n     intx BackEdgeThreshold                         = 100000          {pd product}\n     bool BackgroundCompilation                     = true            {pd product}\n    uintx BaseFootPrintEstimate                     = 268435456       {product}\n     intx BiasedLockingBulkRebiasThreshold          = 20              {product}\n     intx BiasedLockingBulkRevokeThreshold          = 40              {product}\n     intx BiasedLockingDecayTime                    = 25000           {product}\n     intx BiasedLockingStartupDelay                 = 4000            {product}\n     bool BindGCTaskThreadsToCPUs                   = false           {product}\n     bool BlockLayoutByFrequency                    = true            {C2 product}\n     intx BlockLayoutMinDiamondPercentage           = 20              {C2 product}\n     bool BlockLayoutRotateLoops                    = true            {C2 product}\n     bool BranchOnRegister                          = false           {C2 product}\n     bool BytecodeVerificationLocal                 = false           {product}\n     bool BytecodeVerificationRemote                = true            {product}\n     bool C1OptimizeVirtualCallProfiling            = true            {C1 product}\n     bool C1ProfileBranches                         = true            {C1 product}\n     bool C1ProfileCalls                            = true            {C1 product}\n     bool C1ProfileCheckcasts                       = true            {C1 product}\n     bool C1ProfileInlinedCalls                     = true            {C1 product}\n     bool C1ProfileVirtualCalls                     = true            {C1 product}\n     bool C1UpdateMethodData                        = true            {C1 product}\n     intx CICompilerCount                           = 2               {product}\n     bool CICompilerCountPerCPU                     = true            {product}\n     bool CITime                                    = false           {product}\n     bool CMSAbortSemantics                         = false           {product}\n    uintx CMSAbortablePrecleanMinWorkPerIteration   = 100             {product}\n     intx CMSAbortablePrecleanWaitMillis            = 100             {manageable}\n    uintx CMSBitMapYieldQuantum                     = 10485760        {product}\n    uintx CMSBootstrapOccupancy                     = 50              {product}\n     bool CMSClassUnloadingEnabled                  = true            {product}\n    uintx CMSClassUnloadingMaxInterval              = 0               {product}\n     bool CMSCleanOnEnter                           = true            {product}\n     bool CMSCompactWhenClearAllSoftRefs            = true            {product}\n    uintx CMSConcMarkMultiple                       = 32              {product}\n     bool CMSConcurrentMTEnabled                    = true            {product}\n    uintx CMSCoordinatorYieldSleepCount             = 10              {product}\n     bool CMSDumpAtPromotionFailure                 = false           {product}\n     bool CMSEdenChunksRecordAlways                 = true            {product}\n    uintx CMSExpAvgFactor                           = 50              {product}\n     bool CMSExtrapolateSweep                       = false           {product}\n    uintx CMSFullGCsBeforeCompaction                = 0               {product}\n    uintx CMSIncrementalDutyCycle                   = 10              {product}\n    uintx CMSIncrementalDutyCycleMin                = 0               {product}\n     bool CMSIncrementalMode                        = false           {product}\n    uintx CMSIncrementalOffset                      = 0               {product}\n     bool CMSIncrementalPacing                      = true            {product}\n    uintx CMSIncrementalSafetyFactor                = 10              {product}\n    uintx CMSIndexedFreeListReplenish               = 4               {product}\n     intx CMSInitiatingOccupancyFraction            = -1              {product}\n    uintx CMSIsTooFullPercentage                    = 98              {product}\n   double CMSLargeCoalSurplusPercent                = 0.950000        {product}\n   double CMSLargeSplitSurplusPercent               = 1.000000        {product}\n     bool CMSLoopWarn                               = false           {product}\n    uintx CMSMaxAbortablePrecleanLoops              = 0               {product}\n     intx CMSMaxAbortablePrecleanTime               = 5000            {product}\n    uintx CMSOldPLABMax                             = 1024            {product}\n    uintx CMSOldPLABMin                             = 16              {product}\n    uintx CMSOldPLABNumRefills                      = 4               {product}\n    uintx CMSOldPLABReactivityFactor                = 2               {product}\n     bool CMSOldPLABResizeQuicker                   = false           {product}\n    uintx CMSOldPLABToleranceFactor                 = 4               {product}\n     bool CMSPLABRecordAlways                       = true            {product}\n    uintx CMSParPromoteBlocksToClaim                = 16              {product}\n     bool CMSParallelInitialMarkEnabled             = true            {product}\n     bool CMSParallelRemarkEnabled                  = true            {product}\n     bool CMSParallelSurvivorRemarkEnabled          = true            {product}\n    uintx CMSPrecleanDenominator                    = 3               {product}\n    uintx CMSPrecleanIter                           = 3               {product}\n    uintx CMSPrecleanNumerator                      = 2               {product}\n     bool CMSPrecleanRefLists1                      = true            {product}\n     bool CMSPrecleanRefLists2                      = false           {product}\n     bool CMSPrecleanSurvivors1                     = false           {product}\n     bool CMSPrecleanSurvivors2                     = true            {product}\n    uintx CMSPrecleanThreshold                      = 1000            {product}\n     bool CMSPrecleaningEnabled                     = true            {product}\n     bool CMSPrintChunksInDump                      = false           {product}\n     bool CMSPrintEdenSurvivorChunks                = false           {product}\n     bool CMSPrintObjectsInDump                     = false           {product}\n    uintx CMSRemarkVerifyVariant                    = 1               {product}\n     bool CMSReplenishIntermediate                  = true            {product}\n    uintx CMSRescanMultiple                         = 32              {product}\n    uintx CMSSamplingGrain                          = 16384           {product}\n     bool CMSScavengeBeforeRemark                   = false           {product}\n    uintx CMSScheduleRemarkEdenPenetration          = 50              {product}\n    uintx CMSScheduleRemarkEdenSizeThreshold        = 2097152         {product}\n    uintx CMSScheduleRemarkSamplingRatio            = 5               {product}\n   double CMSSmallCoalSurplusPercent                = 1.050000        {product}\n   double CMSSmallSplitSurplusPercent               = 1.100000        {product}\n     bool CMSSplitIndexedFreeListBlocks             = true            {product}\n    uintx CMSTriggerRatio                           = 80              {product}\n     intx CMSWaitDuration                           = 2000            {manageable}\n    uintx CMSWorkQueueDrainThreshold                = 10              {product}\n     bool CMSYield                                  = true            {product}\n    uintx CMSYieldSleepCount                        = 0               {product}\n    uintx CMSYoungGenPerWorker                      = 67108864        {pd product}\n    uintx CMS_FLSPadding                            = 1               {product}\n    uintx CMS_FLSWeight                             = 75              {product}\n    uintx CMS_SweepPadding                          = 1               {product}\n    uintx CMS_SweepTimerThresholdMillis             = 10              {product}\n    uintx CMS_SweepWeight                           = 75              {product}\n     bool CheckJNICalls                             = false           {product}\n     bool ClassUnloading                            = true            {product}\n     intx ClearFPUAtPark                            = 0               {product}\n     bool ClipInlining                              = true            {product}\n    uintx CodeCacheExpansionSize                    = 65536           {pd product}\n    uintx CodeCacheMinimumFreeSpace                 = 512000          {product}\n     bool CollectGen0First                          = false           {product}\n     bool CompactFields                             = true            {product}\n     intx CompilationPolicyChoice                   = 3               {product}\n     intx CompilationRepeat                         = 0               {C1 product}\nccstrlist CompileCommand                            =                 {product}\n    ccstr CompileCommandFile                        =                 {product}\nccstrlist CompileOnly                               =                 {product}\n     intx CompileThreshold                          = 10000           {pd product}\n     bool CompilerThreadHintNoPreempt               = true            {product}\n     intx CompilerThreadPriority                    = -1              {product}\n     intx CompilerThreadStackSize                   = 0               {pd product}\n    uintx CompressedClassSpaceSize                  = 1073741824      {product}\n    uintx ConcGCThreads                             = 0               {product}\n     intx ConditionalMoveLimit                      = 3               {C2 pd product}\n     intx ContendedPaddingWidth                     = 128             {product}\n     bool ConvertSleepToYield                       = true            {pd product}\n     bool ConvertYieldToSleep                       = false           {product}\n     bool CreateMinidumpOnCrash                     = false           {product}\n     bool CriticalJNINatives                        = true            {product}\n     bool DTraceAllocProbes                         = false           {product}\n     bool DTraceMethodProbes                        = false           {product}\n     bool DTraceMonitorProbes                       = false           {product}\n     bool Debugging                                 = false           {product}\n    uintx DefaultMaxRAMFraction                     = 4               {product}\n     intx DefaultThreadPriority                     = -1              {product}\n     intx DeferPollingPageLoopCount                 = -1              {product}\n     intx DeferThrSuspendLoopCount                  = 4000            {product}\n     bool DeoptimizeRandom                          = false           {product}\n     bool DisableAttachMechanism                    = false           {product}\n     bool DisableExplicitGC                         = false           {product}\n     bool DisplayVMOutputToStderr                   = false           {product}\n     bool DisplayVMOutputToStdout                   = false           {product}\n     bool DoEscapeAnalysis                          = true            {C2 product}\n     bool DontCompileHugeMethods                    = true            {product}\n     bool DontYieldALot                             = false           {pd product}\n     bool DumpReplayDataOnError                     = true            {product}\n     bool DumpSharedSpaces                          = false           {product}\n     bool EagerXrunInit                             = false           {product}\n     intx EliminateAllocationArraySizeLimit         = 64              {C2 product}\n     bool EliminateAllocations                      = true            {C2 product}\n     bool EliminateAutoBox                          = false           {C2 product}\n     bool EliminateLocks                            = true            {C2 product}\n     bool EliminateNestedLocks                      = true            {C2 product}\n     intx EmitSync                                  = 0               {product}\n     bool EnableContended                           = true            {product}\n     bool EnableTracing                             = false           {product}\n    uintx ErgoHeapSizeLimit                         = 0               {product}\n    ccstr ErrorFile                                 =                 {product}\n    ccstr ErrorReportServer                         =                 {product}\n     bool EstimateArgEscape                         = true            {product}\n     bool ExplicitGCInvokesConcurrent               = false           {product}\n     bool ExplicitGCInvokesConcurrentAndUnloadsClasses  = false           {product}\n     bool ExtendedDTraceProbes                      = false           {product}\n     bool FLSAlwaysCoalesceLarge                    = false           {product}\n    uintx FLSCoalescePolicy                         = 2               {product}\n   double FLSLargestBlockCoalesceProximity          = 0.990000        {product}\n     bool FailOverToOldVerifier                     = true            {product}\n     bool FastTLABRefill                            = true            {product}\n     intx FenceInstruction                          = 0               {ARCH product}\n     intx FieldsAllocationStyle                     = 1               {product}\n     bool FilterSpuriousWakeups                     = true            {product}\n     bool ForceNUMA                                 = false           {product}\n     bool ForceTimeHighResolution                   = false           {product}\n     intx FreqInlineSize                            = 325             {pd product}\n   double G1ConcMarkStepDurationMillis              = 10.000000       {product}\n    uintx G1ConcRSHotCardLimit                      = 4               {product}\n    uintx G1ConcRSLogCacheSize                      = 10              {product}\n     intx G1ConcRefinementGreenZone                 = 0               {product}\n     intx G1ConcRefinementRedZone                   = 0               {product}\n     intx G1ConcRefinementServiceIntervalMillis     = 300             {product}\n    uintx G1ConcRefinementThreads                   = 0               {product}\n     intx G1ConcRefinementThresholdStep             = 0               {product}\n     intx G1ConcRefinementYellowZone                = 0               {product}\n    uintx G1ConfidencePercent                       = 50              {product}\n    uintx G1HeapRegionSize                          = 0               {product}\n    uintx G1HeapWastePercent                        = 10              {product}\n    uintx G1MixedGCCountTarget                      = 8               {product}\n     intx G1RSetRegionEntries                       = 0               {product}\n    uintx G1RSetScanBlockSize                       = 64              {product}\n     intx G1RSetSparseRegionEntries                 = 0               {product}\n     intx G1RSetUpdatingPauseTimePercent            = 10              {product}\n     intx G1RefProcDrainInterval                    = 10              {product}\n    uintx G1ReservePercent                          = 10              {product}\n    uintx G1SATBBufferEnqueueingThresholdPercent    = 60              {product}\n     intx G1SATBBufferSize                          = 1024            {product}\n     intx G1UpdateBufferSize                        = 256             {product}\n     bool G1UseAdaptiveConcRefinement               = true            {product}\n    uintx GCDrainStackTargetSize                    = 64              {product}\n    uintx GCHeapFreeLimit                           = 2               {product}\n    uintx GCLockerEdenExpansionPercent              = 5               {product}\n     bool GCLockerInvokesConcurrent                 = false           {product}\n    uintx GCLogFileSize                             = 0               {product}\n    uintx GCPauseIntervalMillis                     = 0               {product}\n    uintx GCTaskTimeStampEntries                    = 200             {product}\n    uintx GCTimeLimit                               = 98              {product}\n    uintx GCTimeRatio                               = 99              {product}\n    uintx HeapBaseMinAddress                        = 2147483648      {pd product}\n     bool HeapDumpAfterFullGC                       = false           {manageable}\n     bool HeapDumpBeforeFullGC                      = false           {manageable}\n     bool HeapDumpOnOutOfMemoryError                = false           {manageable}\n    ccstr HeapDumpPath                              =                 {manageable}\n    uintx HeapFirstMaximumCompactionCount           = 3               {product}\n    uintx HeapMaximumCompactionInterval             = 20              {product}\n    uintx HeapSizePerGCThread                       = 87241520        {product}\n     bool IgnoreUnrecognizedVMOptions               = false           {product}\n    uintx IncreaseFirstTierCompileThresholdAt       = 50              {product}\n     bool IncrementalInline                         = true            {C2 product}\n    uintx InitialBootClassLoaderMetaspaceSize       = 4194304         {product}\n    uintx InitialCodeCacheSize                      = 2555904         {pd product}\n    uintx InitialHeapSize                          := 10485760        {product}\n    uintx InitialRAMFraction                        = 64              {product}\n    uintx InitialSurvivorRatio                      = 8               {product}\n    uintx InitialTenuringThreshold                  = 7               {product}\n    uintx InitiatingHeapOccupancyPercent            = 45              {product}\n     bool Inline                                    = true            {product}\n     intx InlineSmallCode                           = 2000            {pd product}\n     bool InlineSynchronizedMethods                 = true            {C1 product}\n     bool InsertMemBarAfterArraycopy                = true            {C2 product}\n     intx InteriorEntryAlignment                    = 16              {C2 pd product}\n     intx InterpreterProfilePercentage              = 33              {product}\n     bool JNIDetachReleasesMonitors                 = true            {product}\n     bool JavaMonitorsInStackTrace                  = true            {product}\n     intx JavaPriority10_To_OSPriority              = -1              {product}\n     intx JavaPriority1_To_OSPriority               = -1              {product}\n     intx JavaPriority2_To_OSPriority               = -1              {product}\n     intx JavaPriority3_To_OSPriority               = -1              {product}\n     intx JavaPriority4_To_OSPriority               = -1              {product}\n     intx JavaPriority5_To_OSPriority               = -1              {product}\n     intx JavaPriority6_To_OSPriority               = -1              {product}\n     intx JavaPriority7_To_OSPriority               = -1              {product}\n     intx JavaPriority8_To_OSPriority               = -1              {product}\n     intx JavaPriority9_To_OSPriority               = -1              {product}\n     bool LIRFillDelaySlots                         = false           {C1 pd product}\n    uintx LargePageHeapSizeThreshold                = 134217728       {product}\n    uintx LargePageSizeInBytes                      = 0               {product}\n     bool LazyBootClassLoader                       = true            {product}\n     intx LiveNodeCountInliningCutoff               = 20000           {C2 product}\n     bool LogCommercialFeatures                     = false           {product}\n     intx LoopMaxUnroll                             = 16              {C2 product}\n     intx LoopOptsCount                             = 43              {C2 product}\n     intx LoopUnrollLimit                           = 60              {C2 pd product}\n     intx LoopUnrollMin                             = 4               {C2 product}\n     bool LoopUnswitching                           = true            {C2 product}\n     bool ManagementServer                          = false           {product}\n    uintx MarkStackSize                             = 4194304         {product}\n    uintx MarkStackSizeMax                          = 536870912       {product}\n    uintx MarkSweepAlwaysCompactCount               = 4               {product}\n    uintx MarkSweepDeadRatio                        = 1               {product}\n     intx MaxBCEAEstimateLevel                      = 5               {product}\n     intx MaxBCEAEstimateSize                       = 150             {product}\n    uintx MaxDirectMemorySize                       = 0               {product}\n     bool MaxFDLimit                                = true            {product}\n    uintx MaxGCMinorPauseMillis                     = 18446744073709551615{product}\n    uintx MaxGCPauseMillis                          = 18446744073709551615{product}\n    uintx MaxHeapFreeRatio                          = 70              {product}\n    uintx MaxHeapSize                              := 10485760        {product}\n     intx MaxInlineLevel                            = 9               {product}\n     intx MaxInlineSize                             = 35              {product}\n     intx MaxJavaStackTraceDepth                    = 1024            {product}\n     intx MaxJumpTableSize                          = 65000           {C2 product}\n     intx MaxJumpTableSparseness                    = 5               {C2 product}\n     intx MaxLabelRootDepth                         = 1100            {C2 product}\n     intx MaxLoopPad                                = 11              {C2 product}\n    uintx MaxMetaspaceExpansion                     = 5451776         {product}\n    uintx MaxMetaspaceFreeRatio                     = 70              {product}\n    uintx MaxMetaspaceSize                          = 18446744073709547520{product}\n    uintx MaxNewSize                               := 3145728         {product}\n     intx MaxNodeLimit                              = 75000           {C2 product}\n uint64_t MaxRAM                                    = 137438953472    {pd product}\n    uintx MaxRAMFraction                            = 4               {product}\n     intx MaxRecursiveInlineLevel                   = 1               {product}\n    uintx MaxTenuringThreshold                      = 15              {product}\n     intx MaxTrivialSize                            = 6               {product}\n     intx MaxVectorSize                             = 16              {C2 product}\n    uintx MetaspaceSize                             = 21807104        {pd product}\n     bool MethodFlushing                            = true            {product}\n    uintx MinHeapDeltaBytes                        := 524288          {product}\n    uintx MinHeapFreeRatio                          = 40              {product}\n     intx MinInliningThreshold                      = 250             {product}\n     intx MinJumpTableSize                          = 10              {C2 pd product}\n    uintx MinMetaspaceExpansion                     = 339968          {product}\n    uintx MinMetaspaceFreeRatio                     = 40              {product}\n    uintx MinRAMFraction                            = 2               {product}\n    uintx MinSurvivorRatio                          = 3               {product}\n    uintx MinTLABSize                               = 2048            {product}\n     intx MonitorBound                              = 0               {product}\n     bool MonitorInUseLists                         = false           {product}\n     intx MultiArrayExpandLimit                     = 6               {C2 product}\n     bool MustCallLoadClassInternal                 = false           {product}\n    uintx NUMAChunkResizeWeight                     = 20              {product}\n    uintx NUMAInterleaveGranularity                 = 2097152         {product}\n    uintx NUMAPageScanRate                          = 256             {product}\n    uintx NUMASpaceResizeRate                       = 1073741824      {product}\n     bool NUMAStats                                 = false           {product}\n    ccstr NativeMemoryTracking                      = off             {product}\n     intx NativeMonitorFlags                        = 0               {product}\n     intx NativeMonitorSpinLimit                    = 20              {product}\n     intx NativeMonitorTimeout                      = -1              {product}\n     bool NeedsDeoptSuspend                         = false           {pd product}\n     bool NeverActAsServerClassMachine              = false           {pd product}\n     bool NeverTenure                               = false           {product}\n    uintx NewRatio                                  = 2               {product}\n    uintx NewSize                                  := 3145728         {product}\n    uintx NewSizeThreadIncrease                     = 5320            {pd product}\n     intx NmethodSweepActivity                      = 10              {product}\n     intx NmethodSweepCheckInterval                 = 5               {product}\n     intx NmethodSweepFraction                      = 16              {product}\n     intx NodeLimitFudgeFactor                      = 2000            {C2 product}\n    uintx NumberOfGCLogFiles                        = 0               {product}\n     intx NumberOfLoopInstrToAlign                  = 4               {C2 product}\n     intx ObjectAlignmentInBytes                    = 8               {lp64_product}\n    uintx OldPLABSize                               = 1024            {product}\n    uintx OldPLABWeight                             = 50              {product}\n    uintx OldSize                                  := 7340032         {product}\n     bool OmitStackTraceInFastThrow                 = true            {product}\nccstrlist OnError                                   =                 {product}\nccstrlist OnOutOfMemoryError                        =                 {product}\n     intx OnStackReplacePercentage                  = 140             {pd product}\n     bool OptimizeFill                              = true            {C2 product}\n     bool OptimizePtrCompare                        = true            {C2 product}\n     bool OptimizeStringConcat                      = true            {C2 product}\n     bool OptoBundling                              = false           {C2 pd product}\n     intx OptoLoopAlignment                         = 16              {pd product}\n     bool OptoScheduling                            = false           {C2 pd product}\n    uintx PLABWeight                                = 75              {product}\n     bool PSChunkLargeArrays                        = true            {product}\n     intx ParGCArrayScanChunk                       = 50              {product}\n    uintx ParGCDesiredObjsFromOverflowList          = 20              {product}\n     bool ParGCTrimOverflow                         = true            {product}\n     bool ParGCUseLocalOverflow                     = false           {product}\n    uintx ParallelGCBufferWastePct                  = 10              {product}\n    uintx ParallelGCThreads                         = 4               {product}\n     bool ParallelGCVerbose                         = false           {product}\n    uintx ParallelOldDeadWoodLimiterMean            = 50              {product}\n    uintx ParallelOldDeadWoodLimiterStdDev          = 80              {product}\n     bool ParallelRefProcBalancingEnabled           = true            {product}\n     bool ParallelRefProcEnabled                    = false           {product}\n     bool PartialPeelAtUnsignedTests                = true            {C2 product}\n     bool PartialPeelLoop                           = true            {C2 product}\n     intx PartialPeelNewPhiDelta                    = 0               {C2 product}\n    uintx PausePadding                              = 1               {product}\n     intx PerBytecodeRecompilationCutoff            = 200             {product}\n     intx PerBytecodeTrapLimit                      = 4               {product}\n     intx PerMethodRecompilationCutoff              = 400             {product}\n     intx PerMethodTrapLimit                        = 100             {product}\n     bool PerfAllowAtExitRegistration               = false           {product}\n     bool PerfBypassFileSystemCheck                 = false           {product}\n     intx PerfDataMemorySize                        = 32768           {product}\n     intx PerfDataSamplingInterval                  = 50              {product}\n    ccstr PerfDataSaveFile                          =                 {product}\n     bool PerfDataSaveToFile                        = false           {product}\n     bool PerfDisableSharedMem                      = false           {product}\n     intx PerfMaxStringConstLength                  = 1024            {product}\n     intx PreInflateSpin                            = 10              {pd product}\n     bool PreferInterpreterNativeStubs              = false           {pd product}\n     intx PrefetchCopyIntervalInBytes               = 576             {product}\n     intx PrefetchFieldsAhead                       = 1               {product}\n     intx PrefetchScanIntervalInBytes               = 576             {product}\n     bool PreserveAllAnnotations                    = false           {product}\n    uintx PretenureSizeThreshold                    = 0               {product}\n     bool PrintAdaptiveSizePolicy                   = false           {product}\n     bool PrintCMSInitiationStatistics              = false           {product}\n     intx PrintCMSStatistics                        = 0               {product}\n     bool PrintClassHistogram                       = false           {manageable}\n     bool PrintClassHistogramAfterFullGC            = false           {manageable}\n     bool PrintClassHistogramBeforeFullGC           = false           {manageable}\n     bool PrintCodeCache                            = false           {product}\n     bool PrintCodeCacheOnCompilation               = false           {product}\n     bool PrintCommandLineFlags                     = false           {product}\n     bool PrintCompilation                          = false           {product}\n     bool PrintConcurrentLocks                      = false           {manageable}\n     intx PrintFLSCensus                            = 0               {product}\n     intx PrintFLSStatistics                        = 0               {product}\n     bool PrintFlagsFinal                          := true            {product}\n     bool PrintFlagsInitial                         = false           {product}\n     bool PrintGC                                   = false           {manageable}\n     bool PrintGCApplicationConcurrentTime          = false           {product}\n     bool PrintGCApplicationStoppedTime             = false           {product}\n     bool PrintGCCause                              = true            {product}\n     bool PrintGCDateStamps                         = false           {manageable}\n     bool PrintGCDetails                            = false           {manageable}\n     bool PrintGCTaskTimeStamps                     = false           {product}\n     bool PrintGCTimeStamps                         = false           {manageable}\n     bool PrintHeapAtGC                             = false           {product rw}\n     bool PrintHeapAtGCExtended                     = false           {product rw}\n     bool PrintHeapAtSIGBREAK                       = true            {product}\n     bool PrintJNIGCStalls                          = false           {product}\n     bool PrintJNIResolving                         = false           {product}\n     bool PrintOldPLAB                              = false           {product}\n     bool PrintOopAddress                           = false           {product}\n     bool PrintPLAB                                 = false           {product}\n     bool PrintParallelOldGCPhaseTimes              = false           {product}\n     bool PrintPromotionFailure                     = false           {product}\n     bool PrintReferenceGC                          = false           {product}\n     bool PrintSafepointStatistics                  = false           {product}\n     intx PrintSafepointStatisticsCount             = 300             {product}\n     intx PrintSafepointStatisticsTimeout           = -1              {product}\n     bool PrintSharedSpaces                         = false           {product}\n     bool PrintStringTableStatistics                = false           {product}\n     bool PrintTLAB                                 = false           {product}\n     bool PrintTenuringDistribution                 = false           {product}\n     bool PrintTieredEvents                         = false           {product}\n     bool PrintVMOptions                            = false           {product}\n     bool PrintVMQWaitTime                          = false           {product}\n     bool PrintWarnings                             = true            {product}\n    uintx ProcessDistributionStride                 = 4               {product}\n     bool ProfileInterpreter                        = true            {pd product}\n     bool ProfileIntervals                          = false           {product}\n     intx ProfileIntervalsTicks                     = 100             {product}\n     intx ProfileMaturityPercentage                 = 20              {product}\n     bool ProfileVM                                 = false           {product}\n     bool ProfilerPrintByteCodeStatistics           = false           {product}\n     bool ProfilerRecordPC                          = false           {product}\n    uintx PromotedPadding                           = 3               {product}\n    uintx QueuedAllocationWarningCount              = 0               {product}\n     bool RangeCheckElimination                     = true            {product}\n     intx ReadPrefetchInstr                         = 0               {ARCH product}\n     bool ReassociateInvariants                     = true            {C2 product}\n     bool ReduceBulkZeroing                         = true            {C2 product}\n     bool ReduceFieldZeroing                        = true            {C2 product}\n     bool ReduceInitialCardMarks                    = true            {C2 product}\n     bool ReduceSignalUsage                         = false           {product}\n     intx RefDiscoveryPolicy                        = 0               {product}\n     bool ReflectionWrapResolutionErrors            = true            {product}\n     bool RegisterFinalizersAtInit                  = true            {product}\n     bool RelaxAccessControlCheck                   = false           {product}\n    ccstr ReplayDataFile                            =                 {product}\n     bool RequireSharedSpaces                       = false           {product}\n    uintx ReservedCodeCacheSize                     = 251658240       {pd product}\n     bool ResizeOldPLAB                             = true            {product}\n     bool ResizePLAB                                = true            {product}\n     bool ResizeTLAB                                = true            {pd product}\n     bool RestoreMXCSROnJNICalls                    = false           {product}\n     bool RestrictContended                         = true            {product}\n     bool RewriteBytecodes                          = true            {pd product}\n     bool RewriteFrequentPairs                      = true            {pd product}\n     intx SafepointPollOffset                       = 256             {C1 pd product}\n     intx SafepointSpinBeforeYield                  = 2000            {product}\n     bool SafepointTimeout                          = false           {product}\n     intx SafepointTimeoutDelay                     = 10000           {product}\n     bool ScavengeBeforeFullGC                      = true            {product}\n     intx SelfDestructTimer                         = 0               {product}\n    uintx SharedBaseAddress                         = 34359738368     {product}\n    uintx SharedMiscCodeSize                        = 122880          {product}\n    uintx SharedMiscDataSize                        = 4194304         {product}\n    uintx SharedReadOnlySize                        = 16777216        {product}\n    uintx SharedReadWriteSize                       = 16777216        {product}\n     bool ShowMessageBoxOnError                     = false           {product}\n     intx SoftRefLRUPolicyMSPerMB                   = 1000            {product}\n     bool SpecialEncodeISOArray                     = true            {C2 product}\n     bool SplitIfBlocks                             = true            {C2 product}\n     intx StackRedPages                             = 1               {pd product}\n     intx StackShadowPages                          = 20              {pd product}\n     bool StackTraceInThrowable                     = true            {product}\n     intx StackYellowPages                          = 2               {pd product}\n     bool StartAttachListener                       = false           {product}\n     intx StarvationMonitorInterval                 = 200             {product}\n     bool StressLdcRewrite                          = false           {product}\n    uintx StringTableSize                           = 60013           {product}\n     bool SuppressFatalErrorMessage                 = false           {product}\n    uintx SurvivorPadding                           = 3               {product}\n    uintx SurvivorRatio                             = 8               {product}\n     intx SuspendRetryCount                         = 50              {product}\n     intx SuspendRetryDelay                         = 5               {product}\n     intx SyncFlags                                 = 0               {product}\n    ccstr SyncKnobs                                 =                 {product}\n     intx SyncVerbose                               = 0               {product}\n    uintx TLABAllocationWeight                      = 35              {product}\n    uintx TLABRefillWasteFraction                   = 64              {product}\n    uintx TLABSize                                  = 0               {product}\n     bool TLABStats                                 = true            {product}\n    uintx TLABWasteIncrement                        = 4               {product}\n    uintx TLABWasteTargetPercent                    = 1               {product}\n    uintx TargetPLABWastePct                        = 10              {product}\n    uintx TargetSurvivorRatio                       = 50              {product}\n    uintx TenuredGenerationSizeIncrement            = 20              {product}\n    uintx TenuredGenerationSizeSupplement           = 80              {product}\n    uintx TenuredGenerationSizeSupplementDecay      = 2               {product}\n     intx ThreadPriorityPolicy                      = 0               {product}\n     bool ThreadPriorityVerbose                     = false           {product}\n    uintx ThreadSafetyMargin                        = 52428800        {product}\n     intx ThreadStackSize                           = 1024            {pd product}\n    uintx ThresholdTolerance                        = 10              {product}\n     intx Tier0BackedgeNotifyFreqLog                = 10              {product}\n     intx Tier0InvokeNotifyFreqLog                  = 7               {product}\n     intx Tier0ProfilingStartPercentage             = 200             {product}\n     intx Tier23InlineeNotifyFreqLog                = 20              {product}\n     intx Tier2BackEdgeThreshold                    = 0               {product}\n     intx Tier2BackedgeNotifyFreqLog                = 14              {product}\n     intx Tier2CompileThreshold                     = 0               {product}\n     intx Tier2InvokeNotifyFreqLog                  = 11              {product}\n     intx Tier3BackEdgeThreshold                    = 60000           {product}\n     intx Tier3BackedgeNotifyFreqLog                = 13              {product}\n     intx Tier3CompileThreshold                     = 2000            {product}\n     intx Tier3DelayOff                             = 2               {product}\n     intx Tier3DelayOn                              = 5               {product}\n     intx Tier3InvocationThreshold                  = 200             {product}\n     intx Tier3InvokeNotifyFreqLog                  = 10              {product}\n     intx Tier3LoadFeedback                         = 5               {product}\n     intx Tier3MinInvocationThreshold               = 100             {product}\n     intx Tier4BackEdgeThreshold                    = 40000           {product}\n     intx Tier4CompileThreshold                     = 15000           {product}\n     intx Tier4InvocationThreshold                  = 5000            {product}\n     intx Tier4LoadFeedback                         = 3               {product}\n     intx Tier4MinInvocationThreshold               = 600             {product}\n     bool TieredCompilation                         = true            {pd product}\n     intx TieredCompileTaskTimeout                  = 50              {product}\n     intx TieredRateUpdateMaxTime                   = 25              {product}\n     intx TieredRateUpdateMinTime                   = 1               {product}\n     intx TieredStopAtLevel                         = 4               {product}\n     bool TimeLinearScan                            = false           {C1 product}\n     bool TraceBiasedLocking                        = false           {product}\n     bool TraceClassLoading                         = false           {product rw}\n     bool TraceClassLoadingPreorder                 = false           {product}\n     bool TraceClassResolution                      = false           {product}\n     bool TraceClassUnloading                       = false           {product rw}\n     bool TraceDynamicGCThreads                     = false           {product}\n     bool TraceGen0Time                             = false           {product}\n     bool TraceGen1Time                             = false           {product}\n    ccstr TraceJVMTI                                =                 {product}\n     bool TraceLoaderConstraints                    = false           {product rw}\n     bool TraceMetadataHumongousAllocation          = false           {product}\n     bool TraceMonitorInflation                     = false           {product}\n     bool TraceParallelOldGCTasks                   = false           {product}\n     intx TraceRedefineClasses                      = 0               {product}\n     bool TraceSafepointCleanupTime                 = false           {product}\n     bool TraceSuspendWaitFailures                  = false           {product}\n     intx TrackedInitializationLimit                = 50              {C2 product}\n     bool TransmitErrorReport                       = false           {product}\n     intx TypeProfileArgsLimit                      = 2               {product}\n    uintx TypeProfileLevel                          = 0               {pd product}\n     intx TypeProfileMajorReceiverPercent           = 90              {C2 product}\n     intx TypeProfileParmsLimit                     = 2               {product}\n     intx TypeProfileWidth                          = 2               {product}\n     intx UnguardOnExecutionViolation               = 0               {product}\n     bool UnlinkSymbolsALot                         = false           {product}\n     bool Use486InstrsOnly                          = false           {ARCH product}\n     bool UseAES                                    = true            {product}\n     bool UseAESIntrinsics                          = true            {product}\n     intx UseAVX                                    = 1               {ARCH product}\n     bool UseAdaptiveGCBoundary                     = false           {product}\n     bool UseAdaptiveGenerationSizePolicyAtMajorCollection  = true            {product}\n     bool UseAdaptiveGenerationSizePolicyAtMinorCollection  = true            {product}\n     bool UseAdaptiveNUMAChunkSizing                = true            {product}\n     bool UseAdaptiveSizeDecayMajorGCCost           = true            {product}\n     bool UseAdaptiveSizePolicy                     = true            {product}\n     bool UseAdaptiveSizePolicyFootprintGoal        = true            {product}\n     bool UseAdaptiveSizePolicyWithSystemGC         = false           {product}\n     bool UseAddressNop                             = true            {ARCH product}\n     bool UseAltSigs                                = false           {product}\n     bool UseAutoGCSelectPolicy                     = false           {product}\n     bool UseBiasedLocking                          = true            {product}\n     bool UseBimorphicInlining                      = true            {C2 product}\n     bool UseBoundThreads                           = true            {product}\n     bool UseBsdPosixThreadCPUClocks                = true            {product}\n     bool UseCLMUL                                  = true            {ARCH product}\n     bool UseCMSBestFit                             = true            {product}\n     bool UseCMSCollectionPassing                   = true            {product}\n     bool UseCMSCompactAtFullCollection             = true            {product}\n     bool UseCMSInitiatingOccupancyOnly             = false           {product}\n     bool UseCRC32Intrinsics                        = true            {product}\n     bool UseCodeCacheFlushing                      = true            {product}\n     bool UseCompiler                               = true            {product}\n     bool UseCompilerSafepoints                     = true            {product}\n     bool UseCompressedClassPointers               := true            {lp64_product}\n     bool UseCompressedOops                        := true            {lp64_product}\n     bool UseConcMarkSweepGC                        = false           {product}\n     bool UseCondCardMark                           = false           {C2 product}\n     bool UseCountLeadingZerosInstruction           = false           {ARCH product}\n     bool UseCounterDecay                           = true            {product}\n     bool UseDivMod                                 = true            {C2 product}\n     bool UseDynamicNumberOfGCThreads               = false           {product}\n     bool UseFPUForSpilling                         = false           {C2 product}\n     bool UseFastAccessorMethods                    = false           {product}\n     bool UseFastEmptyMethods                       = false           {product}\n     bool UseFastJNIAccessors                       = true            {product}\n     bool UseFastStosb                              = true            {ARCH product}\n     bool UseG1GC                                   = false           {product}\n     bool UseGCLogFileRotation                      = false           {product}\n     bool UseGCOverheadLimit                        = true            {product}\n     bool UseGCTaskAffinity                         = false           {product}\n     bool UseHeavyMonitors                          = false           {product}\n     bool UseHugeTLBFS                              = false           {product}\n     bool UseInlineCaches                           = true            {product}\n     bool UseInterpreter                            = true            {product}\n     bool UseJumpTables                             = true            {C2 product}\n     bool UseLWPSynchronization                     = true            {product}\n     bool UseLargePages                             = false           {pd product}\n     bool UseLargePagesInMetaspace                  = false           {product}\n     bool UseLargePagesIndividualAllocation         = false           {pd product}\n     bool UseLockedTracing                          = false           {product}\n     bool UseLoopCounter                            = true            {product}\n     bool UseLoopInvariantCodeMotion                = true            {C1 product}\n     bool UseLoopPredicate                          = true            {C2 product}\n     bool UseMaximumCompactionOnSystemGC            = true            {product}\n     bool UseMembar                                 = true            {pd product}\n     bool UseNUMA                                   = false           {product}\n     bool UseNUMAInterleaving                       = false           {product}\n     bool UseNewLongLShift                          = false           {ARCH product}\n     bool UseOSErrorReporting                       = false           {pd product}\n     bool UseOldInlining                            = true            {C2 product}\n     bool UseOnStackReplacement                     = true            {pd product}\n     bool UseOnlyInlinedBimorphic                   = true            {C2 product}\n     bool UseOprofile                               = false           {product}\n     bool UseOptoBiasInlining                       = true            {C2 product}\n     bool UsePPCLWSYNC                              = true            {product}\n     bool UsePSAdaptiveSurvivorSizePolicy           = true            {product}\n     bool UseParNewGC                               = false           {product}\n     bool UseParallelGC                            := true            {product}\n     bool UseParallelOldGC                          = true            {product}\n     bool UsePerfData                               = true            {product}\n     bool UsePopCountInstruction                    = true            {product}\n     bool UseRDPCForConstantTableBase               = false           {C2 product}\n     bool UseSHM                                    = false           {product}\n     intx UseSSE                                    = 4               {product}\n     bool UseSSE42Intrinsics                        = true            {product}\n     bool UseSerialGC                               = false           {product}\n     bool UseSharedSpaces                           = false           {product}\n     bool UseSignalChaining                         = true            {product}\n     bool UseStoreImmI16                            = false           {ARCH product}\n     bool UseSuperWord                              = true            {C2 product}\n     bool UseTLAB                                   = true            {pd product}\n     bool UseThreadPriorities                       = true            {pd product}\n     bool UseTypeProfile                            = true            {product}\n     bool UseUnalignedLoadStores                    = true            {ARCH product}\n     bool UseVMInterruptibleIO                      = false           {product}\n     bool UseXMMForArrayCopy                        = true            {product}\n     bool UseXmmI2D                                 = false           {ARCH product}\n     bool UseXmmI2F                                 = false           {ARCH product}\n     bool UseXmmLoadAndClearUpper                   = true            {ARCH product}\n     bool UseXmmRegToRegMoveAll                     = true            {ARCH product}\n     bool VMThreadHintNoPreempt                     = false           {product}\n     intx VMThreadPriority                          = -1              {product}\n     intx VMThreadStackSize                         = 1024            {pd product}\n     intx ValueMapInitialSize                       = 11              {C1 product}\n     intx ValueMapMaxLoopSize                       = 8               {C1 product}\n     intx ValueSearchLimit                          = 1000            {C2 product}\n     bool VerifyMergedCPBytecodes                   = true            {product}\n     intx WorkAroundNPTLTimedWaitHang               = 1               {product}\n    uintx YoungGenerationSizeIncrement              = 20              {product}\n    uintx YoungGenerationSizeSupplement             = 80              {product}\n    uintx YoungGenerationSizeSupplementDecay        = 8               {product}\n    uintx YoungPLABSize                             = 4096            {product}\n     bool ZeroTLAB                                  = false           {product}\n     intx hashCode                                  = 5               {product}\n```\n即时编译参数\n* `CompileThreshold`:触发即时编译的阈值\n* `OnStackReplacePercentage`:OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`:即时编译器编译的代码缓存使得最大值\n\n类型加载参数\n* `UseSplitVerifier`:使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`:当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`:在校验阶段放松对类型访问性的限制\n\n多线程相关参数\n* `UseSpinning`:开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`:使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`:使用本地线程优先级\n* `UseBiaseLocking`:是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`:当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n性能参数\n* `AggressiveOpts`:使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`:如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`:使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`:是否使用字符串缓存,开启则使用\n\n*给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=$debug_port\n```\n* suspend:这个参数是用来当JVM启动之后等待debug客户端连接,如果没有debug客户端连接,那么虚拟机就会一直等待，造成假死的现象\n* `-XX:+UseVMInterruptibleIO`:线程中断前或是EINTR在OS_INTRPT中对于I/O操作的结果\n* `-XX:+FailOverToOldVerifier`:当新的类型检测器失败时切换到旧的认证器\n* `-XX:-AllowUserSignalHandlers`:允许为java进程安装信号处理器（限于Linux和Solaris,默认关闭）\n* `-XX:AllocatePrefetchStyle=1`:预取指令的产生代码风格：0-没有预取指令,1-每一次分配内存就执行预取指令,2-当执行预取代码指令时,用TLAB分配水印指针指向门\n* `-XX:AllocatePrefetchLines=1`:在使用JIT生成的预读取指令分配对象后读取的缓存行数.如果上次分配的对象是一个实例则默认值是1,如果是一个数组则是3\n* `-XX:+OptimizeStringConcat`:对字符串拼接进行优化\n* `-XX:+UseCompressedStrings`:如果可以表示为纯ASCII的话,则用byte[]代替字符串.\n* `-XX:+UseBiasedLocking`:使用偏锁.\n* `-XX:LoopUnrollLimit=n`:代表节点数目小于给定值时打开循环体.\n* `-XX:+PerfDataSaveToFile`:Jvm退出时保存jvmstat的二进制数据.\n* `-XX:+AlwaysPreTouch`:当JVM初始化时预先对Java堆进行预先摸底(堆中每个页归零处理).\n* `-XX:InlineSmallCode=n`:当编译的代码小于指定的值时,内联编译的代码.\n* `-XX:InitialTenuringThreshold=7`:设置初始的对象在新生代中最大存活次数.\n* `-XX:+UseCompressedOops`:使用compressedpointers.这个参数默认在64bit的环境下默认启动,但是如果JVM的内存达到32G后,这个参数就会默认为不启动,因为32G内存后,压缩就没有多大必要了,要管理那么大的内存指针也需要很大的宽度了\n* `-XX:AllocatePrefetchDistance=n`:为对象分配设置预取距离.\n* `-XX:MaxInlineSize=35`:内联函数最大的字节码大小.\n* `-XX:-TraceClassResolution`:追踪常量池resolutions.\n* `-XX:FreqInlineSize=n`:经常执行方法内联的最大字节大小\n* `-XX:-TraceLoaderConstraints`:跟踪加载器的限制记录.\n","slug":"jvm/JVM日志输出","published":1,"updated":"2016-06-11T14:04:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cipb8ii6m00favjs66gc9twl3"}],"PostAsset":[],"PostCategory":[{"post_id":"cipb8ihlm0002vjs60ee8pwbn","category_id":"cipb8ihlw0004vjs6afygr4xw","_id":"cipb8ihmc000avjs6on0plm1o"},{"post_id":"cipb8ihlt0003vjs65j364bx3","category_id":"cipb8ihlw0004vjs6afygr4xw","_id":"cipb8ihmm000evjs65aa5usg9"},{"post_id":"cipb8ihmk000dvjs6jqy31klq","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihmr000ivjs6fd2x90i9"},{"post_id":"cipb8ihly0005vjs69ae0uc58","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihmu000lvjs6rbkalcjf"},{"post_id":"cipb8ihmn000fvjs6obgprqgq","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihmw000nvjs6jpfdqg06"},{"post_id":"cipb8ihmp000hvjs6i2mjdjhr","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihmz000qvjs6k7rl9mqz"},{"post_id":"cipb8ihm00006vjs6od720vuy","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihn5000svjs62g3c432n"},{"post_id":"cipb8ihmr000jvjs6c845alvd","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihn8000vvjs6q0p1vgps"},{"post_id":"cipb8ihmu000mvjs655ayqtbd","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihna000xvjs6lrzsv9g2"},{"post_id":"cipb8ihm20007vjs6dgnh55cn","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnd000zvjs6bswswrk3"},{"post_id":"cipb8ihmw000ovjs6qdte44bk","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihng0011vjs6qhgx8vwk"},{"post_id":"cipb8ihn0000rvjs61y01tyjs","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnk0013vjs6kha973tu"},{"post_id":"cipb8ihm60009vjs60jkmudkp","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnn0015vjs6fq2a2thb"},{"post_id":"cipb8ihn5000tvjs6mr0girud","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnp0017vjs656xio7yd"},{"post_id":"cipb8ihn8000wvjs6yb1kmo5f","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihns0019vjs668njkdlb"},{"post_id":"cipb8ihme000bvjs68ihtdns8","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnw001bvjs6kxf2u9e1"},{"post_id":"cipb8ihna000yvjs6b9k2d0ri","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihnz001dvjs68piec3it"},{"post_id":"cipb8ihnd0010vjs63io04c8e","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8iho1001fvjs637nbtybg"},{"post_id":"cipb8ihng0012vjs6gjv9b66u","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8iho4001ivjs6zx0hpgv8"},{"post_id":"cipb8ihnk0014vjs60v2j355p","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8iho6001kvjs6u8swj27o"},{"post_id":"cipb8ihnn0016vjs6rm00tnu5","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8iho8001mvjs606k3jk4h"},{"post_id":"cipb8ihnp0018vjs6xw7sgent","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihob001pvjs6ezgj22e2"},{"post_id":"cipb8ihns001avjs6aq64r1jm","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihog001rvjs6n8o5iqfr"},{"post_id":"cipb8ihnx001cvjs60dkni9rx","category_id":"cipb8ihmh000cvjs6uvc26441","_id":"cipb8ihok001uvjs60zt5oodk"},{"post_id":"cipb8iho6001lvjs6f6t7wm5l","category_id":"cipb8iho4001hvjs6a2lgbgaa","_id":"cipb8ihoq001wvjs6fxhsyzm0"},{"post_id":"cipb8ihnz001evjs6ls9uyvn5","category_id":"cipb8iho4001hvjs6a2lgbgaa","_id":"cipb8ihot001zvjs61euc4d34"},{"post_id":"cipb8iho2001gvjs6qcjxaort","category_id":"cipb8iho4001hvjs6a2lgbgaa","_id":"cipb8ihov0021vjs6yv7k1xug"},{"post_id":"cipb8iho4001jvjs6o0se5wys","category_id":"cipb8iho4001hvjs6a2lgbgaa","_id":"cipb8ihox0024vjs6cv8ugkrg"},{"post_id":"cipb8ihot0020vjs6pilxyjdk","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihoz0026vjs6lcilufqh"},{"post_id":"cipb8iho8001nvjs6sxc8ghg1","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihp20029vjs6jknyku8m"},{"post_id":"cipb8ihov0022vjs6sp0sxpu3","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihp4002bvjs6vlxk5n1d"},{"post_id":"cipb8ihox0025vjs660iiowqy","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihp6002evjs6hud0xvtc"},{"post_id":"cipb8ihob001qvjs6rt9i59tt","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpa002gvjs6bkyx6m0c"},{"post_id":"cipb8ihoz0027vjs6ikyyaeku","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpd002jvjs662do6t48"},{"post_id":"cipb8ihp2002avjs665in9mj6","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpf002lvjs6w9oua952"},{"post_id":"cipb8ihoh001svjs66siiiu2x","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihph002nvjs6y99vlmzm"},{"post_id":"cipb8ihp5002cvjs6xgdv93kx","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpl002pvjs6tdehr9vp"},{"post_id":"cipb8ihp7002fvjs6tvjknl9d","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpn002rvjs638l4wi9a"},{"post_id":"cipb8ihok001vvjs6m0ocacqa","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpp002tvjs670015svo"},{"post_id":"cipb8ihpa002hvjs6qg9zj9ci","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpr002vvjs64k5tkmi4"},{"post_id":"cipb8ihpe002kvjs62gyq7ack","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpt002xvjs6fuyodmlr"},{"post_id":"cipb8ihoq001xvjs6t40otikj","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpw002zvjs6gb00bwmm"},{"post_id":"cipb8ihpf002mvjs6rxnj3wzj","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihpy0031vjs61v7eho9k"},{"post_id":"cipb8ihph002ovjs6eyr75yw8","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq00033vjs6uxbscb0r"},{"post_id":"cipb8ihpl002qvjs63zbiuimx","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq20035vjs6r3j8kakz"},{"post_id":"cipb8ihpn002svjs6zfive1rf","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq40037vjs6qw58iwt4"},{"post_id":"cipb8ihpp002uvjs6zpba78sf","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq50039vjs60n58flmr"},{"post_id":"cipb8ihpr002wvjs6r7d1mrcg","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq7003bvjs67aourj1m"},{"post_id":"cipb8ihpt002yvjs66nq60aqq","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihq8003dvjs6qyjpafnv"},{"post_id":"cipb8ihpx0030vjs6cre864q0","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihqe003fvjs6saakd6xg"},{"post_id":"cipb8ihpz0032vjs6w5g7f1wz","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihqh003hvjs6zb9gc6fw"},{"post_id":"cipb8ihq00034vjs6g942nmzx","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihqr003jvjs65gxuoiju"},{"post_id":"cipb8ihq20036vjs62tgeiuiw","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihqu003lvjs607gz4kww"},{"post_id":"cipb8ihq40038vjs69z2br1i9","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihqw003nvjs6pmaa0ny8"},{"post_id":"cipb8ihq6003avjs6lop1j1f6","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihr2003pvjs6wuec7cyr"},{"post_id":"cipb8ihq7003cvjs6basbmbca","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihr4003rvjs6hibk95vp"},{"post_id":"cipb8ihq9003evjs6qvqulrww","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihr6003tvjs68xqofb8l"},{"post_id":"cipb8ihqf003gvjs6gapsiz2i","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihr9003vvjs648bfnzhy"},{"post_id":"cipb8ihqi003ivjs62rz9jrea","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrd003xvjs66a6zbktc"},{"post_id":"cipb8ihqs003kvjs6e5nt1die","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrf003zvjs6d8993rru"},{"post_id":"cipb8ihqu003mvjs643dutwr7","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrh0042vjs6yl3ybqyu"},{"post_id":"cipb8ihqz003ovjs6uqy064p6","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihri0044vjs6cxqimn9l"},{"post_id":"cipb8ihr2003qvjs6xpin2z6w","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrk0046vjs658pv1clr"},{"post_id":"cipb8ihr4003svjs672ekuzvq","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrm0049vjs6tgg2slz2"},{"post_id":"cipb8ihr6003uvjs606ullasd","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihro004bvjs65rl2tedt"},{"post_id":"cipb8ihr9003wvjs6vjoehcmy","category_id":"cipb8ihos001yvjs6pk0zy835","_id":"cipb8ihrq004evjs6xs6hhald"},{"post_id":"cipb8ihrj0045vjs6w4hesldz","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihrs004gvjs6qcnnhopr"},{"post_id":"cipb8ihrd003yvjs6thfhoir0","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihrx004jvjs6jn48xcoc"},{"post_id":"cipb8ihrk0047vjs63zm5tuqt","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihrz004lvjs6s2l6tiwk"},{"post_id":"cipb8ihrm004avjs67l9w0cfk","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihs1004nvjs6bisxkg0h"},{"post_id":"cipb8ihrf0040vjs687rq49w4","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihs3004qvjs6zxegb922"},{"post_id":"cipb8ihro004cvjs6p3mcsz18","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihs8004svjs65mlcj38k"},{"post_id":"cipb8ihrh0043vjs6r35g69h9","category_id":"cipb8ihrg0041vjs6vcmm2g50","_id":"cipb8ihsd004vvjs6bknadw4a"},{"post_id":"cipb8ihs0004mvjs6fwmeuodl","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsf004xvjs6xgy04m0h"},{"post_id":"cipb8ihrq004fvjs6h10g45zp","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsi004zvjs6e8hdwf5k"},{"post_id":"cipb8ihs1004ovjs6cskryrrg","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsk0051vjs6doied03s"},{"post_id":"cipb8ihs4004rvjs65ccoxem1","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsm0053vjs6brcawqda"},{"post_id":"cipb8ihrs004hvjs6huebg8i9","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihso0055vjs6pkp986pg"},{"post_id":"cipb8ihs9004tvjs6qa82b7rs","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsr0058vjs69py6309y"},{"post_id":"cipb8ihsd004wvjs69ksnegap","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihst005avjs6e7zsvhwu"},{"post_id":"cipb8ihrx004kvjs6xx93ay5x","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsv005cvjs6ksaioa8v"},{"post_id":"cipb8ihsg004yvjs6pfu1naph","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsx005fvjs6kxkixom4"},{"post_id":"cipb8ihsi0050vjs6al28woo4","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8ihsz005hvjs6vcew5pfr"},{"post_id":"cipb8ihsk0052vjs658eggeem","category_id":"cipb8ihrx004ivjs6c1wy2u1d","_id":"cipb8iht2005kvjs6qvr5x9v0"},{"post_id":"cipb8ihst005bvjs6l9z4xez6","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8iht5005mvjs6f5ut6r50"},{"post_id":"cipb8ihsm0054vjs6d8wc39kq","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8iht8005ovjs6exj6wor2"},{"post_id":"cipb8ihsv005dvjs6elzlcf0m","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtb005qvjs6crzgichl"},{"post_id":"cipb8ihsx005gvjs6d12fom9n","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtf005svjs695n3re3h"},{"post_id":"cipb8ihsp0056vjs68bjnep5l","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtk005uvjs6t22vg9bf"},{"post_id":"cipb8iht0005ivjs6nxrvmoj8","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtn005wvjs62v77wqd4"},{"post_id":"cipb8iht3005lvjs6elf1btxp","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtp005yvjs6996yrafw"},{"post_id":"cipb8ihsr0059vjs6mw3tg6tb","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtt0060vjs6dvjf61de"},{"post_id":"cipb8iht5005nvjs698olpeyn","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihtx0062vjs6kclrblgd"},{"post_id":"cipb8iht8005pvjs6j1k78mli","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihu10064vjs6pk1o8cbg"},{"post_id":"cipb8ihtb005rvjs6jbph5y4v","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihu40066vjs6qmb7kyn2"},{"post_id":"cipb8ihtg005tvjs6cd64tdem","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihu80068vjs6yt4hgwm7"},{"post_id":"cipb8ihtl005vvjs6uq2b0tkc","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihub006avjs6fkuqzoyw"},{"post_id":"cipb8ihtn005xvjs6armah9vr","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihug006cvjs6tz7vh9nf"},{"post_id":"cipb8ihtq005zvjs61gpb9yww","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihuk006evjs6ia52b6w2"},{"post_id":"cipb8ihtu0061vjs6xta51ri5","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihun006gvjs6p1u6itao"},{"post_id":"cipb8ihtx0063vjs6um0itsua","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihur006ivjs62otk6zmf"},{"post_id":"cipb8ihu10065vjs6f0dw7dy6","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihuv006kvjs6e0cjx6mz"},{"post_id":"cipb8ihu50067vjs64h73ustr","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihux006mvjs6y9b8dxca"},{"post_id":"cipb8ihu90069vjs6cotlymnx","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihv1006pvjs6vupl3yl9"},{"post_id":"cipb8ihuc006bvjs6jbvwt4gi","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihv5006rvjs6z8re21w7"},{"post_id":"cipb8ihuh006dvjs625qm6unn","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihv9006tvjs6yw18nrpd"},{"post_id":"cipb8ihul006fvjs6mbfs548c","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihvd006wvjs6tv8k7z9e"},{"post_id":"cipb8ihuo006hvjs6mr9c9dba","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihvh006yvjs6qjglhop2"},{"post_id":"cipb8ihur006jvjs6rx339y9c","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ihvl0071vjs6h9b261y2"},{"post_id":"cipb8ihv5006svjs6yipll2yi","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihvo0073vjs6q5b43gf0"},{"post_id":"cipb8ihuv006lvjs6uv82xdb5","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihvs0076vjs6ji02ybvv"},{"post_id":"cipb8ihv9006uvjs6999qx92s","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihvv0078vjs69x7vf27r"},{"post_id":"cipb8ihve006xvjs6fcw0f34f","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihvy007avjs6078fxqaw"},{"post_id":"cipb8ihuy006nvjs6q8k2um22","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihw2007dvjs669u3azju"},{"post_id":"cipb8ihvh006zvjs67uxj9ppy","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihw7007fvjs6m2fe5wzb"},{"post_id":"cipb8ihv1006qvjs6kefkzo7y","category_id":"cipb8ihv0006ovjs6hyjatplw","_id":"cipb8ihwb007ivjs6bhzm1q26"},{"post_id":"cipb8ihvv0079vjs6vajilgpq","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwe007kvjs620kqbm2w"},{"post_id":"cipb8ihvl0072vjs61uk2aequ","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwj007mvjs6xurp1and"},{"post_id":"cipb8ihvz007bvjs6wg7l80l4","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwm007ovjs6usyfowe9"},{"post_id":"cipb8ihw2007evjs62zy6wlsc","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwp007qvjs6xzkcq8jk"},{"post_id":"cipb8ihvo0074vjs6a79b2bmw","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwt007svjs6dz1no3dn"},{"post_id":"cipb8ihw7007gvjs6tp6wxpco","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihwx007uvjs6728oleb3"},{"post_id":"cipb8ihwb007jvjs61dns51ie","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihx0007wvjs6qc3rxgac"},{"post_id":"cipb8ihvs0077vjs6iyd82zh5","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihx3007yvjs67zfos6a4"},{"post_id":"cipb8ihwf007lvjs6mpdafqw1","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihx90080vjs6b7fb1m0m"},{"post_id":"cipb8ihwj007nvjs6q8lgb5ze","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihxe0083vjs6x3dyty4f"},{"post_id":"cipb8ihwm007pvjs6rkyk7tn1","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihxh0085vjs6pcw4jtlw"},{"post_id":"cipb8ihwp007rvjs6q62ntath","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihxl0087vjs609nza259"},{"post_id":"cipb8ihwu007tvjs6ln6d4ia1","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihxp008avjs612b3b0kk"},{"post_id":"cipb8ihwx007vvjs6sulxzste","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihy3008cvjs6aqafa5ni"},{"post_id":"cipb8ihx0007xvjs60ok3a28r","category_id":"cipb8ihvr0075vjs683q0y5fy","_id":"cipb8ihy9008fvjs6sytw8d0j"},{"post_id":"cipb8ihxi0086vjs6jzg4rjsu","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyd008hvjs6oxhgvg7o"},{"post_id":"cipb8ihx4007zvjs6xqna4xe4","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyh008jvjs6z8d1f8ho"},{"post_id":"cipb8ihxl0088vjs6toihhku2","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyk008mvjs6wc1tkr42"},{"post_id":"cipb8ihxp008bvjs69gsl21kv","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyo008ovjs6l334rwjg"},{"post_id":"cipb8ihxa0081vjs6vkst79bp","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyr008qvjs6booundar"},{"post_id":"cipb8ihy4008dvjs6jaucu09w","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihyw008tvjs6kdlhdko0"},{"post_id":"cipb8ihy9008gvjs67a2q1du5","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihz2008vvjs6dsp322h5"},{"post_id":"cipb8ihxe0084vjs66axnqhfd","category_id":"cipb8ihxd0082vjs6mfcsbh7f","_id":"cipb8ihz7008yvjs63zz4y1lw"},{"post_id":"cipb8ihyp008pvjs6ktsetlxq","category_id":"cipb8ihyk008lvjs6ououlp2o","_id":"cipb8ihzc0090vjs6lo6s7q4l"},{"post_id":"cipb8ihyd008ivjs6p0uvs9to","category_id":"cipb8ihyk008lvjs6ououlp2o","_id":"cipb8ihzh0093vjs61cy77dio"},{"post_id":"cipb8ihys008rvjs6tc19nizp","category_id":"cipb8ihyk008lvjs6ououlp2o","_id":"cipb8ihzk0095vjs6q4l7wosn"},{"post_id":"cipb8ihyh008kvjs6qbpj6yr7","category_id":"cipb8ihyk008lvjs6ououlp2o","_id":"cipb8ihzo0098vjs6u7j2pe2i"},{"post_id":"cipb8ihyk008nvjs6xq18fovk","category_id":"cipb8ihyk008lvjs6ououlp2o","_id":"cipb8ihzt009avjs6i7a8bgza"},{"post_id":"cipb8ihzh0094vjs6hzgkr025","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ihzx009dvjs68xt1hdb6"},{"post_id":"cipb8ihyx008uvjs6w87lf6jz","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii02009fvjs6fwtzfetn"},{"post_id":"cipb8ihzl0096vjs6ga09n1yy","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii08009ivjs6pa1j4z70"},{"post_id":"cipb8ihzp0099vjs612ztraz5","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii0c009kvjs6fa4rtjdd"},{"post_id":"cipb8ihz4008wvjs65o3ur937","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii0h009nvjs6qm2m7pai"},{"post_id":"cipb8ihzt009bvjs6ti22lp1w","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii0k009pvjs6u2ib291h"},{"post_id":"cipb8ihz8008zvjs6f1si7878","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii0o009svjs62e709g2v"},{"post_id":"cipb8ihzc0091vjs6joa9exr8","category_id":"cipb8ihzf0092vjs67jdteyed","_id":"cipb8ii0r009uvjs6l9pb2f4h"},{"post_id":"cipb8ii0h009ovjs6vgxlvm3v","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii0v009xvjs67o4pdvbo"},{"post_id":"cipb8ihzx009evjs6h9dk2476","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii0y009zvjs6zbbp27r7"},{"post_id":"cipb8ii0k009qvjs6upjmnxpz","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1200a2vjs6c9gvj12o"},{"post_id":"cipb8ii0o009tvjs6ya8f0zkk","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1600a4vjs688xik9hr"},{"post_id":"cipb8ii02009gvjs6szlq7mde","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1900a6vjs6yjvj73iu"},{"post_id":"cipb8ii0r009vvjs6dtfa9wj7","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1f00a9vjs6wwrhhapp"},{"post_id":"cipb8ii0v009yvjs62zdu4cqo","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1i00abvjs662946h44"},{"post_id":"cipb8ii09009jvjs6m9uwsdep","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1l00advjs69frshijo"},{"post_id":"cipb8ii0z00a0vjs6rq2j9928","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1p00agvjs60mxlaqwj"},{"post_id":"cipb8ii1300a3vjs63zp12xmj","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1u00aivjs6xxhomnjf"},{"post_id":"cipb8ii0d009lvjs618s2hhtx","category_id":"cipb8ii0g009mvjs69ql74hoy","_id":"cipb8ii1z00alvjs69m3sx6sb"},{"post_id":"cipb8ii1j00acvjs6tm0a1spa","category_id":"cipb8ii1d00a8vjs62unkiizf","_id":"cipb8ii2300anvjs6hcxt95py"},{"post_id":"cipb8ii1600a5vjs6bgbxmu0c","category_id":"cipb8ii1d00a8vjs62unkiizf","_id":"cipb8ii2800aqvjs6i1j03lic"},{"post_id":"cipb8ii1900a7vjs6y7zoi2ss","category_id":"cipb8ii1d00a8vjs62unkiizf","_id":"cipb8ii2b00asvjs6a2d7cfge"},{"post_id":"cipb8ii1f00aavjs650dkab3i","category_id":"cipb8ii1d00a8vjs62unkiizf","_id":"cipb8ii2g00avvjs6npdd3j2v"},{"post_id":"cipb8ii2800arvjs65nocmulr","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii2z00axvjs6hy2f9pdy"},{"post_id":"cipb8ii1m00aevjs6ddn7w27i","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii3100b0vjs6nqc1pyl2"},{"post_id":"cipb8ii1p00ahvjs6wxk2uo7h","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii3600b3vjs64qxkzwbq"},{"post_id":"cipb8ii1v00ajvjs6yi6q7t4o","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii3a00b7vjs6lyeg1cae"},{"post_id":"cipb8ii2000amvjs6rwlkibck","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii3i00bbvjs66jex7n9m"},{"post_id":"cipb8ii2400aovjs6yq1x3194","category_id":"cipb8ii2600apvjs6hpi5gul1","_id":"cipb8ii3r00bfvjs65t41fijm"},{"post_id":"cipb8ii2c00atvjs6qve6vovk","category_id":"cipb8ii3k00bcvjs6zztf9r6q","_id":"cipb8ii3v00bjvjs617xbhc2w"},{"post_id":"cipb8ii2g00awvjs6wlrcc6ew","category_id":"cipb8ii3r00bgvjs65922occt","_id":"cipb8ii3z00bnvjs68k7onehn"},{"post_id":"cipb8ii2z00ayvjs64bj4quqs","category_id":"cipb8ii3k00bcvjs6zztf9r6q","_id":"cipb8ii4200brvjs6683ivhqy"},{"post_id":"cipb8ii3200b1vjs6ed78a4jy","category_id":"cipb8ii3r00bgvjs65922occt","_id":"cipb8ii4600bvvjs69wipvga8"},{"post_id":"cipb8ii3400b2vjs6y7fcftvn","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4900bzvjs65ub8enw2"},{"post_id":"cipb8ii3700b5vjs6axo7pky5","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4c00c3vjs65mfj4dyj"},{"post_id":"cipb8ii3900b6vjs6wtb40pmv","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4g00c7vjs65cwxydl4"},{"post_id":"cipb8ii3b00b9vjs6zx8g7ykl","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4l00cbvjs6ccmv49my"},{"post_id":"cipb8ii3e00bavjs6pq8gc1f6","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4p00cfvjs6n0xjiqa7"},{"post_id":"cipb8ii3m00bdvjs6ms2cccm9","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4s00cjvjs6tfoguc25"},{"post_id":"cipb8ii3q00bevjs6z14wj1ub","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii4w00cnvjs6h5c8avx1"},{"post_id":"cipb8ii3s00bhvjs64b4ia6k9","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii5000crvjs6028njnpt"},{"post_id":"cipb8ii3u00bivjs6b8qurlku","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii5300cvvjs6vm8vnp6n"},{"post_id":"cipb8ii3w00blvjs6tetd0p7d","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii5700czvjs6z04kyf2u"},{"post_id":"cipb8ii3y00bmvjs6g6ewna4t","category_id":"cipb8ii4200bsvjs6aqv0lgkz","_id":"cipb8ii5a00d3vjs6ph3vxj7e"},{"post_id":"cipb8ii4000bpvjs6h1dd3dpr","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5d00d8vjs68cwgdf29"},{"post_id":"cipb8ii4100bqvjs60i33vd2b","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5g00dcvjs6r9rxn5ad"},{"post_id":"cipb8ii4300btvjs6w7hog0x1","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5l00dgvjs6diz62wb5"},{"post_id":"cipb8ii4500buvjs6dlimumtm","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5s00dkvjs6frb8n1zm"},{"post_id":"cipb8ii4600bwvjs6ozgfzllm","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5u00dmvjs6310f1d3z"},{"post_id":"cipb8ii4800byvjs6m8z5exjd","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5u00dovjs6nu7k54ym"},{"post_id":"cipb8ii4900c0vjs6yw1llz9x","category_id":"cipb8ii5800d1vjs6i33si4f0","_id":"cipb8ii5v00dqvjs6dh5vmikp"},{"post_id":"cipb8ii4b00c2vjs6qig0ag3w","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii5w00dsvjs62n4g9p1v"},{"post_id":"cipb8ii4c00c4vjs60cinj282","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii5x00duvjs6k143igwl"},{"post_id":"cipb8ii4e00c6vjs64tcb3nal","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii5z00dwvjs6g0sd8xln"},{"post_id":"cipb8ii4h00c8vjs6e9098hmh","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii6000dyvjs6r2ns4bj7"},{"post_id":"cipb8ii4j00cavjs6q95q5k3s","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii6000e0vjs6d4ivelk3"},{"post_id":"cipb8ii4l00ccvjs6a0ihzphc","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii6100e2vjs6f185zxrc"},{"post_id":"cipb8ii4n00cevjs68bbe7uw7","category_id":"cipb8ii5v00dpvjs60v9ouyyx","_id":"cipb8ii6200e4vjs6dh5d9w94"},{"post_id":"cipb8ii4p00cgvjs68guwhrol","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6200e6vjs6dfan7rdi"},{"post_id":"cipb8ii4r00civjs6vec18l4r","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6300e8vjs6ph2igeqn"},{"post_id":"cipb8ii4s00ckvjs6ptzdhflz","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6400eavjs6rs45573y"},{"post_id":"cipb8ii4u00cmvjs6rohaxc54","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6500ecvjs651x7yf5i"},{"post_id":"cipb8ii4w00covjs6v3n6j70k","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6500eevjs6degfg2bh"},{"post_id":"cipb8ii4z00cqvjs6wsw0514f","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6600egvjs6s1oo20cb"},{"post_id":"cipb8ii5000csvjs69pip327d","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6700eivjs698k0q1qw"},{"post_id":"cipb8ii5200cuvjs6jwx9eume","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6900ekvjs6rsqm382r"},{"post_id":"cipb8ii5300cwvjs6jivwf3zf","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6900emvjs6juut2ty4"},{"post_id":"cipb8ii5500cyvjs6ktle2rcp","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6a00eovjs6nuumh31g"},{"post_id":"cipb8ii5700d0vjs6jc8ztg2e","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6b00eqvjs6ijjr0v4r"},{"post_id":"cipb8ii5800d2vjs6tfvdpdc3","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6b00esvjs6huclzsvm"},{"post_id":"cipb8ii5a00d4vjs6zz7att0d","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6c00euvjs6u7c24ihu"},{"post_id":"cipb8ii5b00d6vjs664qb1ntc","category_id":"cipb8ii6100e3vjs6bwcalphe","_id":"cipb8ii6d00ewvjs6g0wlzqwr"},{"post_id":"cipb8ii5d00d7vjs67l8d8r7r","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6d00eyvjs6knf719co"},{"post_id":"cipb8ii5e00davjs66meurn51","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6e00f0vjs6ifgmjema"},{"post_id":"cipb8ii5f00dbvjs60wnxjvri","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6f00f2vjs6ql3gm7nq"},{"post_id":"cipb8ii5i00devjs6li4bnzsi","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6g00f4vjs6avsl56i1"},{"post_id":"cipb8ii5k00dfvjs66xdw5kee","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6g00f6vjs6qclcpqcy"},{"post_id":"cipb8ii5m00divjs6mzy9o1lm","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6h00f8vjs6e0tpmxug"},{"post_id":"cipb8ii5q00djvjs6krrf2nkb","category_id":"cipb8ii6c00evvjs6bv2yijai","_id":"cipb8ii6h00f9vjs62koiqv4y"},{"post_id":"cipb8ii6m00favjs66gc9twl3","category_id":"cipb8ihsq0057vjs6tzov25e9","_id":"cipb8ii6o00fbvjs67xshijlf"}],"PostTag":[],"Tag":[]}}